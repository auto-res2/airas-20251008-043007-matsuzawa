/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[source_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:45,  7.52s/it]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:45,  7.52s/it, loss=2.37, acc=0.0938]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:45,  7.52s/it, loss=2.47, acc=0.099] 
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:45,  7.52s/it, loss=2.47, acc=0.101]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:07<00:13,  1.62it/s, loss=2.47, acc=0.101]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:07<00:13,  1.62it/s, loss=2.49, acc=0.0938]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:07<00:13,  1.62it/s, loss=2.49, acc=0.0938]
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:07<00:04,  3.39it/s, loss=2.49, acc=0.0938]
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:07<00:04,  3.39it/s, loss=2.47, acc=0.092] 
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:07<00:04,  3.39it/s, loss=2.46, acc=0.0893]
[source_fake] Train Epoch 1/1:  71%|███████   | 22/31 [00:07<00:01,  5.39it/s, loss=2.46, acc=0.0893]
[source_fake] Train Epoch 1/1:  71%|███████   | 22/31 [00:07<00:01,  5.39it/s, loss=2.44, acc=0.099] 
[source_fake] Train Epoch 1/1:  71%|███████   | 22/31 [00:07<00:01,  5.39it/s, loss=2.45, acc=0.0949]
[source_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:07<00:00,  7.97it/s, loss=2.45, acc=0.0949]
[source_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:07<00:00,  7.97it/s, loss=2.45, acc=0.0969]
                                                                                                     
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 183, in <module>
    run(cfg, args.results_dir)
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 58, in run
    model = get_model(cfg, num_classes=num_classes).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/model.py", line 206, in get_model
    return TentAdaptor(base_model, lr=tent_cfg.get("lr", 1e-3),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/model.py", line 92, in __init__
    self.optimizer = torch.optim.SGD(self.params, lr=lr)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/optim/sgd.py", line 45, in __init__
    if lr < 0.0:
       ^^^^^^^^
TypeError: '<' not supported between instances of 'str' and 'float'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 116, in <module>
    run_all(str(cfg_path), args.results_dir)
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 85, in run_all
    raise RuntimeError(f"Run {run_id} failed with return code {rc}")
RuntimeError: Run tent_tau0.25_fake failed with return code 1
/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[source_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:40,  7.35s/it]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:40,  7.35s/it, loss=2.38, acc=0.115]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:40,  7.35s/it, loss=2.5, acc=0.099] 
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:07<03:40,  7.35s/it, loss=2.51, acc=0.115]
[source_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:07<00:11,  1.85it/s, loss=2.51, acc=0.115]
[source_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:07<00:11,  1.85it/s, loss=2.55, acc=0.128]
[source_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:07<00:11,  1.85it/s, loss=2.56, acc=0.133]
[source_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:07<00:11,  1.85it/s, loss=2.59, acc=0.141]
[source_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:07<00:03,  3.91it/s, loss=2.59, acc=0.141]
[source_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:07<00:03,  3.91it/s, loss=2.6, acc=0.131] 
[source_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:07<00:03,  3.91it/s, loss=2.61, acc=0.128]
[source_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:07<00:00,  6.31it/s, loss=2.61, acc=0.128]
[source_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:07<00:00,  6.31it/s, loss=2.62, acc=0.124]
[source_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:07<00:00,  6.31it/s, loss=2.61, acc=0.118]
                                                                                                    
/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[tent_tau0.25_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

                                                                           
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 183, in <module>
    run(cfg, args.results_dir)
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 91, in run
    scaler.scale(loss).backward()
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 116, in <module>
    run_all(str(cfg_path), args.results_dir)
  File "/home/toma/pt80-1-a-25/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 85, in run_all
    raise RuntimeError(f"Run {run_id} failed with return code {rc}")
RuntimeError: Run tent_tau0.25_fake failed with return code 1
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[source_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:15<07:30, 15.01s/it]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:15<07:30, 15.01s/it, loss=2.43, acc=0.0729]
[source_fake] Train Epoch 1/1:  16%|█▌        | 5/31 [00:15<00:58,  2.26s/it, loss=2.43, acc=0.0729]
[source_fake] Train Epoch 1/1:  16%|█▌        | 5/31 [00:15<00:58,  2.26s/it, loss=2.41, acc=0.104] 
[source_fake] Train Epoch 1/1:  16%|█▌        | 5/31 [00:15<00:58,  2.26s/it, loss=2.47, acc=0.111]
[source_fake] Train Epoch 1/1:  35%|███▌      | 11/31 [00:15<00:16,  1.23it/s, loss=2.47, acc=0.111]
[source_fake] Train Epoch 1/1:  35%|███▌      | 11/31 [00:15<00:16,  1.23it/s, loss=2.46, acc=0.109]
[source_fake] Train Epoch 1/1:  35%|███▌      | 11/31 [00:15<00:16,  1.23it/s, loss=2.49, acc=0.113]
[source_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:15<00:06,  2.32it/s, loss=2.49, acc=0.113]
[source_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:15<00:06,  2.32it/s, loss=2.52, acc=0.116]
[source_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:15<00:06,  2.32it/s, loss=2.51, acc=0.115]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:15<00:02,  3.81it/s, loss=2.51, acc=0.115]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:15<00:02,  3.81it/s, loss=2.53, acc=0.107]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:15<00:02,  3.81it/s, loss=2.54, acc=0.11] 
[source_fake] Train Epoch 1/1:  94%|█████████▎| 29/31 [00:15<00:00,  5.79it/s, loss=2.54, acc=0.11]
[source_fake] Train Epoch 1/1:  94%|█████████▎| 29/31 [00:15<00:00,  5.79it/s, loss=2.56, acc=0.106]
                                                                                                    
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:69: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[tent_tau0.25_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:88: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

                                                                           
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 183, in <module>
    run(cfg, args.results_dir)
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 91, in run
    scaler.scale(loss).backward()
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 116, in <module>
    run_all(str(cfg_path), args.results_dir)
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 85, in run_all
    raise RuntimeError(f"Run {run_id} failed with return code {rc}")
RuntimeError: Run tent_tau0.25_fake failed with return code 1
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[source_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:20,  8.67s/it]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:20,  8.67s/it, loss=2.42, acc=0.0417]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:20,  8.67s/it, loss=2.46, acc=0.0521]
[source_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.46, acc=0.0521]
[source_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.46, acc=0.0729]
[source_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.47, acc=0.0729]
[source_fake] Train Epoch 1/1:  45%|████▌     | 14/31 [00:08<00:06,  2.58it/s, loss=2.47, acc=0.0729]
[source_fake] Train Epoch 1/1:  45%|████▌     | 14/31 [00:08<00:06,  2.58it/s, loss=2.48, acc=0.0771]
[source_fake] Train Epoch 1/1:  45%|████▌     | 14/31 [00:08<00:06,  2.58it/s, loss=2.54, acc=0.0764]
[source_fake] Train Epoch 1/1:  65%|██████▍   | 20/31 [00:08<00:02,  4.36it/s, loss=2.54, acc=0.0764]
[source_fake] Train Epoch 1/1:  65%|██████▍   | 20/31 [00:08<00:02,  4.36it/s, loss=2.55, acc=0.0789]
[source_fake] Train Epoch 1/1:  65%|██████▍   | 20/31 [00:09<00:02,  4.36it/s, loss=2.57, acc=0.0846]
[source_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:09<00:00,  6.72it/s, loss=2.57, acc=0.0846]
[source_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:09<00:00,  6.72it/s, loss=2.6, acc=0.0856] 
[source_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:09<00:00,  6.72it/s, loss=2.6, acc=0.0854]
                                                                                                    
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[tent_tau0.25_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s]
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s, loss=2.38, acc=0.0833]
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s, loss=2.39, acc=0.0938]
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:01<00:28,  1.07it/s, loss=2.39, acc=0.0972]
[tent_tau0.25_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:01<00:01, 11.47it/s, loss=2.39, acc=0.0972]
[tent_tau0.25_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:01<00:01, 11.47it/s, loss=2.39, acc=0.0885]
[tent_tau0.25_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:01<00:01, 11.47it/s, loss=2.38, acc=0.1]   
[tent_tau0.25_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:01<00:00, 22.10it/s, loss=2.38, acc=0.1]
[tent_tau0.25_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:01<00:00, 22.10it/s, loss=2.38, acc=0.0955]
[tent_tau0.25_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:01<00:00, 22.10it/s, loss=2.37, acc=0.0967]
[tent_tau0.25_fake] Train Epoch 1/1:  55%|█████▍    | 17/31 [00:01<00:00, 22.10it/s, loss=2.37, acc=0.104] 
[tent_tau0.25_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:01<00:00, 32.55it/s, loss=2.37, acc=0.104]
[tent_tau0.25_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:01<00:00, 32.55it/s, loss=2.37, acc=0.109]
[tent_tau0.25_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:01<00:00, 32.55it/s, loss=2.36, acc=0.116]
                                                                                                          
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 194, in <module>
    run(cfg, args.results_dir)
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py", line 124, in run
    logits = model(x)
             ^^^^^^^^
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/model.py", line 101, in forward
    loss.backward()
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/_tensor.py", line 647, in backward
    torch.autograd.backward(
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py", line 354, in backward
    _engine_run_backward(
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/.venv/lib/python3.11/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 116, in <module>
    run_all(str(cfg_path), args.results_dir)
  File "/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/main.py", line 85, in run_all
    raise RuntimeError(f"Run {run_id} failed with return code {rc}")
RuntimeError: Run tent_tau0.25_fake failed with return code 1
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[source_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:99: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it, loss=2.39, acc=0.0833]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it, loss=2.42, acc=0.0833]
[source_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:18,  8.63s/it, loss=2.43, acc=0.0938]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:08<00:15,  1.41it/s, loss=2.43, acc=0.0938]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:08<00:15,  1.41it/s, loss=2.45, acc=0.0938]
[source_fake] Train Epoch 1/1:  29%|██▉       | 9/31 [00:08<00:15,  1.41it/s, loss=2.46, acc=0.0875]
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:08<00:05,  2.96it/s, loss=2.46, acc=0.0875]
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:08<00:05,  2.96it/s, loss=2.49, acc=0.0833]
[source_fake] Train Epoch 1/1:  52%|█████▏    | 16/31 [00:08<00:05,  2.96it/s, loss=2.49, acc=0.0967]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:08<00:01,  5.05it/s, loss=2.49, acc=0.0967]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:08<00:01,  5.05it/s, loss=2.48, acc=0.0898]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.05it/s, loss=2.48, acc=0.0845]
[source_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.05it/s, loss=2.49, acc=0.0854]
[source_fake] Train Epoch 1/1:  97%|█████████▋| 30/31 [00:09<00:00,  7.79it/s, loss=2.49, acc=0.0854]
                                                                                                     
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[tent_tau0.25_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s]
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s, loss=2.57, acc=0.0625]
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:00<00:28,  1.07it/s, loss=2.5, acc=0.0938] 
[tent_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:01<00:28,  1.07it/s, loss=2.51, acc=0.0938]
[tent_tau0.25_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:01<00:01, 12.67it/s, loss=2.51, acc=0.0938]
[tent_tau0.25_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:01<00:01, 12.67it/s, loss=2.52, acc=0.104] 
[tent_tau0.25_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:01<00:01, 12.67it/s, loss=2.53, acc=0.102]
[tent_tau0.25_fake] Train Epoch 1/1:  32%|███▏      | 10/31 [00:01<00:01, 12.67it/s, loss=2.54, acc=0.0972]
[tent_tau0.25_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:01<00:00, 23.08it/s, loss=2.54, acc=0.0972]
[tent_tau0.25_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:01<00:00, 23.08it/s, loss=2.55, acc=0.0908]
[tent_tau0.25_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:01<00:00, 23.08it/s, loss=2.54, acc=0.099] 
[tent_tau0.25_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:01<00:00, 33.34it/s, loss=2.54, acc=0.099]
[tent_tau0.25_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:01<00:00, 33.34it/s, loss=2.55, acc=0.0949]
[tent_tau0.25_fake] Train Epoch 1/1:  84%|████████▍ | 26/31 [00:01<00:00, 33.34it/s, loss=2.54, acc=0.0979]
                                                                                                           
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[adanpc_tau1.0_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[adanpc_tau1.0_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:09<04:30,  9.02s/it]
[adanpc_tau1.0_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:09<04:30,  9.02s/it, loss=2.47, acc=0.0938]
[adanpc_tau1.0_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:09<04:30,  9.02s/it, loss=2.48, acc=0.109] 
[adanpc_tau1.0_fake] Train Epoch 1/1:  23%|██▎       | 7/31 [00:09<00:22,  1.04it/s, loss=2.48, acc=0.109]
[adanpc_tau1.0_fake] Train Epoch 1/1:  23%|██▎       | 7/31 [00:09<00:22,  1.04it/s, loss=2.46, acc=0.111]
[adanpc_tau1.0_fake] Train Epoch 1/1:  23%|██▎       | 7/31 [00:09<00:22,  1.04it/s, loss=2.46, acc=0.109]
[adanpc_tau1.0_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:09<00:07,  2.33it/s, loss=2.46, acc=0.109]
[adanpc_tau1.0_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:09<00:07,  2.33it/s, loss=2.46, acc=0.104]
[adanpc_tau1.0_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:09<00:07,  2.33it/s, loss=2.45, acc=0.108]
[adanpc_tau1.0_fake] Train Epoch 1/1:  61%|██████▏   | 19/31 [00:09<00:02,  4.07it/s, loss=2.45, acc=0.108]
[adanpc_tau1.0_fake] Train Epoch 1/1:  61%|██████▏   | 19/31 [00:09<00:02,  4.07it/s, loss=2.46, acc=0.106]
[adanpc_tau1.0_fake] Train Epoch 1/1:  61%|██████▏   | 19/31 [00:09<00:02,  4.07it/s, loss=2.45, acc=0.111]
[adanpc_tau1.0_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:09<00:00,  6.37it/s, loss=2.45, acc=0.111]
[adanpc_tau1.0_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:09<00:00,  6.37it/s, loss=2.46, acc=0.112]
[adanpc_tau1.0_fake] Train Epoch 1/1:  81%|████████  | 25/31 [00:09<00:00,  6.37it/s, loss=2.46, acc=0.111]
                                                                                                           
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[adanpc_tau0.5_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[adanpc_tau0.5_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.66s/it]
[adanpc_tau0.5_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.66s/it, loss=2.4, acc=0.0521]
[adanpc_tau0.5_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.66s/it, loss=2.39, acc=0.099]
[adanpc_tau0.5_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.39, acc=0.099]
[adanpc_tau0.5_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.42, acc=0.0938]
[adanpc_tau0.5_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.42, acc=0.0833]
[adanpc_tau0.5_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.42, acc=0.0833]
[adanpc_tau0.5_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.43, acc=0.0979]
[adanpc_tau0.5_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.41, acc=0.101] 
[adanpc_tau0.5_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:08<00:03,  3.84it/s, loss=2.41, acc=0.101]
[adanpc_tau0.5_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:09<00:03,  3.84it/s, loss=2.41, acc=0.0967]
[adanpc_tau0.5_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.80it/s, loss=2.41, acc=0.0967]
[adanpc_tau0.5_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.80it/s, loss=2.41, acc=0.103] 
[adanpc_tau0.5_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.80it/s, loss=2.41, acc=0.101]
[adanpc_tau0.5_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:09<00:00,  8.32it/s, loss=2.41, acc=0.101]
[adanpc_tau0.5_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:09<00:00,  8.32it/s, loss=2.41, acc=0.104]
                                                                                                           
/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler(enabled=cfg.get("mixed_precision", True) and device.type == "cuda")

[adanpc_tau0.25_fake] Train Epoch 1/1:   0%|          | 0/31 [00:00<?, ?it/s]/home/toma/t-80-8-a/_work/airas-20251008-043007-matsuzawa/airas-20251008-043007-matsuzawa/src/train.py:94: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler.is_enabled()):

[adanpc_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.65s/it]
[adanpc_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.65s/it, loss=2.68, acc=0.0521]
[adanpc_tau0.25_fake] Train Epoch 1/1:   3%|▎         | 1/31 [00:08<04:19,  8.65s/it, loss=2.65, acc=0.0625]
[adanpc_tau0.25_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.65, acc=0.0625]
[adanpc_tau0.25_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.59, acc=0.0799]
[adanpc_tau0.25_fake] Train Epoch 1/1:  26%|██▌       | 8/31 [00:08<00:18,  1.25it/s, loss=2.57, acc=0.0859]
[adanpc_tau0.25_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.57, acc=0.0859]
[adanpc_tau0.25_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.56, acc=0.0896]
[adanpc_tau0.25_fake] Train Epoch 1/1:  42%|████▏     | 13/31 [00:08<00:07,  2.35it/s, loss=2.55, acc=0.0938]
[adanpc_tau0.25_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:08<00:03,  3.84it/s, loss=2.55, acc=0.0938]
[adanpc_tau0.25_fake] Train Epoch 1/1:  58%|█████▊    | 18/31 [00:09<00:03,  3.84it/s, loss=2.55, acc=0.0893]
[adanpc_tau0.25_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.81it/s, loss=2.55, acc=0.0893]
[adanpc_tau0.25_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.81it/s, loss=2.55, acc=0.0872]
[adanpc_tau0.25_fake] Train Epoch 1/1:  74%|███████▍  | 23/31 [00:09<00:01,  5.81it/s, loss=2.53, acc=0.0926]
[adanpc_tau0.25_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:09<00:00,  8.34it/s, loss=2.53, acc=0.0926]
[adanpc_tau0.25_fake] Train Epoch 1/1:  90%|█████████ | 28/31 [00:09<00:00,  8.34it/s, loss=2.53, acc=0.0906]
                                                                                                             
