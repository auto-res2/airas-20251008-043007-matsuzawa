
Input:
You are an accomplished researcher in machine learning. You are considering a new method described in "New Method" for the research theme provided in "Research Topic". "Related Works" is a list of research papers that are highly relevant to this new method.
Based on the following instructions, output the reasons for the novelty and significance of the newly proposed method, and quantitatively evaluate them.

# Research Topic
Improve Test-Time Adaptation in terms of convergence speed.

# New Method
{
    "Open Problems": "1. Current TTA evaluators penalise slow methods, yet most state-of-the-art approaches (Tent, CoTTA, EATA, …) still need several gradient steps per batch because high learning-rates make the tiny set of trainable parameters (BatchNorm γ,β) explode.\n2. Shrink-Tent’s fixed isotropic L2 pull back to the source parameters stabilises training but cannot exploit that different channels / layers have very different sensitivities; a single λ trades stability for convergence speed and needs tuning per model.\n3. No existing TTA method links the adaptation step size to a provable trust-region on the test loss, nor adapts this region online to meet real-time latency constraints.",
    "Methods": "We propose ProxTTA – a single-step proximal update that performs *closed-form* trust-region adaptation of BN affine parameters per batch.\n\nLet θ be the concatenated vector of all γ,β.  For each incoming batch x we compute the entropy loss L(θ;x).  Instead of a gradient step we solve the *proximal sub-problem*\n\n    θ_{t+1} = argmin_θ  L(θ;x) + (1⁄2)‖θ−θ_t‖^2_Σ^{-1}\n\nwhere Σ is a (frozen) diagonal pre-conditioner equal to the empirical Fisher of θ on the source data.  The solution is simply\n\n    θ_{t+1} = θ_t − Σ ∇_θ L(θ;x)\n\nwhich is a natural-gradient trust-region step whose implicit radius adapts per-parameter (larger for insensitive channels).  Because Σ is pre-computed once and stored as a vector, the extra cost is one Hadamard product – identical FLOPs to plain SGD.\n\nLatency-aware adaptive schedule: we maintain an exponential moving average of the wall-clock adaptation time τ_t.  If τ_t > τ_max (user budget) we skip the proximal update for the next k batches, otherwise we update every batch.  This lets ProxTTA respect the Realistic TTA protocol automatically.\n\nHyper-parameters: none apart from τ_max (milliseconds) supplied by deployment.  No learning-rate tuning.",
    "Experimental Setup": "Reference implementation extends the official Tent repo with two lines (Hadamard product with Σ and optional skip).  Σ is estimated once by running 200 source batches at start-up.\n\nDatasets & streams:\n• CIFAR-10-C, ImageNet-C severity 5.\n• Realistic online protocol at 3 stream speeds (η∈{1,1/2,1/4}).\n• Recurring PTTA stream (Dirichlet δ=0.1) to test collapse.\n\nBaselines: Source, Tent, Shrink-Tent, EATA, RoTTA.\n\nMetrics: (i) Online top-1 error under time-penalty, (ii) wall-clock to reach 90% of Tent’s final accuracy, (iii) memory overhead.",
    "Experimental Code": "# only two extra lines vs Tent\nclass ProxTTA(Tent):\n    def __init__(self, model, fisher, tau_max=None):\n        super().__init__(model, torch.optim.SGD([],lr=1))\n        self.Sigma = fisher      # vector same size as theta\n        self.tau_max=tau_max; self.tau_ema=None\n    @torch.enable_grad()\n    def forward_and_adapt(self,x,model,_):\n        if self.tau_max and self.tau_ema and self.tau_ema>self.tau_max:\n            return model(x)      # skip to meet budget\n        t0=time.time()\n        y=model(x)\n        loss=softmax_entropy(y).mean()\n        grads=torch.autograd.grad(loss,self.params)[0]\n        with torch.no_grad():\n            for p,g,s in zip(self.params,grads,self.Sigma):\n                p-=s*g          # natural-gradient prox step  ***\n        self.tau_ema=0.8*(self.tau_ema or 0)+0.2*(time.time()-t0)\n        model.zero_grad(); return model(x)",
    "Expected Result": "• After a *single* proximal update ProxTTA matches Tent’s 3-step accuracy and outperforms Shrink-Tent by 1–1.5% on both datasets.\n• Under the Realistic protocol it retains >95% of its accuracy at η=1/2 whereas Tent drops below 80% because ProxTTA skips updates to meet the budget.\n• Memory ↑ only by the |θ| vector (≤0.2 MB for ResNet-50).",
    "Expected Conclusion": "A closed-form per-parameter proximal step grounded in natural-gradient trust regions removes the need for learning-rate or λ tuning, accelerates convergence to one step, and automatically adapts to latency budgets.  This bridges optimisation theory and practical TTA, offering a truly plug-and-play, compute-aware solution for real-time deployment."
}

# Related Works
{
    "Title": "Tent: Fully Test-Time Adaptation by Entropy Minimization",
    "Main Contributions": "The paper highlights the novel setting of fully test-time adaptation, where a model adapts to new data during inference using only the target data and its own parameters, without access to source data or supervision. It proposes Tent (Test Entropy Minimization), a scheme to reduce generalization error by optimizing for confidence, measured by minimizing the entropy of model predictions on test data. Tent achieves a new state-of-the-art error of 44.0% on ImageNet-C for robustness to corruptions and demonstrates effective source-free adaptation for digit classification and semantic segmentation, even rivaling methods that use source data and more optimization.",
    "Methodology": "Tent adapts deep networks by minimizing the Shannon entropy of model predictions H(ˆy) during testing. This is achieved by modulating features through two main steps: 1) estimating normalization statistics (mean µ and standard deviation σ) and 2) optimizing channel-wise affine transformation parameters (scale γ and shift β). These modulations are applied to the normalization layers of a pre-trained source model. The normalization statistics are estimated on each batch during the forward pass, while the affine parameters γ and β are updated via gradient descent (SGD with momentum or Adam) on the test entropy, without altering the training process or the majority of model parameters. This process can be applied online (continuous iteration) or offline (fixed number of updates before inference).",
    "Experimental Setup": "The method was evaluated on: 1) Corruption Robustness: CIFAR-10/100-C and ImageNet-C, using 15 corruption types at five severity levels. 2) Domain Adaptation: Digit recognition from SVHN (source) to MNIST, MNIST-M, and USPS (targets); Semantic segmentation from GTA (simulated source) to Cityscapes (real target); Object recognition on VisDA-C challenge (synthetic source to real target). Models used include Residual Networks (R-26 for CIFAR/digits, R-50 for ImageNet), HRNet-W18 for semantic segmentation, and ResNet-50 for VisDA-C. Baselines included 'source' (no adaptation), adversarial domain adaptation (RG), self-supervised domain adaptation (UDA-SS), test-time training (TTT), test-time normalization (BN), and pseudo-labeling (PL). Optimization hyperparameters (batch size, learning rate) were adapted from source model training. Analysis included examining entropy/loss changes, ablating modulation components, and testing generalization across target data and alternative architectures (SAN, MDEQ).",
    "Limitations": "Tent does not improve generalization on all types of dataset shifts, specifically failing to show improvement on natural, unknown shifts like CIFAR 10.1 and ImageNetV2. It can also fail on particularly difficult domain shifts, such as MNIST-to-SVHN, where its error increased, suggesting that joint optimization with source data might be necessary for such challenging cases. The method primarily modulates only normalization and transformation parameters, leaving the majority of the model fixed, which limits its expressiveness for adaptation. The entropy objective requires batches for optimization and cannot update episodically on a single point at a time. Furthermore, the method requires full re-computation of the model for updates, which can be computationally intensive if more local optimization is desired.",
    "Future Research Directions": "Future work could focus on extending test-time adaptation to handle more diverse and challenging types of shifts, including adversarial shifts. Research into adapting a broader set of model parameters, beyond just normalization and transformation layers, is suggested, with emphasis on identifying parameters that are both expressive and reliable. Exploring more effective and efficient loss functions for general but episodic test-time optimization is another direction, potentially including representation-defined losses to reduce computational overhead. Investigating how the entropy loss interacts with calibration for improved uncertainty estimation and adaptation is also proposed. Finally, adapting the input itself through spatial transformations or image translations using input gradients could offer a more general approach to reducing shift without source data.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.jit\nfrom copy import deepcopy\n\nclass Tent(nn.Module):\n    \"\"\"Tent adapts a model by entropy minimization during testing.\n\n    Once tented, a model adapts itself by updating on every forward.\n    \"\"\"\n    def __init__(self, model, optimizer, steps=1, episodic=False):\n        super().__init__()\n        self.model = model\n        self.optimizer = optimizer\n        self.steps = steps\n        assert steps > 0, \"tent requires >= 1 step(s) to forward and update\"\n        self.episodic = episodic\n\n        # note: if the model is never reset, like for continual adaptation,\n        # then skipping the state copy would save memory\n        self.model_state, self.optimizer_state = \\\n            copy_model_and_optimizer(self.model, self.optimizer)\n\n    def forward(self, x):\n        if self.episodic:\n            self.reset()\n\n        for _ in range(self.steps):\n            outputs = forward_and_adapt(x, self.model, self.optimizer)\n\n        return outputs\n\n    def reset(self):\n        if self.model_state is None or self.optimizer_state is None:\n            raise Exception(\"cannot reset without saved model/optimizer state\")\n        load_model_and_optimizer(self.model, self.optimizer,\n                                 self.model_state, self.optimizer_state)\n\n\n@torch.jit.script\ndef softmax_entropy(x: torch.Tensor) -> torch.Tensor:\n    \"\"\"Entropy of softmax distribution from logits.\"\"\"\n    return -(x.softmax(1) * x.log_softmax(1)).sum(1)\n\n\n@torch.enable_grad()  # ensure grads in possible no grad context for testing\ndef forward_and_adapt(x, model, optimizer):\n    \"\"\"Forward and adapt model on batch of data.\n\n    Measure entropy of the model prediction, take gradients, and update params.\n    \"\"\"\n    # forward\n    outputs = model(x)\n    # adapt\n    loss = softmax_entropy(outputs).mean(0)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    return outputs\n\n\ndef collect_params(model):\n    \"\"\"Collect the affine scale + shift parameters from batch norms.\n\n    Walk the model's modules and collect all batch normalization parameters.\n    Return the parameters and their names.\n\n    Note: other choices of parameterization are possible!\n    \"\"\"\n    params = []\n    names = []\n    for nm, m in model.named_modules():\n        if isinstance(m, nn.BatchNorm2d):\n            for np, p in m.named_parameters():\n                if np in ['weight', 'bias']:  # weight is scale, bias is shift\n                    params.append(p)\n                    names.append(f\"{nm}.{np}\")\n    return params, names\n\n\ndef copy_model_and_optimizer(model, optimizer):\n    \"\"\"Copy the model and optimizer states for resetting after adaptation.\"\"\"\n    model_state = deepcopy(model.state_dict())\n    optimizer_state = deepcopy(optimizer.state_dict())\n    return model_state, optimizer_state\n\n\ndef load_model_and_optimizer(model, optimizer, model_state, optimizer_state):\n    \"\"\"Restore the model and optimizer states from copies.\"\"\"\n    model.load_state_dict(model_state, strict=True)\n    optimizer.load_state_dict(optimizer_state)\n\n\ndef configure_model(model):\n    \"\"\"Configure model for use with tent.\"\"\"\n    # train mode, because tent optimizes the model to minimize entropy\n    model.train()\n    # disable grad, to (re-)enable only what tent updates\n    model.requires_grad_(False)\n    # configure norm for tent updates: enable grad + force batch statisics\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.requires_grad_(True)\n            # force use of batch stats in train and eval modes\n            m.track_running_stats = False\n            m.running_mean = None\n            m.running_var = None\n    return model\n\ndef setup_tent(model):\n    \"\"\"Set up tent adaptation.\n\n    Configure the model for training + feature modulation by batch statistics,\n    collect the parameters for feature modulation by gradient optimization,\n    set up the optimizer, and then tent the model.\n    \"\"\"\n    model = configure_model(model)\n    params, param_names = collect_params(model)\n    optimizer = setup_optimizer(params)\n    tent_model = Tent(model, optimizer,\n                           steps=cfg.OPTIM.STEPS,\n                           episodic=cfg.MODEL.EPISODIC)\n    logger.info(f\"model for adaptation: %s\", model)\n    logger.info(f\"params for adaptation: %s\", param_names)\n    logger.info(f\"optimizer for adaptation: %s\", optimizer)\n    return tent_model\n\ndef setup_optimizer(params):\n    \"\"\"Set up optimizer for tent adaptation.\n\n    Tent needs an optimizer for test-time entropy minimization.\n    In principle, tent could make use of any gradient optimizer.\n    In practice, we advise choosing Adam or SGD+momentum.\n    For optimization settings, we advise to use the settings from the end of\n    trainig, if known, or start with a low learning rate (like 0.001) if not.\n\n    For best results, try tuning the learning rate and batch size.\n    \"\"\"\n    if cfg.OPTIM.METHOD == 'Adam':\n        return optim.Adam(params,\n                    lr=cfg.OPTIM.LR,\n                    betas=(cfg.OPTIM.BETA, 0.999),\n                    weight_decay=cfg.OPTIM.WD)\n    elif cfg.OPTIM.METHOD == 'SGD':\n        return optim.SGD(params,\n                   lr=cfg.OPTIM.LR,\n                   momentum=cfg.OPTIM.MOMENTUM,\n                   dampening=cfg.OPTIM.DAMPENING,\n                   weight_decay=cfg.OPTIM.WD,\n                   nesterov=cfg.OPTIM.NESTEROV)\n    else:\n        raise NotImplementedError",
    "Experiment Result": "Method: Tent (test-time entropy minimization)\nAdaptation Mode: Online by default (cfg.MODEL.EPISODIC = False)\nNormalization Layers: Batch Normalization (nn.BatchNorm2d)\nNormalization Statistics: Batch-wise statistics are forced (m.track_running_stats = False, m.running_mean = None, m.running_var = None) for adaptation.\nAffine Parameters: Scale (weight) and shift (bias) parameters of BatchNorm2d layers are collected for optimization.\nNumber of Updates per Batch: 1 (cfg.OPTIM.STEPS = 1)\nOptimizer: Adam (cfg.OPTIM.METHOD = 'Adam')\nLearning Rate: 1e-3 (cfg.OPTIM.LR = 1e-3)\nAdam Betas: (0.9, 0.999) (cfg.OPTIM.BETA = 0.9, default 0.999)\nSGD Momentum: 0.9 (cfg.OPTIM.MOMENTUM = 0.9) - used if SGD is chosen\nSGD Dampening: 0.0 (cfg.OPTIM.DAMPENING = 0.0) - used if SGD is chosen\nSGD Nesterov: True (cfg.OPTIM.NESTEROV = True) - used if SGD is chosen\nWeight Decay (L2 regularization): 0.0 (cfg.OPTIM.WD = 0.0)\nBatch Size for Evaluation/Updates: 128 (cfg.TEST.BATCH_SIZE = 128)\nCorruption Dataset: CIFAR-10-C (cfg.CORRUPTION.DATASET = 'cifar10')\nCorruption Types: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']\nCorruption Severities: [5, 4, 3, 2, 1]\nNumber of Examples per Corruption: 10000 (cfg.CORRUPTION.NUM_EX = 10000)"
}{
    "Title": "What How and When Should Object Detectors Update in Continually Changing Test Domains?",
    "Main Contributions": "The paper proposes an efficient Continual Test-time Adaptation (CTA) method for object detection in continually changing test domains. Its key contributions include the introduction of architecture-agnostic lightweight adaptor modules (0.54%~0.89% of total parameters) that enable rapid and robust adaptation without catastrophic forgetting, applicable to diverse backbones (CNNs, Transformers). It also presents a practical class-wise feature alignment method for object detection, operating at both image and object levels using Exponentially Moving Average (EMA) updated test features and pre-computed training statistics. Furthermore, the research introduces two novel criteria to dynamically determine when model adaptation is needed, thereby enhancing efficiency by skipping unnecessary updates and boosting inference speed by up to approximately 2 times while maintaining adaptation performance. The approach consistently improves mAP by up to 4.9%p and 7.9%p on COCO \n\n COCO-corrupted and SHIFT benchmarks, respectively, while maintaining over 20 FPS.",
    "Methodology": "The proposed methodology addresses \"what, how, and when\" to update object detectors in continually changing test domains. For \"what to update\", it utilizes lightweight, architecture-agnostic adaptor modules (MLP layers for Transformers and 1x1 convolutional layers for ResNet) attached in parallel to backbone blocks. Only these adaptors are updated, while the pre-trained backbone parameters remain frozen. For \"how to update\", it employs an EMA feature alignment strategy to align test domain feature distributions with training data. This includes image-level feature alignment (Limg) by minimizing KL divergence between approximated normal distributions (using EMA-updated test means and pre-computed training means/variances), and region-level class-wise feature alignment (Lobj) for object-level features, incorporating a frequency-based weighting scheme to address class imbalance. The total adaptation loss is a sum of Limg and Lobj. For \"when to update\", an \"adaptation on demand\" mechanism is introduced with two criteria: (1) update if the image-level distribution gap (Limg) significantly exceeds the in-domain distribution gap by a threshold (τ1); (2) update if Limg suddenly increases compared to its Exponentially Moving Average (Ltema) by a threshold (τ2). Adaptation (backward pass) is performed if at least one criterion is met.",
    "Experimental Setup": "The method was evaluated on Faster-RCNN models using ResNet50 and Swin-Tiny backbones with FPN. Three primary scenarios were used for evaluation: COCO \n\n COCO-C, which simulates continuous and drastic domain changes by sequentially evaluating on 15 types of realistic corruptions applied to MS-COCO validation images, followed by evaluation on the original COCO validation set. SHIFT-Discrete/Continuous, a synthetic driving image dataset with 6 classes, simulating discrete (e.g., cloudy \n\n overcast) and continuous (e.g., clear \n\n foggy \n\n clear) changes in weather and time-of-day attributes. An additional experiment was conducted on the KITTI dataset (Fog \n\n Rain \n\n Snow \n\n Clear sequence) for further validation. Baselines included Direct-Test, ActMAD, Mean-Teacher (reproducing TeST), NORM, and DUA. Performance was measured by mAP (mAP@50 for KITTI), number of forward/backward passes, and Frames Per Second (FPS). Standard hyperparameters included a learning rate of 0.001 for the SGD optimizer, EMA update rate α=0.01, and adaptation criteria thresholds τ1=1.1 and τ2=1.05, with a batch size of 4 (16 for KITTI). The adaptor bottleneck reduction ratio (r) was set to 32.",
    "Limitations": "One limitation is that the frequency-based class weighting scheme (wk,t), while generally effective in class-imbalanced scenarios like COCO, shows a slight performance decrease in the SHIFT-Continuous setting. Another constraint or assumption of the method is the approximation of the test feature variance (Σte) as equivalent to the pre-computed training variance (Σtr) to enhance stability, which might not universally hold true. Furthermore, the \"adaptation on demand\" strategy relies on empirically determined hyperparameters (τ1 and τ2) that necessitate tuning to balance the trade-off between mAP performance and inference speed (FPS).",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
    "Main Contributions": "The paper proposes Test-Time Training (TTT), a novel approach to improve predictive models' generalization under distribution shifts. Instead of a fixed decision boundary, TTT updates model parameters on a single unlabeled test sample using a self-supervised learning problem before making a prediction. Key contributions include demonstrating substantial performance improvements on diverse image classification benchmarks (corrupted images, video frames, unknown shifts like CIFAR-10.1) without compromising performance on the original distribution. An online version of TTT further enhances performance under sequential, smoothly changing distribution shifts. Theoretically, the paper establishes that positive gradient correlation between the main and self-supervised task losses is a sufficient condition for TTT to reduce the main task loss in convex models, which is empirically validated for deep learning.",
    "Methodology": "The core methodology involves training a neural network with a Y-shaped architecture, comprising a shared feature extractor (θe) and two task-specific branches: one for the main classification task (θm) and another for a self-supervised auxiliary task (θs). The initial training is multi-task learning, minimizing combined losses on labeled training data. At test time, TTT fine-tunes only the shared feature extractor (θe) by minimizing the self-supervised task's loss on the current unlabeled test sample. The self-supervised task used is image rotation prediction (classifying 0, 90, 180, or 270-degree rotations). The standard TTT performs ten gradient steps on each test sample, initialized from the jointly trained model. Online TTT takes only one gradient step per new test sample, initializing its parameters from the state updated on the previous test sample. Group Normalization (GN) is used instead of Batch Normalization (BN) due to the small batch size (single test image plus augmentations) during test-time updates.",
    "Experimental Setup": "The method was evaluated on object recognition using ResNet architectures (ResNet-26 for CIFAR-10, ResNet-18 for ImageNet). Datasets included: 1) CIFAR-10-C and ImageNet-C, benchmarking robustness to 15 types of corruptions across 5 severity levels; 2) VID-Robust, a video frame dataset for evaluating adaptation to video data; and 3) CIFAR-10.1, a new test set designed to reveal subtle, unknown distribution shifts. Baselines compared were: 'object recognition task only' (plain ResNet), 'joint training' (supervised + self-supervised at training, fixed at test time), Adversarial Logit Pairing (ALP) for CIFAR-10-C, and Unsupervised Domain Adaptation by Self-Supervision (UDA-SS) for CIFAR-10-C (where UDA-SS had access to the entire unlabeled test set). Optimization for joint training used SGD, while test-time training used SGD with a fixed learning rate of 0.001 and zero weight decay/momentum. Data augmentation (random crop, horizontal flip) was applied during test-time updates.",
    "Limitations": "The computational cost of Test-Time Training is significantly higher than standard inference, being proportional to `2 × batch_size × number_of_iterations` slower. The effectiveness of TTT is contingent on the self-supervised task being both 'well defined and non-trivial'; for instance, rotation prediction on certain airplane images with black margins or ambiguous rotations for humans did not yield improvements. While TTT improved performance on CIFAR-10.1, the gain was modest, highlighting the challenge with extremely subtle and unidentifiable distribution shifts. Online TTT relies on the assumption that test samples are from the same or smoothly changing distributions. The method's reliance on Group Normalization indicates a weakness with Batch Normalization for single-sample updates. The theoretical results on gradient correlation are primarily proven for smooth and convex loss functions, while practical applications involve non-convex deep learning models.",
    "Future Research Directions": "Future work can extend Test-Time Training to other machine learning tasks, such as segmentation and detection, and other fields like speech recognition and natural language processing. Researchers can leverage domain knowledge to design more effective and specialized self-supervised tasks. The authors suggest using test-time training as a new evaluation benchmark for general-purpose self-supervised learning algorithms. Further research is needed to improve the computational efficiency of test-time training, potentially through techniques like thresholding the self-supervised loss or making models amenable to faster updates during training. A formal theoretical discussion on the concept of a 'variable decision boundary' is also suggested. Additionally, the approach could potentially benefit from advancements in one-shot learning, as the update rule can be viewed as performing one-shot self-supervised learning. More broadly, the paper encourages a paradigm shift away from fixed decision boundaries and the strict separation of training and testing, advocating for more learning to occur post-deployment.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Robust Test-Time Adaptation in Dynamic Scenarios",
    "Main Contributions": "This paper introduces Practical Test-Time Adaptation (PTTA), a new and more realistic test-time adaptation (TTA) setup that simultaneously accounts for continually changing test data distributions and correlative sampling. The proposed Robust Test-Time Adaptation (RoTTA) method effectively addresses the challenges of PTTA by providing robust statistics estimation, category-balanced sampling with timeliness and uncertainty, and time-aware robust training. Extensive experiments demonstrate that RoTTA achieves state-of-the-art results on CIFAR-10-C, CIFAR-100-C, and DomainNet, outperforming baselines by a significant margin and proving its suitability for rapid deployment in dynamic real-world applications.",
    "Methodology": "RoTTA consists of three main components: (1) Robust Batch Normalization (RBN) replaces traditional batch statistics with global ones maintained by an Exponential Moving Average (EMA) to robustly normalize feature maps, initialized from the pre-trained model's running statistics and updated using buffered samples. (2) Category-Balanced Sampling with Timeliness and Uncertainty (CSTU) manages a memory bank by prioritizing samples that are newer and less uncertain. It uses pseudo-labels for category balancing and assigns a heuristic score based on sample age and prediction entropy to guide replacement. (3) Robust Training with Timeliness utilizes a teacher-student model architecture. The student model's affine parameters in RBN are updated by minimizing a loss function over the memory bank samples, incorporating a timeliness reweighting term (E(Ai)) that reduces the influence of older samples. The teacher model's parameters are updated via EMA of the student's parameters. The training loss is a cross-entropy between the student's prediction on strong-augmented views and the teacher's prediction on weak-augmented views.",
    "Experimental Setup": "Experiments were conducted on CIFAR-10-C, CIFAR-100-C for robustness to corruptions, and DomainNet for generalization under domain shift. Pre-trained models included WildResNet-28 for CIFAR10-C, ResNeXt-29 for CIFAR100-C (from RobustBench), and ResNet-101 for DomainNet. The PTTA setup was simulated by changing corruption types (severity 5) one by one and using a Dirichlet distribution (δ=0.1 by default) to model correlatively sampled test streams. All experiments used PyTorch, Adam optimizer (learning rate 1.0 × 10^-3), batch size 64, and a memory bank capacity N=64. RoTTA's hyperparameters were fixed across experiments (α=0.05, ν=0.001, λt=1.0, λu=1.0). Validation involved comparing average classification error with state-of-the-art TTA methods, ablation studies for each component, and sensitivity analyses for distribution changing order, Dirichlet parameter δ, and batch size.",
    "Limitations": "The Robust Batch Normalization (RBN) component is considered a 'naive solution' for handling correlatively sampled data and requires careful tuning of the parameter α. While RoTTA is designed to prevent model collapse, the paper notes a lack of a explicit recovery mechanism for cases where other methods (like PL, TENT) fail. Furthermore, the simulation of data correlation primarily focuses on category similarity using Dirichlet distribution, and the approach needs further validation in more diverse real-world scenarios to confirm its broader applicability.",
    "Future Research Directions": "Future work could focus on improving the RoTTA algorithm by replacing or refining its existing components. More importantly, the authors hope this work will pave the way for closer integration of TTA algorithms with real-world applications by further enhancing the PTTA setup to make it even more realistic and comprehensive.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom ..utils import memory\nfrom .base_adapter import BaseAdapter\nfrom copy import deepcopy\nfrom .base_adapter import softmax_entropy\nfrom ..utils.bn_layers import RobustBN1d, RobustBN2d\nfrom ..utils.utils import set_named_submodule, get_named_submodule\nfrom ..utils.custom_transforms import get_tta_transforms\n\n\nclass RoTTA(BaseAdapter):\n    def __init__(self, cfg, model, optimizer):\n        super(RoTTA, self).__init__(cfg, model, optimizer)\n        self.mem = memory.CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n        self.model_ema = self.build_ema(self.model)\n        self.transform = get_tta_transforms(cfg)\n        self.nu = cfg.ADAPTER.RoTTA.NU\n        self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY  # actually the same as the size of memory bank\n        self.current_instance = 0\n\n    @torch.enable_grad()\n    def forward_and_adapt(self, batch_data, model, optimizer):\n        # batch data\n        with torch.no_grad():\n            model.eval()\n            self.model_ema.eval()\n            ema_out = self.model_ema(batch_data)\n            predict = torch.softmax(ema_out, dim=1)\n            pseudo_label = torch.argmax(predict, dim=1)\n            entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1)\n\n        # add into memory\n        for i, data in enumerate(batch_data):\n            p_l = pseudo_label[i].item()\n            uncertainty = entropy[i].item()\n            current_instance = (data, p_l, uncertainty)\n            self.mem.add_instance(current_instance)\n            self.current_instance += 1\n\n            if self.current_instance % self.update_frequency == 0:\n                self.update_model(model, optimizer)\n\n        return ema_out\n\n    def update_model(self, model, optimizer):\n        model.train()\n        self.model_ema.train()\n        # get memory data\n        sup_data, ages = self.mem.get_memory()\n        l_sup = None\n        if len(sup_data) > 0:\n            sup_data = torch.stack(sup_data)\n            strong_sup_aug = self.transform(sup_data)\n            ema_sup_out = self.model_ema(sup_data)\n            stu_sup_out = model(strong_sup_aug)\n            instance_weight = timeliness_reweighting(ages)\n            l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean()\n\n        l = l_sup\n        if l is not None:\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n\n        self.update_ema_variables(self.model_ema, self.model, self.nu)\n\n    @staticmethod\n    def update_ema_variables(ema_model, model, nu):\n        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]\n        return ema_model\n\n    def configure_model(self, model: nn.Module):\n\n        model.requires_grad_(False)\n        normlayer_names = []\n\n        for name, sub_module in model.named_modules():\n            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):\n                normlayer_names.append(name)\n\n        for name in normlayer_names:\n            bn_layer = get_named_submodule(model, name)\n            if isinstance(bn_layer, nn.BatchNorm1d):\n                NewBN = RobustBN1d\n            elif isinstance(bn_layer, nn.BatchNorm2d):\n                NewBN = RobustBN2d\n            else:\n                raise RuntimeError()\n\n            momentum_bn = NewBN(bn_layer,\n                                self.cfg.ADAPTER.RoTTA.ALPHA)\n            momentum_bn.requires_grad_(True)\n            set_named_submodule(model, name, momentum_bn)\n        return model\n\n\ndef timeliness_reweighting(ages):\n    if isinstance(ages, list):\n        ages = torch.tensor(ages).float().cuda()\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n",
    "Experiment Result": "RoTTA Configuration:\n- ADAPTER.RoTTA.MEMORY_SIZE: 64 (Capacity of the memory bank for Category-Balanced Sampling with Timeliness and Uncertainty (CSTU))\n- ADAPTER.RoTTA.UPDATE_FREQUENCY: 64 (Frequency, in instances, for triggering model updates using samples from the memory bank)\n- ADAPTER.RoTTA.NU: 0.001 (Exponential Moving Average (EMA) rate for updating the teacher model parameters from the student model)\n- ADAPTER.RoTTA.ALPHA: 0.05 (Momentum value for updating the global statistics in Robust Batch Normalization (RBN) layers)\n- ADAPTER.RoTTA.LAMBDA_T: 1.0 (Weighting factor for timeliness in the CSTU heuristic score calculation)\n- ADAPTER.RoTTA.LAMBDA_U: 1.0 (Weighting factor for uncertainty in the CSTU heuristic score calculation)\n\nTraining and Data Settings:\n- OPTIM.STEPS: 1 (Number of adaptation steps performed per batch of incoming data)\n- OPTIM.LR: 1e-3 (Learning rate for the optimizer updating the student model's RBN affine parameters)\n- OPTIM.METHOD: 'Adam' (Optimizer used for adaptation)\n- CORRUPTION.DATASET: 'cifar10' (Example dataset for corruption evaluation)\n- TEST.BATCH_SIZE: 64 (Batch size used during test-time adaptation)\n- INPUT.SIZE: (32, 32) (Input image resolution for the model)\n- INPUT.PIXEL_MEAN: [0.485, 0.456, 0.406] (Mean for image normalization)\n- INPUT.PIXEL_STD: [0.229, 0.224, 0.225] (Standard deviation for image normalization)"
}{
    "Title": "Evaluation of Test-Time Adaptation Under Computational Time Constraints",
    "Main Contributions": "The paper proposes a novel online evaluation protocol for Test-Time Adaptation (TTA) methods that explicitly accounts for computational time constraints. It penalizes slower methods by providing them with fewer samples for adaptation, thereby offering a more realistic assessment of their real-world applicability. The study benchmarked 15 TTA methods on multiple datasets and scenarios using this protocol, demonstrating that simpler, faster approaches can often outperform more sophisticated but slower methods (e.g., SHOT outperforming SAR) when inference speed is considered. This highlights the critical importance of developing TTA methods that are both accurate and efficient.",
    "Methodology": "The core methodology is the proposed 'Realistic TTA evaluation protocol.' Unlike current offline protocols, this protocol simulates an online setting where data arrives in a constant-speed stream. The key concept is the 'relative adaptation speed C(g),' defined as the integer ratio of the stream's speed (r) to the TTA method's processing speed (R(g(x))). If C(g) = k, the method is allowed to adapt to only every k-th sample; the skipped samples are processed by the most recent adapted model (fθt) or the base model without adaptation. C(g) is computed online for each input as C(g(xt)) = ⌈r/R(g(x))⌉. This intrinsically penalizes slower methods, as longer adaptation times result in fewer samples being utilized for adaptation.",
    "Experimental Setup": "The evaluation focused on image classification using a ResNet-50-BN backbone (pretrained on ImageNet), also extended to ViT and ResNet-18 architectures. Experiments were conducted primarily on ImageNet-C (corruption level 5 across 15 corruptions), and further extended to CIFAR10-C, ImageNet-R, and ImageNet-3DCC. A batch size of 64 was primarily used, with ablations for {1, 16, 32, 128}. Fifteen state-of-the-art TTA methods (e.g., AdaBN, SHOT, TENT, SAR, EATA, MEMO, DDA) from 2017-2023 were benchmarked using their official implementations and recommended hyperparameters. Evaluation scenarios included episodic adaptation, continual adaptation, varying stream speeds (ηr with η ∈ {1/16, 1/8, 1/4, 1/2, 1}), and practical TTA with label imbalances. All main results are reported as the average across three random seeds.",
    "Limitations": "The paper identifies that data-dependent TTA approaches like MEMO and DDA are extremely inefficient, incurring massive computational burdens that significantly degrade their performance under the realistic protocol, making them perform close to the non-adapted baseline. It also notes that methods not employing sample rejection (e.g., SHOT, TENT, TTAC) can scale poorly in offline-continual settings due to overfitting to early distributions. While sample rejection methods like SAR are generally better, SAR's reliance on gradients for rejection reduces its speed, leading to a performance drop. The online computation of C(g) can be noisy due to hardware and input dependence. The default evaluation assumes the concurrent deployment of a base model (fθ) to process skipped samples, which might not be feasible in all real-world scenarios. In a single-model deployment (where only one model can be deployed, and skipped samples are handled by a random classifier), even efficient TTA methods face significant performance penalties if not as fast as the stream.",
    "Future Research Directions": "The paper suggests that future research should prioritize developing practical TTA methods that are both accurate and computationally efficient, explicitly considering inference speed as a critical performance dimension. Specifically, there's a need to increase the efficiency of data-dependent adaptation methods, which currently suffer significantly under computational constraints. For deployment scenarios where only a single model can operate, fostering the development of TTA methods with negligible additional computational overhead is crucial. Furthermore, exploring more sophisticated policies for handling samples skipped by a busy TTA method (e.g., leveraging temporal correlation or distribution bias) when a separate baseline model is unavailable is an open area.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Persistent Test-time Adaptation in Recurring Testing Scenarios",
    "Main Contributions": "This research introduces the recurring Test-time Adaptation (TTA) scenario to diagnose gradual performance degradation and error accumulation in TTA models over prolonged periods, especially when encountering previously seen environments. It formally defines model collapse and provides a theoretical analysis on an \"e-perturbed Gaussian Mixture Model Classifier\" (e-GMMC) to explain dataset- and algorithm-dependent factors leading to this degradation. Based on these insights, the paper proposes Persistent TTA (PeTTA), an adaptation scheme that monitors model divergence and dynamically adjusts the adaptation strategy to balance between adaptation and preventing model collapse, demonstrating superior stability compared to existing approaches in lifelong TTA scenarios.",
    "Methodology": "The paper first introduces the recurring TTA setting, which extends practical TTA by allowing environments to recur over time. It then conducts a theoretical analysis using an e-perturbed binary Gaussian Mixture Model Classifier (e-GMMC) to simulate and understand model collapse, where the pseudo-label predictor is perturbed to maintain a false negative rate. This analysis explains factors contributing to collapse: prior data distribution, intrinsic category differences, update rate, and false negative rate (FNR). PeTTA, the proposed method, equips TTA with a mechanism to sense divergence from the initial model (theta0) by measuring the Mahalanobis distance of feature embedding vectors' first moments (gamma_y_t). It then adaptively adjusts the regularization term coefficient (lambda_t) and the EMA update rate (alpha_t) based on this sensed divergence, prioritizing collapse prevention when deviation is significant. PeTTA integrates these adaptive parameters with a mean teacher update framework, category-balanced memory bank, robust batch normalization, and an anchor loss (LAL) which minimizes KL divergence between current and source model predictions.",
    "Experimental Setup": "The performance of PeTTA is benchmarked against CoTTA, EATA, RMT, MECTA, RoTTA, ROID, TRIBE, LAME, and RDumb on four classification tasks: CIFAR-10 --> CIFAR-10-C, CIFAR-100 --> CIFAR-100-C, ImageNet --> ImageNet-C (corruption level 5), and DomainNet (real --> clipart, painting, sketch). All experiments are conducted in the proposed recurring TTA scenario, where multiple testing scenarios from each test set gradually change and recur K=20 times. For CIFAR-10/100-C and ImageNet-C, a Dirichlet distribution (Dir(0.1) or Dir(0.01)) generates temporally correlated batches. An additional experiment on the Continuously Changing Corruption (CCC) benchmark is performed, covering 80,000 adaptation steps with 5.1M images. Source models are pre-trained on RobustBench and torchvision; PyTorch is used for implementation. Adam optimizer is used with a learning rate of 1e-3. PeTTA's adaptive EMA update rate for robust batch normalization and feature embedding statistics is 5e-2, initial alpha_0 is 1e-3, and lambda_0 is 10 for CIFAR/ImageNet-C and 1 for DomainNet.",
    "Limitations": "The paper notes that a complete elimination of error accumulation cannot be rigorously guaranteed solely through regularization. Additionally, PeTTA relies on a small memory bank to handle temporally correlated testing streams, which may limit scalability. It also assumes the availability of feature statistics (empirical mean and covariant matrix) from the source distribution, which might not always be accessible in real-world settings without accessing unlabeled source samples or pre-computed values.",
    "Future Research Directions": "Future research could focus on developing algorithms that achieve error accumulation-free adaptation by construction, beyond regularization. Exploring alternative methods for reducing memory bank size (e.g., storing embedded features instead of original images) is also a potential direction. Furthermore, research could investigate how to operate PeTTA without the assumption of having access to feature statistics from the source distribution.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom ..utils import memory\nfrom .base_adapter import BaseAdapter\nfrom copy import deepcopy\nfrom .base_adapter import softmax_entropy\nfrom ..utils.bn_layers import RobustBN1d, RobustBN2d\nfrom ..utils.utils import set_named_submodule, get_named_submodule\nfrom ..utils.custom_transforms import get_tta_transforms\n\n\nclass RoTTA(BaseAdapter):\n    def __init__(self, cfg, model, optimizer):\n        super(RoTTA, self).__init__(cfg, model, optimizer)\n        self.mem = memory.CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n        self.model_ema = self.build_ema(self.model)\n        self.transform = get_tta_transforms(cfg)\n        self.nu = cfg.ADAPTER.RoTTA.NU\n        self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY  # actually the same as the size of memory bank\n        self.current_instance = 0\n\n    @torch.enable_grad()\n    def forward_and_adapt(self, batch_data, model, optimizer):\n        # batch data\n        with torch.no_grad():\n            model.eval()\n            self.model_ema.eval()\n            ema_out = self.model_ema(batch_data)\n            predict = torch.softmax(ema_out, dim=1)\n            pseudo_label = torch.argmax(predict, dim=1)\n            entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1)\n\n        # add into memory\n        for i, data in enumerate(batch_data):\n            p_l = pseudo_label[i].item()\n            uncertainty = entropy[i].item()\n            current_instance = (data, p_l, uncertainty)\n            self.mem.add_instance(current_instance)\n            self.current_instance += 1\n\n            if self.current_instance % self.update_frequency == 0:\n                self.update_model(model, optimizer)\n\n        return ema_out\n\n    def update_model(self, model, optimizer):\n        model.train()\n        self.model_ema.train()\n        # get memory data\n        sup_data, ages = self.mem.get_memory()\n        l_sup = None\n        if len(sup_data) > 0:\n            sup_data = torch.stack(sup_data)\n            strong_sup_aug = self.transform(sup_data)\n            ema_sup_out = self.model_ema(sup_data)\n            stu_sup_out = model(strong_sup_aug)\n            instance_weight = timeliness_reweighting(ages)\n            l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean()\n\n        l = l_sup\n        if l is not None:\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n\n        self.update_ema_variables(self.model_ema, self.model, self.nu)\n\n    @staticmethod\n    def update_ema_variables(ema_model, model, nu):\n        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]\n        return ema_model\n\n    def configure_model(self, model: nn.Module):\n\n        model.requires_grad_(False)\n        normlayer_names = []\n\n        for name, sub_module in model.named_modules():\n            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):\n                normlayer_names.append(name)\n\n        for name in normlayer_names:\n            bn_layer = get_named_submodule(model, name)\n            if isinstance(bn_layer, nn.BatchNorm1d):\n                NewBN = RobustBN1d\n            elif isinstance(bn_layer, nn.BatchNorm2d):\n                NewBN = RobustBN2d\n            else:\n                raise RuntimeError()\n\n            momentum_bn = NewBN(bn_layer,\n                                self.cfg.ADAPTER.RoTTA.ALPHA)\n            momentum_bn.requires_grad_(True)\n            set_named_submodule(model, name, momentum_bn)\n        return model\n\n\ndef timeliness_reweighting(ages):\n    if isinstance(ages, list):\n        ages = torch.tensor(ages).float().cuda()\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n\n\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\nimport logging\n\n\nclass BaseAdapter(nn.Module):\n    def __init__(self, cfg, model, optimizer):\n        super().__init__()\n        self.logger = logging.getLogger(\"TTA.adapter\")\n        self.cfg = cfg\n        self.model = self.configure_model(model)\n\n        params, param_names = self.collect_params(self.model)\n        if len(param_names) == 0:\n            self.optimizer = None\n        else:\n            self.optimizer = optimizer(params)\n\n        self.steps = self.cfg.OPTIM.STEPS\n        assert self.steps > 0, \"requires >= 1 step(s) to forward and update\"\n\n    def forward(self, x):\n        for _ in range(self.steps):\n            outputs = self.forward_and_adapt(x, self.model, self.optimizer)\n\n        return outputs\n\n    def forward_and_adapt(self, *args):\n        raise NotImplementedError(\"implement forward_and_adapt by yourself!\")\n\n    def configure_model(self, model):\n        raise NotImplementedError(\"implement configure_model by yourself!\")\n\n    def collect_params(self, model: nn.Module):\n        names = []\n        params = []\n\n        for n, p in model.named_parameters():\n            if p.requires_grad:\n                names.append(n)\n                params.append(p)\n\n        return params, names\n\n    def check_model(self, model):\n        pass\n\n    def before_tta(self, *args, **kwargs):\n        pass\n\n    @staticmethod\n    def build_ema(model):\n        ema_model = deepcopy(model)\n        for param in ema_model.parameters():\n            param.detach_()\n        return ema_model\n\n\n\n@torch.jit.script\ndef softmax_entropy(x, x_ema):\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\n\nimport random\nimport copy\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\nclass MemoryItem:\n    def __init__(self, data=None, uncertainty=0, age=0):\n        self.data = data\n        self.uncertainty = uncertainty\n        self.age = age\n\n    def increase_age(self):\n        if not self.empty():\n            self.age += 1\n\n    def get_data(self):\n        return self.data, self.uncertainty, self.age\n\n    def empty(self):\n        return self.data == \"empty\"\n\n\nclass CSTU:\n    def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0):\n        self.capacity = capacity\n        self.num_class = num_class\n        self.per_class = self.capacity / self.num_class\n        self.lambda_t = lambda_t\n        self.lambda_u = lambda_u\n\n        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]\n\n    def get_occupancy(self):\n        occupancy = 0\n        for data_per_cls in self.data:\n            occupancy += len(data_per_cls)\n        return occupancy\n\n    def per_class_dist(self):\n        per_class_occupied = [0] * self.num_class\n        for cls, class_list in enumerate(self.data):\n            per_class_occupied[cls] = len(class_list)\n\n        return per_class_occupied\n\n    def add_instance(self, instance):\n        assert (len(instance) == 3)\n        x, prediction, uncertainty = instance\n        new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0)\n        new_score = self.heuristic_score(0, uncertainty)\n        if self.remove_instance(prediction, new_score):\n            self.data[prediction].append(new_item)\n        self.add_age()\n\n    def remove_instance(self, cls, score):\n        class_list = self.data[cls]\n        class_occupied = len(class_list)\n        all_occupancy = self.get_occupancy()\n        if class_occupied < self.per_class:\n            if all_occupancy < self.capacity:\n                return True\n            else:\n                majority_classes = self.get_majority_classes()\n                return self.remove_from_classes(majority_classes, score)\n        else:\n            return self.remove_from_classes([cls], score)\n\n    def remove_from_classes(self, classes: list[int], score_base):\n        max_class = None\n        max_index = None\n        max_score = None\n        for cls in classes:\n            for idx, item in enumerate(self.data[cls]):\n                uncertainty = item.uncertainty\n                age = item.age\n                score = self.heuristic_score(age=age, uncertainty=uncertainty)\n                if max_score is None or score >= max_score:\n                    max_score = score\n                    max_index = idx\n                    max_class = cls\n\n        if max_class is not None:\n            if max_score > score_base:\n                self.data[max_class].pop(max_index)\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def get_majority_classes(self):\n        per_class_dist = self.per_class_dist()\n        max_occupied = max(per_class_dist)\n        classes = []\n        for i, occupied in enumerate(per_class_dist):\n            if occupied == max_occupied:\n                classes.append(i)\n\n        return classes\n\n    def heuristic_score(self, age, uncertainty):\n        return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class)\n\n    def add_age(self):\n        for class_list in self.data:\n            for item in class_list:\n                item.increase_age()\n        return\n\n    def get_memory(self):\n        tmp_data = []\n        tmp_age = []\n\n        for class_list in self.data:\n            for item in class_list:\n                tmp_data.append(item.data)\n                tmp_age.append(item.age)\n\n        tmp_age = [x / self.capacity for x in tmp_age]\n\n        return tmp_data, tmp_age\n\n\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\n\n\nclass MomentumBN(nn.Module):\n    def __init__(self, bn_layer: nn.BatchNorm2d, momentum):\n        super().__init__()\n        self.num_features = bn_layer.num_features\n        self.momentum = momentum\n        if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None:\n            self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean))\n            self.register_buffer(\"source_var\", deepcopy(bn_layer.running_var))\n            self.source_num = bn_layer.num_batches_tracked\n        self.weight = deepcopy(bn_layer.weight)\n        self.bias = deepcopy(bn_layer.bias)\n\n        self.register_buffer(\"target_mean\", torch.zeros_like(self.source_mean))\n        self.register_buffer(\"target_var\", torch.ones_like(self.source_var))\n        self.eps = bn_layer.eps\n\n        self.current_mu = None\n        self.current_sigma = None\n\n    def forward(self, x):\n        raise NotImplementedError\n\n\nclass RobustBN1d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False)  # (C,)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1), var.view(1, -1)\n        else:\n            mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1)\n        bias = self.bias.view(1, -1)\n\n        return x * weight + bias\n\n\nclass RobustBN2d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False)  # (C,)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1)\n        else:\n            mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1, 1, 1)\n        bias = self.bias.view(1, -1, 1, 1)\n\n        return x * weight + bias\n\n\nimport torch\nimport torchvision.transforms.functional as F\nfrom torchvision.transforms import ColorJitter, Compose, Lambda\nfrom numpy import random\nimport PIL\nimport torchvision.transforms as transforms\n\n\ndef get_tta_transforms(cfg, gaussian_std: float=0.005, soft=False):\n    img_shape = (*cfg.INPUT.SIZE, 3)\n    n_pixels = img_shape[0]\n\n    clip_min, clip_max = 0.0, 1.0\n\n    p_hflip = 0.5\n\n    tta_transforms = transforms.Compose([\n        Clip(0.0, 1.0),\n        ColorJitterPro(\n            brightness=[0.8, 1.2] if soft else [0.6, 1.4],\n            contrast=[0.85, 1.15] if soft else [0.7, 1.3],\n            saturation=[0.75, 1.25] if soft else [0.5, 1.5],\n            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],\n            gamma=[0.85, 1.15] if soft else [0.7, 1.3]\n        ),\n        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),\n        transforms.RandomAffine(\n            degrees=[-8, 8] if soft else [-15, 15],\n            translate=(1/16, 1/16),\n            scale=(0.95, 1.05) if soft else (0.9, 1.1),\n            shear=None,\n            resample=PIL.Image.BILINEAR,\n            fillcolor=None\n        ),\n        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),\n        transforms.CenterCrop(size=n_pixels),\n        transforms.RandomHorizontalFlip(p=p_hflip),\n        GaussianNoise(0, gaussian_std),\n        Clip(clip_min, clip_max)\n    ])\n    return tta_transforms\n\n\nclass GaussianNoise(torch.nn.Module):\n    def __init__(self, mean=0., std=1.):\n        super().__init__()\n        self.std = std\n        self.mean = mean\n\n    def forward(self, img):\n        noise = torch.randn(img.size()) * self.std + self.mean\n        noise = noise.to(img.device)\n        return img + noise\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\n\nclass Clip(torch.nn.Module):\n    def __init__(self, min_val=0., max_val=1.):\n        super().__init__()\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def forward(self, img):\n        return torch.clip(img, self.min_val, self.max_val)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)\n\n\nclass ColorJitterPro(ColorJitter):\n    \"\"\"Randomly change the brightness, contrast, saturation, and gamma correction of an image.\"\"\"\n\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):\n        super().__init__(brightness, contrast, saturation, hue)\n        self.gamma = self._check_input(gamma, 'gamma')\n\n    @staticmethod\n    @torch.jit.unused\n    def get_params(brightness, contrast, saturation, hue, gamma):\n        \"\"\"Get a randomized transform to be applied on image.\n\n        Arguments are same as that of __init__.\n\n        Returns:\n            Transform which randomly adjusts brightness, contrast and\n            saturation in a random order.\n        \"\"\"\n        transforms = []\n\n        if brightness is not None:\n            brightness_factor = random.uniform(brightness[0], brightness[1])\n            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n\n        if contrast is not None:\n            contrast_factor = random.uniform(contrast[0], contrast[1])\n            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n\n        if saturation is not None:\n            saturation_factor = random.uniform(saturation[0], saturation[1])\n            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n\n        if hue is not None:\n            hue_factor = random.uniform(hue[0], hue[1])\n            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n\n        if gamma is not None:\n            gamma_factor = random.uniform(gamma[0], gamma[1])\n            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))\n\n        random.shuffle(transforms)\n        transform = Compose(transforms)\n\n        return transform\n\n    def forward(self, img):\n        \"\"\"\n        Args:\n            img (PIL Image or Tensor): Input image.\n\n        Returns:\n            PIL Image or Tensor: Color jittered image.\n        \"\"\"\n        fn_idx = torch.randperm(5)\n        for fn_id in fn_idx:\n            if fn_id == 0 and self.brightness is not None:\n                brightness = self.brightness\n                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()\n                img = F.adjust_brightness(img, brightness_factor)\n\n            if fn_id == 1 and self.contrast is not None:\n                contrast = self.contrast\n                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()\n                img = F.adjust_contrast(img, contrast_factor)\n\n            if fn_id == 2 and self.saturation is not None:\n                saturation = self.saturation\n                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()\n                img = F.adjust_saturation(img, saturation_factor)\n\n            if fn_id == 3 and self.hue is not None:\n                hue = self.hue\n                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()\n                img = F.adjust_hue(img, hue_factor)\n\n            if fn_id == 4 and self.gamma is not None:\n                gamma = self.gamma\n                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()\n                img = img.clamp(1e-8, 1.0)  # to fix Nan values in gradients, which happens when applying gamma\n                                            # after contrast\n                img = F.adjust_gamma(img, gamma_factor)\n\n        return img\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + '('\n        format_string += 'brightness={0}'.format(self.brightness)\n        format_string += ', contrast={0}'.format(self.contrast)\n        format_string += ', saturation={0}'.format(self.saturation)\n        format_string += ', hue={0})'.format(self.hue)\n        format_string += ', gamma={0})'.format(self.gamma)\n        return format_string",
    "Experiment Result": "The RoTTA adapter (referred to as PeTTA in the method description) is configured with the following experimental settings:\n\n**Adapter Settings (from `core/configs/defaults.py`):**\n- `ADAPTER.RoTTA.MEMORY_SIZE`: 64 (Capacity of the category-balanced memory bank)\n- `ADAPTER.RoTTA.UPDATE_FREQUENCY`: 64 (Frequency at which the model is updated, corresponding to the memory bank size)\n- `ADAPTER.RoTTA.NU`: 0.001 (EMA update rate, referred to as `alpha_t` in the method description)\n- `ADAPTER.RoTTA.ALPHA`: 0.05 (Momentum for the Robust Batch Normalization layers)\n- `ADAPTER.RoTTA.LAMBDA_T`: 1.0 (Heuristic weight for 'age' in memory management score)\n- `ADAPTER.RoTTA.LAMBDA_U`: 1.0 (Heuristic weight for 'uncertainty' in memory management score)\n\n**Optimization Settings:**\n- `OPTIM.STEPS`: 1 (Number of optimization steps per batch during adaptation)\n- `OPTIM.LR`: 1e-3 (Learning rate for the optimizer)\n- `OPTIM.METHOD`: 'Adam' (Optimizer type)\n\n**Data & Corruption Settings:**\n- `CORRUPTION.DATASET`: 'cifar10' (Dataset used for experiments)\n- `CORRUPTION.TYPE`: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression'] (Types of corruption applied)\n- `CORRUPTION.SEVERITY`: [5, 4, 3, 2, 1] (Severity levels for corruptions)\n- `CORRUPTION.NUM_EX`: 10000 (Number of examples for corrupted datasets)\n- `INPUT.SIZE`: (32, 32) (Input image size)\n- `INPUT.PIXEL_MEAN`: [0.485, 0.456, 0.406] (Mean for normalization)\n- `INPUT.PIXEL_STD`: [0.229, 0.224, 0.225] (Standard deviation for normalization)\n- `TEST.BATCH_SIZE`: 64 (Batch size for testing/adaptation)\n- `LOADER.SAMPLER.TYPE`: 'temporal' (Implies `LabelDirichletDomainSequence` which is designed for temporal/recurring environments)\n- `LOADER.SAMPLER.GAMMA`: 0.1 (Parameter for Dirichlet distribution in the sampler, related to class imbalance handling in temporal settings)\n\n**Note on Discrepancy:** The method description states that PeTTA *adaptively adjusts* the regularization term coefficient (`lambda_t`) and the EMA update rate (`alpha_t`) based on sensed divergence. However, in the provided `RoTTA` implementation, the EMA update rate (`self.nu`, configured by `ADAPTER.RoTTA.NU`) and the memory bank parameters (`self.lambda_t`, `self.lambda_u` from `ADAPTER.RoTTA.LAMBDA_T`, `ADAPTER.RoTTA.LAMBDA_U`) are fixed hyperparameters read from the configuration, not dynamically adjusted during adaptation based on a divergence metric."
}{
    "Title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
    "Main Contributions": "The paper introduces Active Test-Time Adaptation (ATTA), a novel problem setting that integrates active learning within the fully Test-Time Adaptation (TTA) framework to address significant distribution shifts for streaming test data. The main contributions include a learning theory analysis demonstrating that incorporating limited labeled test instances enhances overall performance with theoretical guarantees, and the proposal of SimATTA, a simple yet effective ATTA algorithm. SimATTA utilizes real-time sample selection techniques, including sample entropy balancing, to avoid catastrophic forgetting. Extensive experiments confirm the theoretical analyses, showing substantial performance improvements over TTA methods, comparable effectiveness to Active Domain Adaptation (ADA) methods, and efficiency similar to TTA.",
    "Methodology": "The proposed ATTA framework formally defines the problem of optimizing a pre-trained model on streaming, continuously shifting unlabeled test data by actively selecting and labeling a limited number of informative instances. The core methodology of SimATTA involves partitioning incoming unlabeled test samples into high-entropy and low-entropy sets. Low-entropy samples are pseudo-labeled by the frozen source-pretrained model to form a 'source-like' dataset, primarily to mitigate catastrophic forgetting. High-entropy samples are selected for active labeling (by an oracle) to address distribution shifts, using a novel incremental clustering technique. This clustering method, based on weighted K-means, stores representative samples (anchors) from seen distributions, adapting to new distributions by adding new clusters and merging old ones when exceeding a cluster budget. The model is then fine-tuned using both the pseudo-labeled low-entropy data and the actively labeled high-entropy anchors, balancing their respective training weights and sample numbers as guided by theoretical analyses.",
    "Experimental Setup": "The evaluation of ATTA and SimATTA involves comparisons with three settings: standard TTA, enhanced TTA (TTA baselines fine-tuned with random labeled samples), and Active Domain Adaptation (ADA). Datasets used include PACS, VLCS, Office-Home, and Tiny-ImageNet-C, covering various domain shifts and scales. Source domains were designated (e.g., 'photos' for PACS, 'Caltech101' for VLCS). Two data stream strategies were employed: domain-wise (processing one target domain completely before the next) and random (shuffling samples from all target domains into splits). Baselines for TTA included BN w/o adapt, BN w/ adapt, Tent, EATA, CoTTA, and SAR. ADA baselines included Random, Entropy, K-means, and CLUE. Models used were ResNet-18 (PACS, VLCS, Tiny-ImageNet-C) and ResNet-50 (Office-Home), initialized with ImageNet pre-trained weights. Optimization used Adam for source pre-training and SGD for test-time adaptation, with specific learning rates. SimATTA's label budget was limited (e.g., B ≤ 300 or B ≤ 500 for most datasets, around 4,000 for Tiny-ImageNet-C). Ablation studies were conducted on PACS and VLCS to evaluate the individual contributions of incremental clustering and low-entropy sample training.",
    "Limitations": "The current approach relies on the quality of the pre-trained model for selective entropy minimization, meaning training on incorrectly pseudo-labeled low-entropy samples might reinforce errors. It might not be cost-effective to expend annotation budgets on low-entropy samples. The theoretical bounds established can be loose given small batch sizes, though fine-tuning pre-trained models is empirically argued to behave like learning with a smaller effective VC-dimension. The paper focuses on foundational aspects and major challenges of ATTA, thus not covering various potential applications, scaling up for very large models/datasets (e.g., LLMs), or extensive task-specific configurations.",
    "Future Research Directions": "Potential future research directions include developing alternative methods to prevent catastrophic forgetting in ATTA scenarios, especially exploring more cost-effective strategies for annotation budgets on low-entropy samples, such as correcting incorrect pseudo-labels. Further exploration into scaling the ATTA setting up for large models and datasets, including large language models (LLMs), is also suggested. Additionally, bridging the gap between causal inference and deep learning, possibly through causal representation learning, is identified as a promising avenue for out-of-distribution generalization beyond existing domain generalization and test-time adaptation methods.",
    "Experiment Code": "import copy\nimport pathlib\nimport time\nfrom typing import Union\n\nimport numpy as np\n# from sklearnex import patch_sklearn, config_context\n# patch_sklearn()\n\n# from sklearn.cluster import KMeans\n# from ATTA.utils.fast_pytorch_kmeans import KMeans\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom typing import Literal\n\nfrom torch import nn\nimport torch\n# import models for resnet18\nfrom munch import Munch\nfrom ATTA import register\nfrom ATTA.utils.config_reader import Conf\nfrom ATTA.data.loaders.fast_data_loader import InfiniteDataLoader, FastDataLoader\nfrom torch.utils.data import TensorDataset\nfrom tqdm import tqdm\nfrom .Base import AlgBase\nimport pandas as pd\nfrom ATTA.definitions import STORAGE_DIR\n\n\n\n@register.alg_register\nclass SimATTA(AlgBase):\n    def __init__(self, config: Conf):\n        super(SimATTA, self).__init__(config)\n\n        self.teacher = copy.deepcopy(self.model.to('cpu'))\n\n        self.model.to(config.device)\n        self.teacher.to(config.device)\n        self.update_teacher(0)  # copy student to teacher\n\n        self.budgets = 0\n        self.anchors = None\n        self.source_anchors = None\n        self.buffer = []\n        self.n_clusters = 10\n        self.nc_increase = self.config.atta.SimATTA.nc_increase\n        self.source_n_clusters = 100\n\n        self.cold_start = self.config.atta.SimATTA.cold_start\n\n        self.consistency_weight = 0\n        self.alpha_teacher = 0\n        self.accumulate_weight = True\n        self.weighted_entropy: Union[Literal['low', 'high', 'both'], None] = 'both'\n        self.aggressive = True\n        self.beta = self.config.atta.SimATTA.beta\n        self.alpha = 0.2\n\n        self.target_cluster = True if self.config.atta.SimATTA.target_cluster else False\n        self.LE = True if self.config.atta.SimATTA.LE else False\n        self.vis_round = 0\n\n\n    def __call__(self, *args, **kwargs):\n        # super(SimATTA, self).__call__()\n        self.continue_result_df = pd.DataFrame(\n            index=['Current domain', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in self.config.dataset.test_envs), 'Test AVG'], dtype=float)\n        self.random_result_df = pd.DataFrame(\n            index=['Current step', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in range(4)), 'Test AVG'], dtype=float)\n\n        self.enable_bn(self.model)\n        if 'ImageNet' not in self.config.dataset.name:\n            for env_id in self.config.dataset.test_envs:\n                acc = self.test_on_env(env_id)[1]\n                self.continue_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n                self.random_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n\n        for adapt_id in self.config.dataset.test_envs[1:]:\n            self.continue_result_df.loc['Current domain', adapt_id] = self.adapt_on_env(self.fast_loader, adapt_id)\n            self.continue_result_df.loc['Budgets', adapt_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.continue_result_df.loc[env_id, adapt_id] = self.test_on_env(env_id)[1]\n\n        self.__init__(self.config)\n        for target_split_id in range(4):\n            self.random_result_df.loc['Current step', target_split_id] = self.adapt_on_env(self.target_loader, target_split_id)\n            self.random_result_df.loc['Budgets', target_split_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.random_result_df.loc[env_id, target_split_id] = self.test_on_env(env_id)[1]\n\n        print(f'#IM#\\n{self.continue_result_df.round(4).to_markdown()}\\n'\n              f'{self.random_result_df.round(4).to_markdown()}')\n        # print(self.random_result_df.round(4).to_markdown(), '\\n')\n        self.continue_result_df.round(4).to_csv(f'{self.config.log_file}.csv')\n        self.random_result_df.round(4).to_csv(f'{self.config.log_file}.csv', mode='a')\n\n\n    @torch.no_grad()\n    def val_anchor(self, loader):\n        self.model.eval()\n        val_loss = 0\n        val_acc = 0\n        for data, target in loader:\n            data, target = data.to(self.config.device), target.to(self.config.device)\n            output = self.fc(self.encoder(data))\n            val_loss += self.config.metric.loss_func(output, target, reduction='sum').item()\n            val_acc += self.config.metric.score_func(target, output) * len(data)\n        val_loss /= len(loader.sampler)\n        val_acc /= len(loader.sampler)\n        return val_loss, val_acc\n\n    def update_teacher(self, alpha_teacher):  # , iteration):\n        for t_param, s_param in zip(self.teacher.parameters(), self.model.parameters()):\n            t_param.data[:] = alpha_teacher * t_param[:].data[:] + (1 - alpha_teacher) * s_param[:].data[:]\n        if not self.config.model.freeze_bn:\n            for tm, m in zip(self.teacher.modules(), self.model.modules()):\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    tm.running_mean = alpha_teacher * tm.running_mean + (1 - alpha_teacher) * m.running_mean\n                    tm.running_var = alpha_teacher * tm.running_var + (1 - alpha_teacher) * m.running_var\n\n    @torch.enable_grad()\n    def cluster_train(self, target_anchors, source_anchors):\n        self.model.train()\n\n        source_loader = InfiniteDataLoader(TensorDataset(source_anchors.data, source_anchors.target), weights=None,\n                                           batch_size=self.config.train.train_bs,\n                                           num_workers=self.config.num_workers)\n        target_loader = InfiniteDataLoader(TensorDataset(target_anchors.data, target_anchors.target), weights=None,\n                                             batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        alpha = target_anchors.num_elem() / (target_anchors.num_elem() + source_anchors.num_elem())\n        if source_anchors.num_elem() < self.cold_start:\n            alpha = min(0.2, alpha)\n\n        ST_loader = iter(zip(source_loader, target_loader))\n        val_loader = FastDataLoader(TensorDataset(target_anchors.data, target_anchors.target), weights=None,\n                                    batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.config.atta.SimATTA.lr, momentum=0.9)\n        # print('Cluster train')\n        delay_break = False\n        loss_window = []\n        tol = 0\n        lowest_loss = float('inf')\n        for i, ((S_data, S_targets), (T_data, T_targets)) in enumerate(ST_loader):\n            S_data, S_targets = S_data.to(self.config.device), S_targets.to(self.config.device)\n            T_data, T_targets = T_data.to(self.config.device), T_targets.to(self.config.device)\n            L_T = self.one_step_train(S_data, S_targets, T_data, T_targets, alpha, optimizer)\n            # self.update_teacher(self.alpha_teacher)\n            if len(loss_window) < self.config.atta.SimATTA.stop_tol:\n                loss_window.append(L_T.item())\n            else:\n                mean_loss = np.mean(loss_window)\n                tol += 1\n                if mean_loss < lowest_loss:\n                    lowest_loss = mean_loss\n                    tol = 0\n                if tol > 5:\n                    break\n                loss_window = []\n            if 'ImageNet' in self.config.dataset.name or 'CIFAR' in self.config.dataset.name:\n                if i > self.config.atta.SimATTA.steps:\n                    break\n\n\n    def one_step_train(self, S_data, S_targets, T_data, T_targets, alpha, optimizer):\n        # print('one step train')\n        L_S = self.config.metric.loss_func(self.model(S_data), S_targets)\n        L_T = self.config.metric.loss_func(self.model(T_data), T_targets)\n        loss = (1 - alpha) * L_S + alpha * L_T\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        return L_T\n\n    def softmax_entropy(self, x: torch.Tensor, y: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"Entropy of softmax distribution from logits.\"\"\"\n        if y is None:\n            if x.shape[1] == 1:\n                x = torch.cat([x, -x], dim=1)\n            return -(x.softmax(1) * x.log_softmax(1)).sum(1)\n        else:\n            return - 0.5 * (x.softmax(1) * y.log_softmax(1)).sum(1) - 0.5 * (y.softmax(1) * x.log_softmax(1)).sum(1)\n\n    def update_anchors(self, anchors, data, target, feats, weight):\n        if anchors is None:\n            anchors = Munch()\n            anchors.data = data\n            anchors.target = target\n            anchors.feats = feats\n            anchors.weight = weight\n            anchors.num_elem = lambda: len(anchors.data)\n        else:\n            anchors.data = torch.cat([anchors.data, data])\n            anchors.target = torch.cat([anchors.target, target])\n            anchors.feats = torch.cat([anchors.feats, feats])\n            anchors.weight = torch.cat([anchors.weight, weight])\n        return anchors\n\n    def update_anchors_feats(self, anchors):\n        # sequential_data = torch.arange(200)[:, None]\n        anchors_loader = FastDataLoader(TensorDataset(anchors.data), weights=None,\n                                        batch_size=32, num_workers=self.config.num_workers, sequential=True)\n\n        anchors.feats = None\n        self.model.eval()\n        for data in anchors_loader:\n            # print(data)\n            data = data[0].to(self.config.device)\n            if anchors.feats is None:\n                anchors.feats = self.model[0](data).cpu().detach()\n            else:\n                anchors.feats = torch.cat([anchors.feats, self.model[0](data).cpu().detach()])\n\n        return anchors\n\n    @torch.no_grad()\n    def adapt_on_env(self, loader, env_id):\n        # beta_func = torch.distributions.beta.Beta(0.8, 0.8)\n        acc = 0\n        for data, target in tqdm(loader[env_id]):\n            data, target = data.to(self.config.device), target.to(self.config.device)\n            outputs, closest, self.anchors = self.sample_select(self.model, data, target, self.anchors, int(self.n_clusters), 1, ent_bound=self.config.atta.SimATTA.eh, incremental_cluster=self.target_cluster)\n            acc += self.config.metric.score_func(target, outputs).item() * data.shape[0]\n            if self.LE:\n                _, _, self.source_anchors = self.sample_select(self.teacher, data, target, self.source_anchors, self.source_n_clusters, 0,\n                                                               use_pseudo_label=True, ent_bound=self.config.atta.SimATTA.el, incremental_cluster=False)\n            else:\n                self.source_anchors = self.update_anchors(None, torch.tensor([]), None, None, None)\n            if not self.target_cluster:\n                self.n_clusters = 0\n            self.source_n_clusters = 100\n\n            self.budgets += len(closest)\n            self.n_clusters += self.nc_increase\n            self.source_n_clusters += 1\n\n            print(self.anchors.num_elem(), self.source_anchors.num_elem())\n            if self.source_anchors.num_elem() > 0:\n                self.cluster_train(self.anchors, self.source_anchors)\n            else:\n                self.cluster_train(self.anchors, self.anchors)\n            self.anchors = self.update_anchors_feats(self.anchors)\n        acc /= len(loader[env_id].sampler)\n        print(f'#IN#Env {env_id} real-time Acc.: {acc:.4f}')\n        return acc\n\n    @torch.no_grad()\n    def sample_select(self, model, data, target, anchors, n_clusters, ent_beta, use_pseudo_label=False, ent_bound=1e-2, incremental_cluster=False):\n        model.eval()\n        feats = model[0](data)\n        outputs = model[1](feats)\n        pseudo_label = outputs.argmax(1).cpu().detach()\n        data = data.cpu().detach()\n        feats = feats.cpu().detach()\n        target = target.cpu().detach()\n        entropy = self.softmax_entropy(outputs).cpu()\n        if not incremental_cluster:\n            entropy = entropy.numpy()\n            if ent_beta == 0:\n                closest = np.argsort(entropy)[: n_clusters]\n                closest = closest[entropy[closest] < ent_bound]\n            elif ent_beta == 1:\n                closest = np.argsort(entropy)[- n_clusters:]\n                closest = closest[entropy[closest] >= ent_bound]\n            else:\n                raise NotImplementedError\n            weights = torch.zeros(len(closest), dtype=torch.float)\n        else:\n            if ent_beta == 0:\n                sample_choice = entropy < ent_bound\n            elif ent_beta == 1:\n                sample_choice = entropy >= ent_bound\n            else:\n                raise NotImplementedError\n\n            data = data[sample_choice]\n            target = target[sample_choice]\n            feats = feats[sample_choice]\n            pseudo_label = pseudo_label[sample_choice]\n\n            if anchors:\n                feats4cluster = torch.cat([anchors.feats, feats])\n                sample_weight = torch.cat([anchors.weight, torch.ones(len(feats), dtype=torch.float)])\n            else:\n                feats4cluster = feats\n                sample_weight = torch.ones(len(feats), dtype=torch.float)\n\n            if self.config.atta.gpu_clustering:\n                from ATTA.utils.fast_pytorch_kmeans import KMeans\n                from joblib import parallel_backend\n                kmeans = KMeans(n_clusters=n_clusters, n_init=10, device=self.config.device).fit(\n                    feats4cluster.to(self.config.device),\n                    sample_weight=sample_weight.to(self.config.device))\n                with parallel_backend('threading', n_jobs=8):\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n            # elif self.config.atta.gpu_clustering == 'jax':\n            #     from ott.tools.k_means import k_means as KMeans\n            #     import jax\n            #     import jax.numpy as jnp\n            #     tik = time.time()\n            #     kmeans = KMeans(jnp.array(feats4cluster.numpy()), k=n_clusters, weights=jnp.array(sample_weight.numpy()), n_init=10)\n            #     mit = time.time()\n            #     print(f'#IN#Kmeans time: {mit - tik}')\n            #     @jax.jit\n            #     def jax_pairwise_distances_argmin(c, feats):\n            #         dis = lambda x, y: jnp.sqrt(((x - y) ** 2).sum())\n            #         argmin_dis = lambda x, y: jnp.argmin(jax.vmap(dis, in_axes=(None, 0))(x, y))\n            #         return jax.vmap(argmin_dis, in_axes=(0, None))(c, feats)\n            #     raw_closest = np.array(jax_pairwise_distances_argmin(kmeans.centroids, jnp.array(feats4cluster.numpy())))c.cpu().numpy())\n            #     print(f'#IN#Pairwise distance time: {time.time() - mit}')\n            #     kmeans_labels = np.array(kmeans.assignment)\n            else:\n                from joblib import parallel_backend\n                from sklearn.cluster import KMeans\n                with parallel_backend('threading', n_jobs=8):\n                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, algorithm='elkan').fit(feats4cluster,\n                                                                                                  sample_weight=sample_weight)\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n\n\n\n            if anchors:\n                num_anchors = anchors.num_elem()\n                prev_anchor_cluster = torch.tensor(kmeans_labels[:num_anchors], dtype=torch.long)\n\n                if self.accumulate_weight:\n                    # previous anchor weight accumulation\n                    # Average the weight of the previous anchor if sharing the same cluster\n                    num_prev_anchors_per_cluster = prev_anchor_cluster.unique(return_counts=True)\n                    num_prev_anchors_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_prev_anchors_per_cluster_dict[num_prev_anchors_per_cluster[0].long()] = \\\n                    num_prev_anchors_per_cluster[1]\n\n                    num_newsample_per_cluster = torch.tensor(kmeans_labels).unique(return_counts=True)\n                    num_newsample_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_newsample_per_cluster_dict[num_newsample_per_cluster[0].long()] = num_newsample_per_cluster[1]\n                    assert (num_prev_anchors_per_cluster_dict[prev_anchor_cluster] == 0).sum() == 0\n                    # accumulate the weight of the previous anchor\n                    anchors.weight = anchors.weight + num_newsample_per_cluster_dict[prev_anchor_cluster] / \\\n                                          num_prev_anchors_per_cluster_dict[prev_anchor_cluster].float()\n\n                anchored_cluster_mask = torch.zeros(len(raw_closest), dtype=torch.bool).index_fill_(0,\n                                                                                                    prev_anchor_cluster.unique().long(),\n                                                                                                    True)\n                new_cluster_mask = ~ anchored_cluster_mask\n\n                closest = raw_closest[new_cluster_mask] - num_anchors\n                if (closest < 0).sum() != 0:\n                    # The cluster's closest sample may not belong to the cluster.\n                    # It makes sense to eliminate them.\n                    print('new_cluster_mask: ', new_cluster_mask)\n                    new_cluster_mask = torch.where(new_cluster_mask)[0]\n                    print('new_cluster_mask: ', new_cluster_mask)\n                    print(closest)\n                    print(closest >= 0)\n                    new_cluster_mask = new_cluster_mask[closest >= 0]\n                    closest = closest[closest >= 0]\n\n\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1][new_cluster_mask]\n            else:\n                num_anchors = 0\n                closest = raw_closest\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1]\n\n        if use_pseudo_label:\n            anchors = self.update_anchors(anchors, data[closest], pseudo_label[closest], feats[closest], weights)\n        else:\n            anchors = self.update_anchors(anchors, data[closest], target[closest], feats[closest], weights)\n\n        return outputs, closest, anchors\n\n    def enable_bn(self, model):\n        if not self.config.model.freeze_bn:\n            for m in model.modules():\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    m.momentum = 0.1",
    "Experiment Result": "The SimATTA framework is applied for optimizing a pre-trained model on streaming, continuously shifting unlabeled test data. The core methodology involves partitioning incoming unlabeled test samples into high-entropy and low-entropy sets. Low-entropy samples are pseudo-labeled by a frozen source-pretrained model, forming a 'source-like' dataset. High-entropy samples are selected for active labeling using a novel incremental clustering technique.\n\n**Experimental Settings:**\n*   **Framework:** ATTA (Active Test-Time Adaptation)\n*   **Method:** SimATTA\n*   **Datasets:** VLCS (Visual Concept Learning for Semantic Video Labeling Challenge) is primarily used, with PACS also available for experiments (based on `launch.py`).\n*   **Base Model:** The base model architecture is configured through `config.model.name` (e.g., ResNet-18 or ResNet-50 based on `config.model.resnet18` flag, as defined in `ATTA/networks/domainbed_networks/networks.py`).\n*   **Teacher Model:** A deep copy of the student model, which is effectively frozen or a direct copy as `alpha_teacher` is initialized to 0 in `SimATTA.__init__` and passed as 0 to `update_teacher`.\n*   **Optimizer for Fine-tuning:** Stochastic Gradient Descent (SGD) with a learning rate (`lr`) sourced from `config.atta.SimATTA.lr` and a momentum of 0.9.\n*   **Loss Function:** Dynamically set based on the dataset's task (`config.metric.loss_func`): Binary Cross Entropy for binary classification, Cross Entropy for multi-label classification, and L1 Loss for regression.\n*   **Data Loaders:** `InfiniteDataLoader` and `FastDataLoader` are utilized with `num_workers=4`.\n\n**SimATTA Specific Hyperparameters (and their sweep ranges/values):**\n*   `--atta.SimATTA.cold_start`: 100. This value defines the initial number of source-like samples required before a dynamic adjustment of the balancing weight (`alpha`) becomes less aggressive.\n*   `--atta.SimATTA.el` (Entropy Low threshold): Set to 1e-3 for VLCS (and 1e-4 for PACS, if enabled). This threshold is used to identify samples considered to be of low entropy, which are then pseudo-labeled by the teacher model.\n*   `--atta.SimATTA.eh` (Entropy High threshold): Its value is loaded from `config.atta.SimATTA.eh` (not explicitly defined in `launch.py`, implying it's a default from `SimATTA.yaml`). This threshold identifies samples considered to be of high entropy, making them candidates for active labeling.\n*   `--atta.SimATTA.nc_increase` (Number of Clusters to Increase `k`): Swept over `[0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3]`. This parameter dictates the increment in the number of target clusters in each adaptation round.\n*   `--atta.SimATTA.LE` (Low-Entropy samples enabled): Swept over `{0, 1}` (0 for False, 1 for True). When `True`, low-entropy samples are pseudo-labeled and incorporated into the model's fine-tuning process.\n*   `--atta.SimATTA.target_cluster` (Incremental Clustering for target samples enabled): Swept over `{0, 1}`. When `True`, high-entropy samples are selected using an incremental weighted K-means clustering technique.\n*   `--atta.gpu_clustering`: `True`. This flag enables GPU acceleration for the K-means clustering algorithm.\n*   `Initial high-entropy clusters (self.n_clusters)`: 10. This is the starting number of clusters for high-entropy samples.\n*   `Initial low-entropy clusters (self.source_n_clusters)`: 100. This is the starting number of clusters for low-entropy samples.\n*   `Balancing weight (self.alpha)`: Initially set to 0.2. It is dynamically adjusted during `cluster_train` based on `cold_start` and the relative number of `target_anchors` and `source_anchors`.\n*   `Steps for adaptation (self.config.atta.SimATTA.steps)`: Loaded from `config.atta.SimATTA.steps` (not explicitly defined in `launch.py`). This sets the maximum number of training iterations within an adaptation round.\n*   `Stopping tolerance for cluster training (self.config.atta.SimATTA.stop_tol)`: Loaded from `config.atta.SimATTA.stop_tol` (not explicitly defined in `launch.py`). This criterion is used to stop the `cluster_train` loop if the loss stabilizes over a few iterations.\n*   `Experiment Round (exp_round)`: 1. Used for setting random seeds to ensure reproducibility.\n*   `self.aggressive`: Initialized as `True` by default, indicating a specific (but not detailed in the provided code) behavior setting."
}{
    "Title": "Test Time Adaptation via Conjugate Pseudo-labels",
    "Main Contributions": "The paper addresses the problem of designing effective test-time adaptation (TTA) losses for neural networks facing distribution shifts with only unlabeled test samples. It presents the surprising finding that meta-learning the \"best\" TTA loss recovers a temperature-scaled softmax-entropy for cross-entropy trained classifiers, but a negative squared error for squared-loss trained classifiers. The core contribution is a principled explanation for this phenomenon through the lens of the convex conjugate function of the supervised training loss. This analysis leads to a generic recipe for deriving a suitable TTA loss for a broad class of training losses, interpreted as self-training with \"conjugate pseudo-labels\". Empirically, the proposed conjugate pseudo-labeling consistently outperforms prior TTA alternatives across various domain adaptation benchmarks, especially for classifiers trained with novel losses like PolyLoss, providing a broader framework for understanding and improving TTA.",
    "Methodology": "The methodology involves two main parts: an empirical exploration using meta-learning and a theoretical framework based on convex conjugates. For exploration, TTA loss is parameterized by a neural network and learned via meta-learning, differentiating through the adaptation process to find the loss achieving the best performance on distribution shifts. The core method proposes the conjugate adaptation loss, Lconj(hθ(x)) = f(hθ(x)) −∇f(hθ(x))⊤hθ(x), derived from the convex conjugate (f⋆) of the source training loss L(hθ(x),y) = f(hθ(x)) −y⊤hθ(x). This loss is shown to recover softmax-entropy for cross-entropy and negative squared error for squared loss. The approach is further interpreted as a self-training mechanism using specific soft pseudo-labels called \"conjugate pseudo-labels\" (˜yCPL θ (x) = ∇f(hθ(x))). The adaptation process involves updating the model parameters (specifically, scale and shift parameters of batch normalization layers) by optimizing this conjugate pseudo-label loss on temperature-scaled predictions.",
    "Experimental Setup": "The evaluation was conducted on three common corruption benchmarks (CIFAR-10-C, CIFAR-100-C, ImageNet-C) and three domain adaptation datasets (SVHN to MNIST, ImageNet-R, VisDA-C). Source classifiers used ResNet-26 for CIFAR, ResNet-18 for SVHN, and ResNet-50 for ImageNet/VisDA-C. Models were trained with cross-entropy, PolyLoss, and squared loss. Baselines included hard pseudo-labeling, soft pseudo-labeling, Entropy Minimization (TENT), Robust Pseudo-Label, and MEMO. TTA involved fine-tuning batch normalization parameters (scale and shift) and updating batch normalization statistics per batch. Performance was reported as average error across corruptions (highest severity for CIFAR, all severities for ImageNet-C). Hyperparameters (learning rate and temperature) were tuned via grid-search on validation noises for corruption benchmarks, while fixed values (T=1) were used for domain adaptation tasks without validation sets.",
    "Limitations": "The meta-learning framework used in this work was constrained to learning functions over the logits of individual inputs, which could be expanded to more complex setups involving intermediate representations or batch interactions. The paper does not fully resolve the question of what constitutes the optimal TTA loss and why, despite demonstrating the conjugate loss's proximity to the oracle supervised loss. Achieving good TTA still relies on several heuristics, such as updating only batch norm parameters, and the role of these heuristics (e.g., temperature scaling) requires a more concrete understanding. It remains an open problem to determine under which real-world distribution shifts self-training based approaches are most effective. Finally, truly unsupervised TTA would ideally not require a held-out validation dataset for hyperparameter tuning like temperature scaling.",
    "Future Research Directions": "Future research could involve expanding the meta-learning framework to learn TTA loss functions over intermediate representations or a batch of inputs, accounting for their interactions. Another direction is to gain a more concrete understanding of the role of various heuristics currently employed in TTA, such as updating only batch normalization parameters and temperature scaling. Investigating under what types of real-world distribution shifts self-training-based approaches are most beneficial and robust is also a promising area. Additionally, extending and applying the proposed conjugate pseudo-labeling framework to other machine learning settings, such as semi-supervised learning, is suggested.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Improved Test-Time Adaptation for Domain Generalization",
    "Main Contributions": "The paper addresses the domain generalization (DG) problem by proposing an Improved Test-Time Adaptation (ITTA) method. It focuses on two key factors for Test-Time Training (TTT): selecting an auxiliary TTT task and identifying reliable parameters to update. The main contributions are: 1) Introducing a learnable consistency loss for the TTT task, which contains learnable parameters adjusted to align better with the main prediction task by enforcing the same optimization direction. 2) Introducing additional adaptive parameters for the trained model and suggesting only updating these new adaptive parameters during the test phase, leaving the original model parameters unchanged. Extensive experiments demonstrate that ITTA achieves superior performance over current state-of-the-art methods on several DG benchmarks for both multi-source and single-source DG tasks.",
    "Methodology": "ITTA improves the TTT strategy in two ways. First, instead of empirically defining an auxiliary objective, a learnable consistency loss (Lwcont) is proposed for the TTT task. This loss, derived from multi-view consistency learning, incorporates a weight subnetwork (fw) with learnable parameters. Lwcont is combined with the main cross-entropy loss (Lmain), and fw is updated by minimizing the L2 norm between the normalized gradients of Lmain and Lwcont with respect to the feature extractor parameters, ensuring alignment. Second, additional adaptive parameters (fΘ) are introduced after each block of the pretrained feature extractor (fθ) during the test-time adaptation phase. Only these new adaptive parameters (Θ) are updated during testing, using the learned consistency loss as the objective. During training, fθ and the classifier fϕ are updated with a combined loss (Lmain + αLwcont), and fw is updated to align the gradients. During testing, fθ and fϕ are frozen, and fΘ is updated with the learned consistency loss on test samples. For final prediction, the original fθ and fϕ are used with the adapted fΘ.",
    "Experimental Setup": "ITTA was evaluated on five benchmark datasets: PACS, VLCS, OfficeHome, TerraInc, and DomainNet. The model uses an ImageNet pretrained ResNet18 backbone with 4 blocks as the feature extractor (fθ). Four blocks of additional adaptive parameters (fΘ) were included, each with 5 layers of learnable parameters. The weight subnetwork (fw) consists of 10 layers of learnable parameters. The classifier (fϕ) is an MLP layer. The weight parameter α for balancing main and consistency losses was set to 1. All experiments followed the rigorous DomainBed benchmark protocol, including dynamic settings for random seeds, learning rates, batch sizes, and augmentation skills. Evaluations were conducted for both multi-source (leave-one-out strategy, 60 trials per unseen domain) and single-source (PACS dataset, trained on one domain, tested on three, 60 trials per unseen domain) domain generalization tasks. Model selection used the 'training-domain validate set' method, picking the best-performing model on validation samples.",
    "Limitations": "The primary limitation lies in the computational burden introduced by the learnable consistency loss. Updating the weight subnetwork (fw) requires computing second-order derivatives, which translates to one extra forward pass and three extra backward passes during the training phase. This significantly increases the computational cost compared to using a simpler auxiliary loss. Additionally, while the paper uses one TTT step for efficiency, it notes that more TTT steps do not greatly improve accuracy but proportionally increase computational time, indicating a trade-off between performance and resource consumption.",
    "Future Research Directions": "Future research efforts will focus on simplifying the overall optimization process of ITTA to reduce its computational cost, particularly addressing the burden of computing second-order derivatives for the learnable consistency loss. This could involve exploring more efficient gradient alignment strategies or alternative architectures for the weight subnetwork and adaptive parameters.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.autograd as autograd\nimport random\nimport torchvision.models\nfrom collections import OrderedDict\nfrom numbers import Number\nimport operator\n\n# Helper function from domainbed.lib.misc\ndef l2_between_dicts(dict_1, dict_2, normalize=False):\n    assert len(dict_1) == len(dict_2)\n    dict_1_values = [dict_1[key] for key in sorted(dict_1.keys())]\n    dict_2_values = [dict_2[key] for key in sorted(dict_1.keys())]\n    dict_1_tensor = torch.cat(tuple([t.view(-1) for t in dict_1_values]))\n    dict_2_tensor = torch.cat(tuple([t.view(-1) for t in dict_2_values]))\n    if normalize:\n        dict_1_tensor = (dict_1_tensor-dict_1_tensor.mean().item()) / dict_1_tensor.std().item()\n        dict_2_tensor = (dict_2_tensor-dict_2_tensor.mean().item()) / dict_2_tensor.std().item()\n        dict_2_tensor = dict_2_tensor.detach()\n    return (dict_1_tensor-dict_2_tensor).pow(2).mean()\n\n# Helper class from domainbed.lib.misc\nclass ParamDict(OrderedDict):\n    \"\"\"Code adapted from https://github.com/Alok/rl_implementations/tree/master/reptile.\n    A dictionary where the values are Tensors, meant to represent weights of\n    a model. This subclass lets you perform arithmetic on weights directly.\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, *kwargs)\n\n    def _prototype(self, other, op):\n        if isinstance(other, Number):\n            return ParamDict({k: op(v, other) for k, v in self.items()})\n        elif isinstance(other, dict):\n            return ParamDict({k: op(self[k], other[k]) for k in self})\n        else:\n            raise NotImplementedError\n\n    def __add__(self, other):\n        return self._prototype(other, operator.add)\n\n    def __rmul__(self, other):\n        return self._prototype(other, operator.mul)\n\n    __mul__ = __rmul__\n\n    def __neg__(self):\n        return ParamDict({k: -v for k, v in self.items()})\n\n    def __rsub__(self, other):\n        # a- b := a + (-b)\n        return self.__add__(other.__neg__())\n\n    __sub__ = __rsub__\n\n    def __truediv__(self, other):\n        return self._prototype(other, operator.truediv)\n\n# Network component from domainbed.networks\nclass Identity(nn.Module):\n    \"\"\"An identity layer\"\"\"\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\n# Network component from domainbed.networks\ndef Classifier(in_features, out_features, is_nonlinear=False):\n    if is_nonlinear:\n        return torch.nn.Sequential(\n            torch.nn.Linear(in_features, in_features // 2),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features // 2, in_features // 4),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features // 4, out_features))\n    else:\n        return torch.nn.Linear(in_features, out_features)\n\n# Network component from domainbed.networks\nclass MappingNetwork(torch.nn.Module):\n    def __init__(self, depth=5):\n        super().__init__()\n        self.depth = depth\n        self.weight1 = nn.ParameterList()\n        self.bias1 = nn.ParameterList()\n        self.weight2 = nn.ParameterList()\n        self.bias2 = nn.ParameterList()\n        self.weight3 = nn.ParameterList()\n        self.bias3 = nn.ParameterList()\n        self.weight4 = nn.ParameterList()\n        self.bias4 = nn.ParameterList()\n        for i in range(depth):\n            self.weight1.append(nn.Parameter(torch.ones((64,56,56))))\n            self.bias1.append(nn.Parameter(torch.zeros((64,56,56))))\n\n            self.weight2.append(nn.Parameter(torch.ones((128,28,28))))\n            self.bias2.append(nn.Parameter(torch.zeros((128,28,28))))\n\n            self.weight3.append(nn.Parameter(torch.ones((256,14,14))))\n            self.bias3.append(nn.Parameter(torch.zeros((256,14,14))))\n\n            self.weight4.append(nn.Parameter(torch.ones((512, 7, 7))))\n            self.bias4.append(nn.Parameter(torch.zeros((512, 7, 7))))\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def fea1(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight1[i] * x + self.bias1[i])\n        x = self.weight1[i+1] * x + self.bias1[i+1]\n        return x\n\n    def fea2(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight2[i] * x + self.bias2[i])\n        x = self.weight2[i + 1] * x + self.bias2[i + 1]\n        return x\n\n    def fea3(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight3[i] * x + self.bias3[i])\n        x = self.weight3[i + 1] * x + self.bias3[i + 1]\n        return x\n\n    def fea4(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight4[i] * x + self.bias4[i])\n        x = self.weight4[i+1] * x + self.bias4[i+1]\n        return x\n\n# Network component from domainbed.networks\nclass Adaparams(nn.Module):\n    def __init__(self, depth=10):\n        super(Adaparams, self).__init__()\n        self.relu = nn.ReLU(inplace=True)\n        self.depth = depth\n        self.weight = nn.ParameterList()\n        self.bias = nn.ParameterList()\n        for i in range(depth):\n            self.weight.append(nn.Parameter(torch.ones(512)))\n            self.bias.append(nn.Parameter(torch.zeros(512)))\n\n    def forward(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight[i] * x + self.bias[i])\n        x = self.weight[i+1] * x + self.bias[i+1]\n        return x\n        \n\n# Featurizer for ITTA from domainbed.networks\nclass ResNet_ITTA(torch.nn.Module):\n    \"\"\"ResNet with the softmax chopped off and the batchnorm frozen\"\"\"\n    def __init__(self, input_shape, hparams):\n        super(ResNet_ITTA, self).__init__()\n        if hparams['resnet18']:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 512\n        else:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 2048\n\n        nc = input_shape[0]\n        if nc != 3:\n            tmp = self.network.conv1.weight.data.clone()\n\n            self.network.conv1 = nn.Conv2d(\n                nc, 64, kernel_size=(7, 7),\n                stride=(2, 2), padding=(3, 3), bias=False)\n\n            for i in range(nc):\n                self.network.conv1.weight.data[:, i, :, :] = tmp[:, i % 3, :, :]\n\n        # save memory\n        self.network.fc = Identity()\n        self.isaug = True\n        self.freeze_bn()\n        self.hparams = hparams\n        self.dropout = nn.Dropout(hparams['resnet_dropout'])\n        self.eps = 1e-6\n\n    def mixstyle(self, x):\n        alpha = 0.1\n        beta = torch.distributions.Beta(alpha, alpha)\n        B = x.size(0)\n        mu = x.mean(dim=[2, 3], keepdim=True)\n        var = x.var(dim=[2, 3], keepdim=True)\n        sig = (var + self.eps).sqrt()\n        mu, sig = mu.detach(), sig.detach()\n        x_normed = (x - mu) / sig\n        lmda = beta.sample((B, 1, 1, 1))\n        lmda = lmda.to(x.device)\n        perm = torch.randperm(B)\n        mu2, sig2 = mu[perm], sig[perm]\n        mu_mix = mu * lmda + mu2 * (1 - lmda)\n        sig_mix = sig * lmda + sig2 * (1 - lmda)\n        return x_normed * sig_mix + mu_mix\n\n    def fea_forward(self, x):\n        x = self.fea3(x)\n        x = self.fea4(x)\n\n        x = self.flat(x)\n        return x\n\n    def fea2(self, x, aug_x):\n        x = self.network.layer2(x)\n        aug_x = self.network.layer2(aug_x)\n        if not self.isaug:\n            aug_x = self.mixstyle(aug_x)\n        return x, aug_x\n\n    def fea3(self, x):\n        x = self.network.layer3(x)\n        return x\n\n    def fea4(self, x):\n        x = self.network.layer4(x)\n        return x\n\n    def flat(self, x):\n        x = self.network.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.network.fc(x)\n        x = self.dropout(x)\n        return x\n\n    def forward(self, x):\n        \"\"\"Encode x into a feature vector of size n_outputs.\"\"\"\n        x = self.network.conv1(x)\n        x = self.network.bn1(x)\n        x = self.network.relu(x)\n        x = self.network.maxpool(x)\n\n        x = self.network.layer1(x)\n        if random.random() > 0.5:\n            self.isaug = True\n            aug_x = self.mixstyle(x)\n        else:\n            self.isaug = False\n            aug_x = x\n\n        return x, aug_x\n\n    def train(self, mode=True):\n        \"\"\"\n        Override the default train() to freeze the BN parameters\n        \"\"\"\n        super().train(mode)\n        self.freeze_bn()\n\n    def freeze_bn(self):\n        for m in self.network.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\n# ITTA Algorithm from domainbed.algorithms\nclass ITTA(nn.Module):\n    \"\"\"\n    Improved Test-Time Adaptation (ITTA)\n    \"\"\"\n\n    def __init__(self, input_shape, num_classes, num_domains, hparams):\n        super(ITTA, self).__init__() # Inherits from Algorithm, but here for brevity, directly from nn.Module\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        # networks is a placeholder for actual imports. Assuming ResNet_ITTA, Classifier etc are defined.\n        self.featurizer = ResNet_ITTA(input_shape, hparams)\n        self.classifier = Classifier(\n            self.featurizer.n_outputs,\n            num_classes,\n            hparams['nonlinear_classifier'])\n        self.test_mapping = MappingNetwork() #specialized for resnet18\n        self.test_optimizer = torch.optim.Adam(self.test_mapping.parameters(), lr=hparams[\"lr\"]*0.1)\n        self.optimizer = torch.optim.Adam([\n            {'params': self.featurizer.parameters()},\n            {'params': self.classifier.parameters()}],\n            lr=hparams[\"lr\"],\n            weight_decay=hparams['weight_decay']\n        )\n        self.MSEloss = nn.MSELoss()\n        self.adaparams = Adaparams() #specialized for resnet18\n        self.adaparams_optimizer = torch.optim.Adam(self.adaparams.parameters(), lr=hparams[\"lr\"]*0.1)\n        self.hparams = hparams # Store hparams for later use\n\n    def _get_grads(self, loss):\n        self.optimizer.zero_grad()\n        loss.backward(inputs=list(self.featurizer.parameters()),\n                          retain_graph=True, create_graph=True)\n        dict_grads = OrderedDict(\n            [\n                (name, weights.grad.clone().view(weights.grad.size(0),-1))\n                for name, weights in self.featurizer.named_parameters()\n            ]\n        )\n\n        return dict_grads\n\n    def update(self, minibatches, unlabeled=None):\n        all_x = torch.cat([x for x,y in minibatches])\n        all_y = torch.cat([y for x,y in minibatches])\n        ############################# this is for network update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        loss = loss_reg + loss_cla\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        ############################# this is for adaparams update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        dict_reg = self._get_grads(loss_reg)\n        dict_cla = self._get_grads(loss_cla)\n        penalty = l2_between_dicts(dict_reg, dict_cla, normalize=True) * 0.1\n        self.adaparams_optimizer.zero_grad()\n        penalty.backward(inputs=list(self.adaparams.parameters()))\n        self.adaparams_optimizer.step()\n\n        return {'loss': loss_cla.item(), 'reg': loss_reg.item()}\n\n    def test_adapt(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori, z_aug = self.test_mapping.fea1(z_ori), self.test_mapping.fea1(z_aug)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.test_mapping.fea2(z_ori), self.test_mapping.fea2(z_aug)\n        z_ori, z_aug = self.featurizer.fea3(z_ori), self.featurizer.fea3(z_aug)\n        z_ori, z_aug = self.test_mapping.fea3(z_ori), self.test_mapping.fea3(z_aug)\n        z_ori, z_aug = self.featurizer.fea4(z_ori), self.featurizer.fea4(z_aug)\n        z_ori, z_aug = self.test_mapping.fea4(z_ori), self.test_mapping.fea4(z_aug)\n        z_ori, z_aug = self.featurizer.flat(z_ori), self.featurizer.flat(z_aug)\n        ########## small lr for large datasets\n        loss_reg = self.MSEloss(self.adaparams(z_aug-z_ori), torch.zeros_like(z_ori)) * self.hparams['ada_lr']\n        self.test_optimizer.zero_grad()\n        loss_reg.backward(inputs=list(self.test_mapping.parameters()))\n        self.test_optimizer.step()\n\n    def predict(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori = self.test_mapping.fea1(z_ori)\n        z_ori, z_aug = self.featurizer.fea2(z_ori,z_aug)\n        z_ori = self.test_mapping.fea2(z_ori)\n        z_ori = self.featurizer.fea3(z_ori)\n        z_ori = self.test_mapping.fea3(z_ori)\n        z_ori = self.featurizer.fea4(z_ori)\n        z_ori = self.test_mapping.fea4(z_ori)\n        z_ori = self.featurizer.flat(z_ori)\n        return self.classifier(z_ori)",
    "Experiment Result": "ITTA (Improved Test-Time Adaptation) enhances the Test-Time Training (TTT) strategy through two main contributions: a learnable consistency loss (Lwcont) and the introduction of adaptive parameters (fΘ) during test-time adaptation.\n\n**Training Phase (update method):**\n1.  **Feature Extraction and Augmentation:** For a batch of input `x`, the `featurizer` (`ResNet_ITTA`) produces an original feature `z_ori` and an augmented feature `z_aug` (using `mixstyle`). These features are further processed through the `featurizer`'s internal layers.\n2.  **Loss Calculation:**\n    *   **Main Loss (Lmain):** A standard cross-entropy loss is calculated for both `z_ori` and `z_aug` predictions from the `classifier`, summed together: `Lmain = F.cross_entropy(classifier(z_ori), y) + F.cross_entropy(classifier(z_aug), y)`.\n    *   **Learnable Consistency Loss (Lwcont):** This loss is computed using the `adaparams` (fw) subnetwork. It measures the mean squared error between the output of `adaparams` applied to the difference of `z_aug` and `z_ori`, and a zero tensor: `Lwcont = MSEloss(adaparams(z_aug - z_ori), torch.zeros_like(z_aug))`.\n    *   The total loss for the main network update is `Ltotal = Lmain + Lwcont`.\n3.  **Network Parameter Update:** The parameters of the `featurizer` and `classifier` (fθ and fϕ) are updated by minimizing `Ltotal` using `self.optimizer` (Adam).\n4.  **Weight Subnetwork (fw) Update:** To ensure alignment of `Lmain` and `Lwcont` gradients, the `adaparams` (fw) subnetwork is updated. This is done by computing the L2 norm between the normalized gradients of `Lwcont` and `Lmain` with respect to the `featurizer` parameters. This L2 norm, scaled by 0.1, acts as a `penalty` which is then used to update `adaparams` using `self.adaparams_optimizer` (Adam).\n\n**Test-Time Adaptation Phase (test_adapt method):**\n1.  During this phase, the `featurizer` (fθ) and `classifier` (fϕ) are frozen.\n2.  New adaptive parameters `fΘ` are introduced in the `MappingNetwork` (`test_mapping`) after each block of the pretrained feature extractor.\n3.  For a given test input `x`, original `z_ori` and augmented `z_aug` features are obtained. These features are passed through the `test_mapping` layers, interleaving with some fixed `featurizer` layers.\n4.  The learned consistency loss `Lwcont_test = MSEloss(adaparams(z_aug-z_ori), torch.zeros_like(z_ori)) * hparams['ada_lr']` is computed.\n5.  Only the parameters of `test_mapping` (Θ) are updated by minimizing `Lwcont_test` using `self.test_optimizer` (Adam).\n\n**Final Prediction Phase (predict method):**\n1.  The `featurizer` extracts initial features from the test input `x`.\n2.  These features are then passed sequentially through the *adapted* `test_mapping` layers (fΘ), interleaved with relevant `featurizer` layers, to produce a refined feature representation.\n3.  Finally, this refined feature is passed to the original `classifier` to obtain the final prediction.\n\n**Hyperparameters:**\n*   `lr`: Base learning rate for the main network (featurizer and classifier). (e.g., 5e-5 for larger images, 1e-3 for small images)\n*   `weight_decay`: L2 regularization for the main network. (e.g., 0. or 10^-6 to 10^-2)\n*   `batch_size`: Number of samples per minibatch. (e.g., 32 or 64)\n*   `resnet18`: Boolean, specifies if ResNet-18 is used as the backbone featurizer (default: True).\n*   `resnet_dropout`: Dropout rate for the ResNet featurizer (default: 0.).\n*   `nonlinear_classifier`: Boolean, specifies if the classifier is nonlinear (default: False).\n*   `ada_lr`: A specific learning rate applied as a multiplier to the consistency loss during test-time adaptation. This controls the step size for updating the `test_mapping` parameters (fΘ). For 'DomainNet', it's 0.1; for other datasets, it's 1e-6.\n*   Learning rate for `test_optimizer` and `adaparams_optimizer` is `hparams['lr'] * 0.1`."
}{
    "Title": "Robust Test-Time Adaptation in Dynamic Scenarios",
    "Main Contributions": "The paper introduces Practical Test-Time Adaptation (PTTA), a new and more realistic Test-Time Adaptation (TTA) setup that considers both continually changing distributions and correlative sampling in test data streams, which is crucial for real-world applications like autonomous driving. It proposes Robust Test-Time Adaptation (RoTTA) as a comprehensive method to address PTTA challenges. The work benchmarks prior methods under PTTA, highlighting their ineffectiveness due to neglecting both aspects. RoTTA achieves state-of-the-art results, significantly outperforming baselines by reducing average classification error by over 5.9% on CIFAR-10-C, 5.5% on CIFAR-100-C, and 2.2% on DomainNet, demonstrating its effectiveness and ease of implementation for practical deployment.",
    "Methodology": "The proposed Robust Test-Time Adaptation (RoTTA) method consists of three key components: 1) Robust Batch Normalization (RBN): It replaces standard batch normalization by maintaining global statistics (mean and variance) updated through exponential moving average, using statistics from a memory bank, to normalize feature maps robustly against correlative test data. 2) Category-balanced sampling with timeliness and uncertainty (CSTU): A memory bank is maintained to capture a stable snapshot of the current distribution. Samples are added based on category balance, prioritizing newer (lower age) and less uncertain (lower prediction entropy) samples, guided by pseudo-labels from the teacher model. 3) Robust training with timeliness: A teacher-student model is employed. The student model's affine parameters in RBN layers are updated by minimizing a cross-entropy loss between strong-augmented student predictions and weak-augmented teacher predictions. A time-aware reweighting strategy, `E(Ai) = exp(−Ai/N) / (1 + exp(−Ai/N))`, is applied to the loss, giving higher weight to newer samples from the memory bank. The teacher model's parameters are updated via exponential moving average of the student's parameters.",
    "Experimental Setup": "Experiments were conducted on CIFAR10-C, CIFAR100-C, and DomainNet datasets. CIFAR10-C and CIFAR100-C, common TTA benchmarks, were used to test robustness under 15 types of corruptions at severity 5, with corruption types changing continually. DomainNet, a large-scale dataset, was used for generalization under huge domain shifts, adapting from one source domain to five target domains. Pre-trained models included WildResNet-28 for CIFAR10-C, ResNeXt-29 for CIFAR100-C (from RobustBench), and ResNet-101 for DomainNet (trained with standard classification loss). Correlative sampling in test streams was simulated using a Dirichlet distribution with parameter δ (defaulted to 0.1). Adam optimizer with a learning rate of 1.0 × 10−3 and a batch size of 64 were used across all methods. The memory bank capacity for RoTTA was N=64. RoTTA's hyperparameters (α=0.05, ν=0.001, λt=1.0, λu=1.0, δ=0.1) were unified across experiments. Validation involved comparing average classification error, ablation studies for each component, and sensitivity analyses for distribution changing order, Dirichlet parameter δ, and batch size.",
    "Limitations": "The Robust Batch Normalization (RBN) used is considered a naive solution and requires careful design for its α value. The method currently lacks a way to recover the model from a collapse state, although RoTTA is designed to prevent such collapses. The simulation of correlative sampling primarily focuses on category similarity using Dirichlet distribution, and the approach needs further validation in more diverse real-world scenarios beyond this simulation.",
    "Future Research Directions": "Future work could focus on improving the RoTTA algorithm by replacing or refining some of its existing components. There is also a direction to enhance the Practical Test-Time Adaptation (PTTA) setup itself to make it even more realistic for real-world scenarios. The authors hope this work paves the way for achieving the original goal of test-time adaptation, which is robust deployment of models in dynamic real-world applications.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom ..utils import memory\nfrom .base_adapter import BaseAdapter\nfrom copy import deepcopy\nfrom .base_adapter import softmax_entropy\nfrom ..utils.bn_layers import RobustBN1d, RobustBN2d\nfrom ..utils.utils import set_named_submodule, get_named_submodule\nfrom ..utils.custom_transforms import get_tta_transforms\n\n\nclass RoTTA(BaseAdapter):\n    def __init__(self, cfg, model, optimizer):\n        super(RoTTA, self).__init__(cfg, model, optimizer)\n        self.mem = memory.CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n        self.model_ema = self.build_ema(self.model)\n        self.transform = get_tta_transforms(cfg)\n        self.nu = cfg.ADAPTER.RoTTA.NU\n        self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY\n        self.current_instance = 0\n\n    @torch.enable_grad()\n    def forward_and_adapt(self, batch_data, model, optimizer):\n        with torch.no_grad():\n            model.eval()\n            self.model_ema.eval()\n            ema_out = self.model_ema(batch_data)\n            predict = torch.softmax(ema_out, dim=1)\n            pseudo_label = torch.argmax(predict, dim=1)\n            entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1)\n\n        for i, data in enumerate(batch_data):\n            p_l = pseudo_label[i].item()\n            uncertainty = entropy[i].item()\n            current_instance = (data, p_l, uncertainty)\n            self.mem.add_instance(current_instance)\n            self.current_instance += 1\n\n            if self.current_instance % self.update_frequency == 0:\n                self.update_model(model, optimizer)\n\n        return ema_out\n\n    def update_model(self, model, optimizer):\n        model.train()\n        self.model_ema.train()\n        sup_data, ages = self.mem.get_memory()\n        l_sup = None\n        if len(sup_data) > 0:\n            sup_data = torch.stack(sup_data)\n            strong_sup_aug = self.transform(sup_data)\n            ema_sup_out = self.model_ema(sup_data)\n            stu_sup_out = model(strong_sup_aug)\n            instance_weight = timeliness_reweighting(ages)\n            l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean()\n\n        l = l_sup\n        if l is not None:\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n\n        self.update_ema_variables(self.model_ema, self.model, self.nu)\n\n    @staticmethod\n    def update_ema_variables(ema_model, model, nu):\n        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]\n        return ema_model\n\n    def configure_model(self, model: nn.Module):\n\n        model.requires_grad_(False)\n        normlayer_names = []\n\n        for name, sub_module in model.named_modules():\n            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):\n                normlayer_names.append(name)\n\n        for name in normlayer_names:\n            bn_layer = get_named_submodule(model, name)\n            if isinstance(bn_layer, nn.BatchNorm1d):\n                NewBN = RobustBN1d\n            elif isinstance(bn_layer, nn.BatchNorm2d):\n                NewBN = RobustBN2d\n            else:\n                raise RuntimeError()\n\n            momentum_bn = NewBN(bn_layer,\n                                self.cfg.ADAPTER.RoTTA.ALPHA)\n            momentum_bn.requires_grad_(True)\n            set_named_submodule(model, name, momentum_bn)\n        return model\n\n\ndef timeliness_reweighting(ages):\n    if isinstance(ages, list):\n        ages = torch.tensor(ages).float().cuda()\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n\n\n\nimport torch\nimport torch.nn as nn\nfrom copy import deepcopy\n\n\nclass MomentumBN(nn.Module):\n    def __init__(self, bn_layer: nn.BatchNorm2d, momentum):\n        super().__init__()\n        self.num_features = bn_layer.num_features\n        self.momentum = momentum\n        if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None:\n            self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean))\n            self.register_buffer(\"source_var\", deepcopy(bn_layer.running_var))\n            self.source_num = bn_layer.num_batches_tracked\n        self.weight = deepcopy(bn_layer.weight)\n        self.bias = deepcopy(bn_layer.bias)\n\n        self.register_buffer(\"target_mean\", torch.zeros_like(self.source_mean))\n        self.register_buffer(\"target_var\", torch.ones_like(self.source_var))\n        self.eps = bn_layer.eps\n\n        self.current_mu = None\n        self.current_sigma = None\n\n    def forward(self, x):\n        raise NotImplementedError\n\n\nclass RobustBN1d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1), var.view(1, -1)\n        else:\n            mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1)\n        bias = self.bias.view(1, -1)\n\n        return x * weight + bias\n\n\nclass RobustBN2d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1)\n        else:\n            mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1, 1, 1)\n        bias = self.bias.view(1, -1, 1, 1)\n\n        return x * weight + bias\n\n\n\nimport random\nimport copy\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\nclass MemoryItem:\n    def __init__(self, data=None, uncertainty=0, age=0):\n        self.data = data\n        self.uncertainty = uncertainty\n        self.age = age\n\n    def increase_age(self):\n        if not self.empty():\n            self.age += 1\n\n    def get_data(self):\n        return self.data, self.uncertainty, self.age\n\n    def empty(self):\n        return self.data == \"empty\"\n\n\nclass CSTU:\n    def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0):\n        self.capacity = capacity\n        self.num_class = num_class\n        self.per_class = self.capacity / self.num_class\n        self.lambda_t = lambda_t\n        self.lambda_u = lambda_u\n\n        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]\n\n    def get_occupancy(self):\n        occupancy = 0\n        for data_per_cls in self.data:\n            occupancy += len(data_per_cls)\n        return occupancy\n\n    def per_class_dist(self):\n        per_class_occupied = [0] * self.num_class\n        for cls, class_list in enumerate(self.data):\n            per_class_occupied[cls] = len(class_list)\n\n        return per_class_occupied\n\n    def add_instance(self, instance):\n        assert (len(instance) == 3)\n        x, prediction, uncertainty = instance\n        new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0)\n        new_score = self.heuristic_score(0, uncertainty)\n        if self.remove_instance(prediction, new_score):\n            self.data[prediction].append(new_item)\n        self.add_age()\n\n    def remove_instance(self, cls, score):\n        class_list = self.data[cls]\n        class_occupied = len(class_list)\n        all_occupancy = self.get_occupancy()\n        if class_occupied < self.per_class:\n            if all_occupancy < self.capacity:\n                return True\n            else:\n                majority_classes = self.get_majority_classes()\n                return self.remove_from_classes(majority_classes, score)\n        else:\n            return self.remove_from_classes([cls], score)\n\n    def remove_from_classes(self, classes: list[int], score_base):\n        max_class = None\n        max_index = None\n        max_score = None\n        for cls in classes:\n            for idx, item in enumerate(self.data[cls]):\n                uncertainty = item.uncertainty\n                age = item.age\n                score = self.heuristic_score(age=age, uncertainty=uncertainty)\n                if max_score is None or score >= max_score:\n                    max_score = score\n                    max_index = idx\n                    max_class = cls\n\n        if max_class is not None:\n            if max_score > score_base:\n                self.data[max_class].pop(max_index)\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def get_majority_classes(self):\n        per_class_dist = self.per_class_dist()\n        max_occupied = max(per_class_dist)\n        classes = []\n        for i, occupied in enumerate(per_class_dist):\n            if occupied == max_occupied:\n                classes.append(i)\n\n        return classes\n\n    def heuristic_score(self, age, uncertainty):\n        return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class)\n\n    def add_age(self):\n        for class_list in self.data:\n            for item in class_list:\n                item.increase_age()\n        return\n\n    def get_memory(self):\n        tmp_data = []\n        tmp_age = []\n\n        for class_list in self.data:\n            for item in class_list:\n                tmp_data.append(item.data)\n                tmp_age.append(item.age)\n\n        tmp_age = [x / self.capacity for x in tmp_age]\n\n        return tmp_data, tmp_age\n\n\n\n@torch.jit.script\ndef softmax_entropy(x, x_ema):\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\n\n\nimport torch\nimport torchvision.transforms.functional as F\nfrom torchvision.transforms import ColorJitter, Compose, Lambda\nfrom numpy import random\nimport PIL\nimport torchvision.transforms as transforms\n\n\ndef get_tta_transforms(cfg, gaussian_std: float=0.005, soft=False):\n    img_shape = (*cfg.INPUT.SIZE, 3)\n    n_pixels = img_shape[0]\n\n    clip_min, clip_max = 0.0, 1.0\n\n    p_hflip = 0.5\n\n    tta_transforms = transforms.Compose([\n        Clip(0.0, 1.0),\n        ColorJitterPro(\n            brightness=[0.8, 1.2] if soft else [0.6, 1.4],\n            contrast=[0.85, 1.15] if soft else [0.7, 1.3],\n            saturation=[0.75, 1.25] if soft else [0.5, 1.5],\n            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],\n            gamma=[0.85, 1.15] if soft else [0.7, 1.3]\n        ),\n        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),\n        transforms.RandomAffine(\n            degrees=[-8, 8] if soft else [-15, 15],\n            translate=(1/16, 1/16),\n            scale=(0.95, 1.05) if soft else (0.9, 1.1),\n            shear=None,\n            resample=PIL.Image.BILINEAR,\n            fillcolor=None\n        ),\n        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),\n        transforms.CenterCrop(size=n_pixels),\n        transforms.RandomHorizontalFlip(p=p_hflip),\n        GaussianNoise(0, gaussian_std),\n        Clip(clip_min, clip_max)\n    ])\n    return tta_transforms\n\n\nclass GaussianNoise(torch.nn.Module):\n    def __init__(self, mean=0., std=1.):\n        super().__init__()\n        self.std = std\n        self.mean = mean\n\n    def forward(self, img):\n        noise = torch.randn(img.size()) * self.std + self.mean\n        noise = noise.to(img.device)\n        return img + noise\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\n\nclass Clip(torch.nn.Module):\n    def __init__(self, min_val=0., max_val=1.):\n        super().__init__()\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def forward(self, img):\n        return torch.clip(img, self.min_val, self.max_val)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)\n\n\nclass ColorJitterPro(ColorJitter):\n    \"\"\"Randomly change the brightness, contrast, saturation, and gamma correction of an image.\"\"\"\n\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):\n        super().__init__(brightness, contrast, saturation, hue)\n        self.gamma = self._check_input(gamma, 'gamma')\n\n    @staticmethod\n    @torch.jit.unused\n    def get_params(brightness, contrast, saturation, hue, gamma):\n        \"\"\"Get a randomized transform to be applied on image.\n\n        Arguments are same as that of __init__.\n\n        Returns:\n            Transform which randomly adjusts brightness, contrast and\n            saturation in a random order.\n        \"\"\"\n        transforms = []\n\n        if brightness is not None:\n            brightness_factor = random.uniform(brightness[0], brightness[1])\n            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n\n        if contrast is not None:\n            contrast_factor = random.uniform(contrast[0], contrast[1])\n            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n\n        if saturation is not None:\n            saturation_factor = random.uniform(saturation[0], saturation[1])\n            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n\n        if hue is not None:\n            hue_factor = random.uniform(hue[0], hue[1])\n            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n\n        if gamma is not None:\n            gamma_factor = random.uniform(gamma[0], gamma[1])\n            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))\n\n        random.shuffle(transforms)\n        transform = Compose(transforms)\n\n        return transform\n\n    def forward(self, img):\n        \"\"\"\n        Args:\n            img (PIL Image or Tensor): Input image.\n\n        Returns:\n            PIL Image or Tensor: Color jittered image.\n        \"\"\"\n        fn_idx = torch.randperm(5)\n        for fn_id in fn_idx:\n            if fn_id == 0 and self.brightness is not None:\n                brightness = self.brightness\n                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()\n                img = F.adjust_brightness(img, brightness_factor)\n\n            if fn_id == 1 and self.contrast is not None:\n                contrast = self.contrast\n                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()\n                img = F.adjust_contrast(img, contrast_factor)\n\n            if fn_id == 2 and self.saturation is not None:\n                saturation = self.saturation\n                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()\n                img = F.adjust_saturation(img, saturation_factor)\n\n            if fn_id == 3 and self.hue is not None:\n                hue = self.hue\n                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()\n                img = F.adjust_hue(img, hue_factor)\n\n            if fn_id == 4 and self.gamma is not None:\n                gamma = self.gamma\n                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()\n                img = img.clamp(1e-8, 1.0)\n                img = F.adjust_gamma(img, gamma_factor)\n\n        return img\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + '('\n        format_string += 'brightness={0}'.format(self.brightness)\n        format_string += ', contrast={0}'.format(self.contrast)\n        format_string += ', saturation={0}'.format(self.saturation)\n        format_string += ', hue={0})'.format(self.hue)\n        format_string += ', gamma={0})'.format(self.gamma)\n        return format_string",
    "Experiment Result": "{\n  \"ADAPTER.RoTTA.MEMORY_SIZE\": 64,\n  \"CORRUPTION.NUM_CLASS\": -1,\n  \"ADAPTER.RoTTA.LAMBDA_T\": 1.0,\n  \"ADAPTER.RoTTA.LAMBDA_U\": 1.0,\n  \"ADAPTER.RoTTA.ALPHA\": 0.05,\n  \"ADAPTER.RoTTA.NU\": 0.001,\n  \"ADAPTER.RoTTA.UPDATE_FREQUENCY\": 64,\n  \"OPTIM.STEPS\": 1,\n  \"OPTIM.LR\": 0.001,\n  \"INPUT.SIZE\": [32, 32]\n}"
}{
    "Title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
    "Main Contributions": "The paper introduces Test-Time Training (TTT), a novel approach to enhance the generalization of predictive models when training and test data exhibit distribution shifts. The core idea is to convert a single unlabeled test sample into a self-supervised learning problem, allowing model parameters to be updated at test time before making a prediction. Key findings include substantial improvements in robustness on diverse image classification benchmarks (e.g., corrupted images, video frames, unknown shifts) without degrading performance on the original distribution. The method also extends naturally to online data streams by continuously updating parameters. Theoretically, the paper establishes that positive gradient correlation between the main and self-supervised task losses is a sufficient condition for TTT to improve performance.",
    "Methodology": "Test-Time Training (TTT) works by fine-tuning a pre-trained model on individual unlabeled test samples. The model is initially trained in a multi-task learning fashion on both a main classification task and a self-supervised auxiliary task, sharing a feature extractor (ResNets with Group Normalization are used). For the self-supervised task, rotation prediction (predicting 0, 90, 180, or 270-degree rotations of the input image) is employed. At test time, for each incoming unlabeled sample, the shared feature extractor's parameters are updated by minimizing the self-supervised task loss on that sample (augmented with random crop and horizontal flip). The updated model then makes the main task prediction. An 'Online Test-Time Training' version extends this by initializing parameters for the current test sample with those updated from the previous sample in a stream, taking one gradient step per image. Theoretical analysis demonstrates that for convex models, a positive inner product between the gradients of the main and self-supervised tasks guarantees performance improvement.",
    "Experimental Setup": "Experiments were conducted using ResNet-26 for CIFAR-10 and ResNet-18 for ImageNet, configured with Group Normalization. Datasets included CIFAR-10-C and ImageNet-C (benchmarking robustness to 15 types of common corruptions at 5 severity levels), VID-Robust (video frames for object recognition), and CIFAR-10.1 (a new test set simulating unknown distribution shifts for CIFAR-10). Baselines included a plain ResNet ('object recognition task only'), a model jointly trained on main and self-supervised tasks but fixed at test time ('joint training'), Unsupervised Domain Adaptation by Self-Supervision (UDA-SS), and Adversarial Logit Pairing (ALP). Optimization used Stochastic Gradient Descent (SGD). Standard TTT involved 10 gradient steps per test sample with a learning rate of 0.001, while online TTT used 1 step per sample. Performance was evaluated using test error or accuracy.",
    "Limitations": "One significant limitation is the computational cost, as Test-Time Training is slower than regular inference (e.g., up to 20 times slower for standard TTT compared to a single forward pass). The method is also sensitive to the choice of normalization layer; Batch Normalization (BN) proved ineffective due to the small batch sizes (single image) used at test time, necessitating Group Normalization (GN) or specific workarounds that might reduce performance. Furthermore, the effectiveness of TTT relies on the self-supervised task being 'well defined and non-trivial' for the given test sample; if the self-supervised task provides trivial hints (e.g., rotation prediction on images with clear black margins, or on objects like airplanes where rotation is ambiguous even for humans), TTT yields no improvement.",
    "Future Research Directions": "Future work could focus on improving the computational efficiency of Test-Time Training, potentially by exploring methods to make models amenable to faster updates during training, or by dynamically deciding when to apply TTT (e.g., using a thresholding trick based on self-supervised loss). Developing more effective and general-purpose self-supervised tasks, potentially leveraging specific domain knowledge, is another promising direction. The paper also suggests using TTT as a new evaluation benchmark for self-supervised tasks. Broader applications of TTT to other tasks (e.g., segmentation, detection) and fields (e.g., speech recognition, natural language processing) are envisioned. A more formal theoretical exploration of the 'variable decision boundary' concept introduced by TTT is also proposed. Finally, further progress in one-shot learning could potentially enhance the update rule used in TTT. The authors encourage researchers to reconsider the artificial division between training and testing, envisioning a paradigm where much of the learning occurs after model deployment.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Evaluation of Test-Time Adaptation Under Computational Time Constraints",
    "Main Contributions": "This paper proposes a novel online evaluation protocol for Test-Time Adaptation (TTA) methods that explicitly accounts for the computational cost and adaptation speed of these methods. The current evaluation protocols overlook this crucial aspect, affecting real-world applicability. The new protocol penalizes slower TTA methods by providing them with fewer samples for adaptation from a constant-speed data stream. Through extensive benchmarking of 15 TTA methods across multiple datasets and scenarios, the paper demonstrates that, when inference speed is considered, simple and fast approaches can significantly outperform more sophisticated but slower state-of-the-art methods. This highlights the critical importance of developing TTA methods that are both accurate and computationally efficient for practical deployment.",
    "Methodology": "The core of the methodology is the Realistic TTA Evaluation Protocol, which addresses the shortcomings of the conventional offline evaluation. The current protocol implicitly assumes the data stream waits for a TTA method's adaptation to complete, neglecting inference speed. The proposed realistic protocol simulates a constant-speed data stream and introduces the 'relative adaptation speed' C(g), defined as the integer ratio of the stream's speed (r) to the TTA method's processing speed (R(g(x))). If C(g) = k, the method g is allowed to adapt only every k-th sample. For skipped samples, the most recently adapted model or the initial pre-trained model (fθ) is used for prediction, assuming fθ operates in real-time (C(fθ) = 1). C(g) is computed online for each input batch using C(g(xt)) = ⌈r/R(g(x))⌉, accounting for hardware and input variations. The protocol ensures that slower methods intrinsically adapt to fewer samples, thereby penalizing their performance in a realistic online setting.",
    "Experimental Setup": "The experiments primarily focus on the task of image classification. The baseline model used is a ResNet-50-BN3, pretrained on ImageNet, with additional experiments using ViT and ResNet-18 architectures. Data streams reveal batches of size 64, except for MEMO which processes single images. Benchmarking was conducted on several datasets: ImageNet-C (with corruption level 5 for all 15 corruptions), CIFAR10-C, ImageNet-R, and ImageNet-3DCC (level 5 severity). A total of 15 state-of-the-art TTA methods, published between 2017 and 2023, were evaluated (including BN, AdaBN, SHOT, TENT, SAR, CoTTA, EATA, MEMO, DDA, among others), using their official implementations and recommended hyperparameters. The evaluation encompassed multiple scenarios: episodic domain shifts (single corruption, model reset), continual domain shifts (concatenated corruptions, no reset), varying stream speeds (ηr with η ∈ {1/16, 1/8, 1/4, 1/2, 1}), and a practical TTA setup with label imbalances (PTTA) using RoTTA on CIFAR10-C. Hyperparameter tuning effects were also studied with TENT. All results are averaged across three random seeds.",
    "Limitations": "The primary limitation identified by the paper is that existing TTA evaluation protocols overlook computational costs, making them unrealistic. An implicit limitation of the proposed realistic evaluation protocol, explored in the appendix, is its assumption of the capacity to concurrently deploy two models (the TTA method 'g' and a fast baseline model 'fθ') to handle samples skipped by 'g'. In a stricter 'single model evaluation' scenario where only one model can be deployed, and skipped samples are processed by a random classifier (due to lack of temporal correlation or bias in datasets like ImageNet-C), slower TTA methods are heavily penalized to the extent that the non-adapted pre-trained model becomes a better alternative. This suggests that the real-world applicability of slower TTA methods is highly dependent on the system's ability to process unadapted samples efficiently.",
    "Future Research Directions": "The paper strongly advocates for future research to focus on developing practical TTA methods that are both accurate and computationally efficient. Specific directions include increasing the efficiency of data-dependent adaptation methods (e.g., MEMO and DDA), which currently incur massive computational burdens and perform poorly under realistic time constraints. The authors hope their proposed evaluation scheme inspires the TTA research community to consider inference speed as a critical dimension that significantly affects real-world performance. Furthermore, there is an implicit call for developing efficient TTA methods with negligible additional computational overhead, particularly for deployment scenarios where only a single model can be used and skipped samples cannot be efficiently processed by a separate baseline.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Test-Time Adaptation for Depth Completion",
    "Main Contributions": "The paper introduces ProxyTTA, an online test-time adaptation (TTA) method for depth completion that effectively bridges the performance gap due to domain shift in a single pass. It presents a novel study on how domain shift affects different data modalities, observing that sparse depth is more resilient than image modality. Based on this, it proposes an embedding module trained in the source domain that maps sparse depth features to proxy embeddings, serving as guidance to adapt auxiliary parameters (an adaptation layer) at test time. This method is shown to improve over baselines by an average of 21.09% and is the first to introduce TTA for depth completion.",
    "Methodology": "The proposed ProxyTTA method operates in three stages: initialization, preparation, and adaptation. In the initialization stage, an adaptation layer (a convolutional layer) is integrated into the pretrained encoder and trained on the source dataset, with the rest of the network frozen. The preparation stage learns a proxy mapping by minimizing a cosine similarity loss between features encoded from sparse depth (with a null-image) and features encoded from both image and sparse depth, all from the source domain. This mapping creates 'proxy embeddings' that capture source domain photometric information. During the test-time adaptation stage, the learned proxy mapping is frozen, and only the adaptation layer parameters are updated. The adaptation loss is a linear combination of sparse depth consistency loss (L1 error), local smoothness loss (L1 penalty on gradients weighted by image gradients), and a proxy consistency loss, which maximizes the cosine similarity between target domain image and sparse depth embeddings and the fixed proxy embeddings from the source domain. This implicitly aligns target RGB features to the source distribution.",
    "Experimental Setup": "The method was evaluated on various indoor and outdoor scenarios using a mix of real and synthetic datasets. Indoor datasets include VOID, NYUv2, SceneNet, and ScanNet, primarily for VIO settings. Outdoor datasets include KITTI, Virtual KITTI (VKITTI), nuScenes, and Waymo Open Dataset, primarily for lidar sensor data. Three representative depth completion architectures were used: MSG-CHN (CNN-based), NLSPN (SPN-based), and CostDCNet (cost volume-based). Adaptation scenarios included VOID to NYUv2/SceneNet/ScanNet for indoor, and KITTI to VKITTI (with fog)/nuScenes/Waymo for outdoor. The method was compared against pretrained models, BN Adapt (updating batch statistics), BN Adapt with sparse depth consistency and local smoothness losses, and CoTTA (continual test-time domain adaptation). Performance was measured using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) on specific cropped regions and depth ranges for outdoor and full images for indoor settings.",
    "Limitations": "The effectiveness of the proxy embedding may be limited in scenarios where the source dataset is sampled from scenes that do not share any objects with the target test dataset. In such cases, the proxy embeddings would offer minimal gain, requiring reliance on generic regularizers like local smoothness. Additionally, the method assumes access to the source dataset prior to deployment for the preparation stage. This presents a challenge for 'off-the-shelf' models trained on private datasets, where the preparation pipeline (adaptation layer and proxy embedding module) would need to be released alongside the network weights during initial model training.",
    "Future Research Directions": "The authors aim to motivate further interest in Test-Time Adaptation for multi-modal tasks like depth completion. Implicitly, future work could involve developing strategies to apply this TTA method to 'off-the-shelf' models trained on private datasets, perhaps by standardizing the release of adaptation layers and proxy embedding modules. Another direction could be to investigate robust proxy embeddings or adaptation strategies for scenarios with extreme domain discrepancies where source and target scenes share very few, if any, common objects or layouts.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "What How and When Should Object Detectors Update in Continually Changing Test Domains?",
    "Main Contributions": "The paper addresses the problem of object detector performance degradation due to continually changing test-time distribution shifts, a challenge where existing Test-Time Adaptation (TTA) methods are often inefficient, prone to catastrophic forgetting, or limited to classification tasks. The main contributions include proposing an efficient online Continual Test-time Adaptation (CTA) method for object detection; introducing architecture-agnostic, lightweight adaptor modules (0.54% to 0.89% of total parameters) that enable rapid, robust adaptation and prevent catastrophic forgetting; developing a practical class-wise feature alignment method at both image and object levels to effectively resolve domain shifts; and enhancing adaptation efficiency by introducing two novel criteria that dynamically determine when to adapt, thereby skipping unnecessary updates. The approach achieves significant performance improvements (up to 4.9%p and 7.9%p in mAP for COCO->COCO-corrupted and SHIFT, respectively) while maintaining high inference speeds (around 20 FPS or higher).",
    "Methodology": "The proposed method focuses on three key aspects: 'what, how, and when' to update the model. For 'what to update', it introduces shallow, lightweight adaptors (low-rank MLPs for Transformer backbones and 1x1 CNNs for ResNet backbones) in parallel to each block of the detector's backbone. Only these adaptors are updated during test time, while the original pre-trained backbone parameters are frozen to preserve task-specific knowledge and ensure efficiency. For 'how to update', the method employs Exponentially Moving Average (EMA) feature alignment to match the feature distributions of the test domain with those of the training data. This involves using pre-computed mean (µtr) and variance (Σtr) from a small subset of training data, estimating the test-time mean (µt te) via EMA, and approximating the test variance (Σte \r\n\r\n Σtr) due to small batch sizes. The adaptation loss (L = Limg + Lobj) comprises an image-level alignment (Limg) based on KL divergence between training and test image feature distributions, and a region-level class-wise alignment (Lobj) which applies weighted KL divergence to object features, filtered by background scores and adjusted by class frequency weighting (wk,t) to mitigate class imbalance. For 'when to update', two novel, resource-free criteria are introduced to dynamically skip or resume adaptation: 1) if the current image-level distribution gap (Limg) relative to an in-domain distribution gap (Din KL) exceeds a threshold (τ1=1.1); and 2) if the current Limg relative to its exponentially moving average (Ltema) suddenly increases beyond a threshold (τ2=1.05). Adaptation proceeds if at least one criterion is met.",
    "Experimental Setup": "The research employs Faster-RCNN models with ResNet50 and Swin-Tiny backbones, both integrated with FPN. Experiments were conducted across three primary scenarios: 1) COCO \r\n\r\n COCO-C, where models are trained on MS-COCO and sequentially evaluated on COCO-C (15 realistic corruptions applied to COCO validation set) to simulate continuous and drastic test domain changes, followed by evaluation on the original COCO validation set ('Org.') to assess catastrophic forgetting. 2) SHIFT-(Discrete / Continuous), a synthetic driving image dataset with 6 classes. SHIFT-Discrete simulates drastic changes by sequential evaluation across attributes (e.g., cloudy \r\n\r\n overcast \r\n\r\n foggy), while SHIFT-Continuous evaluates on sequences with gradual transitions (e.g., clear to foggy/rainy and back). Additionally, experiments were performed on the KITTI dataset (supplementary) for driving scenes (Fog \r\n\r\n Rain \r\n\r\n Snow \r\n\r\n Clear sequence). Baselines included Direct-Test (no adaptation), ActMAD, Mean-Teacher (reproducing TeST), NORM, and DUA. Performance was evaluated using mAP (and mAP@50 for KITTI), along with efficiency metrics such as the number of forward and backward passes, Frames Per Second (FPS), and memory usage (Cache). Key hyperparameters were a learning rate of 0.001 for the SGD optimizer, EMA α of 0.01, and thresholds τ1=1.1 and τ2=1.05, with a batch size of 4 (16 for KITTI).",
    "Limitations": "1. The method approximates test feature variance by assuming it is similar to the training variance (\r\n\r\n_te \r\n\r\n \r\n\r\n_tr) due to small batch sizes, which might introduce inaccuracies if the test domain's true feature variance significantly deviates from the training data's.2. The dynamic 'when to update' criteria rely on fixed thresholds (\r\n1=1.1, \r\n2=1.05). While these values demonstrated effectiveness across tested scenarios and backbones, their optimality may be sensitive and potentially require tuning for highly diverse or novel domain shift patterns.3. The approach is primarily validated on common image corruptions and driving scenarios. Its generalizability and performance may vary for other distinct types of domain shifts or more complex, less-studied real-world environments.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts",
    "Main Contributions": "The paper addresses the challenge of poor predictive accuracy of least squares estimators when trained on scarce target domain samples in supervised domain adaptation. It introduces a novel framework to synthesize a family of robust least squares experts by altering various moment-based distribution sets. Two intuitive strategies, \"Interpolate, then Robustify\" (IR) and \"Surround, then Intersect\" (SI), are proposed to construct these sets, capturing different belief levels on the source domain's explanatory power onto the target domain. When moment information is prescribed using Kullback-Leibler or Wasserstein-type divergences, the robust estimators are shown to be efficiently formed by solving convex optimization problems. These experts are then aggregated using the Bernstein Online Aggregation algorithm to generate predictions for sequential target test samples. Numerical experiments on real data demonstrate that the proposed robust strategies can systematically outperform non-robust interpolations of empirical least squares estimators.",
    "Methodology": "The proposed framework integrates two main components: an Expert Generation Module and an Expert Aggregation Module. The Expert Generation Module constructs a set of competitive experts by solving distributionally robust least squares estimation problems. This is achieved by defining moment ambiguity sets (B) that contain distributions whose moments belong to a specified set (U). The two strategies for constructing U are: (1) \"Interpolate, then Robustify\" (IR): It interpolates between empirical source and target moments to obtain a barycenter, then forms a robustness ball of a certain radius around this barycenter. (2) \"Surround, then Intersect\" (SI): It defines two robustness balls around the empirical source and target moments, and then takes their intersection. Both strategies leverage Kullback-Leibler (KL) type or Wasserstein (WASS) type divergences to quantify distributional dissimilarity. Experts derived using KL-type divergence are solved efficiently via a gradient-descent algorithm, while those derived using Wasserstein-type divergence are formulated as second-order cone programs (for IR-WASS) or linear semidefinite programs (for SI-WASS) and solved with off-the-shelf solvers like MOSEK. The Expert Aggregation Module utilizes the Bernstein Online Aggregation (BOA) algorithm to combine the predictions of these generated experts for sequentially arriving target test samples, updating expert weights based on their performance.",
    "Experimental Setup": "The performance of the proposed robust experts (IR-KL, IR-WASS, SI-KL, SI-WASS) was evaluated on five Kaggle regression datasets: Uber&Lyft, US Births (2018), Life Expectancy, House Prices in King Country, and California Housing Prices. For each dataset, a source and target domain were defined. All available source data was used for training, while an initial target training set consisted of NT = d samples (where d is the number of features). Subsequently, J = 1000 data points from the remaining target samples were used as a sequentially arriving test stream. The experimental procedure was replicated 100 times to ensure robustness. Ridge regression had a regularization parameter η = 10^-6, and the Bernstein Online Aggregation learning rate was υ = 0.5. The robust experts generated 10 experts each, with parameters (λ for IR, ρS for SI) spaced exponentially. These were benchmarked against various convex combination strategies (CC-L, CC-TL, CC-SL, CC-TE, CC-SE), a reweighting strategy (RWS), and two dynamically adapting sequential empirical ridge regression estimators (LSE-T and LSE-T&S) which incorporated new data over time. Performance was measured by the normalized cumulative loss, averaged over 100 independent runs, at different time steps J = {5, 10, 50, 100}.",
    "Limitations": "The paper primarily focuses on ensuring competitive performance in the short term, noting that for asymptotic regimes with sufficient target sample size, directly training machine learning models on all available target data becomes more attractive. A key limitation identified is the numerical instability of KL-type divergence schemes, which stems from the computation of the log-determinant and the inverse of potentially nearly singular covariance matrices. Furthermore, setting parameters for KL-type divergence schemes is challenging due to the inherent asymmetry of the D divergence. The benchmark sequential empirical ridge regression estimators (LSE-T and LSE-T&S) were acknowledged to possess an \"unfair advantage\" in the long run because they dynamically incorporated new data, unlike the proposed experts which were trained only once at the beginning with initial target samples.",
    "Future Research Directions": "Future research could extend the current work by exploring extrapolating schemes, in addition to the interpolating schemes that were the sole focus of this paper.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
    "Main Contributions": "The paper proposes Test-Time Training (TTT), a novel approach to improve the generalization of predictive models under distribution shifts between training and test data. TTT converts a single unlabeled test sample into a self-supervised learning problem, on which model parameters are updated before making a prediction. An online version of TTT is introduced, which further enhances performance by preserving parameter states across sequential test samples. The method achieves substantial improvements on diverse image classification benchmarks, including corrupted images (CIFAR-10-C, ImageNet-C), video frames (VID-Robust), and datasets with unknown distribution shifts (CIFAR-10.1), while maintaining or slightly improving performance on the original distribution. The authors also provide theoretical insights, showing that a positive gradient correlation between the main and self-supervised task losses is a sufficient condition for TTT to reduce the main task loss in convex models, which is empirically validated.",
    "Methodology": "The core methodology involves a neural network with a Y-structure, consisting of a shared feature extractor and two task-specific branches for the main task (e.g., classification) and a self-supervised auxiliary task. The auxiliary task used is rotation prediction, where the model predicts the angle (0, 90, 180, or 270 degrees) of a rotated input image. Models are initially trained jointly on both tasks using multi-task learning on the training data. At test time, for each unlabeled test sample, the shared feature extractor's parameters are fine-tuned by minimizing only the self-supervised auxiliary task loss on that specific sample. The standard TTT takes ten gradient steps per test sample. The online version of TTT initializes parameters with those adapted from the previous test sample in a sequence and takes one gradient step per new image. Group Normalization (GN) is used in the architecture instead of Batch Normalization (BN) to mitigate issues with small batch sizes during test-time updates.",
    "Experimental Setup": "The method was evaluated on three categories of benchmarks for distribution shifts: 1. Object recognition on corrupted images using CIFAR-10-C and ImageNet-C datasets (15 corruption types, 5 severity levels). 2. Object recognition on video frames using the VID-Robust dataset. 3. Object recognition on the CIFAR-10.1 dataset, which has subtle, unknown distribution shifts. The architectures used were ResNets (26-layer for CIFAR-10, 18-layer for ImageNet). Baselines included a plain ResNet ('object recognition task only'), a model jointly trained on both tasks but fixed at test time ('joint training'), Unsupervised Domain Adaptation by Self-Supervision (UDA-SS) as an oracle comparison, and Adversarial Logit Pairing (ALP) for robustness comparison. Optimization for both joint training and TTT used Stochastic Gradient Descent (SGD) with specific learning rates (0.001 for TTT), zero weight decay, and zero momentum for TTT. Data augmentation (random crop, horizontal flip) was applied. Performance was measured using test error (%) or accuracy (%).",
    "Limitations": "Test-Time Training (TTT) incurs a higher computational cost compared to standard inference, being approximately '2 × batch size × number of iterations' times slower. The effectiveness of TTT is dependent on the self-supervised task being 'well-defined and non-trivial'; for instance, it showed limited improvement on classes where rotational cues were ambiguous or trivial (e.g., 'airplane' class with black margins). Batch Normalization (BN) is not effective with the single-image batch sizes typically used in TTT, necessitating the use of Group Normalization (GN). While empirical evidence extends the theoretical findings, the formal theoretical guarantees are primarily for smooth and convex loss functions.",
    "Future Research Directions": "Future work includes extending Test-Time Training to other machine learning tasks like segmentation, detection, speech recognition, and natural language processing. There is potential to leverage domain-specific expertise to design more effective special-purpose self-supervised tasks. The authors suggest using TTT as a new evaluation benchmark for general-purpose self-supervised tasks. Further research into improving the computational efficiency of TTT, potentially through strategies like thresholding updates based on self-supervised loss or designing models more amenable to fast updates during training, is encouraged. More broadly, the paper advocates for abandoning the traditional fixed decision boundary constraint at test time and the artificial separation of training and testing, moving towards a paradigm where learning is continuous and occurs after model deployment. A formal theoretical discussion on the concept of a variable decision boundary is also suggested.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Improved Test-Time Adaptation for Domain Generalization",
    "Main Contributions": "The main contributions are addressing the domain generalization (DG) problem by improving Test-Time Training (TTT) strategies. The work proposes an Improved Test-Time Adaptation (ITTA) method with two key components: a learnable consistency loss for the TTT task, which dynamically aligns with the main prediction task through learnable parameters and shared optimization direction, and the introduction of additional adaptive parameters in the trained model, which are exclusively updated during the test phase. ITTA achieves superior performance over state-of-the-art methods on various DG benchmarks for both multi-source and single-source tasks.",
    "Methodology": "The methodology revolves around two main strategies: 1) A Learnable Consistency Loss for TTT: Instead of empirically defining an auxiliary objective, a learnable consistency loss (Lwcont) is introduced using a weight subnetwork (fw(·)) to measure consistency between an input and its augmented version (z, z'). The loss Lwcont = ||fw(z - z')||, where fw is implemented with stacked ReLU layers. This loss is enforced to align with the main cross-entropy loss (Lmain) by minimizing the difference between their normalized gradients (min w ||ˆgmain − ˆgwcont||). Training involves alternating updates for the feature extractor/classifier and the weight subnetwork. 2) Including Additional Adaptive Parameters: New adaptive blocks (fΘ), parameterized by Θ, are inserted after each block of the pretrained feature extractor fθ. During the test-time adaptation phase, only these additional adaptive parameters fΘ are updated using the learned consistency loss (min Θ ||fw(z - z')||), leaving the original model parameters unchanged. Test-time adaptation uses an online updating setting.",
    "Experimental Setup": "ITTA was evaluated on five benchmark datasets for multi-source domain generalization: PACS, VLCS, OfficeHome, TerraInc, and DomainNet. For single-source domain generalization, the PACS dataset was used. The backbone model was an ImageNet-pretrained ResNet18 with 4 blocks as the feature extractor. The additional adaptive parameters (fΘ) consisted of 4 blocks, each implemented with 5 layers of learnable parameters. The weight subnetwork (fw) had 10 layers of learnable parameters. The classifier (fϕ) was an MLP layer. The weight parameter α for balancing main and consistency losses was set to 1. All experiments followed rigorous evaluation protocols, including 60 trials per source domain, 5,000 iteration steps per trial, and dynamic setting of random seeds, learning rates, batch size, and augmentation skills according to the DomainBed benchmark. Model selection was based on the 'training-domain validate set' method from validation samples. The primary augmentation strategy used was MixStyle [75], with additional experiments conducted using an affine transformation [41]. Test-time adaptation steps were primarily one, with ablation studies for more steps and episodic updating.",
    "Limitations": "The primary limitation is the increased computational cost. Updating the learnable weight subnetwork (fw) requires computing second-order derivatives for gradient alignment (Eq. 5), which incurs additional computational burden (1 extra forward pass and 3 extra backward passes) compared to simpler TTT objectives. Consequently, ITTA demands more FLOPS and processing time during inference compared to a baseline model, though the model size increase is moderate.",
    "Future Research Directions": "Future research will focus on simplifying the overall optimization process of ITTA and reducing its computational cost to make the method more efficient.",
    "Experiment Code": "class ITTA(Algorithm):\n    \"\"\"\n    Improved Test-Time Adaptation (ITTA)\n    \"\"\"\n\n    def __init__(self, input_shape, num_classes, num_domains, hparams):\n        super(ITTA, self).__init__(input_shape, num_classes, num_domains,\n                                  hparams)\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.featurizer = networks.ResNet_ITTA(input_shape, self.hparams)\n        self.classifier = networks.Classifier(\n            self.featurizer.n_outputs,\n            num_classes,\n            self.hparams['nonlinear_classifier'])\n        self.test_mapping = networks.MappingNetwork() #specialized for resnet18\n        self.test_optimizer = torch.optim.Adam(self.test_mapping.parameters(), lr=self.hparams[\"lr\"]*0.1)\n        self.optimizer = torch.optim.Adam([\n            {'params': self.featurizer.parameters()},\n            {'params': self.classifier.parameters()}],\n            lr=self.hparams[\"lr\"],\n            weight_decay=self.hparams['weight_decay']\n        )\n        self.MSEloss = nn.MSELoss()\n        self.adaparams = networks.Adaparams() #specialized for resnet18\n        self.adaparams_optimizer = torch.optim.Adam(self.adaparams.parameters(), lr=self.hparams[\"lr\"]*0.1)\n\n    def _get_grads(self, loss):\n        self.optimizer.zero_grad()\n        loss.backward(inputs=list(self.featurizer.parameters()),\n                          retain_graph=True, create_graph=True)\n        dict = OrderedDict(\n            [\n                (name, weights.grad.clone().view(weights.grad.size(0),-1))\n                for name, weights in self.featurizer.named_parameters()\n            ]\n        )\n\n        return dict\n\n    def update(self, minibatches, unlabeled=None):\n        all_x = torch.cat([x for x,y in minibatches])\n        all_y = torch.cat([y for x,y in minibatches])\n        ############################# this is for network update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        loss = loss_reg + loss_cla\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        ############################# this is for adaparams update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        dict_reg = self._get_grads(loss_reg)\n        dict_cla = self._get_grads(loss_cla)\n        penalty = l2_between_dicts(dict_reg, dict_cla, normalize=True) * 0.1\n        self.adaparams_optimizer.zero_grad()\n        penalty.backward(inputs=list(self.adaparams.parameters()))\n        self.adaparams_optimizer.step()\n\n        return {'loss': loss_cla.item(), 'reg': loss_reg.item()}\n\n    def test_adapt(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori, z_aug = self.test_mapping.fea1(z_ori), self.test_mapping.fea1(z_aug)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.test_mapping.fea2(z_ori), self.test_mapping.fea2(z_aug)\n        z_ori, z_aug = self.featurizer.fea3(z_ori), self.featurizer.fea3(z_aug)\n        z_ori, z_aug = self.test_mapping.fea3(z_ori), self.test_mapping.fea3(z_aug)\n        z_ori, z_aug = self.featurizer.fea4(z_ori), self.featurizer.fea4(z_aug)\n        z_ori, z_aug = self.test_mapping.fea4(z_ori), self.test_mapping.fea4(z_aug)\n        z_ori, z_aug = self.featurizer.flat(z_ori), self.featurizer.flat(z_aug)\n        ########## small lr for large datasets\n        loss_reg = self.MSEloss(self.adaparams(z_aug-z_ori), torch.zeros_like(z_ori)) * self.hparams['ada_lr']\n        self.test_optimizer.zero_grad()\n        loss_reg.backward(inputs=list(self.test_mapping.parameters()))\n        self.test_optimizer.step()\n\n    def predict(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori = self.test_mapping.fea1(z_ori)\n        z_ori, z_aug = self.featurizer.fea2(z_ori,z_aug)\n        z_ori = self.test_mapping.fea2(z_ori)\n        z_ori = self.featurizer.fea3(z_ori)\n        z_ori = self.test_mapping.fea3(z_ori)\n        z_ori = self.featurizer.fea4(z_ori)\n        z_ori = self.test_mapping.fea4(z_ori)\n        z_ori = self.featurizer.flat(z_ori)\n        return self.classifier(z_ori)\n\n\nclass ResNet_ITTA(torch.nn.Module):\n    \"\"\"ResNet with the softmax chopped off and the batchnorm frozen\"\"\"\n    def __init__(self, input_shape, hparams):\n        super(ResNet_ITTA, self).__init__()\n        if hparams['resnet18']:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 512\n        else:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 2048\n\n        nc = input_shape[0]\n        if nc != 3:\n            tmp = self.network.conv1.weight.data.clone()\n\n            self.network.conv1 = nn.Conv2d(\n                nc, 64, kernel_size=(7, 7),\n                stride=(2, 2), padding=(3, 3), bias=False)\n\n            for i in range(nc):\n                self.network.conv1.weight.data[:, i, :, :] = tmp[:, i % 3, :, :]\n\n        # save memory\n        self.network.fc = Identity()\n        self.isaug = True\n        self.freeze_bn()\n        self.hparams = hparams\n        self.dropout = nn.Dropout(hparams['resnet_dropout'])\n        self.eps = 1e-6\n\n    def mixstyle(self, x):\n        alpha = 0.1\n        beta = torch.distributions.Beta(alpha, alpha)\n        B = x.size(0)\n        mu = x.mean(dim=[2, 3], keepdim=True)\n        var = x.var(dim=[2, 3], keepdim=True)\n        sig = (var + self.eps).sqrt()\n        mu, sig = mu.detach(), sig.detach()\n        x_normed = (x - mu) / sig\n        lmda = beta.sample((B, 1, 1, 1))\n        lmda = lmda.to(x.device)\n        perm = torch.randperm(B)\n        mu2, sig2 = mu[perm], sig[perm]\n        mu_mix = mu * lmda + mu2 * (1 - lmda)\n        sig_mix = sig * lmda + sig2 * (1 - lmda)\n        return x_normed * sig_mix + mu_mix\n\n    def fea_forward(self, x):\n        x = self.fea3(x)\n        x = self.fea4(x)\n\n        x = self.flat(x)\n        return x\n\n    def fea2(self, x, aug_x):\n        x = self.network.layer2(x)\n        aug_x = self.network.layer2(aug_x)\n        if not self.isaug:\n            aug_x = self.mixstyle(aug_x)\n        return x, aug_x\n\n    def fea3(self, x):\n        x = self.network.layer3(x)\n        return x\n\n    def fea4(self, x):\n        x = self.network.layer4(x)\n        return x\n\n    def flat(self, x):\n        x = self.network.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.network.fc(x)\n        x = self.dropout(x)\n        return x\n\n    def forward(self, x):\n        \"\"\"Encode x into a feature vector of size n_outputs.\"\"\"\n        x = self.network.conv1(x)\n        x = self.network.bn1(x)\n        x = self.network.relu(x)\n        x = self.network.maxpool(x)\n\n        x = self.network.layer1(x)\n        if random.random() > 0.5:\n            self.isaug = True\n            aug_x = self.mixstyle(x)\n        else:\n            self.isaug = False\n            aug_x = x\n\n        return x, aug_x\n\n    def train(self, mode=True):\n        \"\"\"\n        Override the default train() to freeze the BN parameters\n        \"\"\"\n        super().train(mode)\n        self.freeze_bn()\n\n    def freeze_bn(self):\n        for m in self.network.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()\n\nclass MappingNetwork(torch.nn.Module):\n    def __init__(self, depth=5):\n        super().__init__()\n        self.depth = depth\n        self.weight1 = nn.ParameterList()\n        self.bias1 = nn.ParameterList()\n        self.weight2 = nn.ParameterList()\n        self.bias2 = nn.ParameterList()\n        self.weight3 = nn.ParameterList()\n        self.bias3 = nn.ParameterList()\n        self.weight4 = nn.ParameterList()\n        self.bias4 = nn.ParameterList()\n        for i in range(depth):\n            self.weight1.append(nn.Parameter(torch.ones((64,56,56))))\n            self.bias1.append(nn.Parameter(torch.zeros((64,56,56))))\n\n            self.weight2.append(nn.Parameter(torch.ones((128,28,28))))\n            self.bias2.append(nn.Parameter(torch.zeros((128,28,28))))\n\n            self.weight3.append(nn.Parameter(torch.ones((256,14,14))))\n            self.bias3.append(nn.Parameter(torch.zeros((256,14,14))))\n\n            self.weight4.append(nn.Parameter(torch.ones((512, 7, 7))))\n            self.bias4.append(nn.Parameter(torch.zeros((512, 7, 7))))\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def fea1(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight1[i] * x + self.bias1[i])\n        x = self.weight1[i+1] * x + self.bias1[i+1]\n        return x\n\n    def fea2(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight2[i] * x + self.bias2[i])\n        x = self.weight2[i + 1] * x + self.bias2[i + 1]\n        return x\n\n    def fea3(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight3[i] * x + self.bias3[i])\n        x = self.weight3[i + 1] * x + self.bias3[i + 1]\n        return x\n\n    def fea4(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight4[i] * x + self.bias4[i])\n        x = self.weight4[i+1] * x + self.bias4[i+1]\n        return x\n\n\nclass Adaparams(nn.Module):\n    def __init__(self, depth=10):\n        super(Adaparams, self).__init__()\n        self.relu = nn.ReLU(inplace=True)\n        self.depth = depth\n        self.weight = nn.ParameterList()\n        self.bias = nn.ParameterList()\n        for i in range(depth):\n            self.weight.append(nn.Parameter(torch.ones(512)))\n            self.bias.append(nn.Parameter(torch.zeros(512)))\n\n    def forward(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight[i] * x + self.bias[i])\n        x = self.weight[i+1] * x + self.bias[i+1]\n        return x\n\ndef l2_between_dicts(dict_1, dict_2, normalize=False):\n    assert len(dict_1) == len(dict_2)\n    dict_1_values = [dict_1[key] for key in sorted(dict_1.keys())]\n    dict_2_values = [dict_2[key] for key in sorted(dict_1.keys())]\n    dict_1_tensor = torch.cat(tuple([t.view(-1) for t in dict_1_values]))\n    dict_2_tensor = torch.cat(tuple([t.view(-1) for t in dict_2_values]))\n    if normalize:\n        dict_1_tensor = (dict_1_tensor-dict_1_tensor.mean().item()) / dict_1_tensor.std().item()\n        dict_2_tensor = (dict_2_tensor-dict_2_tensor.mean().item()) / dict_2_tensor.std().item()\n        dict_2_tensor = dict_2_tensor.detach()\n    return (dict_1_tensor-dict_2_tensor).pow(2).mean()\n\ndef accuracy_tsc(network, loader, weights, device):\n    correct = 0\n    total = 0\n    weights_offset = 0\n    network.featurizer.requires_grad_(False)\n    network.classifier.requires_grad_(False)\n    for x, y in loader:\n        x = x.to(device)\n        y = y.to(device)\n        network.train()\n        #############\n        for i in range(1):\n            network.test_adapt(x)\n        network.eval()\n        with torch.no_grad():\n            p = network.predict(x)\n        ##############\n        if weights is None:\n            batch_weights = torch.ones(len(x))\n        else:\n            batch_weights = weights[weights_offset : weights_offset + len(x)]\n            weights_offset += len(x)\n        batch_weights = batch_weights.to(device)\n        if p.size(1) == 1:\n            correct += (p.gt(0).eq(y).float() * batch_weights.view(-1, 1)).sum().item()\n        else:\n            correct += (p.argmax(1).eq(y).float() * batch_weights).sum().item()\n        total += batch_weights.sum().item()\n    network.train()\n    network.featurizer.requires_grad_(True)\n    network.classifier.requires_grad_(True)\n\n    return correct / total",
    "Experiment Result": "The ITTA algorithm employs two main strategies: a learnable consistency loss for Test-Time Training (TTT) and the inclusion of additional adaptive parameters. The learnable consistency loss (Lwcont) is computed as the Mean Squared Error (MSE) between the output of a weight subnetwork (Adaparams) applied to the difference of original and augmented features, and a tensor of zeros. The Adaparams subnetwork is implemented with stacked ReLU layers.\n\nDuring source domain training, the main feature extractor and classifier are updated using a combined loss of cross-entropy and Lwcont. Simultaneously, the Adaparams subnetwork is updated by minimizing a gradient alignment penalty. This penalty is calculated as the L2 distance between the normalized gradients of the Lwcont and the main cross-entropy loss, with respect to the feature extractor's parameters, scaled by a factor of 0.1.\n\nFor Test-Time Adaptation, new adaptive blocks (MappingNetwork) are inserted after each block of the pretrained ResNet feature extractor. Only these adaptive parameters are updated using the Lwcont, which is computed between features processed by these adaptive blocks and their augmented versions. The learning rate for these adaptive parameters (`ada_lr`) is dynamically set based on the dataset: 0.1 for 'DomainNet' and 1e-6 for other datasets.\n\nThe augmentation (`mixstyle`) within the `ResNet_ITTA` featurizer utilizes a Beta distribution with `alpha=0.1` to mix mean and variance statistics across a batch, applied with a 50% probability after the first ResNet layer.\n\nEvaluation is performed using `accuracy_tsc`, which incorporates online test-time adaptation by performing `network.test_adapt(x)` for each input `x` before prediction."
}{
    "Title": "TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation",
    "Main Contributions": "The paper addresses the performance degradation of deep neural networks in test-time adaptation (TTA) due to domain shifts, particularly highlighting the limitations of Transductive Batch Normalization (TBN) under impractical assumptions like large and i.i.d test batches. It proposes Test-Time Normalization (TTN), a novel domain-shift aware batch normalization strategy that interpolates between Conventional Batch Normalization (CBN) and TBN. TTN uses channel-wise interpolating weights, optimized in a post-training phase, based on the domain-shift sensitivity of each BN layer. This approach improves model robustness across various batch sizes and realistic evaluation scenarios (stationary, continuously changing, and mixed domain adaptation), while also preserving source knowledge and improving the performance of other TTA methods.",
    "Methodology": "The proposed TTN layer standardizes features by combining source statistics (mean \"µs\" and variance \"σ²s\") and current test mini-batch statistics (mean \"µ\" and variance \"σ²\") using a learnable channel-wise interpolating weight \"α\". Specifically, the combined statistics are \": \":\n\"˜µ = αµ + (1−α)µs\" and \"˜σ² = ασ² + (1−α)σ²s + α(1 −α)(µ−µs)². The method introduces a post-training phase (after pre-training, before testing) to optimize these \"α\" parameters while freezing all other model weights. This phase consists of two stages: 1) Obtaining a Prior A: By simulating domain shifts through data augmentation and comparing gradients of affine parameters (γ, β) between clean and augmented inputs, the method identifies BN layers/channels sensitive to domain shifts. A gradient distance score is computed and squared to form the prior \"A\". 2) Optimizing \"α\": \"α\" is initialized with \"A\" and then optimized using a combined loss function: cross-entropy loss (LCE) for consistent predictions on augmented data, and a mean-squared error loss (LMSE = ∥α−A∥²) to regularize \"α\" towards the prior.",
    "Experimental Setup": "The method was evaluated on:Image Classification: CIFAR-10/100-C and ImageNet-C corruption benchmark datasets, using WideResNet-40-2 (for CIFAR) and ResNet-50 (for ImageNet) as backbone models.Semantic Segmentation: Cityscapes, BDD-100K, Mapillary, GTA V, and SYNTHIA domain generalization benchmarks, using a ResNet-50-based DeepLabV3+ model.Evaluation Scenarios: Single domain adaptation, continuously changing domain adaptation, and mixed domain adaptation, all with varying test batch sizes (from 200 down to 1). Additional evaluations included source domain adaptation and class-imbalanced target domains.Baselines for comparison included normalization-based methods (TBN, AdaptiveBN, α-BN, MixNorm) and optimization-based TTA methods (TENT, SWR, CoTTA), with comparisons also made against the source model (using CBN). Post-training details involved using Adam optimizer, cosine learning rate schedule, and specific data augmentation types for prior calculation and alpha optimization.",
    "Limitations": "The proposed method employs a fixed mixing ratio (interpolating weight α) during test time. This ratio is optimized before model deployment and does not dynamically adjust based on the varying domain gaps that might be encountered during actual test-time inference.",
    "Future Research Directions": "Future work could focus on dynamically determining the optimal mixing ratio for CBN and TBN according to the specific distribution shifts encountered during test time, rather than using a fixed, pre-optimized ratio. This would allow for even greater performance improvements and adaptability.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
    "Main Contributions": "This paper introduces Active Test-Time Adaptation (ATTA), a novel problem setting that integrates active learning into fully Test-Time Adaptation (TTA) to address significant distribution shifts in streaming test data and mitigate catastrophic forgetting (CF). The key contributions include a learning theory analysis demonstrating that incorporating limited labeled test instances enhances performance with theoretical guarantees, and the proposal of SimATTA, a simple yet effective ATTA algorithm that employs real-time sample selection and balanced entropy minimization. SimATTA achieves substantial performance improvements over TTA methods and comparable effectiveness to Active Domain Adaptation (ADA) methods, while maintaining efficiency and avoiding CF.",
    "Methodology": "The ATTA problem is formally defined, aiming to optimize a pre-trained model on streaming test data by actively selecting and labeling informative instances within a budget. The theoretical framework analyzes how ATTA alleviates distribution shifts through active learning and combats catastrophic forgetting (CF) using a selective entropy minimization approach. Specifically, low-entropy samples (well-aligned with the source-pretrained model) are pseudo-labeled to act as 'source-like' data, helping to prevent CF. High-entropy samples are actively selected for annotation. The SimATTA algorithm implements this by partitioning unlabeled test samples into high and low entropy sets. High-entropy samples are selected using an incremental clustering technique (based on weighted K-means) to obtain diverse and representative 'anchors' for oracle labeling. The model is then fine-tuned using these labeled anchors and the pseudo-labeled low-entropy samples, with balanced weighting to optimize for both target domain performance and CF avoidance.",
    "Experimental Setup": "Experiments were conducted to validate ATTA's effectiveness and efficiency, and to compare it against various baselines. Datasets used include PACS, VLCS, Office-Home (from DomainBed), and Tiny-ImageNet-C, known for evaluating out-of-distribution (OOD) performance. One domain was designated as the source, and others formed test data streams (domain-wise or random order). Baselines included source-only models (BN w/o adapt, BN w/ adapt), state-of-the-art TTA methods (Tent, EATA, CoTTA, SAR), and Active Domain Adaptation (ADA) methods (Random, Entropy, K-means, CLUE). Models were ResNet-18 or ResNet-50, initialized with ImageNet pre-trained weights. Evaluation was based on accuracy, with metrics reported for current domain adaptation and post-adaptation performance on all domains. Ablation studies investigated the impact of incremental clustering and low-entropy sample training.",
    "Limitations": "The theoretical bounds can be loose with a small number of unlabeled test samples (`m`), although fine-tuning pre-trained models is empirically found to behave like training a model with a relatively small VC-dimension (`d`). The current framework does not cover situations where the support of `Y` (labels) changes, such as class-incremental problems. The selective entropy minimization for CF prevention relies on the quality of the pre-trained model, and training on incorrectly predicted low-entropy samples may reinforce errors. The cost-effectiveness of expending annotation budgets on low-entropy samples, versus correcting them, is an open question. The current paper focuses on foundational aspects and does not cover scaling ATTA for large models (e.g., LLMs) or extensive task-specific practical applications.",
    "Future Research Directions": "Future research could focus on developing alternative strategies to prevent catastrophic forgetting (CF) in ATTA scenarios, especially considering the potential pitfalls of selective entropy minimization. Investigating the cost-effectiveness of annotating low-entropy samples and exploring alternative solutions, such as correcting them, is another promising direction. Bridging the gap between causal inference and deep learning could lead to new avenues for OOD generalization. Scaling ATTA methods for large models and datasets, such as large language models (LLMs), where retraining is computationally expensive and source data may be inaccessible, represents a significant future area of exploration. Furthermore, applying and tailoring ATTA to more specialized real-world applications is also a valuable direction.",
    "Experiment Code": "import copy\nimport pathlib\nimport time\nfrom typing import Union\n\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom typing import Literal\n\nfrom torch import nn\nimport torch\nfrom munch import Munch\nfrom ATTA import register\nfrom ATTA.utils.config_reader import Conf\nfrom ATTA.data.loaders.fast_data_loader import InfiniteDataLoader, FastDataLoader\nfrom torch.utils.data import TensorDataset\nfrom tqdm import tqdm\nfrom .Base import AlgBase\nimport pandas as pd\nfrom ATTA.definitions import STORAGE_DIR\n\n\n\n@register.alg_register\nclass SimATTA(AlgBase):\n    def __init__(self, config: Conf):\n        super(SimATTA, self).__init__(config)\n\n        self.teacher = copy.deepcopy(self.model.to('cpu'))\n\n        self.model.to(config.device)\n        self.teacher.to(config.device)\n        self.update_teacher(0)  # copy student to teacher\n\n        self.budgets = 0\n        self.anchors = None\n        self.source_anchors = None\n        self.buffer = []\n        self.n_clusters = 10\n        self.nc_increase = self.config.atta.SimATTA.nc_increase\n        self.source_n_clusters = 100\n\n        self.cold_start = self.config.atta.SimATTA.cold_start\n\n        self.consistency_weight = 0\n        self.alpha_teacher = 0\n        self.accumulate_weight = True\n        self.weighted_entropy: Union[Literal['low', 'high', 'both'], None] = 'both'\n        self.aggressive = True\n        self.beta = self.config.atta.SimATTA.beta\n        self.alpha = 0.2\n\n        self.target_cluster = True if self.config.atta.SimATTA.target_cluster else False\n        self.LE = True if self.config.atta.SimATTA.LE else False\n        self.vis_round = 0\n\n\n    def __call__(self, *args, **kwargs):\n        self.continue_result_df = pd.DataFrame(\n            index=['Current domain', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in self.config.dataset.test_envs), 'Test AVG'], dtype=float)\n        self.random_result_df = pd.DataFrame(\n            index=['Current step', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in range(4)), 'Test AVG'], dtype=float)\n\n        self.enable_bn(self.model)\n        if 'ImageNet' not in self.config.dataset.name:\n            for env_id in self.config.dataset.test_envs:\n                acc = self.test_on_env(env_id)[1]\n                self.continue_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n                self.random_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n\n        for adapt_id in self.config.dataset.test_envs[1:]:\n            self.continue_result_df.loc['Current domain', adapt_id] = self.adapt_on_env(self.fast_loader, adapt_id)\n            self.continue_result_df.loc['Budgets', adapt_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.continue_result_df.loc[env_id, adapt_id] = self.test_on_env(env_id)[1]\n\n        self.__init__(self.config)\n        for target_split_id in range(4):\n            self.random_result_df.loc['Current step', target_split_id] = self.adapt_on_env(self.target_loader, target_split_id)\n            self.random_result_df.loc['Budgets', target_split_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.random_result_df.loc[env_id, target_split_id] = self.test_on_env(env_id)[1]\n\n        print(f'#IM#\\n{self.continue_result_df.round(4).to_markdown()}\\n'\n              f'{self.random_result_df.round(4).to_markdown()}')\n        self.continue_result_df.round(4).to_csv(f'{self.config.log_file}.csv')\n        self.random_result_df.round(4).to_csv(f'{self.config.log_file}.csv', mode='a')\n\n\n    def update_teacher(self, alpha_teacher):  # , iteration):\n        for t_param, s_param in zip(self.teacher.parameters(), self.model.parameters()):\n            t_param.data[:] = alpha_teacher * t_param[:].data[:] + (1 - alpha_teacher) * s_param[:].data[:]\n        if not self.config.model.freeze_bn:\n            for tm, m in zip(self.teacher.modules(), self.model.modules()):\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    tm.running_mean = alpha_teacher * tm.running_mean + (1 - alpha_teacher) * m.running_mean\n                    tm.running_var = alpha_teacher * tm.running_var + (1 - alpha_teacher) * m.running_var\n\n    @torch.enable_grad()\n    def cluster_train(self, target_anchors, source_anchors):\n        self.model.train()\n\n        source_loader = InfiniteDataLoader(TensorDataset(source_anchors.data, source_anchors.target), weights=None,\n                                           batch_size=self.config.train.train_bs,\n                                           num_workers=self.config.num_workers)\n        target_loader = InfiniteDataLoader(TensorDataset(target_anchors.data, target_anchors.target), weights=None,\n                                             batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        alpha = target_anchors.num_elem() / (target_anchors.num_elem() + source_anchors.num_elem())\n        if source_anchors.num_elem() < self.cold_start:\n            alpha = min(0.2, alpha)\n\n        ST_loader = iter(zip(source_loader, target_loader))\n        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.config.atta.SimATTA.lr, momentum=0.9)\n        delay_break = False\n        loss_window = []\n        tol = 0\n        lowest_loss = float('inf')\n        for i, ((S_data, S_targets), (T_data, T_targets)) in enumerate(ST_loader):\n            S_data, S_targets = S_data.to(self.config.device), S_targets.to(self.config.device)\n            T_data, T_targets = T_data.to(self.config.device), T_targets.to(self.config.device)\n            L_T = self.one_step_train(S_data, S_targets, T_data, T_targets, alpha, optimizer)\n            if len(loss_window) < self.config.atta.SimATTA.stop_tol:\n                loss_window.append(L_T.item())\n            else:\n                mean_loss = np.mean(loss_window)\n                tol += 1\n                if mean_loss < lowest_loss:\n                    lowest_loss = mean_loss\n                    tol = 0\n                if tol > 5:\n                    break\n                loss_window = []\n            if 'ImageNet' in self.config.dataset.name or 'CIFAR' in self.config.dataset.name:\n                if i > self.config.atta.SimATTA.steps:\n                    break\n\n\n    def one_step_train(self, S_data, S_targets, T_data, T_targets, alpha, optimizer):\n        L_S = self.config.metric.loss_func(self.model(S_data), S_targets)\n        L_T = self.config.metric.loss_func(self.model(T_data), T_targets)\n        loss = (1 - alpha) * L_S + alpha * L_T\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        return L_T\n\n    def softmax_entropy(self, x: torch.Tensor, y: torch.Tensor = None) -> torch.Tensor:\n        if y is None:\n            if x.shape[1] == 1:\n                x = torch.cat([x, -x], dim=1)\n            return -(x.softmax(1) * x.log_softmax(1)).sum(1)\n        else:\n            return - 0.5 * (x.softmax(1) * y.log_softmax(1)).sum(1) - 0.5 * (y.softmax(1) * x.log_softmax(1)).sum(1)\n\n    def update_anchors(self, anchors, data, target, feats, weight):\n        if anchors is None:\n            anchors = Munch()\n            anchors.data = data\n            anchors.target = target\n            anchors.feats = feats\n            anchors.weight = weight\n            anchors.num_elem = lambda: len(anchors.data)\n        else:\n            anchors.data = torch.cat([anchors.data, data])\n            anchors.target = torch.cat([anchors.target, target])\n            anchors.feats = torch.cat([anchors.feats, feats])\n            anchors.weight = torch.cat([anchors.weight, weight])\n        return anchors\n\n    def update_anchors_feats(self, anchors):\n        anchors_loader = FastDataLoader(TensorDataset(anchors.data), weights=None,\n                                        batch_size=32, num_workers=self.config.num_workers, sequential=True)\n\n        anchors.feats = None\n        self.model.eval()\n        for data in anchors_loader:\n            data = data[0].to(self.config.device)\n            if anchors.feats is None:\n                anchors.feats = self.model[0](data).cpu().detach()\n            else:\n                anchors.feats = torch.cat([anchors.feats, self.model[0](data).cpu().detach()])\n        return anchors\n\n    @torch.no_grad()\n    def adapt_on_env(self, loader, env_id):\n        acc = 0\n        for data, target in tqdm(loader[env_id]):\n            data, target = data.to(self.config.device), target.to(self.config.device)\n            outputs, closest, self.anchors = self.sample_select(self.model, data, target, self.anchors, int(self.n_clusters), 1, ent_bound=self.config.atta.SimATTA.eh, incremental_cluster=self.target_cluster)\n            acc += self.config.metric.score_func(target, outputs).item() * data.shape[0]\n            if self.LE:\n                _, _, self.source_anchors = self.sample_select(self.teacher, data, target, self.source_anchors, self.source_n_clusters, 0,\n                                                               use_pseudo_label=True, ent_bound=self.config.atta.SimATTA.el, incremental_cluster=False)\n            else:\n                self.source_anchors = self.update_anchors(None, torch.tensor([]), None, None, None)\n            if not self.target_cluster:\n                self.n_clusters = 0\n            self.source_n_clusters = 100\n\n            self.budgets += len(closest)\n            self.n_clusters += self.nc_increase\n            self.source_n_clusters += 1\n\n            print(self.anchors.num_elem(), self.source_anchors.num_elem())\n            if self.source_anchors.num_elem() > 0:\n                self.cluster_train(self.anchors, self.source_anchors)\n            else:\n                self.cluster_train(self.anchors, self.anchors)\n            self.anchors = self.update_anchors_feats(self.anchors)\n        acc /= len(loader[env_id].sampler)\n        print(f'#IN#Env {env_id} real-time Acc.: {acc:.4f}')\n        return acc\n\n    @torch.no_grad()\n    def sample_select(self, model, data, target, anchors, n_clusters, ent_beta, use_pseudo_label=False, ent_bound=1e-2, incremental_cluster=False):\n        model.eval()\n        feats = model[0](data)\n        outputs = model[1](feats)\n        pseudo_label = outputs.argmax(1).cpu().detach()\n        data = data.cpu().detach()\n        feats = feats.cpu().detach()\n        target = target.cpu().detach()\n        entropy = self.softmax_entropy(outputs).cpu()\n        if not incremental_cluster:\n            entropy = entropy.numpy()\n            if ent_beta == 0:\n                closest = np.argsort(entropy)[: n_clusters]\n                closest = closest[entropy[closest] < ent_bound]\n            elif ent_beta == 1:\n                closest = np.argsort(entropy)[- n_clusters:]\n                closest = closest[entropy[closest] >= ent_bound]\n            else:\n                raise NotImplementedError\n            weights = torch.zeros(len(closest), dtype=torch.float)\n        else:\n            if ent_beta == 0:\n                sample_choice = entropy < ent_bound\n            elif ent_beta == 1:\n                sample_choice = entropy >= ent_bound\n            else:\n                raise NotImplementedError\n\n            data = data[sample_choice]\n            target = target[sample_choice]\n            feats = feats[sample_choice]\n            pseudo_label = pseudo_label[sample_choice]\n\n            if anchors:\n                feats4cluster = torch.cat([anchors.feats, feats])\n                sample_weight = torch.cat([anchors.weight, torch.ones(len(feats), dtype=torch.float)])\n            else:\n                feats4cluster = feats\n                sample_weight = torch.ones(len(feats), dtype=torch.float)\n\n            if self.config.atta.gpu_clustering:\n                from ATTA.utils.fast_pytorch_kmeans import KMeans\n                from joblib import parallel_backend\n                kmeans = KMeans(n_clusters=n_clusters, n_init=10, device=self.config.device).fit(\n                    feats4cluster.to(self.config.device),\n                    sample_weight=sample_weight.to(self.config.device))\n                with parallel_backend('threading', n_jobs=8):\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n            else:\n                from joblib import parallel_backend\n                from sklearn.cluster import KMeans\n                with parallel_backend('threading', n_jobs=8):\n                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, algorithm='elkan').fit(feats4cluster,\n                                                                                                  sample_weight=sample_weight)\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n\n            if anchors:\n                num_anchors = anchors.num_elem()\n                prev_anchor_cluster = torch.tensor(kmeans_labels[:num_anchors], dtype=torch.long)\n\n                if self.accumulate_weight:\n                    num_prev_anchors_per_cluster = prev_anchor_cluster.unique(return_counts=True)\n                    num_prev_anchors_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_prev_anchors_per_cluster_dict[num_prev_anchors_per_cluster[0].long()] = \\\n                    num_prev_anchors_per_cluster[1]\n\n                    num_newsample_per_cluster = torch.tensor(kmeans_labels).unique(return_counts=True)\n                    num_newsample_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_newsample_per_cluster_dict[num_newsample_per_cluster[0].long()] = num_newsample_per_cluster[1]\n                    assert (num_prev_anchors_per_cluster_dict[prev_anchor_cluster] == 0).sum() == 0\n                    anchors.weight = anchors.weight + num_newsample_per_cluster_dict[prev_anchor_cluster] / \\\n                                          num_prev_anchors_per_cluster_dict[prev_anchor_cluster].float()\n\n                anchored_cluster_mask = torch.zeros(len(raw_closest), dtype=torch.bool).index_fill_(0,\n                                                                                                    prev_anchor_cluster.unique().long(),\n                                                                                                    True)\n                new_cluster_mask = ~ anchored_cluster_mask\n\n                closest = raw_closest[new_cluster_mask] - num_anchors\n                if (closest < 0).sum() != 0:\n                    new_cluster_mask = torch.where(new_cluster_mask)[0]\n                    new_cluster_mask = new_cluster_mask[closest >= 0]\n                    closest = closest[closest >= 0]\n\n\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1][new_cluster_mask]\n            else:\n                num_anchors = 0\n                closest = raw_closest\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1]\n\n        if use_pseudo_label:\n            anchors = self.update_anchors(anchors, data[closest], pseudo_label[closest], feats[closest], weights)\n        else:\n            anchors = self.update_anchors(anchors, data[closest], target[closest], feats[closest], weights)\n\n        return outputs, closest, anchors\n\n    def enable_bn(self, model):\n        if not self.config.model.freeze_bn:\n            for m in model.modules():\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    m.momentum = 0.1",
    "Experiment Result": "The SimATTA algorithm is implemented to address the ATTA problem, aiming to optimize a pre-trained model on streaming test data by actively selecting and labeling informative instances within a budget, while combating catastrophic forgetting. The method uses a teacher-student framework, where the teacher model is updated via Exponential Moving Average (EMA).\n\n**Key Experimental Settings and Implementation Details:**\n\n*   **Entropy-based Sample Partitioning:**\n    *   `softmax_entropy(x)` function computes the entropy of predictions to classify samples as high or low entropy.\n    *   `ent_bound` (`eh` for high-entropy samples, `el` for low-entropy samples) defines the thresholds for this partitioning. The `launch.py` script explores `el` values like `1e-3`.\n    *   High-entropy samples are selected for active learning (oracle labeling) using `ent_beta=1` in `sample_select`, choosing samples with entropy `>= ent_bound`.\n    *   Low-entropy samples are pseudo-labeled as 'source-like' data using `ent_beta=0` in `sample_select`, choosing samples with entropy `< ent_bound` for catastrophic forgetting avoidance (controlled by `self.LE` flag).\n\n*   **Active Learning with Incremental Clustering:**\n    *   High-entropy samples are actively selected using an incremental clustering technique, enabled by `self.target_cluster` (explored as `ic` [0, 1] in `launch.py`).\n    *   Weighted K-Means clustering (`sklearn.cluster.KMeans` or `ATTA.utils.fast_pytorch_kmeans.KMeans` if `gpu_clustering` is true) is applied on concatenated features of existing anchors and new samples.\n    *   `sample_weight` for K-Means combines existing anchor weights (potentially accumulated) and `torch.ones` for new samples. The method description mentions "
}{
    "Title": "Robust Test-Time Adaptation in Dynamic Scenarios",
    "Main Contributions": "The paper introduces Practical Test-Time Adaptation (PTTA), a new and more realistic TTA setup that simultaneously addresses distribution changing and correlative sampling in test data streams. It benchmarks existing TTA methods under PTTA, revealing their limitations. To overcome these challenges, the paper proposes Robust Test-Time Adaptation (RoTTA), a comprehensive method demonstrating state-of-the-art performance on CIFAR-10-C, CIFAR-100-C, and DomainNet, reducing averaged classification error significantly.",
    "Methodology": "RoTTA addresses PTTA challenges with three main components. First, Robust Batch Normalization (RBN) is introduced to stably estimate normalization statistics, replacing current batch statistics with global ones maintained by exponential moving average from buffered samples. Second, a Category-Balanced Sampling with Timeliness and Uncertainty (CSTU) memory bank is utilized. This memory bank samples data to maintain category balance while prioritizing newer and less uncertain samples based on a heuristic score. Third, robust training with timeliness is implemented using a teacher-student model. The student model is updated by minimizing a loss on the memory bank, and the teacher model is updated via an exponential moving average of the student's parameters. A time-aware reweighting strategy assigns lower weights to older samples in the loss calculation to stabilize adaptation, and only affine parameters in RBN are trained.",
    "Experimental Setup": "Experiments were conducted on CIFAR-10-C and CIFAR-100-C datasets for robustness under corruptions, where corruptions change sequentially at severity 5 to simulate distribution shifts. For generalization under large domain gaps, the DomainNet dataset was used, adapting a source pre-trained model to correlatively sampled streams of five other domains. Correlative sampling was simulated using a Dirichlet distribution with parameter δ=0.1. Pre-trained models included WildResNet-28 for CIFAR-10-C, ResNeXt-29 for CIFAR-100-C, and ResNet-101 for DomainNet. The Adam optimizer was used with a learning rate of 1.0e-3, a batch size of 64, and a memory bank capacity of N=64. RoTTA used unified hyperparameters: α=0.05, ν=0.001, λt=1.0, λu=1.0, and δ=0.1. Performance was measured by classification error, and ablation studies validated each component's efficacy. Sensitivity analyses were performed for Dirichlet parameter δ, batch size, and the hyperparameters λt/λu, α, and ν. Comparisons were made against BN, PL, TENT, LAME, CoTTA, and NOTE.",
    "Limitations": "The Robust Batch Normalization (RBN) is considered a naive solution for normalizing correlatively sampled data, requiring careful tuning of its parameter α. The current method lacks a mechanism to recover the model from a collapsed state, though RoTTA aims to prevent such occurrences. Furthermore, the evaluation of correlation primarily focused on category similarity simulated by Dirichlet distribution, indicating a need for validation in more diverse real-world scenarios.",
    "Future Research Directions": "Future work could focus on improving existing components of the RoTTA algorithm, potentially by designing more sophisticated solutions for robust batch normalization or memory management. More importantly, there's a direction to enhance the Practical Test-Time Adaptation (PTTA) setup itself to further increase its realism, aiming to bridge the gap towards deploying models effectively in complex, dynamic real-world applications.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom ..utils import memory\nfrom .base_adapter import BaseAdapter\nfrom copy import deepcopy\nfrom .base_adapter import softmax_entropy\nfrom ..utils.bn_layers import RobustBN1d, RobustBN2d\nfrom ..utils.utils import set_named_submodule, get_named_submodule\nfrom ..utils.custom_transforms import get_tta_transforms\n\n\nclass RoTTA(BaseAdapter):\n    def __init__(self, cfg, model, optimizer):\n        super(RoTTA, self).__init__(cfg, model, optimizer)\n        self.mem = memory.CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n        self.model_ema = self.build_ema(self.model)\n        self.transform = get_tta_transforms(cfg)\n        self.nu = cfg.ADAPTER.RoTTA.NU\n        self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY\n        self.current_instance = 0\n\n    @torch.enable_grad()\n    def forward_and_adapt(self, batch_data, model, optimizer):\n        with torch.no_grad():\n            model.eval()\n            self.model_ema.eval()\n            ema_out = self.model_ema(batch_data)\n            predict = torch.softmax(ema_out, dim=1)\n            pseudo_label = torch.argmax(predict, dim=1)\n            entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1)\n\n        for i, data in enumerate(batch_data):\n            p_l = pseudo_label[i].item()\n            uncertainty = entropy[i].item()\n            current_instance = (data, p_l, uncertainty)\n            self.mem.add_instance(current_instance)\n            self.current_instance += 1\n\n            if self.current_instance % self.update_frequency == 0:\n                self.update_model(model, optimizer)\n\n        return ema_out\n\n    def update_model(self, model, optimizer):\n        model.train()\n        self.model_ema.train()\n        sup_data, ages = self.mem.get_memory()\n        l_sup = None\n        if len(sup_data) > 0:\n            sup_data = torch.stack(sup_data)\n            strong_sup_aug = self.transform(sup_data)\n            ema_sup_out = self.model_ema(sup_data)\n            stu_sup_out = model(strong_sup_aug)\n            instance_weight = timeliness_reweighting(ages)\n            l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean()\n\n        l = l_sup\n        if l is not None:\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n\n        self.update_ema_variables(self.model_ema, self.model, self.nu)\n\n    @staticmethod\n    def update_ema_variables(ema_model, model, nu):\n        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]\n        return ema_model\n\n    def configure_model(self, model: nn.Module):\n        model.requires_grad_(False)\n        normlayer_names = []\n\n        for name, sub_module in model.named_modules():\n            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):\n                normlayer_names.append(name)\n\n        for name in normlayer_names:\n            bn_layer = get_named_submodule(model, name)\n            if isinstance(bn_layer, nn.BatchNorm1d):\n                NewBN = RobustBN1d\n            elif isinstance(bn_layer, nn.BatchNorm2d):\n                NewBN = RobustBN2d\n            else:\n                raise RuntimeError()\n\n            momentum_bn = NewBN(bn_layer,\n                                self.cfg.ADAPTER.RoTTA.ALPHA)\n            momentum_bn.requires_grad_(True)\n            set_named_submodule(model, name, momentum_bn)\n        return model\n\n\ndef timeliness_reweighting(ages):\n    if isinstance(ages, list):\n        ages = torch.tensor(ages).float().cuda()\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n\n\n# From core/adapter/base_adapter.py\n@torch.jit.script\ndef softmax_entropy(x, x_ema):\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\n\n# From core/utils/bn_layers.py\nclass MomentumBN(nn.Module):\n    def __init__(self, bn_layer: nn.BatchNorm2d, momentum):\n        super().__init__()\n        self.num_features = bn_layer.num_features\n        self.momentum = momentum\n        if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None:\n            self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean))\n            self.register_buffer(\"source_var\", deepcopy(bn_layer.running_var))\n            self.source_num = bn_layer.num_batches_tracked\n        self.weight = deepcopy(bn_layer.weight)\n        self.bias = deepcopy(bn_layer.bias)\n\n        self.register_buffer(\"target_mean\", torch.zeros_like(self.source_mean))\n        self.register_buffer(\"target_var\", torch.ones_like(self.source_var))\n        self.eps = bn_layer.eps\n\n        self.current_mu = None\n        self.current_sigma = None\n\n    def forward(self, x):\n        raise NotImplementedError\n\n\nclass RobustBN1d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1), var.view(1, -1)\n        else:\n            mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1)\n        bias = self.bias.view(1, -1)\n\n        return x * weight + bias\n\n\nclass RobustBN2d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1)\n        else:\n            mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1, 1, 1)\n        bias = self.bias.view(1, -1, 1, 1)\n\n        return x * weight + bias\n\n\n# From core/utils/memory.py\nimport random\nimport copy\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\nclass MemoryItem:\n    def __init__(self, data=None, uncertainty=0, age=0):\n        self.data = data\n        self.uncertainty = uncertainty\n        self.age = age\n\n    def increase_age(self):\n        if not self.empty():\n            self.age += 1\n\n    def get_data(self):\n        return self.data, self.uncertainty, self.age\n\n    def empty(self):\n        return self.data == \"empty\"\n\n\nclass CSTU:\n    def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0):\n        self.capacity = capacity\n        self.num_class = num_class\n        self.per_class = self.capacity / self.num_class\n        self.lambda_t = lambda_t\n        self.lambda_u = lambda_u\n\n        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]\n\n    def get_occupancy(self):\n        occupancy = 0\n        for data_per_cls in self.data:\n            occupancy += len(data_per_cls)\n        return occupancy\n\n    def per_class_dist(self):\n        per_class_occupied = [0] * self.num_class\n        for cls, class_list in enumerate(self.data):\n            per_class_occupied[cls] = len(class_list)\n\n        return per_class_occupied\n\n    def add_instance(self, instance):\n        assert (len(instance) == 3)\n        x, prediction, uncertainty = instance\n        new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0)\n        new_score = self.heuristic_score(0, uncertainty)\n        if self.remove_instance(prediction, new_score):\n            self.data[prediction].append(new_item)\n        self.add_age()\n\n    def remove_instance(self, cls, score):\n        class_list = self.data[cls]\n        class_occupied = len(class_list)\n        all_occupancy = self.get_occupancy()\n        if class_occupied < self.per_class:\n            if all_occupancy < self.capacity:\n                return True\n            else:\n                majority_classes = self.get_majority_classes()\n                return self.remove_from_classes(majority_classes, score)\n        else:\n            return self.remove_from_classes([cls], score)\n\n    def remove_from_classes(self, classes: list[int], score_base):\n        max_class = None\n        max_index = None\n        max_score = None\n        for cls in classes:\n            for idx, item in enumerate(self.data[cls]):\n                uncertainty = item.uncertainty\n                age = item.age\n                score = self.heuristic_score(age=age, uncertainty=uncertainty)\n                if max_score is None or score >= max_score:\n                    max_score = score\n                    max_index = idx\n                    max_class = cls\n\n        if max_class is not None:\n            if max_score > score_base:\n                self.data[max_class].pop(max_index)\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def get_majority_classes(self):\n        per_class_dist = self.per_class_dist()\n        max_occupied = max(per_class_dist)\n        classes = []\n        for i, occupied in enumerate(per_class_dist):\n            if occupied == max_occupied:\n                classes.append(i)\n\n        return classes\n\n    def heuristic_score(self, age, uncertainty):\n        return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class)\n\n    def add_age(self):\n        for class_list in self.data:\n            for item in class_list:\n                item.increase_age()\n        return\n\n    def get_memory(self):\n        tmp_data = []\n        tmp_age = []\n\n        for class_list in self.data:\n            for item in class_list:\n                tmp_data.append(item.data)\n                tmp_age.append(item.age)\n\n        tmp_age = [x / self.capacity for x in tmp_age]\n\n        return tmp_data, tmp_age",
    "Experiment Result": "RoTTA Adapter Specific Settings:\n- Memory Bank Size (MEMORY_SIZE): 64 samples\n- Model Update Frequency (UPDATE_FREQUENCY): 64 instances (same as memory bank size)\n- Teacher Model EMA Update Rate (NU): 0.001\n- Robust Batch Normalization Momentum (ALPHA): 0.05\n- Timeliness Weight for Heuristic Score (LAMBDA_T): 1.0\n- Uncertainty Weight for Heuristic Score (LAMBDA_U): 1.0\n\nOptimization Settings:\n- Adaptation Steps per Batch (OPTIM.STEPS): 1\n- Learning Rate (OPTIM.LR): 0.001\n- Optimizer Method (OPTIM.METHOD): Adam\n\nGeneral Settings:\n- Test Batch Size (TEST.BATCH_SIZE): 64\n- Number of Classes (CORRUPTION.NUM_CLASS): Determined at runtime based on the dataset (e.g., 10 for CIFAR-10, 100 for CIFAR-100)."
}{
    "Title": "Navigating Scaling Laws: Compute Optimality in Adaptive Model Training",
    "Main Contributions": "This research introduces adaptive model training, allowing models to dynamically change their 'shape' (e.g., patch size, context length, model width, batch size, training objective) during training. This adaptive approach optimizes resource allocation, enabling models to traverse between different scaling laws and significantly reduce the computational resources (FLOPs) required to achieve a target performance, often by more than 50% for Vision Transformers. The paper presents a simple and effective strategy to determine when to adapt a model, based on maximizing performance gain per unit of compute, and demonstrates its efficiency across different modalities and shape parameters.",
    "Methodology": "The core methodology involves adapting model shape parameters based on neural scaling laws. For a set of scaling laws {fP} (where P is a shape parameter) that map compute C to performance E, the method calculates the inverse laws f−1P(E), which predict the compute needed for a given performance E. To determine the optimal transition point for adapting a shape parameter, the partial derivative qP(E*) = ∂f−1P(E)/∂E | E=E* is computed. The shape parameter P that maximizes this derivative (i.e., offers the steepest descent or maximal performance gain for minimal additional compute) is chosen. This creates a scheduler for shape parameter changes. For Vision Transformers (ViTs), FlexiViT's mechanism for resizing patch embeddings and bilinearly interpolating positional encodings is used to smoothly adapt patch sizes. For adaptive model width, a simple expansion with randomly initialized weights (based on the norm of existing weights) is used, although function-preserving methods are acknowledged as ideal. The same principle is extended to adapting batch size and switching between standard and distillation training objectives.",
    "Experimental Setup": "Experiments were conducted on Vision Transformers (ViTs) and Language Models (LMs). ViTs of various sizes (e.g., V640-12, V256-6) were pre-trained on the ImageNet-21k dataset, with images resized to 120x120. Different fixed patch sizes (P ∈ {120, 60, ..., 1}) were explored, with data augmentation (random cropping, horizontal flipping). Performance was measured by 10-shot error on ImageNet-1k. Compute (FLOPs) excluded the network head and approximated backward pass as twice the forward pass. Hyperparameters were optimized using a greedy search for a fixed, small compute budget (4e17 FLOPs). LMs (Llama models with embedding dim 768, depth 12) were trained on subsets of English Wikipedia and Books datasets, evaluating on test loss. Comparisons were made against static models, FlexiViT's random patch size scheduler, and simple linear/logarithmic schedulers. Additional studies involved adapting model width, batch size ({256, 2048}), and training objectives (standard vs. distillation from a V640-10/12 teacher model). Environmental impact was estimated in tCO2eq based on GPU-hours and power consumption.",
    "Limitations": "The hyperparameter optimization was conducted with a small compute budget, and optimal parameters may differ for larger budgets. Determining the optimal scheduler requires upfront computational cost to establish scaling behaviors, though this information is often pre-existing for common parameters. Learning rate scheduling was not performed for low-compute budgets, which might influence results but is not expected to change the main conclusion. While compute-optimal, the adaptive models show the largest gains earlier in training and are not expected to achieve universally better performance with infinite compute, but rather reach target performance more efficiently. The simple random initialization used for expanding model width caused momentary performance drops, suggesting more sophisticated function-preserving expansion techniques would be beneficial. Momentary performance changes (slight degradation or boost) during shape parameter transitions were observed but quickly recovered from.",
    "Future Research Directions": "Future work could involve applying this adaptive scheduling method to other model shape parameters not explored in this paper, such as model depth or sparsity, or even to combinations of multiple parameters simultaneously for further efficiency gains. There is also scope for integrating this approach with existing techniques designed to improve scaling laws or training efficiency, such as data pruning or optimal model shaping (e.g., depth vs. width ratios), as these methods are complementary. Further research could also focus on developing more robust and function-preserving mechanisms for dynamically changing model architecture, particularly for width expansion, to minimize temporary performance degradation during transitions.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": " Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods ",
    "Main Contributions": "The paper formulates neural network optimization as a Bayesian filtering problem, where backpropagated gradients are observations. It introduces AdaBayes, an optimizer that recovers the root-mean-square gradient normalizer for Adam and RMSprop by accounting for the temporal dynamics of all other parameters. AdaBayes adaptively transitions between SGD-like and Adam-like behaviors, automatically recovers AdamW (a state-of-the-art variant of Adam with decoupled weight decay), and achieves generalization performance competitive with SGD.",
    "Methodology": "Neural network optimization is framed as Bayesian inference using Kalman filtering. The optimal weight for a parameter is treated as a latent variable, and backpropagated gradients are observations. The stochastic dynamics of the optimal weight are modeled using discretised Ornstein-Uhlenbeck dynamics for the other parameters. The Hessian (Hii) is approximated using the squared gradient. The developed algorithms are AdaBayes, which uses iterative updates for mean and variance, and AdaBayes-FP, which directly sets the variance to its fixed-point value based on a quadratic equation solution.",
    "Experimental Setup": "Experiments were conducted using a 34-layer ResNet and a 121-layer DenseNet on CIFAR-10 and CIFAR-100 datasets. Networks were trained for 200 epochs (or more), with learning rates decreasing by a factor of 10 at epoch 150. Baseline optimizers (SGD, Adam, AdaGrad, AMSGrad, AdaBound, AMSBound, AdamW) used optimized hyperparameters from previous work. For AdamW and AdaBayes, specific hyperparameters were set: \"etaSGD\"=0.1, \"sigma^2\"= \"etaSGD\"/minibatch size, \"etaAdam\"=\"eta\"=0.001, and a decoupled weight decay of 5e-4 (with \",lambda\"=5e-5). Performance was validated by comparing minimal test error and test loss.",
    "Limitations": "The approach relies on approximating the Hessian (Hii) using the squared gradient, which is noted as an area for future improvement. The assumption that other parameters obey oversimplified Ornstein-Uhlenbeck dynamics is a simplification. Empirically, SGD frequently outperforms all tested adaptive methods, including AdaBayes, particularly concerning test-loss on CIFAR-100, suggesting that adaptive methods still have generalization limitations compared to SGD in certain scenarios.",
    "Future Research Directions": "Future research directions include improving the approximation of the Hessian (Hii), further pursuing the dynamical Bayesian approach to develop improved optimizers, and exploring the exploitation of Kronecker factorisation for better optimization algorithms.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective",
    "Main Contributions": "This paper addresses the challenge of automatically choosing and dynamically adapting the 'integration schedule' (sorted discretization points) required for the Thermodynamic Variational Objective (TVO), a recently proposed variational lower bound. The key contribution is the introduction of a bespoke Gaussian process bandit optimization method for this purpose. The approach automates the selection of these points and adapts their positions during optimization, leading to improved model learning and inference. Theoretical guarantees are provided, demonstrating that the bandit optimization converges to a regret-minimizing choice of integration points. Empirical validation shows improved learning and inference in Variational Autoencoders (VAEs) and Sigmoid Belief Networks (SBNs).",
    "Methodology": "The methodology frames the choice of integration points (β, a d-dimensional vector) for the TVO as a time-varying Gaussian process (GP) bandit optimization problem. A time-varying reward function is defined as the difference in TVO log evidence estimates between training windows, which is equivalent to maximizing the final log evidence. A time-varying, permutation-invariant GP model is constructed by combining spatial and temporal covariance functions. Specifically, k(x,x') = kβ(β,β') × kT(t,t'), where kT is a temporal covariance function and kβ uses a projection operator Φ to ensure ordering constraints (0 < β1 < ... < βd-1 < 1) by sorting the β vector. At each round, the algorithm selects the next integration schedule βt by maximizing an acquisition function, a linear combination of the GP posterior mean and variance (GP-UCB variant), balancing exploration and exploitation. The GP model is then updated with the observed reward.",
    "Experimental Setup": "The method was empirically validated on Variational Autoencoders (VAEs) using MNIST and Fashion MNIST datasets, and on Sigmoid Belief Networks (SBNs) with binarized MNIST and binarized Omniglot. Additionally, it was applied to a Probabilistic Context Free Grammar (PCFG) model using the Astronomers PCFG dataset. Experiments were conducted with varying numbers of importance samples (S ∈ {10, 50}) and schedule dimensions (d ∈ {2, 5, 10, 15}), each with 5 random seeds. Model learning was measured by test log evidence (using IWAE bound with 5000 samples) and KL divergence to true parameters (for PCFG), while inference performance was measured by DKL[qφ(z|x) || pθ(z|x)]. Baselines included log-uniform, linear-uniform, and moments schedules. The GP implementation used an exponentiated quadratic kernel, type II maximum likelihood for hyperparameter estimation, multi-start BFGS for acquisition function optimization, and a dynamic update frequency (w). Ablation studies compared the GP-bandit against random search and examined permutation-invariant versus non-permutation-invariant GPs. A wall-clock time benchmark was performed against grid search.",
    "Limitations": "The primary limitation noted is that the proposed GP bandit optimization, while automating the selection of integration points, still relies on the number of partitions (d) as a fixed hyperparameter throughout the training process. Additionally, the restriction of β values to the range [0.05, 0.95]d was found necessary to avoid negative performance impacts, implying a constraint on the search space.",
    "Future Research Directions": "A clear direction for future research is to incorporate the adaptive selection of the number of partitions (d) directly into the bandit optimization framework. This would further automate the integration schedule selection beyond just the point locations, addressing the current limitation of d being a fixed hyperparameter.",
    "Experiment Code": "File Path: src/BOv.py---class BayesOpt:    def __init__(self, func, SearchSpace, GPtype=\"timevarying_perm\",verbose=1):        self.SearchSpace=SearchSpace        self.dim = SearchSpace.shape[0]        scaler = MinMaxScaler()        scaler.fit(SearchSpace.T)        self.Xscaler=scaler        self.scaleSearchSpace=np.array([np.zeros(self.dim), np.ones(self.dim)]).T        self.f = func        self.X_ori= None        self.X = None        self.Y = None        self.Y_ori = None        self.time_opt=0        if \"timevarying_perm\" in GPtype:            self.gp=GPTV_Perm(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        elif GPtype==\"vanillaGP\":            self.gp=GaussianProcess(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        else:            self.gp=GPTV(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        self.acq_func = None        self.logmarginal=0    def init_with_data(self, init_X,init_Y,isPermutation=False):        init_Y=(init_Y-np.mean(init_Y))/np.std(init_Y)        idx1=np.where( init_Y<=3)[0]        init_Y=init_Y[idx1]        init_X=init_X[idx1]        idx=np.where( init_Y>=-3)[0]        init_X=init_X[idx]        init_Y=init_Y[idx]        self.Y_ori = np.asarray(init_Y)        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)        self.X_ori=np.asarray(init_X)        self.X = self.Xscaler.transform(init_X)    def gp_ucb(self,xTest):        xTest=np.reshape(xTest,(-1,self.dim))        mean, var,_,_ = self.gp.predict(xTest)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T        beta_t =np.log(len(self.gp.Y))        return mean + np.sqrt(beta_t) * np.sqrt(var)    def select_next_point(self):        self.Y=np.reshape(self.Y,(-1,1))        self.gp.fit(self.X, self.Y)        start_opt=time.time()        x_max = self.acq_max_scipy(ac=self.gp_ucb)        x_max_ori=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim)))        if self.f is None:            return x_max,x_max_ori        finished_opt=time.time()        elapse_opt=finished_opt-start_opt        self.time_opt=np.hstack((self.time_opt,elapse_opt))        self.X = np.vstack((self.X, x_max.reshape((1, -1))))        self.X_ori=np.vstack((self.X_ori, x_max_ori))        self.Y_ori = np.append(self.Y_ori, self.f(x_max_ori))        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)        return x_max,x_max_ori    def acq_max_scipy(self,ac):        x_max = self.scaleSearchSpace[:, 0]        max_acq = None        myopts ={'maxiter':50*self.dim,'maxfun':50*self.dim}        for i in range(3*self.dim):            x_tries = np.random.uniform(self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1],size=(10*self.dim, self.dim))            y_tries=ac(x_tries)            x_init_max=x_tries[np.argmax(y_tries)]            res = minimize(lambda x: -ac(x.reshape(1, -1)),x_init_max.reshape(1, -1),                   bounds=self.scaleSearchSpace,method=\"L-BFGS-B\",options=myopts)            val=ac(res.x)            if max_acq is None or val >= max_acq:                if 'x' not in res:                    x_max = res                else:                    x_max = res.x                max_acq = val        return np.clip(x_max, self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1])\nFile Path: src/gaussianprocess/gptv.py---class GPTV(object):    def cov_RBF_time(self,x1,x2,hyper):        variance=hyper['var']        lengthscale=hyper['lengthscale']        eps=hyper['epsilon']        if x1.shape[1]!=x2.shape[1]:            x1=np.reshape(x1,(-1,x2.shape[1]))        Euc_dist=euclidean_distances(x1,x2)        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)        if x1.shape[0]==1:            time_vector1=np.asarray([1])        else:            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)            time_vector1=time_vector1/(x1.shape[0]+1)            time_vector1=time_vector1[:-1]        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)        time_vector2=time_vector2/(x1.shape[0]+1)        time_vector2=time_vector2[:-1]        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')        timekernel=(1-eps)**(0.5*dists)        output=RBF*timekernel        return output\nFile Path: src/gaussianprocess/gptv_perm.py---class GPTV_Perm(GPTV):    def cov_RBF_time_set(self,x1,x2,hyper):        variance=hyper['var']        lengthscale=hyper['lengthscale']        eps=hyper['epsilon']        if x1.shape[1]!=x2.shape[1]:            x1=np.reshape(x1,(-1,x2.shape[1]))        x1=np.sort(x1,axis=1)        x2=np.sort(x2,axis=1)        Euc_dist=euclidean_distances(x1,x2)        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)        if x1.shape[0]==1:            time_vector1=np.asarray([1])        else:            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)            time_vector1=time_vector1/(x1.shape[0]+1)            time_vector1=time_vector1[:-1]        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)        time_vector2=time_vector2/(x1.shape[0]+1)        time_vector2=time_vector2[:-1]        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')        timekernel=(1-eps)**(0.5*dists)        output=RBF*timekernel        return output\nFile Path: src/gp_bandit.py---def append_Xori_Yori_from_args(args):    if args.len_terminated_epoch >0:        average_y=np.mean(args.logtvopx_all[-args.len_terminated_epoch:])    else:        average_y=np.mean(args.logtvopx_all[-args.schedule_update_frequency:])    args.average_y=np.append(args.average_y,average_y)    if len(args.average_y)==1:        print(\"ignore for the first time to save the first value of Y\")        return    prev_y=args.average_y[-1] -args.average_y[-2]    args.X_ori=np.vstack(( args.X_ori, np.reshape(format_input(args.partition),(1,args.K+1) )))    args.Y_ori=np.append(args.Y_ori, prev_y)    prev_X=np.round(args.X_ori[-1],decimals=4)\ndef calculate_BO_points(model,args):    append_Xori_Yori_from_args(args)    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float)    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))    if args.K==2:        SearchSpace[0,1]=0.7    else:        ll=np.linspace(0,args.bandit_beta_max,args.K)        for kk in range(args.K-1):            SearchSpace[kk,1]=ll[kk+1]    if args.schedule==\"gp\":        X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori))    else:        X,Y=extract_X_Y_from_args(SearchSpace,args)    if Y is None:        return X    x_all_zeros=np.reshape(np.asarray([args.bandit_beta_min]*(args.K-1)),(1,-1))    x_all_ones=np.reshape(np.asarray([args.bandit_beta_max]*(args.K-1)),(1,-1))    worse_score=np.min(Y)    X=np.vstack((X,x_all_zeros))    X=np.vstack((X,x_all_ones))    Y=np.vstack((Y,np.asarray(worse_score)))    Y=np.vstack((Y,np.asarray(worse_score)))    if args.schedule==\"gp_bandit\":        myBO=BayesOpt(func=None,SearchSpace=SearchSpace)    elif args.schedule==\"gptv\" or args.schedule==\"gp\":        myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype=\"vanillaGP\")    else:        print(\"the schedule is not implemented \",args.schedule)    myBO.init_with_data(X,Y)    new_X=myBO.select_next_point()[1]    new_X=np.round(new_X,decimals=4)    new_X = np.append(np.append(0,np.sort(new_X)), 1)    temp_new_X=np.unique(new_X)    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or         np.array_equal(temp_new_X, [0, 1]) :        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))        return np.append(np.append(0,np.sort(rand_X)), 1)    else:        return new_X\nFile Path: src/models/updates.py---def GP_bandits(model, args):    points = gp_bandit.calculate_BO_points(model, args)    K=len(points)    points=mlh.tensor(points,args)    print(\"==================================\")    print(\"K={} points={}\".format(K,points))    print(\"==================================\")    return points",
    "Experiment Result": "The experiments use the Thermodynamic Variational Objective (TVO) loss. The choice of integration points (beta, a d-dimensional vector) for TVO is framed as a time-varying Gaussian Process (GP) bandit optimization problem. The GP model used is time-varying and permutation-invariant. The reward function for the bandit is defined as the difference in TVO log evidence estimates between training windows, maximizing the final log evidence. An acquisition function (GP-UCB variant) balances exploration and exploitation. Ordering constraints (0 < beta1 < ... < betad-1 < 1) are maintained by sorting the beta vector. Hyperparameters for the GP bandit scheduling include:\n- `schedule`: 'gp_bandit'\n- `K`: 5 (number of internal integration points, so d=K+1 total points including 0 and 1)\n- `S`: 10 (number of samples for MC estimates)\n- `burn_in`: 20 epochs before scheduling begins\n- `schedule_update_frequency`: 6 epochs (how often the schedule is updated)\n- `bandit_beta_min`: 0.05 (lower bound for beta search space)\n- `bandit_beta_max`: 0.95 (upper bound for beta search space)\n- `truncation_threshold`: 30*K (for truncating historical data in time-varying settings)\n- `increment_update_frequency`: 10 (frequency for increasing schedule_update_frequency if conditions are met)\n- `drip_threshold`: -0.05 (threshold to terminate a chosen beta early if logpx drops significantly)\n\nThe datasets used can be variants of MNIST, such as 'tiny_mnist' or 'mnist'."
}{
    "Title": "Active Statistical Inference",
    "Main Contributions": "The paper introduces 'active inference,' a novel methodology for statistical inference that strategically guides data collection using machine learning models to identify which data points are most beneficial to label. It addresses the challenge of collecting high-quality labeled data under stringent budgets. The key contributions include constructing provably valid confidence intervals and hypothesis tests, leveraging any black-box machine learning model and handling any data distribution. Active inference achieves the same level of accuracy with significantly fewer samples than existing baselines, saving over 80% of the sample budget compared to classical inference and between 20-60% compared to uniform prediction-powered inference, resulting in smaller confidence intervals and more powerful p-values. It is applicable to all convex M-estimation problems and supports both batch and sequential data collection settings.",
    "Methodology": "Active inference operates on the intuition of prioritizing labels for data points where the machine learning model is uncertain and relying on model predictions where it is confident. The core mechanism is based on Augmented Inverse Propensity Weighting (AIPW) estimators for mean estimation and a general M-estimation framework for other targets. A key component is the sampling rule, π(x), which determines the probability of labeling an instance x. This rule is derived from a measure of model uncertainty, u(x). For regression, u(x) is trained to predict the magnitude of the model error, |f(X)-Y|, while for classification (e.g., binary), it's based on predictive probabilities (e.g., 2 * min{p(x), 1-p(x)}). The sampling rule is calibrated to meet a given budget `nb` by scaling `π(x) = u(x) * nb / (n * E[u(X)])`. In the batch setting, a pre-trained model and fixed sampling rule are used. In the sequential setting, the model and sampling rule are iteratively updated as new labels are collected, respecting a martingale structure for tractable inference. Practical sampling rules stabilize the `u(x)`-based rule by mixing it with a uniform sampling rule (`πunif = nb/n`) using a parameter `τ` (e.g., `π(τ)(x) = (1-τ)π(x) + τπunif(x)`) to prevent instability from near-zero uncertainty estimates.",
    "Experimental Setup": "The methodology was evaluated across three distinct domains: 1. Post-election survey research: Analyzing average approval rates of political messaging from the Pew Research Center 2020 US presidential election data (binary classification). 2. Census data analysis: Investigating the linear regression coefficient quantifying the relationship between age and income from American Community Survey (ACS) Public Use Microdata Sample (PUMS) data. 3. AlphaFold-assisted proteomics research: Estimating the odds ratio between protein phosphorylation and being part of an intrinsically disordered region (IDR). For all experiments, XGBoost models were used as black-box predictors (f) and for uncertainty estimation (u or e). Baselines included a 'uniform' baseline (Prediction-Powered Inference, PPI) which uses ML predictions but uniform sampling, and a 'classical' baseline which uses no ML and uniform sampling. Evaluation metrics were average confidence interval width, coverage (target α=0.1), and percentage of budget saved. Experiments involved 1000 trials for batch settings and 100 for sequential settings. Sequential fine-tuning was also evaluated by initializing models with limited data and updating them with collected labels.",
    "Limitations": "The primary results focus on asymptotic confidence intervals, although non-asymptotic and time-uniform analogues exist for mean estimation (which naturally overcover). The effectiveness of active inference relies on having a 'reasonably good' machine learning model for predicting labels. The exact expected value of the uncertainty measure, `E[u(X)]`, required for budget normalization, cannot be known precisely and must be empirically estimated. Practical sampling rules need stabilization (e.g., mixing with a uniform rule) to prevent variance blow-up if the model mistakenly estimates near-zero uncertainty when errors are large. In the sequential setting, there's a risk of underutilizing the budget if the model consistently estimates low uncertainty, which is addressed by periodically sampling uniformly. The consistency condition for the batch setting requires `nb/n` to have a limit and a discrete space of tuning parameters. The sequential setting requires the Lindeberg condition (increments without very heavy tails) and convergence of the model-sampling rule pairs.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "def ols(features, outcome):\n    ols_coeffs = np.linalg.pinv(features).dot(outcome)\n    return ols_coeffs\ndef make_width_coverage_plot(df, estimand_title, filename, theta_true, alpha = 0.1, n_l = 0, n_u = np.inf, num_trials = 100, n_example_ind = 0, finetuning=False, more_precision=False, less_precision=False):\n    num_ints = 5\n    inds = np.random.choice(num_trials, num_ints)\n    ns = df[\"$n_b$\"].unique()\n    estimators = df[\"estimator\"].unique()\n    n_example = ns[n_example_ind]\n    ints = [ [] for _ in range(len(estimators)) ]\n    widths = np.zeros((len(estimators), len(ns)))\n\n    for i in range(len(estimators)):\n        for j in range(len(ns)):\n            widths[i,j] = df[(df.estimator == estimators[i]) & (df[\"$n_b$\"] == ns[j])]['interval width'].mean()\n    \n        for j in range(num_ints):\n            ind = inds[j]\n            ints[i].append([df[(df.estimator == estimators[i]) & (df['$n_b$'] == n_example)].iloc[ind].lb, df[(df.estimator == estimators[i]) & (df['$n_b$'] == n_example)].iloc[ind].ub])\n\n    n_l = n_l\n    n_u = n_u\n    inds_n = np.where((ns>n_l) & (ns<n_u))[0]\n    x_ticks = np.logspace(np.log10(min(df['$n_b$'][(df['$n_b$'] > n_l)])), np.log10(max(df['$n_b$'][(df['$n_b$'] < n_u)])), num=5)\n    x_ticks = [int(x) for x in x_ticks]\n    y_ticks = np.logspace(np.log10(np.min(widths[:,inds_n[-1]])), np.log10(np.max(widths[:,inds_n[0]])), num=5)\n\n    gap = 0.03\n    start1 = 0.5\n    start2 = 0.35\n    start3 = 0.2\n    linewidth_inner = 5\n    linewidth_outer = 7\n    col = [sns.color_palette(\"pastel\")[1], sns.color_palette(\"pastel\")[2], sns.color_palette(\"pastel\")[0]]\n    if finetuning:\n        col = [sns.color_palette(\"pastel\")[1], sns.color_palette(\"pastel\")[0], sns.color_palette(\"pastel\")[2]]\n    sns.set_theme(font_scale=1.5, style='white', palette=col, rc={'lines.linewidth': 3})\n    if finetuning:\n        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(18,3.3))\n    else:\n        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,3.3))\n    sns.lineplot(ax=axs[1],data=df[(df['$n_b$'] > n_l) & (df['$n_b$'] < n_u)], x='$n_b$', y='interval width', hue='estimator', alpha=0.8)\n    sns.lineplot(ax=axs[2],data=df[(df['$n_b$'] > n_l) & (df['$n_b$'] < n_u)], x='$n_b$', y='coverage', hue='estimator', alpha=0.8, errorbar=None)\n\n    axs[0].axvline(theta_true, color='gray', linestyle='dashed')\n    for i in reversed(range(num_ints)):\n        if i == 0:\n            axs[0].plot([ints[0][i][0] , ints[0][i][1] ],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color=lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()],  solid_capstyle='butt')\n            axs[0].plot([ints[1][i][0] , ints[1][i][1] ],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()],  solid_capstyle='butt')\n            axs[0].plot([ints[2][i][0] , ints[2][i][1] ],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[2]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()],  solid_capstyle='butt')\n        if i > 0:\n            axs[0].plot([ints[0][i][0], ints[0][i][1]],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color= lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()], solid_capstyle='butt')\n            axs[0].plot([ints[1][i][0] , ints[1][i][1]],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()], solid_capstyle='butt')\n            axs[0].plot([ints[2][i][0] , ints[2][i][1]],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[2]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()], solid_capstyle='butt')\n    axs[0].set_xlabel(estimand_title, fontsize=16)\n    axs[0].set_yticks([])\n    \n    axs[1].get_legend().remove()\n    axs[1].set(xscale='log', yscale='log')\n    axs[1].set_xticks(x_ticks)\n    axs[1].set_yticks(y_ticks)\n    axs[1].xaxis.set_minor_formatter(NullFormatter())\n    axs[1].yaxis.set_minor_formatter(NullFormatter())\n    axs[1].get_xaxis().set_major_formatter(ScalarFormatter())\n    axs[1].get_yaxis().set_major_formatter(ScalarFormatter())\n    axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n    if more_precision:\n        axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n    if less_precision:\n        axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[1].grid(True)\n    \n    axs[2].axhline(1-alpha, color=\"#888888\", linestyle='dashed', zorder=1, alpha=0.8)\n    handles, labels = axs[2].get_legend_handles_labels()\n    if finetuning:\n        axs[2].legend(handles=handles, labels=labels, loc='lower right', bbox_to_anchor=(1.9, 0.43))\n    else:\n        axs[2].legend(handles=handles, labels=labels, loc='lower right', bbox_to_anchor=(1.6, 0.43))\n    axs[2].set_ylim([0.6,1])\n    x_ticks_coverage = np.linspace(np.min(ns[ns>n_l]), np.max(ns[ns<n_u]), 5)\n    x_ticks_coverage = [int(x) for x in x_ticks_coverage]\n    axs[2].set_xticks(x_ticks_coverage)\n    axs[2].set_xlim([np.min(ns[ns>n_l]), np.max(ns[ns<n_u])])\n    axs[2].grid(True)\n    \n    sns.despine(top=True, right=True)\n    sns.despine(left=True, ax = axs[0])\n    plt.tight_layout()\n    \n    plt.savefig(filename)\n    plt.show()\ndef make_budget_plot(df, plot_title, filename, finetuning=False, include_ylabel=True):\n    ns = df[\"$n_b$\"].unique()\n    estimators = df[\"estimator\"].unique()\n    widths = np.zeros((len(estimators), len(ns)))\n\n    for i in range(len(estimators)):\n        for j in range(len(ns)):\n            widths[i,j] = df[(df.estimator == estimators[i]) & (df[\"$n_b$\"] == ns[j])]['interval width'].mean() \n            \n    save1 = []\n    save2 = []\n\n    ns_large1 = ns[np.where(widths[0,0] > widths[1,:])]\n    for n in ns_large1:\n        target_width = df[(df.estimator == estimators[1]) & (df[\"$n_b$\"] == n)]['interval width'].mean()\n        active_0 = np.where(np.array(widths[0,:]) > target_width)[0][-1]\n        active_1 = active_0 + 1\n        active_n = round((widths[0,active_0] - target_width)/(widths[0,active_0] - widths[0,active_1])*(ns[active_1] - ns[active_0]) + ns[active_0])\n        save1.append((n - active_n)/n*100)\n\n    ns_large2 = ns[np.where(widths[0,0] > widths[2,:])]\n    for n in ns_large2:\n        target_width = df[(df.estimator == estimators[2]) & (df[\"$n_b$\"] == n)]['interval width'].mean()\n        active_0 = np.where(np.array(widths[0,:]) > target_width)[0][-1]\n        active_1 = active_0 + 1\n        active_n = round((widths[0,active_0] - target_width)/(widths[0,active_0] - widths[0,active_1])*(ns[active_1] - ns[active_0]) + ns[active_0])\n        save2.append((n - active_n)/n*100)\n\n\n    col = [sns.color_palette(\"pastel\")[1]]\n    sns.set_theme(font_scale=1.7, style='white', palette=col, rc={'lines.linewidth': 3})\n    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,6))\n\n    y_ticks = [0, 25, 50, 75, 100]\n    \n    axs[0].set_title(plot_title)\n    axs[0].plot(ns_large1, save1, marker=\"o\", markersize=8, linestyle='dashed', alpha=0.8)\n    axs[0].set_xlabel('$n_b$')\n    axs[0].set_ylim([0,100])\n    axs[0].set_yticks(y_ticks)\n    if include_ylabel:\n        if finetuning:\n            axs[0].set_ylabel('budget save over\\n no fine-tuning (%)')\n        else:\n            axs[0].set_ylabel('budget save\\n over classical (%)')\n    axs[0].get_yaxis().set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[0].grid(True)\n\n    axs[1].plot(ns_large2, save2, marker=\"o\", markersize=8, linestyle='dashed', alpha=0.8)\n    axs[1].set_xlabel('$n_b$')\n    axs[1].set_ylim([0,100])\n    axs[1].set_yticks(y_ticks)\n    if include_ylabel:\n        axs[1].set_ylabel('budget save\\n over uniform (%)')\n    axs[1].get_yaxis().set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[1].grid(True)\n\n    sns.despine(top=True, right=True)\n    plt.tight_layout()\n    \n    plt.savefig(filename)\n    plt.show()\n    return fig, axs",
    "Experiment Result": "Data Source: Folktables ACSDataSource with `horizon='1-Year'`, `survey='person'`, and `states=[\"CA\"]`. The survey year, features, and outcome are configurable parameters.\nExperimental Settings for Plotting (from `make_width_coverage_plot`):\n- Confidence level for coverage plots: `alpha = 0.1` (used to draw `1-alpha` line).\n- Budget range for plotting: `n_l = 0`, `n_u = np.inf` (default, actual range based on data).\n- Number of trials simulated for interval calculation: `num_trials = 100`.\n- `finetuning` flag: `False` by default in both plotting functions, likely indicating whether sequential updates (fine-tuning of the model and sampling rule) are active or if a fixed, batch setting is used.\nComparison:\n- Plots are generated for different \"estimators\" (active learning strategies), comparing interval width, coverage, and budget savings. This implies comparing active inference against at least two other methods, referred to as \"classical\" and \"uniform\" sampling in `make_budget_plot`."
}{
    "Title": "Active Statistical Inference",
    "Main Contributions": "The paper introduces 'active inference,' a novel methodology for statistical inference that strategically guides data collection using machine learning. The core problem addressed is the high cost and bias associated with labeled data collection, and the pitfall of solely relying on machine learning predictions for inference. The main contributions are: 1) It leverages a black-box machine learning model to identify which data points are most beneficial to label by prioritizing those where the model is uncertain and relying on predictions where it is confident. 2) It constructs provably valid confidence intervals and hypothesis tests for any black-box machine learning model and data distribution. 3) It significantly reduces the number of samples needed to achieve the same level of accuracy as non-adaptively collected data, enabling smaller confidence intervals and more powerful p-values. Experiments demonstrate over 80% budget savings compared to classical inference and substantial savings over prediction-powered inference (PPI). 4) The methodology is applicable to all convex M-estimation problems and supports both batch and sequential data collection settings.",
    "Methodology": "Active inference operates on the principle of sampling data points based on a machine learning model's uncertainty. A sampling rule π(x) is derived from an uncertainty measure u(x) (e.g., predicting error magnitude in regression, or using probability distribution entropy in classification), with π(x) being proportional to u(x) and normalized to meet a predefined labeling budget. In the batch setting, a pre-trained model f is fixed, and labels are collected simultaneously. The estimator used is an augmented inverse propensity weighting (AIPW) type for mean estimation, and a modified M-estimator for general convex M-estimation, where the loss function incorporates predictions and inverse propensity weights. In the sequential setting, the model ft and sampling rule πt are iteratively updated as new labels are collected, leveraging a martingale structure for tractable inference via the martingale central limit theorem. An 'oracle' sampling rule is derived to minimize variance, which samples proportionally to the expected magnitude of model error. Practically, the sampling rule π(x) ∝ u(x) is stabilized by mixing it with a uniform sampling rule (πunif = nb/n) using a tuning parameter τ, defined as π(τ)(x) = (1 - τ) * π(x) + τ * πunif(x). τ can be optimized on historical data or set as a constant.",
    "Experimental Setup": "The active inference methodology is evaluated against two baselines: the 'uniform' baseline (prediction-powered inference, PPI), which uses ML predictions but employs uniform random sampling, and the 'classical' baseline, which removes ML entirely and relies on uniform random sampling. Confidence intervals are computed based on asymptotic normality with an error level α=0.1. Performance is measured by average interval width, coverage, and percentage of budget saved, averaged over 1000 trials for batch settings and 100 trials for sequential settings. The ground-truth parameter is derived from the full dataset. Three real-world applications are used: 1) Post-election survey research (Pew Research Center 2020 US election data) for estimating average approval rates (binary classification) using an XGBoost model. 2) Census data analysis (American Community Survey PUMS from California 2019) for estimating linear regression coefficients (regression) using XGBoost for both the prediction model and a separate error prediction model. 3) AlphaFold-assisted proteomics research for estimating odds ratios related to protein phosphorylation and intrinsically disordered regions (binary outcome), leveraging AlphaFold predictions. Additionally, fine-tuning experiments for survey and census data are conducted, starting with poorly trained models and iteratively updating them as data is collected.",
    "Limitations": "The primary theoretical guarantees are asymptotic, meaning the validity of confidence intervals holds as the sample size approaches infinity, though non-asymptotic analogues are discussed for mean estimation. The consistency conditions for asymptotic normality in the batch setting rely on assumptions about the scaling of the budget (nb/n) and the discreteness of the tuning parameter space. For general M-estimation, the consistency of the estimator itself (ˆθη* p → θ*) is assumed. In the sequential setting, convergence of the model-sampling rule pairs and the Lindeberg condition for martingale increments are required assumptions. The 'oracle' sampling rules derived for optimal variance reduction are not directly implementable because they depend on unobserved information. Practical sampling rules approximate this optimum, and issues like a model mistakenly estimating near-zero uncertainty for large errors can arise, potentially inflating estimator variance. This is mitigated by mixing with a uniform rule. In sequential settings, there's a risk of budget underutilization if the model consistently estimates low uncertainty, necessitating periodic deviations from the sampling rule to ensure budget consumption.",
    "Future Research Directions": "Not mentioned",
    "Experiment Code": "def ols(features, outcome):\n    ols_coeffs = np.linalg.pinv(features).dot(outcome)\n    return ols_coeffs\n\ndef make_width_coverage_plot(df, estimand_title, filename, theta_true, alpha = 0.1, n_l = 0, n_u = np.inf, num_trials = 100, n_example_ind = 0, finetuning=False, more_precision=False, less_precision=False):\n    num_ints = 5\n    inds = np.random.choice(num_trials, num_ints)\n    ns = df[\"$n_b$\"].unique()\n    estimators = df[\"estimator\"].unique()\n    n_example = ns[n_example_ind]\n    ints = [ [] for _ in range(len(estimators)) ]\n    widths = np.zeros((len(estimators), len(ns)))\n\n    # compute example intervals and average widths\n    for i in range(len(estimators)):\n        for j in range(len(ns)):\n            widths[i,j] = df[(df.estimator == estimators[i]) & (df[\"$n_b$\"] == ns[j])]['interval width'].mean()\n    \n        for j in range(num_ints):\n            ind = inds[j]\n            ints[i].append([df[(df.estimator == estimators[i]) & (df['$n_b$'] == n_example)].iloc[ind].lb, df[(df.estimator == estimators[i]) & (df['$n_b$'] == n_example)].iloc[ind].ub])\n\n    n_l = n_l\n    n_u = n_u\n    inds_n = np.where((ns>n_l) & (ns<n_u))[0] # budget indices that will be plotted\n    x_ticks = np.logspace(np.log10(min(df['$n_b$'][(df['$n_b$'] > n_l)])), np.log10(max(df['$n_b$'][(df['$n_b$'] < n_u)])), num=5) # adjust 'num' for more/less ticks\n    x_ticks = [int(x) for x in x_ticks]\n    y_ticks = np.logspace(np.log10(np.min(widths[:,inds_n[-1]])), np.log10(np.max(widths[:,inds_n[0]])), num=5) # adjust 'num' for more/less ticks\n\n    # plotting params\n    gap = 0.03\n    start1 = 0.5\n    start2 = 0.35\n    start3 = 0.2\n    linewidth_inner = 5\n    linewidth_outer = 7\n    col = [sns.color_palette(\"pastel\")[1], sns.color_palette(\"pastel\")[2], sns.color_palette(\"pastel\")[0]]\n    if finetuning:\n        col = [sns.color_palette(\"pastel\")[1], sns.color_palette(\"pastel\")[0], sns.color_palette(\"pastel\")[2]]\n    sns.set_theme(font_scale=1.5, style='white', palette=col, rc={'lines.linewidth': 3})\n    if finetuning:\n        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(18,3.3))\n    else:\n        fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,3.3))\n    sns.lineplot(ax=axs[1],data=df[(df['$n_b$'] > n_l) & (df['$n_b$'] < n_u)], x='$n_b$', y='interval width', hue='estimator', alpha=0.8)\n    sns.lineplot(ax=axs[2],data=df[(df['$n_b$'] > n_l) & (df['$n_b$'] < n_u)], x='$n_b$', y='coverage', hue='estimator', alpha=0.8, errorbar=None)\n\n    axs[0].axvline(theta_true, color='gray', linestyle='dashed')\n    for i in reversed(range(num_ints)):\n        if i == 0:\n            axs[0].plot([ints[0][i][0] , ints[0][i][1] ],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color=lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()],  solid_capstyle='butt')\n            axs[0].plot([ints[1][i][0] , ints[1][i][1] ],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()],  solid_capstyle='butt')\n            axs[0].plot([ints[2][i][0] , ints[2][i][1] ],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[2]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()],  solid_capstyle='butt')\n        if i > 0:\n            axs[0].plot([ints[0][i][0], ints[0][i][1]],[start1+i*gap,start1+i*gap], linewidth=linewidth_inner, color= lighten_color(col[0],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[0]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[0]), pe.Normal()], solid_capstyle='butt')\n            axs[0].plot([ints[1][i][0] , ints[1][i][1]],[start2+i*gap, start2+i*gap], linewidth=linewidth_inner, color=lighten_color(col[1],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[1]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[1]), pe.Normal()], solid_capstyle='butt')\n            axs[0].plot([ints[2][i][0] , ints[2][i][1]],[start3+i*gap, start3+i*gap], linewidth=linewidth_inner, color=lighten_color(col[2],0.6), path_effects=[pe.Stroke(linewidth=linewidth_outer, offset=(-1,0), foreground=col[2]), pe.Stroke(linewidth=linewidth_outer, offset=(1,0), foreground=col[2]), pe.Normal()], solid_capstyle='butt')\n    axs[0].set_xlabel(estimand_title, fontsize=16)\n    axs[0].set_yticks([])\n    \n    axs[1].get_legend().remove()\n    axs[1].set(xscale='log', yscale='log')\n    axs[1].set_xticks(x_ticks)\n    axs[1].set_yticks(y_ticks)\n    axs[1].xaxis.set_minor_formatter(NullFormatter())\n    axs[1].yaxis.set_minor_formatter(NullFormatter())\n    axs[1].get_xaxis().set_major_formatter(ScalarFormatter())\n    axs[1].get_yaxis().set_major_formatter(ScalarFormatter())\n    axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n    if more_precision:\n        axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n    if less_precision:\n        axs[1].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[1].grid(True)\n    \n    axs[2].axhline(1-alpha, color=\"#888888\", linestyle='dashed', zorder=1, alpha=0.8)\n    handles, labels = axs[2].get_legend_handles_labels()\n    if finetuning:\n        axs[2].legend(handles=handles, labels=labels, loc='lower right', bbox_to_anchor=(1.9, 0.43))\n    else:\n        axs[2].legend(handles=handles, labels=labels, loc='lower right', bbox_to_anchor=(1.6, 0.43))\n    axs[2].set_ylim([0.6,1])\n    x_ticks_coverage = np.linspace(np.min(ns[ns>n_l]), np.max(ns[ns<n_u]), 5)\n    x_ticks_coverage = [int(x) for x in x_ticks_coverage]\n    axs[2].set_xticks(x_ticks_coverage)\n    axs[2].set_xlim([np.min(ns[ns>n_l]), np.max(ns[ns<n_u])])\n    axs[2].grid(True)\n    \n    sns.despine(top=True, right=True)\n    sns.despine(left=True, ax = axs[0])\n    plt.tight_layout()\n    \n    # save plot\n    plt.savefig(filename)\n    plt.show()\n\n\ndef make_budget_plot(df, plot_title, filename, finetuning=False, include_ylabel=True):\n    ns = df[\"$n_b$\"].unique()\n    estimators = df[\"estimator\"].unique()\n    widths = np.zeros((len(estimators), len(ns)))\n\n    # compute average widths\n    for i in range(len(estimators)):\n        for j in range(len(ns)):\n            widths[i,j] = df[(df.estimator == estimators[i]) & (df[\"$n_b$\"] == ns[j])]['interval width'].mean() \n            \n    save1 = []\n    save2 = []\n\n    ns_large1 = ns[np.where(widths[0,0] > widths[1,:])]\n    for n in ns_large1:\n        target_width = df[(df.estimator == estimators[1]) & (df[\"$n_b$\"] == n)]['interval width'].mean()\n        active_0 = np.where(np.array(widths[0,:]) > target_width)[0][-1]\n        active_1 = active_0 + 1\n        # linearly interpolate:\n        active_n = round((widths[0,active_0] - target_width)/(widths[0,active_0] - widths[0,active_1])*(ns[active_1] - ns[active_0]) + ns[active_0])\n        save1.append((n - active_n)/n*100)\n\n    ns_large2 = ns[np.where(widths[0,0] > widths[2,:])]\n    for n in ns_large2:\n        target_width = df[(df.estimator == estimators[2]) & (df[\"$n_b$\"] == n)]['interval width'].mean()\n        active_0 = np.where(np.array(widths[0,:]) > target_width)[0][-1]\n        active_1 = active_0 + 1\n        # linearly interpolate:\n        active_n = round((widths[0,active_0] - target_width)/(widths[0,active_0] - widths[0,active_1])*(ns[active_1] - ns[active_0]) + ns[active_0])\n        save2.append((n - active_n)/n*100)\n\n\n    col = [sns.color_palette(\"pastel\")[1]]\n    sns.set_theme(font_scale=1.7, style='white', palette=col, rc={'lines.linewidth': 3})\n    fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(6,6))\n\n    y_ticks = [0, 25, 50, 75, 100]\n    \n    axs[0].set_title(plot_title)\n    axs[0].plot(ns_large1, save1, marker=\"o\", markersize=8, linestyle='dashed', alpha=0.8)\n    axs[0].set_xlabel('$n_b$')\n    axs[0].set_ylim([0,100])\n    axs[0].set_yticks(y_ticks)\n    if include_ylabel:\n        if finetuning:\n            axs[0].set_ylabel('budget save over\\n no fine-tuning (%)')\n        else:\n            axs[0].set_ylabel('budget save\\n over classical (%)')\n    axs[0].get_yaxis().set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[0].grid(True)\n\n    axs[1].plot(ns_large2, save2, marker=\"o\", markersize=8, linestyle='dashed', alpha=0.8)\n    axs[1].set_xlabel('$n_b$')\n    axs[1].set_ylim([0,100])\n    axs[1].set_yticks(y_ticks)\n    if include_ylabel:\n        axs[1].set_ylabel('budget save\\n over uniform (%)')\n    axs[1].get_yaxis().set_major_formatter(FormatStrFormatter('%.0f'))\n    axs[1].grid(True)\n\n    # xticks_locations = axs[1].get_xticks()\n    # xlim = axs[1].get_xlim()\n    # axs[0].set_xticks(xticks_locations)\n    # axs[0].set_xlim(xlim)\n    # axs[1].set_xticks(xticks_locations)\n    # axs[1].set_xlim(xlim)\n\n    sns.despine(top=True, right=True)\n    plt.tight_layout()\n    \n    # save plot\n    plt.savefig(filename)\n    plt.show()\n    return fig, axs",
    "Experiment Result": "Experiments are conducted with `num_trials = 100` repetitions. The confidence level for interval estimation is set with `alpha = 0.1` (90% confidence intervals). The experiments evaluate and compare different 'estimators' (corresponding to various sampling rules and estimation methods, including baselines like classical/uniform) across a range of labeling budgets (`$n_b$`). Performance is measured by 'interval width', 'coverage', and 'budget savings' (comparing against classical and uniform sampling). A `finetuning` parameter suggests conditions related to optimizing parameters like `τ` or sequential model updates."
}{
    "Title": "Convergence Rates of Variational Inference in Sparse Deep Learning",
    "Main Contributions": "This paper presents the first theoretical generalization error bounds for variational inference (VI) in Bayesian deep learning, showing that sparse VI in deep neural networks (DNNs) achieves near-minimax convergence rates for Hölder smooth functions, akin to exact Bayesian inference. It introduces a robust notion of consistency for Bayesian estimators using tempered posteriors to handle model misspecification. The research demonstrates that architecture selection through Evidence Lower Bound (ELBO) maximization adaptively achieves optimal convergence rates without prior knowledge of the regression function's smoothness and does not overfit. It also analyzes the impact of optimization errors on generalization, linking ELBO convergence to algorithm consistency.",
    "Methodology": "The methodology centers on sparse variational inference (VI) for Bayesian Deep Neural Networks in a nonparametric regression framework. It employs a hierarchical spike-and-slab prior to induce sparsity in network parameters. The paper uses tempered posterior distributions (likelihood raised to an α-power, α<1) for robustness and theoretical tractability. Variational approximations are obtained by minimizing the Kullback-Leibler (KL) divergence, which is equivalent to maximizing the ELBO. Theoretical generalization error bounds are derived using PAC-Bayes theory. An ELBO maximization framework is introduced for adaptive model selection, guiding the optimal choice of network architecture (depth, width, and sparsity).",
    "Experimental Setup": "The paper primarily presents a theoretical study. The framework considers nonparametric regression where observed data (Xi, Yi) are i.i.d. with Yi = f0(Xi) + ζi, where ζi is i.i.d. Gaussian noise and f0 is a β-Hölder smooth function. For the theoretical results, ReLU activation functions are considered, and specific network architectures (L, D, S for layers, width, and sparsity, respectively) are defined to achieve minimax rates of convergence. No empirical datasets, benchmarks, or practical experiments are performed; the validation is purely through mathematical proofs of convergence rates and generalization bounds.",
    "Limitations": "The paper explicitly states that the challenges related to optimization, particularly proving the global convergence of ELBO maximization algorithms (which are often non-convex), fall outside its scope. While it discusses the impact of optimization error on generalization, it does not provide concrete algorithms or guarantees for achieving the ideal variational solution. The theoretical framework also relies on assumptions like 1-Lipschitz continuous activation functions and a bounded range for network coefficients (though a relaxation for unbounded parameters is discussed in the appendix).",
    "Future Research Directions": "Future research directions include the design of new, computationally efficient algorithms for spike-and-slab deep learning that can handle sparsity-inducing variational inference, building upon existing works. Another key area is the theoretical study of global convergence for these approximate algorithms, especially in non-convex settings, focusing on Bayesian gradient descent methods and the convergence of the ELBO. Developing algorithms that effectively preserve network sparsity during the training process is also highlighted as an important extension.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Test Time Adaptation via Conjugate Pseudo-labels",
    "Main Contributions": "The paper addresses the unclear choice of unsupervised objectives for Test-Time Adaptation (TTA) to distribution shifts. It presents a surprising phenomenon: meta-learning the 'best' TTA loss recovers softmax-entropy for cross-entropy trained classifiers, and negative squared error for squared-loss trained classifiers. To explain this, the authors propose a generic recipe for TTA loss based on the convex conjugate of the supervised training loss, which is shown to locally approximate the original supervised loss without labels. This framework recovers prior empirical findings and justifies existing TTA strategies. They introduce 'conjugate pseudo-labels' as a form of self-training, providing a principled way to derive soft pseudo-labels for various loss functions (e.g., PolyLoss). Empirically, their conjugate pseudo-labeling approach consistently outperforms other TTA methods across diverse benchmarks and training losses, particularly for novel loss functions where it substantially differs from (and outperforms) entropy-based losses.",
    "Methodology": "The methodology involves two main parts. First, an empirical meta-learning approach is used to discover effective TTA losses. This involves parameterizing the TTA loss as a neural network and learning its parameters via meta-learning, differentiating through the adaptation process on a validation set. Second, a theoretical framework based on convex conjugate functions is proposed. For supervised losses of the form L(h(x),y) = f(h(x)) - y^T h(x), the conjugate adaptation loss is defined as Lconj(h(x)) = -f*(∇f(h(x))). This loss is shown to be equivalent to self-training with 'conjugate pseudo-labels' ỹCPL(x) = ∇f(h(x)). The full adaptation procedure (Algorithm 1) involves iteratively updating model parameters on test batches using the original loss with conjugate pseudo-labels, often with an additional temperature scaling.",
    "Experimental Setup": "Experiments are conducted on three common corruption benchmarks: CIFAR-10-C, CIFAR-100-C, and ImageNet-C, evaluating average error across corruptions. Three domain adaptation datasets are also used: SVHN to MNIST, ImageNet to ImageNet-R, and synthetic to real data in VISDA-C. Source classifiers include ResNet-26 (CIFAR), ResNet-18 (SVHN), and ResNet-50 (ImageNet, VisDA-C), trained with cross-entropy, PolyLoss, or squared loss. Baselines include Hard Pseudo-Label, Soft Pseudo-Label (softmax), Entropy Minimization (TENT), Robust Pseudo-Label, and MEMO. TTA fine-tuning updates only the learnable scale and shift parameters of batch normalization layers, with batch normalization statistics updated per batch. Hyperparameters (learning rate and temperature) are tuned via grid-search on validation noises for corruption benchmarks, while fixed values are used for domain adaptation tasks without held-out target domains.",
    "Limitations": "The work does not fully answer what the optimal test-time adaptation loss is and why, despite meta-learning results hinting at optimality. The meta-learning framework was constrained to learning functions over the logits of individual inputs and could be expanded to intermediate representations or batch-level interactions. Achieving good TTA still involves several heuristics, such as updating only batch norm parameters and temperature scaling, whose roles need a more concrete understanding. It remains an open problem to understand under what real-world distribution shifts self-training based approaches would be most effective.",
    "Future Research Directions": "Future research directions include expanding the meta-learning framework to learn functions over intermediate representations or batch-level interactions. Further investigation is needed to more concretely understand the role and regularization effects of TTA heuristics like updating batch normalization parameters and temperature scaling. Another area for exploration is to understand the specific real-world distribution shifts for which self-training based approaches would be most beneficial. Finally, the authors suggest extending and applying the conjugate pseudo-labeling framework to other settings beyond TTA, such as semi-supervised learning.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
    "Main Contributions": "This paper addresses the limitations of existing Test-Time Adaptation (TTA) methods in handling significant domain distribution shifts by proposing Active Test-Time Adaptation (ATTA). ATTA integrates active learning within the fully TTA setting, leveraging limited labeled test instances to enhance performance with theoretical guarantees. The paper introduces SimATTA, a simple yet effective ATTA algorithm that employs real-time sample selection and sample entropy balancing to avoid catastrophic forgetting. Extensive experiments demonstrate that ATTA significantly improves performance over TTA methods while maintaining efficiency comparable to TTA and effectiveness similar to more demanding Active Domain Adaptation (ADA) methods.",
    "Methodology": "The proposed ATTA framework involves continuously selecting informative instances from test batches for labeling and subsequent model learning. A formal definition of ATTA is provided, optimizing a pre-trained model by minimizing a combination of cross-entropy loss (for labeled samples) and an unsupervised learning loss (for unlabeled samples), subject to a labeling budget. Theoretical analysis provides learning bounds to guarantee mitigation of distribution shifts and prevention of catastrophic forgetting (CF). The core algorithm, SimATTA, incorporates balanced sample selections using selective entropy minimization to combat CF (by identifying 'source-like' low-entropy samples) and an incremental clustering technique to select informative high-entropy samples (anchors) from streaming data for active labeling, reducing redundancy and increasing distribution coverage. The model is fine-tuned on these pseudo-labeled low-entropy samples and actively labeled high-entropy anchors.",
    "Experimental Setup": "The method's effectiveness was validated on multiple datasets: PACS, VLCS, Office-Home, and Tiny-ImageNet-C, covering various domain shifts and corruptions. For DomainBed datasets (PACS, VLCS, Office-Home), two data stream orders were used: domain-wise (sequential domains) and random (shuffled target domains). Baselines included source-only models (BN w/o adapt, BN w/ adapt), state-of-the-art TTA methods (Tent, EATA, CoTTA, SAR), and Active Domain Adaptation (ADA) methods (Random, Entropy, Kmeans, CLUE). Evaluation was based on accuracy, with comparisons focusing on efficiency and performance metrics. ResNet-18 (for PACS, VLCS, Tiny-ImageNet-C) and ResNet-50 (for Office-Home) models were used, pre-trained on ImageNet or specific source domains. Training parameters included Adam and SGD optimizers with specified learning rates and training iterations. Budget limits for labeled samples were set (e.g., B <= 300, B <= 500). Ablation studies were conducted to assess individual components like incremental clustering and low-entropy sample training.",
    "Limitations": "The theoretical bounds can be loose with small batches of unlabeled test samples, as the VC-dimension of the hypothesis class (ResNet models) is large. While fine-tuning reduces this effect, it relies on the assumption that fine-tuning is equivalent to learning with a relatively small VC-dimension. The effectiveness of selective entropy minimization for CF prevention relies on the quality of the pre-trained model; training on incorrectly pseudo-labeled low-entropy samples may reinforce errors. It might not be cost-effective to spend annotation budgets on low-entropy samples, although correcting them could be an alternative. The paper also acknowledges that constructing a new setting involves complexities, and scaling to large models/datasets or specialized task-specific applications is not fully covered.",
    "Future Research Directions": "Future research could involve developing alternative methods to prevent catastrophic forgetting in ATTA scenarios, especially since selective entropy minimization on low-entropy samples, while empirically effective, relies on pre-trained model quality and could reinforce errors if pseudo-labels are incorrect. Investigating whether correcting incorrectly predicted low-entropy samples is a viable alternative solution is also suggested. Another promising avenue is designing ATTA methods for large language models (LLMs), where retraining is prohibitively expensive and source data may be inaccessible. The work also generally points to bridging the gap between causal inference and deep learning through causal representation learning for out-of-distribution generalization.",
    "Experiment Code": "File Path: ATTA/kernel/algorithms/SimATTA.py\nContent:\nimport copy\nimport pathlib\nimport time\nfrom typing import Union\n\nimport numpy as np\nfrom sklearn.metrics import pairwise_distances_argmin_min\nfrom typing import Literal\n\nfrom torch import nn\nimport torch\nfrom munch import Munch\nfrom ATTA import register\nfrom ATTA.utils.config_reader import Conf\nfrom ATTA.data.loaders.fast_data_loader import InfiniteDataLoader, FastDataLoader\nfrom torch.utils.data import TensorDataset\nfrom tqdm import tqdm\nfrom .Base import AlgBase\nimport pandas as pd\nfrom ATTA.definitions import STORAGE_DIR\n\n\n\n@register.alg_register\nclass SimATTA(AlgBase):\n    def __init__(self, config: Conf):\n        super(SimATTA, self).__init__(config)\n\n        self.teacher = copy.deepcopy(self.model.to('cpu'))\n\n        self.model.to(config.device)\n        self.teacher.to(config.device)\n        self.update_teacher(0)  # copy student to teacher\n\n        self.budgets = 0\n        self.anchors = None\n        self.source_anchors = None\n        self.buffer = []\n        self.n_clusters = 10\n        self.nc_increase = self.config.atta.SimATTA.nc_increase\n        self.source_n_clusters = 100\n\n        self.cold_start = self.config.atta.SimATTA.cold_start\n\n        self.consistency_weight = 0\n        self.alpha_teacher = 0\n        self.accumulate_weight = True\n        self.weighted_entropy: Union[Literal['low', 'high', 'both'], None] = 'both'\n        self.aggressive = True\n        self.beta = self.config.atta.SimATTA.beta\n        self.alpha = 0.2\n\n        self.target_cluster = True if self.config.atta.SimATTA.target_cluster else False\n        self.LE = True if self.config.atta.SimATTA.LE else False\n        self.vis_round = 0\n\n\n    def __call__(self, *args, **kwargs):\n        self.continue_result_df = pd.DataFrame(\n            index=['Current domain', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in self.config.dataset.test_envs), 'Test AVG'], dtype=float)\n        self.random_result_df = pd.DataFrame(\n            index=['Current step', 'Budgets', *(i for i in self.config.dataset.test_envs), 'Frame AVG'],\n            columns=[*(i for i in range(4)), 'Test AVG'], dtype=float)\n\n        self.enable_bn(self.model)\n        if 'ImageNet' not in self.config.dataset.name:\n            for env_id in self.config.dataset.test_envs:\n                acc = self.test_on_env(env_id)[1]\n                self.continue_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n                self.random_result_df.loc[env_id, self.config.dataset.test_envs[0]] = acc\n\n        for adapt_id in self.config.dataset.test_envs[1:]:\n            self.continue_result_df.loc['Current domain', adapt_id] = self.adapt_on_env(self.fast_loader, adapt_id)\n            self.continue_result_df.loc['Budgets', adapt_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.continue_result_df.loc[env_id, adapt_id] = self.test_on_env(env_id)[1]\n\n        self.__init__(self.config)\n        for target_split_id in range(4):\n            self.random_result_df.loc['Current step', target_split_id] = self.adapt_on_env(self.target_loader, target_split_id)\n            self.random_result_df.loc['Budgets', target_split_id] = self.budgets\n            print(self.budgets)\n            if 'ImageNet' not in self.config.dataset.name:\n                for env_id in self.config.dataset.test_envs:\n                    self.random_result_df.loc[env_id, target_split_id] = self.test_on_env(env_id)[1]\n\n        print(f'#IM#\\n{self.continue_result_df.round(4).to_markdown()}\\n'\n              f'{self.random_result_df.round(4).to_markdown()}')\n        self.continue_result_df.round(4).to_csv(f'{self.config.log_file}.csv')\n        self.random_result_df.round(4).to_csv(f'{self.config.log_file}.csv', mode='a')\n\n\n    @torch.no_grad()\n    def val_anchor(self, loader):\n        self.model.eval()\n        val_loss = 0\n        val_acc = 0\n        for data, target in loader:\n            data, target = data.to(self.config.device), target.to(self.config.device)\n            output = self.fc(self.encoder(data))\n            val_loss += self.config.metric.loss_func(output, target, reduction='sum').item()\n            val_acc += self.config.metric.score_func(target, output) * len(data)\n        val_loss /= len(loader.sampler)\n        val_acc /= len(loader.sampler)\n        return val_loss, val_acc\n\n    def update_teacher(self, alpha_teacher):  # , iteration):\n        for t_param, s_param in zip(self.teacher.parameters(), self.model.parameters()):\n            t_param.data[:] = alpha_teacher * t_param[:].data[:] + (1 - alpha_teacher) * s_param[:].data[:]\n        if not self.config.model.freeze_bn:\n            for tm, m in zip(self.teacher.modules(), self.model.modules()):\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    tm.running_mean = alpha_teacher * tm.running_mean + (1 - alpha_teacher) * m.running_mean\n                    tm.running_var = alpha_teacher * tm.running_var + (1 - alpha_teacher) * m.running_var\n\n    @torch.enable_grad()\n    def cluster_train(self, target_anchors, source_anchors):\n        self.model.train()\n\n        source_loader = InfiniteDataLoader(TensorDataset(source_anchors.data, source_anchors.target), weights=None,\n                                           batch_size=self.config.train.train_bs,\n                                           num_workers=self.config.num_workers)\n        target_loader = InfiniteDataLoader(TensorDataset(target_anchors.data, target_anchors.target), weights=None,\n                                             batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        alpha = target_anchors.num_elem() / (target_anchors.num_elem() + source_anchors.num_elem())\n        if source_anchors.num_elem() < self.cold_start:\n            alpha = min(0.2, alpha)\n\n        ST_loader = iter(zip(source_loader, target_loader))\n        val_loader = FastDataLoader(TensorDataset(target_anchors.data, target_anchors.target), weights=None,\n                                    batch_size=self.config.train.train_bs, num_workers=self.config.num_workers)\n        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.config.atta.SimATTA.lr, momentum=0.9)\n        delay_break = False\n        loss_window = []\n        tol = 0\n        lowest_loss = float('inf')\n        for i, ((S_data, S_targets), (T_data, T_targets)) in enumerate(ST_loader):\n            S_data, S_targets = S_data.to(self.config.device), S_targets.to(self.config.device)\n            T_data, T_targets = T_data.to(self.config.device), T_targets.to(self.config.device)\n            L_T = self.one_step_train(S_data, S_targets, T_data, T_targets, alpha, optimizer)\n            if len(loss_window) < self.config.atta.SimATTA.stop_tol:\n                loss_window.append(L_T.item())\n            else:\n                mean_loss = np.mean(loss_window)\n                tol += 1\n                if mean_loss < lowest_loss:\n                    lowest_loss = mean_loss\n                    tol = 0\n                if tol > 5:\n                    break\n                loss_window = []\n            if 'ImageNet' in self.config.dataset.name or 'CIFAR' in self.config.dataset.name:\n                if i > self.config.atta.SimATTA.steps:\n                    break\n\n\n    def one_step_train(self, S_data, S_targets, T_data, T_targets, alpha, optimizer):\n        L_S = self.config.metric.loss_func(self.model(S_data), S_targets)\n        L_T = self.config.metric.loss_func(self.model(T_data), T_targets)\n        loss = (1 - alpha) * L_S + alpha * L_T\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        return L_T\n\n    def softmax_entropy(self, x: torch.Tensor, y: torch.Tensor = None) -> torch.Tensor:\n        if y is None:\n            if x.shape[1] == 1:\n                x = torch.cat([x, -x], dim=1)\n            return -(x.softmax(1) * x.log_softmax(1)).sum(1)\n        else:\n            return - 0.5 * (x.softmax(1) * y.log_softmax(1)).sum(1) - 0.5 * (y.softmax(1) * x.log_softmax(1)).sum(1)\n\n    def update_anchors(self, anchors, data, target, feats, weight):\n        if anchors is None:\n            anchors = Munch()\n            anchors.data = data\n            anchors.target = target\n            anchors.feats = feats\n            anchors.weight = weight\n            anchors.num_elem = lambda: len(anchors.data)\n        else:\n            anchors.data = torch.cat([anchors.data, data])\n            anchors.target = torch.cat([anchors.target, target])\n            anchors.feats = torch.cat([anchors.feats, feats])\n            anchors.weight = torch.cat([anchors.weight, weight])\n        return anchors\n\n    def update_anchors_feats(self, anchors):\n        anchors_loader = FastDataLoader(TensorDataset(anchors.data), weights=None,\n                                        batch_size=32, num_workers=self.config.num_workers, sequential=True)\n\n        anchors.feats = None\n        self.model.eval()\n        for data in anchors_loader:\n            data = data[0].to(self.config.device)\n            if anchors.feats is None:\n                anchors.feats = self.model[0](data).cpu().detach()\n            else:\n                anchors.feats = torch.cat([anchors.feats, self.model[0](data).cpu().detach()])\n\n        return anchors\n\n    @torch.no_grad()\n    def adapt_on_env(self, loader, env_id):\n        acc = 0\n        for data, target in tqdm(loader[env_id]):\n            data, target = data.to(self.config.device), target.to(self.config.device)\n            outputs, closest, self.anchors = self.sample_select(self.model, data, target, self.anchors, int(self.n_clusters), 1, ent_bound=self.config.atta.SimATTA.eh, incremental_cluster=self.target_cluster)\n            acc += self.config.metric.score_func(target, outputs).item() * data.shape[0]\n            if self.LE:\n                _, _, self.source_anchors = self.sample_select(self.teacher, data, target, self.source_anchors, self.source_n_clusters, 0,\n                                                               use_pseudo_label=True, ent_bound=self.config.atta.SimATTA.el, incremental_cluster=False)\n            else:\n                self.source_anchors = self.update_anchors(None, torch.tensor([]), None, None, None)\n            if not self.target_cluster:\n                self.n_clusters = 0\n            self.source_n_clusters = 100\n\n            self.budgets += len(closest)\n            self.n_clusters += self.nc_increase\n            self.source_n_clusters += 1\n\n            print(self.anchors.num_elem(), self.source_anchors.num_elem())\n            if self.source_anchors.num_elem() > 0:\n                self.cluster_train(self.anchors, self.source_anchors)\n            else:\n                self.cluster_train(self.anchors, self.anchors)\n            self.anchors = self.update_anchors_feats(self.anchors)\n        acc /= len(loader[env_id].sampler)\n        print(f'#IN#Env {env_id} real-time Acc.: {acc:.4f}')\n        return acc\n\n    @torch.no_grad()\n    def sample_select(self, model, data, target, anchors, n_clusters, ent_beta, use_pseudo_label=False, ent_bound=1e-2, incremental_cluster=False):\n        model.eval()\n        feats = model[0](data)\n        outputs = model[1](feats)\n        pseudo_label = outputs.argmax(1).cpu().detach()\n        data = data.cpu().detach()\n        feats = feats.cpu().detach()\n        target = target.cpu().detach()\n        entropy = self.softmax_entropy(outputs).cpu()\n        if not incremental_cluster:\n            entropy = entropy.numpy()\n            if ent_beta == 0:\n                closest = np.argsort(entropy)[: n_clusters]\n                closest = closest[entropy[closest] < ent_bound]\n            elif ent_beta == 1:\n                closest = np.argsort(entropy)[- n_clusters:]\n                closest = closest[entropy[closest] >= ent_bound]\n            else:\n                raise NotImplementedError\n            weights = torch.zeros(len(closest), dtype=torch.float)\n        else:\n            if ent_beta == 0:\n                sample_choice = entropy < ent_bound\n            elif ent_beta == 1:\n                sample_choice = entropy >= ent_bound\n            else:\n                raise NotImplementedError\n\n            data = data[sample_choice]\n            target = target[sample_choice]\n            feats = feats[sample_choice]\n            pseudo_label = pseudo_label[sample_choice]\n\n            if anchors:\n                feats4cluster = torch.cat([anchors.feats, feats])\n                sample_weight = torch.cat([anchors.weight, torch.ones(len(feats), dtype=torch.float)])\n            else:\n                feats4cluster = feats\n                sample_weight = torch.ones(len(feats), dtype=torch.float)\n\n            if self.config.atta.gpu_clustering:\n                from ATTA.utils.fast_pytorch_kmeans import KMeans\n                from joblib import parallel_backend\n                kmeans = KMeans(n_clusters=n_clusters, n_init=10, device=self.config.device).fit(\n                    feats4cluster.to(self.config.device),\n                    sample_weight=sample_weight.to(self.config.device))\n                with parallel_backend('threading', n_jobs=8):\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n            else:\n                from joblib import parallel_backend\n                from sklearn.cluster import KMeans\n                with parallel_backend('threading', n_jobs=8):\n                    kmeans = KMeans(n_clusters=n_clusters, n_init=10, algorithm='elkan').fit(feats4cluster,\n                                                                                                  sample_weight=sample_weight)\n                    raw_closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, feats4cluster)\n                kmeans_labels = kmeans.labels_\n\n\n\n            if anchors:\n                num_anchors = anchors.num_elem()\n                prev_anchor_cluster = torch.tensor(kmeans_labels[:num_anchors], dtype=torch.long)\n\n                if self.accumulate_weight:\n                    num_prev_anchors_per_cluster = prev_anchor_cluster.unique(return_counts=True)\n                    num_prev_anchors_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_prev_anchors_per_cluster_dict[num_prev_anchors_per_cluster[0].long()] = \\\n                    num_prev_anchors_per_cluster[1]\n\n                    num_newsample_per_cluster = torch.tensor(kmeans_labels).unique(return_counts=True)\n                    num_newsample_per_cluster_dict = torch.zeros(len(raw_closest), dtype=torch.long)\n                    num_newsample_per_cluster_dict[num_newsample_per_cluster[0].long()] = num_newsample_per_cluster[1]\n                    assert (num_prev_anchors_per_cluster_dict[prev_anchor_cluster] == 0).sum() == 0\n                    anchors.weight = anchors.weight + num_newsample_per_cluster_dict[prev_anchor_cluster] / \\\n                                          num_prev_anchors_per_cluster_dict[prev_anchor_cluster].float()\n\n                anchored_cluster_mask = torch.zeros(len(raw_closest), dtype=torch.bool).index_fill_(0,\n                                                                                                    prev_anchor_cluster.unique().long(),\n                                                                                                    True)\n                new_cluster_mask = ~ anchored_cluster_mask\n\n                closest = raw_closest[new_cluster_mask] - num_anchors\n                if (closest < 0).sum() != 0:\n                    print('new_cluster_mask: ', new_cluster_mask)\n                    new_cluster_mask = torch.where(new_cluster_mask)[0]\n                    print('new_cluster_mask: ', new_cluster_mask)\n                    print(closest)\n                    print(closest >= 0)\n                    new_cluster_mask = new_cluster_mask[closest >= 0]\n                    closest = closest[closest >= 0]\n\n\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1][new_cluster_mask]\n            else:\n                num_anchors = 0\n                closest = raw_closest\n                weights = torch.tensor(kmeans_labels).unique(return_counts=True)[1]\n\n        if use_pseudo_label:\n            anchors = self.update_anchors(anchors, data[closest], pseudo_label[closest], feats[closest], weights)\n        else:\n            anchors = self.update_anchors(anchors, data[closest], target[closest], feats[closest], weights)\n\n        return outputs, closest, anchors\n\n    def enable_bn(self, model):\n        if not self.config.model.freeze_bn:\n            for m in model.modules():\n                if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n                    m.momentum = 0.1",
    "Experiment Result": "SimATTA (Self-Supervised Incremental Active Test-Time Adaptation) Framework:\n\n**Core Components & Parameters:**\n1.  **Model Architecture:** Inherits from `AlgBase`, utilizing a feature encoder (`self.encoder`) and a classifier (`self.fc`). A teacher model (`self.teacher`) is maintained as a deep copy of the student model.\n2.  **Model Adaptation Loop (`__call__`, `adapt_on_env`):** The algorithm iterates through test environments or data splits, performing sample selection and model fine-tuning in batches.\n3.  **Sample Selection (`sample_select` method):**\n    *   **Selective Entropy Minimization:** Identifies 'source-like' low-entropy samples and 'informative' high-entropy samples from incoming test data batches.\n    *   `ent_bound` (`config.atta.SimATTA.eh` for high entropy, `config.atta.SimATTA.el` for low entropy): Thresholds used to classify samples as low-entropy (potential pseudo-labels) or high-entropy (potential anchors).\n    *   **Incremental Clustering (`incremental_cluster=True`):** For high-entropy samples (target anchors):\n        *   Clusters features (`feats4cluster`) using KMeans (`sklearn.cluster.KMeans` or `ATTA.utils.fast_pytorch_kmeans.KMeans` if `gpu_clustering` is enabled) with `n_init=10`, `algorithm='elkan'`. Sampling weights (`sample_weight`) can be applied during clustering.\n        *   `n_clusters`: Initial number of clusters for target anchors (default `10`).\n        *   `nc_increase` (`config.atta.SimATTA.nc_increase`): The number of clusters to incrementally increase for each time step.\n        *   Identifies `closest` samples to cluster centers to serve as new anchors, prioritizing new clusters if existing anchors are present (`anchored_cluster_mask`).\n        *   `accumulate_weight=True`: Weights of previous anchors are adjusted based on cluster counts.\n    *   **Low-Entropy Sample Selection (`LE=True`, `ent_beta=0`, `use_pseudo_label=True`):** For 'source-like' low-entropy samples:\n        *   Selects `source_n_clusters` (initial `100`, then increases by `1`) samples with entropy below `config.atta.SimATTA.el`.\n        *   These samples are pseudo-labeled by the teacher model for fine-tuning.\n4.  **Model Fine-tuning (`cluster_train`, `one_step_train` methods):**\n    *   The model is fine-tuned using an SGD optimizer (learning rate `config.atta.SimATTA.lr`, momentum `0.9`).\n    *   A combined loss is minimized: `(1 - alpha) * L_S + alpha * L_T`, where `L_S` is cross-entropy loss on source-like (low-entropy) samples and `L_T` is cross-entropy loss on target (high-entropy anchor) samples.\n    *   `alpha`: Dynamically calculated based on the number of target and source anchors (`target_anchors.num_elem() / (target_anchors.num_elem() + source_anchors.num_elem())`).\n    *   `cold_start` (`config.atta.SimATTA.cold_start`): During the initial phase (when `source_anchors.num_elem() < cold_start`), `alpha` is capped at `0.2` to prioritize target adaptation.\n    *   `stop_tol` (`config.atta.SimATTA.stop_tol`): A stopping criterion for `cluster_train` based on the mean of a loss window.\n5.  **Teacher Model Update (`update_teacher` method):** The teacher model parameters are updated via Exponential Moving Average (EMA) from the student model. Batch Normalization (BN) layer statistics are also updated if `config.model.freeze_bn` is `False`.\n6.  **Budgets:** `self.budgets` accumulates the number of actively labeled samples (i.e., new anchors) during adaptation.\n\n**Key Configurable Parameters from `ATTA/utils/args.py` (SimATTAArgs):**\n*   `steps`: Number of optimization steps for `cluster_train` (e.g., `config.atta.SimATTA.steps`).\n*   `lr`: Learning rate for model fine-tuning.\n*   `eh`: Entropy high threshold for selecting target anchors (`config.atta.SimATTA.eh`).\n*   `el`: Entropy low threshold for selecting source-like samples (`config.atta.SimATTA.el`).\n*   `cold_start`: Number of source samples before `alpha` is allowed to increase beyond 0.2.\n*   `beta`: Unused in the provided `SimATTA.py` code (but present in `SimATTAArgs`).\n*   `nc_increase`: Controls the incremental growth of the number of target clusters.\n*   `stop_tol`: Number of iterations for which a loss window is maintained to determine training convergence.\n*   `target_cluster`: Boolean flag (0 or 1) to enable/disable incremental clustering for target anchors.\n*   `LE`: Boolean flag (0 or 1) to enable/disable the selection of low-entropy (source-like) samples.\n*   `gpu_clustering`: Boolean flag to enable GPU-accelerated KMeans from `ATTA.utils.fast_pytorch_kmeans`."
}{
    "Title": "EcoTTA: Memory-Efficient Continual Test-Time Adaptation via Self-Distilled Regularization",
    "Main Contributions": "This paper introduces EcoTTA, a memory-efficient approach for continual Test-Time Adaptation (TTA). The primary contributions include a novel architecture utilizing lightweight meta networks that adapt frozen original networks to target domains, significantly minimizing memory consumption by reducing intermediate activation sizes (up to 86% less memory than CoTTA). It also proposes a self-distilled regularization technique that prevents catastrophic forgetting and error accumulation during long-term adaptation by controlling meta network outputs to align with frozen original network outputs, preserving source knowledge without additional memory. The method demonstrates superior TTA performance and memory efficiency across image classification (CIFAR-C, ImageNet-C) and semantic segmentation (Cityscapes-C) tasks.",
    "Methodology": "EcoTTA consists of two main components. First, a memory-efficient architecture uses frozen original networks to discard intermediate activations, attaching lightweight meta networks (one batch normalization and one convolution block) to K partitioned parts of the original network. These meta networks are warmed up on source data before deployment. Shallow layers of the encoder are partitioned more densely. Second, a self-distilled regularization method is introduced, employing an L1 loss (Rk = ||~xk - xk||1) to prevent the meta network's output (~xk) from significantly deviating from the frozen original network's output (xk). This preserves source knowledge and prevents error accumulation. The overall loss combines entropy minimization (Lent) with this regularization loss (Ltotal = Lent + λ * sum(Rk)).",
    "Experimental Setup": "Experiments were conducted on continual TTA tasks using image classification and semantic segmentation. For classification, CIFAR10-C, CIFAR100-C, and ImageNet-C datasets were used, featuring 15 corruption types with 5 severity levels. WideResNet-28, WideResNet-40, and ResNet-50 were used as backbone models. For semantic segmentation, Cityscapes-C (with brightness, fog, frost, and snow corruptions) was used with a DeepLabV3+-ResNet-50 model. The continual TTA setup involves adapting the model to each corruption type sequentially without resetting. Evaluation metrics include error rates (for classification), mean Intersection over Union (mIoU for segmentation), and total memory consumption (model parameters + activations). Meta networks were warmed up using SGD (LR 5e-2) for 10 epochs (CIFAR) or 3 epochs (ImageNet). Test-time adaptation used SGD (LR 5e-3), batch sizes of 64 (CIFAR) and 32 (ImageNet), an entropy threshold of 0.4*ln C, and a regularization importance (λ) of 0.5.",
    "Limitations": "The proposed method requires access to the source dataset for a pre-deployment warm-up phase of the meta networks, which might not always be universally available in all TTA scenarios. Although the paper argues this is feasible, it is a dependency. Additionally, the paper notes an engineering-based issue where current PyTorch implementations do not fully support fine-grained gradient computations, meaning the theoretical computational efficiency of EcoTTA is higher than its measured wall-clock time. Performance gain from increasing the model partition factor K tends to saturate beyond K=4 or K=5, indicating diminishing returns for further partitioning.",
    "Future Research Directions": "The paper concludes with a broad statement that the efforts made will \"facilitate a variety of studies that make test-time adaptation for edge devices feasible in practice.\" This suggests a general direction towards further practical deployment and optimization of TTA on resource-constrained edge devices. Specific avenues could involve further integration with advanced small-batch size adaptation techniques beyond AdaptBN, or exploring more complex adaptation losses while maintaining memory efficiency.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nimport torch.jit\nimport PIL\nimport torchvision.transforms as transforms\nimport my_transforms as my_transforms\nfrom copy import deepcopy\n\ndef get_tta_transforms(gaussian_std: float=0.005, soft=False, clip_inputs=False):\n    img_shape = (32, 32, 3) # Note: For ImageNet, this would be (224, 224, 3)\n    n_pixels = img_shape[0]\n    clip_min, clip_max = 0.0, 1.0\n    p_hflip = 0.5\n    tta_transforms = transforms.Compose([\n        my_transforms.Clip(0.0, 1.0), \n        my_transforms.ColorJitterPro(\n            brightness=[0.8, 1.2] if soft else [0.6, 1.4],\n            contrast=[0.85, 1.15] if soft else [0.7, 1.3],\n            saturation=[0.75, 1.25] if soft else [0.5, 1.5],\n            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],\n            gamma=[0.85, 1.15] if soft else [0.7, 1.3]\n        ),\n        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),  \n        transforms.RandomAffine(\n            degrees=[-8, 8] if soft else [-15, 15],\n            translate=(1/16, 1/16),\n            scale=(0.95, 1.05) if soft else (0.9, 1.1),\n            shear=None,\n            resample=PIL.Image.BILINEAR,\n            fillcolor=None\n        ),\n        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),\n        transforms.CenterCrop(size=n_pixels),\n        transforms.RandomHorizontalFlip(p=p_hflip),\n        my_transforms.GaussianNoise(0, gaussian_std),\n        my_transforms.Clip(clip_min, clip_max)\n    ])\n    return tta_transforms\n\ndef update_ema_variables(ema_model, model, alpha_teacher):\n    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n        ema_param.data[:] = alpha_teacher * ema_param[:].data[:] + (1 - alpha_teacher) * param[:].data[:]\n    return ema_model\n\nclass CoTTA(nn.Module):\n    \"\"\"CoTTA adapts a model by entropy minimization during testing.\n\n    Once tented, a model adapts itself by updating on every forward.\n    \"\"\"\n    def __init__(self, model, optimizer, steps=1, episodic=False, mt_alpha=0.99, rst_m=0.1, ap=0.9):\n        super().__init__()\n        self.model = model\n        self.optimizer = optimizer\n        self.steps = steps\n        assert steps > 0, \"cotta requires >= 1 step(s) to forward and update\"\n        self.episodic = episodic\n        \n        self.model_state, self.optimizer_state, self.model_ema, self.model_anchor = \\\n            copy_model_and_optimizer(self.model, self.optimizer)\n        self.transform = get_tta_transforms()    \n        self.mt = mt_alpha\n        self.rst = rst_m\n        self.ap = ap\n\n    def forward(self, x):\n        if self.episodic:\n            self.reset()\n\n        for _ in range(self.steps):\n            outputs = self.forward_and_adapt(x, self.model, self.optimizer)\n\n        return outputs\n\n    def reset(self):\n        if self.model_state is None or self.optimizer_state is None:\n            raise Exception(\"cannot reset without saved model/optimizer state\")\n        load_model_and_optimizer(self.model, self.optimizer,\n                                 self.model_state, self.optimizer_state)\n        self.model_state, self.optimizer_state, self.model_ema, self.model_anchor = \\\n            copy_model_and_optimizer(self.model, self.optimizer)\n\n    @torch.enable_grad()  # ensure grads in possible no grad context for testing\n    def forward_and_adapt(self, x, model, optimizer):\n        outputs = self.model(x)\n        # Teacher Prediction\n        anchor_prob = torch.nn.functional.softmax(self.model_anchor(x), dim=1).max(1)[0]\n        standard_ema = self.model_ema(x)\n        # Augmentation-averaged Prediction\n        N = 32 \n        outputs_emas = []\n        # For ImageNet, a condition 'to_aug = anchor_prob.mean(0)<0.1' is applied here.\n        # The CIFAR version simplifies directly to the condition below.\n        for i in range(N):\n            outputs_  = self.model_ema(self.transform(x)).detach()\n            outputs_emas.append(outputs_)\n        # Threshold choice discussed in supplementary\n        if anchor_prob.mean(0)<self.ap:\n            outputs_ema = torch.stack(outputs_emas).mean(0)\n        else:\n            outputs_ema = standard_ema\n        # Student update\n        loss = (softmax_entropy(outputs, outputs_ema)).mean(0) \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        # Teacher update\n        self.model_ema = update_ema_variables(ema_model = self.model_ema, model = self.model, alpha_teacher=self.mt)\n        # Stochastic restore\n        if True:\n            for nm, m  in self.model.named_modules():\n                for npp, p in m.named_parameters():\n                    if npp in ['weight', 'bias'] and p.requires_grad:\n                        mask = (torch.rand(p.shape)<self.rst).float().cuda() \n                        with torch.no_grad():\n                            p.data = self.model_state[f\"{nm}.{npp}\"] * mask + p * (1.-mask)\n        return outputs_ema\n\n@torch.jit.script\ndef softmax_entropy(x, x_ema):# -> torch.Tensor:\n    \"\"\"Entropy of softmax distribution from logits.\"\"\"\n    # For ImageNet, this is defined as -0.5*(x_ema.softmax(1) * x.log_softmax(1)).sum(1)-0.5*(x.softmax(1) * x_ema.log_softmax(1)).sum(1)\n    # The CIFAR version is simpler:\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\ndef collect_params(model):\n    \"\"\"Collect all trainable parameters.\n\n    Walk the model's modules and collect all parameters.\n    Return the parameters and their names.\n    \"\"\"\n    params = []\n    names = []\n    for nm, m in model.named_modules():\n        if True: # Collect all\n            for np, p in m.named_parameters():\n                if np in ['weight', 'bias'] and p.requires_grad:\n                    params.append(p)\n                    names.append(f\"{nm}.{np}\")\n    return params, names\n\ndef copy_model_and_optimizer(model, optimizer):\n    \"\"\"Copy the model and optimizer states for resetting after adaptation.\"\"\"\n    model_state = deepcopy(model.state_dict())\n    model_anchor = deepcopy(model)\n    optimizer_state = deepcopy(optimizer.state_dict())\n    ema_model = deepcopy(model)\n    for param in ema_model.parameters():\n        param.detach_()\n    return model_state, optimizer_state, ema_model, model_anchor\n\ndef load_model_and_optimizer(model, optimizer, model_state, optimizer_state):\n    \"\"\"Restore the model and optimizer states from copies.\"\"\"\n    model.load_state_dict(model_state, strict=True)\n    optimizer.load_state_dict(optimizer_state)\n\ndef configure_model(model):\n    \"\"\"Configure model for use with tent.\"\"\"\n    model.train()\n    model.requires_grad_(False)\n    for m in model.modules():\n        if isinstance(m, nn.BatchNorm2d):\n            m.requires_grad_(True)\n            m.track_running_stats = False\n            m.running_mean = None\n            m.running_var = None\n        else:\n            m.requires_grad_(True)\n    return model\n\n# Custom transforms from my_transforms.py\nclass GaussianNoise(torch.nn.Module):\n    def __init__(self, mean=0., std=1.):\n        super().__init__()\n        self.std = std\n        self.mean = mean\n\n    def forward(self, img):\n        noise = torch.randn(img.size()) * self.std + self.mean\n        noise = noise.to(img.device)\n        return img + noise\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\nclass Clip(torch.nn.Module):\n    def __init__(self, min_val=0., max_val=1.):\n        super().__init__()\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def forward(self, img):\n        return torch.clip(img, self.min_val, self.max_val)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)\n\nclass ColorJitterPro(ColorJitter):\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):\n        super().__init__(brightness, contrast, saturation, hue)\n        self.gamma = self._check_input(gamma, 'gamma')\n\n    @staticmethod\n    @torch.jit.unused\n    def get_params(brightness, contrast, saturation, hue, gamma):\n        transforms = []\n        if brightness is not None:\n            brightness_factor = random.uniform(brightness[0], brightness[1])\n            transforms.append(Lambda(lambda img: F.adjust_brightness(img, brightness_factor)))\n        if contrast is not None:\n            contrast_factor = random.uniform(contrast[0], contrast[1])\n            transforms.append(Lambda(lambda img: F.adjust_contrast(img, contrast_factor)))\n        if saturation is not None:\n            saturation_factor = random.uniform(saturation[0], saturation[1])\n            transforms.append(Lambda(lambda img: F.adjust_saturation(img, saturation_factor)))\n        if hue is not None:\n            hue_factor = random.uniform(hue[0], hue[1])\n            transforms.append(Lambda(lambda img: F.adjust_hue(img, hue_factor)))\n        if gamma is not None:\n            gamma_factor = random.uniform(gamma[0], gamma[1])\n            transforms.append(Lambda(lambda img: F.adjust_gamma(img, gamma_factor)))\n        random.shuffle(transforms)\n        transform = Compose(transforms)\n        return transform\n\n    def forward(self, img):\n        fn_idx = torch.randperm(5)\n        for fn_id in fn_idx:\n            if fn_id == 0 and self.brightness is not None:\n                brightness = self.brightness\n                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()\n                img = F.adjust_brightness(img, brightness_factor)\n            if fn_id == 1 and self.contrast is not None:\n                contrast = self.contrast\n                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()\n                img = F.adjust_contrast(img, contrast_factor)\n            if fn_id == 2 and self.saturation is not None:\n                saturation = self.saturation\n                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()\n                img = F.adjust_saturation(img, saturation_factor)\n            if fn_id == 3 and self.hue is not None:\n                hue = self.hue\n                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()\n                img = F.adjust_hue(img, hue_factor)\n            if fn_id == 4 and self.gamma is not None:\n                gamma = self.gamma\n                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()\n                img = img.clamp(1e-8, 1.0) # to fix Nan values in gradients, which happens when applying gamma after contrast\n                img = F.adjust_gamma(img, gamma_factor)\n        return img\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + '('\n        format_string += 'brightness={0}'.format(self.brightness)\n        format_string += ', contrast={0}'.format(self.contrast)\n        format_string += ', saturation={0}'.format(self.saturation)\n        format_string += ', hue={0})'.format(self.hue)\n        format_string += ', gamma={0})'.format(self.gamma)\n        return format_string",
    "Experiment Result": "The EcoTTA method is evaluated for test-time adaptation on corrupted datasets (CIFAR-10, CIFAR-100, and ImageNet). The core adaptation logic is encapsulated in the `CoTTA` class, which uses an Exponential Moving Average (EMA) teacher model and a stochastic restoration mechanism for the student model's parameters. Test-time augmentation (TTA) is also applied.\n\n**Configuration Parameters (from `conf.py`):**\n*   **Model Adaptation Method (`MODEL.ADAPTATION`):** `cotta`\n*   **Episodic Adaptation (`MODEL.EPISODIC`):** `False` (adaptation persists across batches)\n*   **EMA Momentum (`OPTIM.MT`):** `0.999`\n*   **Stochastic Restore Rate (`OPTIM.RST`):** `0.01`\n*   **Augmentation-averaged Prediction Threshold (`OPTIM.AP`):** `0.92` (used for conditional application of augmentation-averaged prediction for the teacher's output, specific to CIFAR implementation. ImageNet version uses a fixed threshold of `0.1`).\n*   **Optimizer Steps per Batch (`OPTIM.STEPS`):** `1`\n*   **Learning Rate (`OPTIM.LR`):** `1e-3`\n*   **Optimizer Method (`OPTIM.METHOD`):** `Adam` (or `SGD` with `momentum=0.9`, `dampening=0.0`, `nesterov=True`)\n*   **Test Batch Size (`TEST.BATCH_SIZE`):** `128`\n\n**Dataset and Corruption Settings:**\n*   **Dataset (`CORRUPTION.DATASET`):** `cifar10`, `cifar100`, or `imagenet` C datasets.\n*   **Corruption Types (`CORRUPTION.TYPE`):** A list including `['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']`.\n*   **Corruption Severities (`CORRUPTION.SEVERITY`):** `[5, 4, 3, 2, 1]` (evaluated from highest to lowest severity).\n*   **Number of Examples (`CORRUPTION.NUM_EX`):** `10000` for CIFAR, `5000` for ImageNet.\n\n**Evaluation Protocol:**\nThe evaluation proceeds by loading a pre-trained `base_model`. If `cfg.MODEL.ADAPTATION` is `cotta`, the `setup_cotta` function configures the model for adaptation. The model is then evaluated iteratively for each `severity` level and `corruption_type`. For each corruption, the model's internal state (student, EMA, anchor models, and optimizer state) is reset at the beginning of processing the first severity for a new corruption type (i.e., `i_c == 0`). For subsequent corruption types or when `episodic` is False, the model is not reset, simulating continual adaptation. Accuracy is computed for each (corruption, severity) pair, and the error rate is logged."
}{
    "Title": "Robust Test-Time Adaptation in Dynamic Scenarios",
    "Main Contributions": "The paper introduces a new, more realistic Test-Time Adaptation (TTA) setting called Practical Test-Time Adaptation (PTTA), which simultaneously considers continually changing distributions and correlative sampling in test data streams. To address the challenges of PTTA, it proposes Robust Test-Time Adaptation (RoTTA), a method designed for robust adaptation. RoTTA is shown to be effective and easy to implement, making it a practical deployment option. Extensive experiments demonstrate that RoTTA achieves state-of-the-art results on CIFAR-10-C, CIFAR-100-C, and DomainNet, significantly outperforming existing baselines.",
    "Methodology": "RoTTA consists of three main components: (1) Robust Batch Normalization (RBN): It replaces standard BatchNorm statistics with global statistics (running mean µg and variance σ²g) maintained via Exponential Moving Average (EMA). These global statistics are initialized from the pre-trained model's source domain statistics and updated using EMA with statistics from the buffered samples in the memory bank, providing a more stable normalization for correlatively sampled data. (2) Category-Balanced Sampling with Timeliness and Uncertainty (CSTU): A memory bank stores samples, updated based on category balance, timeliness (age of the sample), and uncertainty (entropy of prediction). Newer and less uncertain samples are prioritized, and capacity is equally distributed per category, with major categories replaced first. (3) Robust Training with Timeliness: A teacher-student model architecture is employed. The student model's affine parameters in RBN layers are updated by minimizing a loss (Lr) over samples from the memory bank. This loss is a cross-entropy between strongly-augmented student predictions and weakly-augmented teacher predictions, reweighted by a timeliness term (E(Ai) = exp(−Ai/N) / (1 + exp(−Ai/N))). The teacher model is updated via EMA of the student's parameters.",
    "Experimental Setup": "The method was evaluated on CIFAR-10-C, CIFAR-100-C for robustness under corruptions, and DomainNet for generalization under large domain shifts. For CIFAR-C datasets, WildResNet-28 and ResNeXt-29 were used, pre-trained from RobustBench. For DomainNet, a ResNet-101 was pre-trained for each source domain. The PTTA setup was simulated by continually changing corruption types (severity 5) for CIFAR-C and adapting to different target domains for DomainNet. Correlative sampling was simulated using a Dirichlet distribution with parameter δ=0.1. Experiments used the Adam optimizer with a learning rate of 1.0 × 10⁻³, batch size of 64, and a memory bank capacity of N=64. Unified hyperparameters for RoTTA were α=0.05, ν=0.001, λt=1.0, and λu=1.0. Performance was measured by average classification error, and ablation studies confirmed the efficacy of each component, as well as sensitivity analyses to hyper-parameters, batch size, and distribution changing order.",
    "Limitations": "The adopted Robust Batch Normalization (RBN) is a naive solution and its effectiveness is sensitive to the design of the α value. While RoTTA is designed to prevent model collapse, the paper notes that an explicit mechanism to recover a model from a collapsed state, as observed in some baselines (e.g., PL, TENT), is still missing. The simulation of correlative sampling primarily focuses on category similarity using Dirichlet distribution, and the approach needs further validation in more diverse real-world scenarios beyond this specific simulation.",
    "Future Research Directions": "Future work could focus on improving the RoTTA algorithm by replacing or refining some of its current components. More importantly, the authors hope this work paves the way for further research into Practical Test-Time Adaptation (PTTA) to make it even more realistic and applicable for deploying models in real-world dynamic scenarios.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nfrom ..utils import memory\nfrom .base_adapter import BaseAdapter\nfrom copy import deepcopy\nfrom .base_adapter import softmax_entropy\nfrom ..utils.bn_layers import RobustBN1d, RobustBN2d\nfrom ..utils.utils import set_named_submodule, get_named_submodule\nfrom ..utils.custom_transforms import get_tta_transforms\n\n\nclass RoTTA(BaseAdapter):\n    def __init__(self, cfg, model, optimizer):\n        super(RoTTA, self).__init__(cfg, model, optimizer)\n        self.mem = memory.CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U)\n        self.model_ema = self.build_ema(self.model)\n        self.transform = get_tta_transforms(cfg)\n        self.nu = cfg.ADAPTER.RoTTA.NU\n        self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY\n        self.current_instance = 0\n\n    @torch.enable_grad()\n    def forward_and_adapt(self, batch_data, model, optimizer):\n        with torch.no_grad():\n            model.eval()\n            self.model_ema.eval()\n            ema_out = self.model_ema(batch_data)\n            predict = torch.softmax(ema_out, dim=1)\n            pseudo_label = torch.argmax(predict, dim=1)\n            entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1)\n\n        for i, data in enumerate(batch_data):\n            p_l = pseudo_label[i].item()\n            uncertainty = entropy[i].item()\n            current_instance = (data, p_l, uncertainty)\n            self.mem.add_instance(current_instance)\n            self.current_instance += 1\n\n            if self.current_instance % self.update_frequency == 0:\n                self.update_model(model, optimizer)\n\n        return ema_out\n\n    def update_model(self, model, optimizer):\n        model.train()\n        self.model_ema.train()\n        sup_data, ages = self.mem.get_memory()\n        l_sup = None\n        if len(sup_data) > 0:\n            sup_data = torch.stack(sup_data)\n            strong_sup_aug = self.transform(sup_data)\n            ema_sup_out = self.model_ema(sup_data)\n            stu_sup_out = model(strong_sup_aug)\n            instance_weight = timeliness_reweighting(ages)\n            l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean()\n\n        l = l_sup\n        if l is not None:\n            optimizer.zero_grad()\n            l.backward()\n            optimizer.step()\n\n        self.update_ema_variables(self.model_ema, self.model, self.nu)\n\n    @staticmethod\n    def update_ema_variables(ema_model, model, nu):\n        for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n            ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:]\n        return ema_model\n\n    def configure_model(self, model: nn.Module):\n\n        model.requires_grad_(False)\n        normlayer_names = []\n\n        for name, sub_module in model.named_modules():\n            if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d):\n                normlayer_names.append(name)\n\n        for name in normlayer_names:\n            bn_layer = get_named_submodule(model, name)\n            if isinstance(bn_layer, nn.BatchNorm1d):\n                NewBN = RobustBN1d\n            elif isinstance(bn_layer, nn.BatchNorm2d):\n                NewBN = RobustBN2d\n            else:\n                raise RuntimeError()\n\n            momentum_bn = NewBN(bn_layer,\n                                self.cfg.ADAPTER.RoTTA.ALPHA)\n            momentum_bn.requires_grad_(True)\n            set_named_submodule(model, name, momentum_bn)\n        return model\n\n\ndef timeliness_reweighting(ages):\n    if isinstance(ages, list):\n        ages = torch.tensor(ages).float().cuda()\n    return torch.exp(-ages) / (1 + torch.exp(-ages))\n\n# From core/adapter/base_adapter.py\n@torch.jit.script\ndef softmax_entropy(x, x_ema):\n    return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1)\n\n# From core/utils/bn_layers.py\nclass MomentumBN(nn.Module):\n    def __init__(self, bn_layer: nn.BatchNorm2d, momentum):\n        super().__init__()\n        self.num_features = bn_layer.num_features\n        self.momentum = momentum\n        if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None:\n            self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean))\n            self.register_buffer(\"source_var\", deepcopy(bn_layer.running_var))\n            self.source_num = bn_layer.num_batches_tracked\n        self.weight = deepcopy(bn_layer.weight)\n        self.bias = deepcopy(bn_layer.bias)\n\n        self.register_buffer(\"target_mean\", torch.zeros_like(self.source_mean))\n        self.register_buffer(\"target_var\", torch.ones_like(self.source_var))\n        self.eps = bn_layer.eps\n\n        self.current_mu = None\n        self.current_sigma = None\n\n    def forward(self, x):\n        raise NotImplementedError\n\n\nclass RobustBN1d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1), var.view(1, -1)\n        else:\n            mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1)\n        bias = self.bias.view(1, -1)\n\n        return x * weight + bias\n\n\nclass RobustBN2d(MomentumBN):\n    def forward(self, x):\n        if self.training:\n            b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False)\n            mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean\n            var = (1 - self.momentum) * self.source_var + self.momentum * b_var\n            self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach())\n            mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1)\n        else:\n            mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1)\n\n        x = (x - mean) / torch.sqrt(var + self.eps)\n        weight = self.weight.view(1, -1, 1, 1)\n        bias = self.bias.view(1, -1, 1, 1)\n\n        return x * weight + bias\n\n# From core/utils/memory.py\nimport random\nimport copy\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport math\n\n\nclass MemoryItem:\n    def __init__(self, data=None, uncertainty=0, age=0):\n        self.data = data\n        self.uncertainty = uncertainty\n        self.age = age\n\n    def increase_age(self):\n        if not self.empty():\n            self.age += 1\n\n    def get_data(self):\n        return self.data, self.uncertainty, self.age\n\n    def empty(self):\n        return self.data == \"empty\"\n\n\nclass CSTU:\n    def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0):\n        self.capacity = capacity\n        self.num_class = num_class\n        self.per_class = self.capacity / self.num_class\n        self.lambda_t = lambda_t\n        self.lambda_u = lambda_u\n\n        self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)]\n\n    def get_occupancy(self):\n        occupancy = 0\n        for data_per_cls in self.data:\n            occupancy += len(data_per_cls)\n        return occupancy\n\n    def per_class_dist(self):\n        per_class_occupied = [0] * self.num_class\n        for cls, class_list in enumerate(self.data):\n            per_class_occupied[cls] = len(class_list)\n\n        return per_class_occupied\n\n    def add_instance(self, instance):\n        assert (len(instance) == 3)\n        x, prediction, uncertainty = instance\n        new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0)\n        new_score = self.heuristic_score(0, uncertainty)\n        if self.remove_instance(prediction, new_score):\n            self.data[prediction].append(new_item)\n        self.add_age()\n\n    def remove_instance(self, cls, score):\n        class_list = self.data[cls]\n        class_occupied = len(class_list)\n        all_occupancy = self.get_occupancy()\n        if class_occupied < self.per_class:\n            if all_occupancy < self.capacity:\n                return True\n            else:\n                majority_classes = self.get_majority_classes()\n                return self.remove_from_classes(majority_classes, score)\n        else:\n            return self.remove_from_classes([cls], score)\n\n    def remove_from_classes(self, classes: list[int], score_base):\n        max_class = None\n        max_index = None\n        max_score = None\n        for cls in classes:\n            for idx, item in enumerate(self.data[cls]):\n                uncertainty = item.uncertainty\n                age = item.age\n                score = self.heuristic_score(age=age, uncertainty=uncertainty)\n                if max_score is None or score >= max_score:\n                    max_score = score\n                    max_index = idx\n                    max_class = cls\n\n        if max_class is not None:\n            if max_score > score_base:\n                self.data[max_class].pop(max_index)\n                return True\n            else:\n                return False\n        else:\n            return True\n\n    def get_majority_classes(self):\n        per_class_dist = self.per_class_dist()\n        max_occupied = max(per_class_dist)\n        classes = []\n        for i, occupied in enumerate(per_class_dist):\n            if occupied == max_occupied:\n                classes.append(i)\n\n        return classes\n\n    def heuristic_score(self, age, uncertainty):\n        return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class)\n\n    def add_age(self):\n        for class_list in self.data:\n            for item in class_list:\n                item.increase_age()\n        return\n\n    def get_memory(self):\n        tmp_data = []\n        tmp_age = []\n\n        for class_list in self.data:\n            for item in class_list:\n                tmp_data.append(item.data)\n                tmp_age.append(item.age)\n\n        tmp_age = [x / self.capacity for x in tmp_age]\n\n        return tmp_data, tmp_age\n\n# From core/utils/custom_transforms.py\nimport torch\nimport torchvision.transforms.functional as F\nfrom torchvision.transforms import ColorJitter, Compose, Lambda\nfrom numpy import random\nimport PIL\nimport torchvision.transforms as transforms\n\n\ndef get_tta_transforms(cfg, gaussian_std: float=0.005, soft=False):\n    img_shape = (*cfg.INPUT.SIZE, 3)\n    n_pixels = img_shape[0]\n\n    clip_min, clip_max = 0.0, 1.0\n\n    p_hflip = 0.5\n\n    tta_transforms = transforms.Compose([\n        Clip(0.0, 1.0),\n        ColorJitterPro(\n            brightness=[0.8, 1.2] if soft else [0.6, 1.4],\n            contrast=[0.85, 1.15] if soft else [0.7, 1.3],\n            saturation=[0.75, 1.25] if soft else [0.5, 1.5],\n            hue=[-0.03, 0.03] if soft else [-0.06, 0.06],\n            gamma=[0.85, 1.15] if soft else [0.7, 1.3]\n        ),\n        transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'),\n        transforms.RandomAffine(\n            degrees=[-8, 8] if soft else [-15, 15],\n            translate=(1/16, 1/16),\n            scale=(0.95, 1.05) if soft else (0.9, 1.1),\n            shear=None,\n            resample=PIL.Image.BILINEAR,\n            fillcolor=None\n        ),\n        transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]),\n        transforms.CenterCrop(size=n_pixels),\n        transforms.RandomHorizontalFlip(p=p_hflip),\n        GaussianNoise(0, gaussian_std),\n        Clip(clip_min, clip_max)\n    ])\n    return tta_transforms\n\n\nclass GaussianNoise(torch.nn.Module):\n    def __init__(self, mean=0., std=1.):\n        super().__init__()\n        self.std = std\n        self.mean = mean\n\n    def forward(self, img):\n        noise = torch.randn(img.size()) * self.std + self.mean\n        noise = noise.to(img.device)\n        return img + noise\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n\n\nclass Clip(torch.nn.Module):\n    def __init__(self, min_val=0., max_val=1.):\n        super().__init__()\n        self.min_val = min_val\n        self.max_val = max_val\n\n    def forward(self, img):\n        return torch.clip(img, self.min_val, self.max_val)\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val)\n\n\nclass ColorJitterPro(ColorJitter):\n    \"\"\"Randomly change the brightness, contrast, saturation, and gamma correction of an image.\"\"\"\n\n    def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0):\n        super().__init__(brightness, contrast, saturation, hue)\n        self.gamma = self._check_input(gamma, 'gamma')\n\n    def forward(self, img):\n        fn_idx = torch.randperm(5)\n        for fn_id in fn_idx:\n            if fn_id == 0 and self.brightness is not None:\n                brightness = self.brightness\n                brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item()\n                img = F.adjust_brightness(img, brightness_factor)\n\n            if fn_id == 1 and self.contrast is not None:\n                contrast = self.contrast\n                contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item()\n                img = F.adjust_contrast(img, contrast_factor)\n\n            if fn_id == 2 and self.saturation is not None:\n                saturation = self.saturation\n                saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item()\n                img = F.adjust_saturation(img, saturation_factor)\n\n            if fn_id == 3 and self.hue is not None:\n                hue = self.hue\n                hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item()\n                img = F.adjust_hue(img, hue_factor)\n\n            if fn_id == 4 and self.gamma is not None:\n                gamma = self.gamma\n                gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item()\n                img = img.clamp(1e-8, 1.0)\n                img = F.adjust_gamma(img, gamma_factor)\n        return img",
    "Experiment Result": "Robust Batch Normalization (RBN):\n- The momentum (`ALPHA`) for updating the global mean and variance in `RobustBN1d` and `RobustBN2d` layers is set to 0.05.\n\nCategory-Balanced Sampling with Timeliness and Uncertainty (CSTU):\n- Memory bank capacity (`MEMORY_SIZE`) is 64 samples.\n- The weight for timeliness (`LAMBDA_T`) in the heuristic score for sample prioritization is 1.0.\n- The weight for uncertainty (`LAMBDA_U`) in the heuristic score for sample prioritization is 1.0.\n- The number of classes (`num_class`) for category balancing is dynamically set by the dataset (e.g., 10 for CIFAR-10, 100 for CIFAR-100).\n\nRobust Training with Timeliness:\n- Teacher Model Update: The Exponential Moving Average (EMA) update rate (`NU`) for the teacher model's parameters is 0.001.\n- Student Model Training:\n  - The student model's affine parameters within the RBN layers are updated.\n  - `UPDATE_FREQUENCY`: The model is updated using samples from the memory bank every 64 processed instances.\n  - `OPTIM.STEPS`: The number of optimization steps performed per batch is 1.\n  - `OPTIM.LR`: The learning rate for the optimizer is 1e-3.\n  - `OPTIM.METHOD`: The optimizer used is Adam, with default `betas=(0.9, 0.999)` and `weight_decay=0.0`.\n  - Strong Augmentation (`get_tta_transforms`):\n    - `ColorJitterPro` is applied with random adjustments to:\n      - brightness: [0.6, 1.4]\n      - contrast: [0.7, 1.3]\n      - saturation: [0.5, 1.5]\n      - hue: [-0.06, 0.06]\n      - gamma: [0.7, 1.3]\n    - `RandomAffine` transformations are applied including:\n      - degrees: [-15, 15]\n      - translate: (1/16, 1/16)\n      - scale: (0.9, 1.1)\n      - resample: PIL.Image.BILINEAR\n    - `GaussianBlur` with `kernel_size=5` and `sigma` in the range [0.001, 0.5].\n    - `RandomHorizontalFlip` with a probability of 0.5.\n    - `GaussianNoise` with `mean=0` and `std=0.005`.\n    - Images are padded by half their size (`int(n_pixels / 2)`) using `edge` mode before affine transformations, then `CenterCrop`ped back to the original size.\n    - Image pixel values are clipped to [0.0, 1.0] at the beginning and end of the transform pipeline.\n  - Loss Function: A cross-entropy loss (`softmax_entropy`) is calculated between strongly-augmented student predictions and weakly-augmented teacher predictions. This loss is reweighted by a timeliness term `exp(−Ai) / (1 + exp(−Ai))`, where `Ai` represents the normalized age of the sample (`ages / self.capacity`)."
}{
    "Title": "Improved Test-Time Adaptation for Domain Generalization",
    "Main Contributions": "The paper addresses the domain generalization (DG) problem by improving test-time training (TTT) strategies, specifically tackling the challenges of selecting an appropriate auxiliary TTT task and identifying reliable parameters to update. The Improved Test-Time Adaptation (ITTA) method proposes a learnable consistency loss for the TTT task, which contains adjustable parameters for better alignment with the main prediction task. Additionally, it introduces new adaptive parameters to the trained model, suggesting that only these adaptive parameters should be updated during the test phase. Extensive experiments demonstrate that ITTA achieves superior performance compared to state-of-the-art methods on various DG benchmarks for both multi-source and single-source DG tasks, validating the effectiveness of the proposed strategies.",
    "Methodology": "The ITTA method improves test-time training for domain generalization through two main components. First, it introduces a **learnable consistency loss (Lwcont)** for the TTT task. Unlike heuristically defined objectives, Lwcont is made learnable by augmenting it with a weight subnetwork (fw), which measures consistency between original and augmented representations (z, z') from a feature extractor fθ(x). The training objective for the feature extractor (fθ) and classifier (fϕ) combines the main cross-entropy loss (Lmain) with Lwcont, weighted by α. To ensure alignment between Lmain and Lwcont, the weight subnetwork (fw) is updated by minimizing the L2 norm of the difference between the normalized gradients of Lmain and Lwcont with respect to fθ's parameters. Second, the method introduces **additional adaptive parameters (fΘ)** as new blocks placed after each block of the pretrained feature extractor (fθ). During the test-time adaptation phase, only these new adaptive parameters (fΘ) are updated by minimizing the learned consistency loss, while the original model parameters (fθ, fϕ) remain fixed. The training process for fθ, fϕ, and fw, and the test-time adaptation process for fΘ are performed in an alternative and online manner, respectively.",
    "Experimental Setup": "ITTA was evaluated on five benchmark datasets: PACS, VLCS, OfficeHome, TerraInc, and DomainNet. The model used an ImageNet-pretrained ResNet18 backbone with 4 blocks as the feature extractor (fθ). Four blocks of additional adaptive parameters (fΘ) were included, each implemented with 5 layers of learnable parameters. The weight subnetwork (fw) consisted of 10 layers of learnable parameters. The classifier (fϕ) was an MLP layer provided by the DomainBed benchmark. The weight parameter (α) for balancing loss terms was set to 1. Experiments followed the rigorous evaluation protocol of DomainBed, conducting 60 trials for each unseen domain, with 5,000 iteration steps per trial. Model selection was based on the 'training-domain validate set' method, picking the best-performing model on validation samples. Multi-source generalization used a leave-one-out strategy, while single-source generalization focused on PACS, training on one domain and testing on the other three. The method was compared against 21 existing domain generalization methods (e.g., ERM, MMD, MixStyle) and three TTT-based methods (TTT, MT3, TENT). Ablation studies were conducted to analyze the effectiveness of the learnable consistency loss (vs. naive consistency, entropy, rotation tasks), adaptive parameters (vs. no TTT, updating all, updating BN layers), α sensitivity, different augmentation skills, varying TTT steps and updating strategies, and different network structures and locations for fw and fΘ.",
    "Limitations": "The proposed learnable consistency loss introduces a computational burden. Specifically, updating the weight subnetwork (fw) requires computing second-order derivatives, which entails an additional forward pass and three backward passes compared to a simpler approach without fw (which requires one forward and one backward pass). This adds extra computational cost to the system.",
    "Future Research Directions": "Future research efforts will focus on simplifying the overall optimization process to reduce the computational cost associated with ITTA, particularly the overhead introduced by updating the learnable weight subnetwork.",
    "Experiment Code": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.autograd as autograd\n\nimport copy\nimport numpy as np\nfrom collections import defaultdict, OrderedDict\n\nfrom domainbed import networks\nfrom domainbed import HSIC\nfrom domainbed.lib.misc import (\n    random_pairs_of_minibatches, ParamDict, MovingAverage, l2_between_dicts\n)\n\n\nclass Algorithm(torch.nn.Module):\n    \"\"\"\n    A subclass of Algorithm implements a domain generalization algorithm.\n    Subclasses should implement the following:\n    - update()\n    - predict()\n    \"\"\"\n    def __init__(self, input_shape, num_classes, num_domains, hparams):\n        super(Algorithm, self).__init__()\n        self.hparams = hparams\n\n    def update(self, minibatches, unlabeled=None):\n        \"\"\"\n        Perform one update step, given a list of (x, y) tuples for all\n        environments.\n\n        Admits an optional list of unlabeled minibatches from the test domains,\n        when task is domain_adaptation.\n        \"\"\"\n        raise NotImplementedError\n\n    def predict(self, x):\n        raise NotImplementedError\n\nclass ITTA(Algorithm):\n    \"\"\"\n    Improved Test-Time Adaptation (ITTA)\n    \"\"\"\n\n    def __init__(self, input_shape, num_classes, num_domains, hparams):\n        super(ITTA, self).__init__(input_shape, num_classes, num_domains,\n                                  hparams)\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.featurizer = networks.ResNet_ITTA(input_shape, self.hparams)\n        self.classifier = networks.Classifier(\n            self.featurizer.n_outputs,\n            num_classes,\n            self.hparams['nonlinear_classifier'])\n        self.test_mapping = networks.MappingNetwork() #specialized for resnet18\n        self.test_optimizer = torch.optim.Adam(self.test_mapping.parameters(), lr=self.hparams[\"lr\"]*0.1)\n        self.optimizer = torch.optim.Adam([\n            {'params': self.featurizer.parameters()},\n            {'params': self.classifier.parameters()}],\n            lr=self.hparams[\"lr\"],\n            weight_decay=self.hparams['weight_decay']\n        )\n        self.MSEloss = nn.MSELoss()\n        self.adaparams = networks.Adaparams() #specialized for resnet18\n        self.adaparams_optimizer = torch.optim.Adam(self.adaparams.parameters(), lr=self.hparams[\"lr\"]*0.1)\n\n    def _get_grads(self, loss):\n        self.optimizer.zero_grad()\n        loss.backward(inputs=list(self.featurizer.parameters()),\n                          retain_graph=True, create_graph=True)\n        dict = OrderedDict(\n            [\n                (name, weights.grad.clone().view(weights.grad.size(0),-1))\n                for name, weights in self.featurizer.named_parameters()\n            ]\n        )\n\n        return dict\n\n    def update(self, minibatches, unlabeled=None):\n        all_x = torch.cat([x for x,y in minibatches])\n        all_y = torch.cat([y for x,y in minibatches])\n        ############################# this is for network update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        loss = loss_reg + loss_cla\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        ############################# this is for adaparams update\n        #############################\n        z_ori, z_aug = self.featurizer(all_x)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.featurizer.fea_forward(z_ori), self.featurizer.fea_forward(z_aug)\n        loss_reg = self.MSEloss(self.adaparams(z_aug - z_ori), torch.zeros_like(z_aug))\n        loss_cla = F.cross_entropy(self.classifier(z_ori), all_y) + \\\n                   F.cross_entropy(self.classifier(z_aug), all_y)\n        dict_reg = self._get_grads(loss_reg)\n        dict_cla = self._get_grads(loss_cla)\n        penalty = l2_between_dicts(dict_reg, dict_cla, normalize=True) * 0.1\n        self.adaparams_optimizer.zero_grad()\n        penalty.backward(inputs=list(self.adaparams.parameters()))\n        self.adaparams_optimizer.step()\n\n        return {'loss': loss_cla.item(), 'reg': loss_reg.item()}\n\n    def test_adapt(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori, z_aug = self.test_mapping.fea1(z_ori), self.test_mapping.fea1(z_aug)\n        z_ori, z_aug = self.featurizer.fea2(z_ori, z_aug)\n        z_ori, z_aug = self.test_mapping.fea2(z_ori), self.test_mapping.fea2(z_aug)\n        z_ori, z_aug = self.featurizer.fea3(z_ori), self.featurizer.fea3(z_aug)\n        z_ori, z_aug = self.test_mapping.fea3(z_ori), self.test_mapping.fea3(z_aug)\n        z_ori, z_aug = self.featurizer.fea4(z_ori), self.featurizer.fea4(z_aug)\n        z_ori, z_aug = self.test_mapping.fea4(z_ori), self.test_mapping.fea4(z_aug)\n        z_ori, z_aug = self.featurizer.flat(z_ori), self.featurizer.flat(z_aug)\n        ########## small lr for large datasets\n        loss_reg = self.MSEloss(self.adaparams(z_aug-z_ori), torch.zeros_like(z_ori)) * self.hparams['ada_lr']\n        self.test_optimizer.zero_grad()\n        loss_reg.backward(inputs=list(self.test_mapping.parameters()))\n        self.test_optimizer.step()\n\n    def predict(self, x):\n        z_ori, z_aug = self.featurizer(x)\n        z_ori = self.test_mapping.fea1(z_ori)\n        z_ori, z_aug = self.featurizer.fea2(z_ori,z_aug)\n        z_ori = self.test_mapping.fea2(z_ori)\n        z_ori = self.featurizer.fea3(z_ori)\n        z_ori = self.test_mapping.fea3(z_ori)\n        z_ori = self.featurizer.fea4(z_ori)\n        z_ori = self.test_mapping.fea4(z_ori)\n        z_ori = self.featurizer.flat(z_ori)\n        return self.classifier(z_ori)\n\ndef l2_between_dicts(dict_1, dict_2, normalize=False):\n    assert len(dict_1) == len(dict_2)\n    dict_1_values = [dict_1[key] for key in sorted(dict_1.keys())]\n    dict_2_values = [dict_2[key] for key in sorted(dict_1.keys())]\n    dict_1_tensor = torch.cat(tuple([t.view(-1) for t in dict_1_values]))\n    dict_2_tensor = torch.cat(tuple([t.view(-1) for t in dict_2_values]))\n    if normalize:\n        dict_1_tensor = (dict_1_tensor-dict_1_tensor.mean().item()) / dict_1_tensor.std().item()\n        dict_2_tensor = (dict_2_tensor-dict_2_tensor.mean().item()) / dict_2_tensor.std().item()\n        dict_2_tensor = dict_2_tensor.detach()\n    return (dict_1_tensor-dict_2_tensor).pow(2).mean()\n\nclass Identity(nn.Module):\n    \"\"\"An identity layer\"\"\"\n    def __init__(self):\n        super(Identity, self).__init__()\n\n    def forward(self, x):\n        return x\n\nclass MappingNetwork(torch.nn.Module):\n    def __init__(self, depth=5):\n        super().__init__()\n        self.depth = depth\n        self.weight1 = nn.ParameterList()\n        self.bias1 = nn.ParameterList()\n        self.weight2 = nn.ParameterList()\n        self.bias2 = nn.ParameterList()\n        self.weight3 = nn.ParameterList()\n        self.bias3 = nn.ParameterList()\n        self.weight4 = nn.ParameterList()\n        self.bias4 = nn.ParameterList()\n        for i in range(depth):\n            self.weight1.append(nn.Parameter(torch.ones((64,56,56))))\n            self.bias1.append(nn.Parameter(torch.zeros((64,56,56))))\n\n            self.weight2.append(nn.Parameter(torch.ones((128,28,28))))\n            self.bias2.append(nn.Parameter(torch.zeros((128,28,28))))\n\n            self.weight3.append(nn.Parameter(torch.ones((256,14,14))))\n            self.bias3.append(nn.Parameter(torch.zeros((256,14,14))))\n\n            self.weight4.append(nn.Parameter(torch.ones((512, 7, 7))))\n            self.bias4.append(nn.Parameter(torch.zeros((512, 7, 7))))\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def fea1(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight1[i] * x + self.bias1[i])\n        x = self.weight1[i+1] * x + self.bias1[i+1]\n        return x\n\n    def fea2(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight2[i] * x + self.bias2[i])\n        x = self.weight2[i + 1] * x + self.bias2[i + 1]\n        return x\n\n    def fea3(self, x):\n        for i in range(self.depth - 1):\n            x = self.relu(self.weight3[i] * x + self.bias3[i])\n        x = self.weight3[i + 1] * x + self.bias3[i + 1]\n        return x\n\n    def fea4(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight4[i] * x + self.bias4[i])\n        x = self.weight4[i+1] * x + self.bias4[i+1]\n        return x\n\n\nclass Adaparams(nn.Module):\n    def __init__(self, depth=10):\n        super(Adaparams, self).__init__()\n        self.relu = nn.ReLU(inplace=True)\n        self.depth = depth\n        self.weight = nn.ParameterList()\n        self.bias = nn.ParameterList()\n        for i in range(depth):\n            self.weight.append(nn.Parameter(torch.ones(512)))\n            self.bias.append(nn.Parameter(torch.zeros(512)))\n\n    def forward(self, x):\n        for i in range(self.depth-1):\n            x = self.relu(self.weight[i] * x + self.bias[i])\n        x = self.weight[i+1] * x + self.bias[i+1]\n        return x\n        \n\ndef Classifier(in_features, out_features, is_nonlinear=False):\n    if is_nonlinear:\n        return torch.nn.Sequential(\n            torch.nn.Linear(in_features, in_features // 2),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features // 2, in_features // 4),\n            torch.nn.ReLU(),\n            torch.nn.Linear(in_features // 4, out_features))\n    else:\n        return torch.nn.Linear(in_features, out_features)\n\n\nclass ResNet_ITTA(torch.nn.Module):\n    \"\"\"ResNet with the softmax chopped off and the batchnorm frozen\"\"\"\n    def __init__(self, input_shape, hparams):\n        super(ResNet_ITTA, self).__init__()\n        if hparams['resnet18']:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 512\n        else:\n            self.network = torchvision.models.resnet18(pretrained=True)\n            self.n_outputs = 2048\n\n        nc = input_shape[0]\n        if nc != 3:\n            tmp = self.network.conv1.weight.data.clone()\n\n            self.network.conv1 = nn.Conv2d(\n                nc, 64, kernel_size=(7, 7),\n                stride=(2, 2), padding=(3, 3), bias=False)\n\n            for i in range(nc):\n                self.network.conv1.weight.data[:, i, :, :] = tmp[:, i % 3, :, :]\n\n        # save memory\n        self.network.fc = Identity()\n        self.isaug = True\n        self.freeze_bn()\n        self.hparams = hparams\n        self.dropout = nn.Dropout(hparams['resnet_dropout'])\n        self.eps = 1e-6\n\n    def mixstyle(self, x):\n        alpha = 0.1\n        beta = torch.distributions.Beta(alpha, alpha)\n        B = x.size(0)\n        mu = x.mean(dim=[2, 3], keepdim=True)\n        var = x.var(dim=[2, 3], keepdim=True)\n        sig = (var + self.eps).sqrt()\n        mu, sig = mu.detach(), sig.detach()\n        x_normed = (x - mu) / sig\n        lmda = beta.sample((B, 1, 1, 1))\n        lmda = lmda.to(x.device)\n        perm = torch.randperm(B)\n        mu2, sig2 = mu[perm], sig[perm]\n        mu_mix = mu * lmda + mu2 * (1 - lmda)\n        sig_mix = sig * lmda + sig2 * (1 - lmda)\n        return x_normed * sig_mix + mu_mix\n\n    def fea_forward(self, x):\n        x = self.fea3(x)\n        x = self.fea4(x)\n\n        x = self.flat(x)\n        return x\n\n    def fea2(self, x, aug_x):\n        x = self.network.layer2(x)\n        aug_x = self.network.layer2(aug_x)\n        if not self.isaug:\n            aug_x = self.mixstyle(aug_x)\n        return x, aug_x\n\n    def fea3(self, x):\n        x = self.network.layer3(x)\n        return x\n\n    def fea4(self, x):\n        x = self.network.layer4(x)\n        return x\n\n    def flat(self, x):\n        x = self.network.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.network.fc(x)\n        x = self.dropout(x)\n        return x\n\n    def forward(self, x):\n        \"\"\"Encode x into a feature vector of size n_outputs.\"\"\"\n        x = self.network.conv1(x)\n        x = self.network.bn1(x)\n        x = self.network.relu(x)\n        x = self.network.maxpool(x)\n\n        x = self.network.layer1(x)\n        if random.random() > 0.5:\n            self.isaug = True\n            aug_x = self.mixstyle(x)\n        else:\n            self.isaug = False\n            aug_x = x\n\n        return x, aug_x\n\n    def train(self, mode=True):\n        \"\"\"\n        Override the default train() to freeze the BN parameters\n        \"\"\"\n        super().train(mode)\n        self.freeze_bn()\n\n    def freeze_bn(self):\n        for m in self.network.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.eval()",
    "Experiment Result": "The ITTA method uses a ResNet_ITTA model as the feature extractor (fθ) and a linear classifier (fϕ). It introduces a `MappingNetwork` (fΘ) for adaptive parameters and an `Adaparams` network (fw) for the learnable consistency loss. \n\n**Training Process:**\n1.  **Network Update (fθ, fϕ):**\n    *   The `featurizer` (ResNet_ITTA) processes input `x` to produce `z_ori` and `z_aug` (augmented by `mixstyle` with `alpha=0.1`).\n    *   `Lwcont` (consistency loss) is computed as `MSEloss(adaparams(z_aug - z_ori), zeros_like(z_aug))`. `z_aug` and `z_ori` are feature representations after processing through initial ResNet blocks.\n    *   `Lmain` (classification loss) is `F.cross_entropy(classifier(z_ori), y) + F.cross_entropy(classifier(z_aug), y)`.\n    *   The total loss for network update is `loss = Lwcont + Lmain`.\n    *   The `featurizer` and `classifier` parameters are updated using `torch.optim.Adam` with `lr` (default 5e-5 for large datasets, 1e-3 for small images) and `weight_decay` (default 0.0 for small images, 10**r.uniform(-6, -2) for large datasets).\n\n2.  **Adaparams Update (fw):**\n    *   Gradients of `Lwcont` (`dict_reg`) and `Lmain` (`dict_cla`) with respect to `featurizer` parameters are computed.\n    *   A penalty term `l2_between_dicts(dict_reg, dict_cla, normalize=True) * 0.1` is calculated. The `0.1` is a fixed multiplier.\n    *   The `adaparams` network parameters are updated by minimizing this penalty using `torch.optim.Adam` with `lr = hparams[\"lr\"] * 0.1`.\n\n**Test-Time Adaptation (fΘ):**\n*   During `test_adapt`, new `MappingNetwork` blocks (fΘ) are inserted after each main block of the `featurizer`.\n*   Only these `test_mapping` parameters are updated by minimizing `Lwcont` using `torch.optim.Adam` with `lr = hparams[\"lr\"] * 0.1`. The consistency loss is scaled by `hparams['ada_lr']`.\n\n**Hyperparameters:**\n*   `lr`: 5e-5 (default for large image datasets like PACS/DomainNet), 1e-3 (for small image datasets like ColoredMNIST/RotatedMNIST).\n*   `weight_decay`: 0.0 (default for small image datasets), 10**r.uniform(-6, -2) (for large datasets).\n*   `ada_lr`: 0.1 (specifically for DomainNet), 1e-6 (for other datasets). This scales the consistency loss during test-time adaptation.\n*   `resnet18`: True (default), meaning a ResNet-18 backbone is used.\n*   `resnet_dropout`: 0.0 (default).\n*   `nonlinear_classifier`: False (default, using a linear classifier).\n*   `batch_size`: 32 (default for large datasets, also for DomainNet), 64 (for small image datasets)."
}{
    "Title": "Persistent Test-time Adaptation in Recurring Testing Scenarios",
    "Main Contributions": "The paper addresses the overlooked problem of gradual performance degradation (model collapse) in Test-Time Adaptation (TTA) over prolonged periods, especially in recurring testing scenarios where environments reappear. It introduces \"recurring TTA\" as a novel diagnostic setting. It formally defines TTA model collapse and provides a theoretical analysis using an ϵ-perturbed Gaussian Mixture Model Classifier (ϵ-GMMC) to identify dataset- and algorithm-dependent factors causing error accumulation. Finally, it proposes Persistent TTA (PeTTA), an adaptation scheme that senses model divergence and adaptively adjusts strategy to balance adaptation and collapse prevention, demonstrating superior and persistent performance over existing baselines.",
    "Methodology": "The paper first establishes a theoretical foundation using an ϵ-perturbed Gaussian Mixture Model Classifier (ϵ-GMMC) to simulate and analyze model collapse, identifying data- and algorithm-dependent factors. Based on these insights, it proposes Persistent TTA (PeTTA). PeTTA employs a divergence sensing mechanism that measures the Mahalanobis distance of feature embedding vectors from the source model's statistics (γy t). This sensed divergence (¯γt) is then used to adaptively adjust the regularization coefficient (λt) and the exponential moving average (EMA) update rate (αt) of the mean-teacher model, balancing adaptation and collapse prevention. It also incorporates an anchor loss (LAL) to minimize KL divergence between the current and source model's output probabilities, along with a category-balanced memory bank and robust batch normalization from prior work.",
    "Experimental Setup": "Experiments were conducted on four TTA classification tasks: CIFAR-10 → CIFAR-10-C, CIFAR-100 → CIFAR-100-C, ImageNet → ImageNet-C (corruption level 5), and DomainNet (real → clipart, painting, sketch). A synthesized ϵ-perturbed Gaussian Mixture Model Classifier (ϵ-GMMC) dataset was used for theoretical validation. Performance was benchmarked in a novel \"recurring TTA\" setting (K=20 revisits with temporally correlated batches) and on the \"Continuously Changing Corruption (CCC)\" benchmark. Compared methods include CoTTA, EATA, RMT, MECTA, RoTTA, ROID, TRIBE, LAME, and RDumb. Implementation utilized PyTorch, pre-trained ResNet50 models from RobustBench and torchvision, Adam optimizer, and specific hyperparameters for PeTTA's adaptive components. Results for PeTTA are averaged over 5 runs with different random seeds, reporting mean and standard deviation.",
    "Limitations": "The paper acknowledges that complete elimination of error accumulation cannot be rigorously guaranteed solely through regularization. PeTTA's current design necessitates the use of a small memory bank to handle temporally correlated testing streams, and it assumes the availability of feature statistics (empirical mean and covariant matrix) from the source distribution. These requirements could potentially limit its scalability and applicability in certain real-world scenarios where source data is strictly inaccessible or memory is severely constrained.",
    "Future Research Directions": "Future work could focus on developing algorithms that inherently prevent error accumulation by construction, moving beyond regularization-based mitigation. Additionally, exploring alternative strategies for reducing the memory footprint, such as storing only embedded features instead of raw images in the memory bank, is suggested to improve scalability.",
    "Experiment Code": "import torch import torch.nn as nn import logging from copy import deepcopy import math import torchvision.transforms.functional as F_vision from torchvision.transforms import ColorJitter, Compose, Lambda from numpy import random as np_random import PIL import torchvision.transforms as transforms @torch.jit.script def softmax_entropy(x, x_ema): return -(x_ema.softmax(1) * x.log_softmax(1)).sum(1) def get_named_submodule(model, sub_name: str): names = sub_name.split(\".\") module = model for name in names: module = getattr(module, name) return module def set_named_submodule(model, sub_name, value): names = sub_name.split(\".\") module = model for i in range(len(names)): if i != len(names) - 1: module = getattr(module, names[i]) else: setattr(module, names[i], value) class MomentumBN(nn.Module): def __init__(self, bn_layer: nn.BatchNorm2d, momentum): super().__init__() self.num_features = bn_layer.num_features self.momentum = momentum if bn_layer.track_running_stats and bn_layer.running_var is not None and bn_layer.running_mean is not None: self.register_buffer(\"source_mean\", deepcopy(bn_layer.running_mean)) self.register_buffer(\"source_var\", deepcopy(bn_layer.running_var)) self.source_num = bn_layer.num_batches_tracked self.weight = deepcopy(bn_layer.weight) self.bias = deepcopy(bn_layer.bias) self.register_buffer(\"target_mean\", torch.zeros_like(self.source_mean)) self.register_buffer(\"target_var\", torch.ones_like(self.source_var)) self.eps = bn_layer.eps self.current_mu = None self.current_sigma = None def forward(self, x): raise NotImplementedError class RobustBN1d(MomentumBN): def forward(self, x): if self.training: b_var, b_mean = torch.var_mean(x, dim=0, unbiased=False, keepdim=False) mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean var = (1 - self.momentum) * self.source_var + self.momentum * b_var self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach()) mean, var = mean.view(1, -1), var.view(1, -1) else: mean, var = self.source_mean.view(1, -1), self.source_var.view(1, -1) x = (x - mean) / torch.sqrt(var + self.eps) weight = self.weight.view(1, -1) bias = self.bias.view(1, -1) return x * weight + bias class RobustBN2d(MomentumBN): def forward(self, x): if self.training: b_var, b_mean = torch.var_mean(x, dim=[0, 2, 3], unbiased=False, keepdim=False) mean = (1 - self.momentum) * self.source_mean + self.momentum * b_mean var = (1 - self.momentum) * self.source_var + self.momentum * b_var self.source_mean, self.source_var = deepcopy(mean.detach()), deepcopy(var.detach()) mean, var = mean.view(1, -1, 1, 1), var.view(1, -1, 1, 1) else: mean, var = self.source_mean.view(1, -1, 1, 1), self.source_var.view(1, -1, 1, 1) x = (x - mean) / torch.sqrt(var + self.eps) weight = self.weight.view(1, -1, 1, 1) bias = self.bias.view(1, -1, 1, 1) return x * weight + bias class MemoryItem: def __init__(self, data=None, uncertainty=0, age=0): self.data = data self.uncertainty = uncertainty self.age = age def increase_age(self): if not self.empty(): self.age += 1 def get_data(self): return self.data, self.uncertainty, self.age def empty(self): return self.data == \"empty\" class CSTU: def __init__(self, capacity, num_class, lambda_t=1.0, lambda_u=1.0): self.capacity = capacity self.num_class = num_class self.per_class = self.capacity / self.num_class self.lambda_t = lambda_t self.lambda_u = lambda_u self.data: list[list[MemoryItem]] = [[] for _ in range(self.num_class)] def get_occupancy(self): occupancy = 0 for data_per_cls in self.data: occupancy += len(data_per_cls) return occupancy def per_class_dist(self): per_class_occupied = [0] * self.num_class for cls, class_list in enumerate(self.data): per_class_occupied[cls] = len(class_list) return per_class_occupied def add_instance(self, instance): assert (len(instance) == 3) x, prediction, uncertainty = instance new_item = MemoryItem(data=x, uncertainty=uncertainty, age=0) new_score = self.heuristic_score(0, uncertainty) if self.remove_instance(prediction, new_score): self.data[prediction].append(new_item) self.add_age() def remove_instance(self, cls, score): class_list = self.data[cls] class_occupied = len(class_list) all_occupancy = self.get_occupancy() if class_occupied < self.per_class: if all_occupancy < self.capacity: return True else: majority_classes = self.get_majority_classes() return self.remove_from_classes(majority_classes, score) else: return self.remove_from_classes([cls], score) def remove_from_classes(self, classes: list[int], score_base): max_class = None max_index = None max_score = None for cls in classes: for idx, item in enumerate(self.data[cls]): uncertainty = item.uncertainty age = item.age score = self.heuristic_score(age=age, uncertainty=uncertainty) if max_score is None or score >= max_score: max_score = score max_index = idx max_class = cls if max_class is not None: if max_score > score_base: self.data[max_class].pop(max_index) return True else: return False else: return True def get_majority_classes(self): per_class_dist = self.per_class_dist() max_occupied = max(per_class_dist) classes = [] for i, occupied in enumerate(per_class_dist): if occupied == max_occupied: classes.append(i) return classes def heuristic_score(self, age, uncertainty): return self.lambda_t * 1 / (1 + math.exp(-age / self.capacity)) + self.lambda_u * uncertainty / math.log(self.num_class) def add_age(self): for class_list in self.data: for item in class_list: item.increase_age() return def get_memory(self): tmp_data = [] tmp_age = [] for class_list in self.data: for item in class_list: tmp_data.append(item.data) tmp_age.append(item.age) tmp_age = [x / self.capacity for x in tmp_age] return tmp_data, tmp_age def get_tta_transforms(cfg, gaussian_std: float=0.005, soft=False): img_shape = (*cfg.INPUT.SIZE, 3) n_pixels = img_shape[0] clip_min, clip_max = 0.0, 1.0 p_hflip = 0.5 tta_transforms = transforms.Compose([ Clip(0.0, 1.0), ColorJitterPro( brightness=[0.8, 1.2] if soft else [0.6, 1.4], contrast=[0.85, 1.15] if soft else [0.7, 1.3], saturation=[0.75, 1.25] if soft else [0.5, 1.5], hue=[-0.03, 0.03] if soft else [-0.06, 0.06], gamma=[0.85, 1.15] if soft else [0.7, 1.3] ), transforms.Pad(padding=int(n_pixels / 2), padding_mode='edge'), transforms.RandomAffine( degrees=[-8, 8] if soft else [-15, 15], translate=(1/16, 1/16), scale=(0.95, 1.05) if soft else (0.9, 1.1), shear=None, resample=PIL.Image.BILINEAR, fillcolor=None ), transforms.GaussianBlur(kernel_size=5, sigma=[0.001, 0.25] if soft else [0.001, 0.5]), transforms.CenterCrop(size=n_pixels), transforms.RandomHorizontalFlip(p=p_hflip), GaussianNoise(0, gaussian_std), Clip(clip_min, clip_max) ]) return tta_transforms class GaussianNoise(torch.nn.Module): def __init__(self, mean=0., std=1.): super().__init__() self.std = std self.mean = mean def forward(self, img): noise = torch.randn(img.size()) * self.std + self.mean noise = noise.to(img.device) return img + noise def __repr__(self): return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std) class Clip(torch.nn.Module): def __init__(self, min_val=0., max_val=1.): super().__init__() self.min_val = min_val self.max_val = max_val def forward(self, img): return torch.clip(img, self.min_val, self.max_val) def __repr__(self): return self.__class__.__name__ + '(min_val={0}, max_val={1})'.format(self.min_val, self.max_val) class ColorJitterPro(ColorJitter): \"\"\"Randomly change the brightness, contrast, saturation, and gamma correction of an image.\"\"\" def __init__(self, brightness=0, contrast=0, saturation=0, hue=0, gamma=0): super().__init__(brightness, contrast, saturation, hue) self.gamma = self._check_input(gamma, 'gamma') @staticmethod @torch.jit.unused def get_params(brightness, contrast, saturation, hue, gamma): \"\"\"Get a randomized transform to be applied on image. Arguments are same as that of __init__. Returns: Transform which randomly adjusts brightness, contrast and saturation in a random order.\"\"\" transforms = [] if brightness is not None: brightness_factor = np_random.uniform(brightness[0], brightness[1]) transforms.append(Lambda(lambda img: F_vision.adjust_brightness(img, brightness_factor))) if contrast is not None: contrast_factor = np_random.uniform(contrast[0], contrast[1]) transforms.append(Lambda(lambda img: F_vision.adjust_contrast(img, contrast_factor))) if saturation is not None: saturation_factor = np_random.uniform(saturation[0], saturation[1]) transforms.append(Lambda(lambda img: F_vision.adjust_saturation(img, saturation_factor))) if hue is not None: hue_factor = np_random.uniform(hue[0], hue[1]) transforms.append(Lambda(lambda img: F_vision.adjust_hue(img, hue_factor))) if gamma is not None: gamma_factor = np_random.uniform(gamma[0], gamma[1]) transforms.append(Lambda(lambda img: F_vision.adjust_gamma(img, gamma_factor))) np_random.shuffle(transforms) transform = Compose(transforms) return transform def forward(self, img): \"\"\" Args: img (PIL Image or Tensor): Input image. Returns: PIL Image or Tensor: Color jittered image.\"\"\" fn_idx = torch.randperm(5) for fn_id in fn_idx: if fn_id == 0 and self.brightness is not None: brightness = self.brightness brightness_factor = torch.tensor(1.0).uniform_(brightness[0], brightness[1]).item() img = F_vision.adjust_brightness(img, brightness_factor) if fn_id == 1 and self.contrast is not None: contrast = self.contrast contrast_factor = torch.tensor(1.0).uniform_(contrast[0], contrast[1]).item() img = F_vision.adjust_contrast(img, contrast_factor) if fn_id == 2 and self.saturation is not None: saturation = self.saturation saturation_factor = torch.tensor(1.0).uniform_(saturation[0], saturation[1]).item() img = F_vision.adjust_saturation(img, saturation_factor) if fn_id == 3 and self.hue is not None: hue = self.hue hue_factor = torch.tensor(1.0).uniform_(hue[0], hue[1]).item() img = F_vision.adjust_hue(img, hue_factor) if fn_id == 4 and self.gamma is not None: gamma = self.gamma gamma_factor = torch.tensor(1.0).uniform_(gamma[0], gamma[1]).item() img = img.clamp(1e-8, 1.0) img = F_vision.adjust_gamma(img, gamma_factor) return img def __repr__(self): format_string = self.__class__.__name__ + '(' format_string += 'brightness={0}'.format(self.brightness) format_string += ', contrast={0}'.format(self.contrast) format_string += ', saturation={0}'.format(self.saturation) format_string += ', hue={0})'.format(self.hue) format_string += ', gamma={0})'.format(self.gamma) return format_string class BaseAdapter(nn.Module): def __init__(self, cfg, model, optimizer): super().__init__() self.logger = logging.getLogger(\"TTA.adapter\") self.cfg = cfg self.model = self.configure_model(model) params, param_names = self.collect_params(self.model) if len(param_names) == 0: self.optimizer = None else: self.optimizer = optimizer(params) self.steps = self.cfg.OPTIM.STEPS assert self.steps > 0, \"requires >= 1 step(s) to forward and update\" def forward(self, x): for _ in range(self.steps): outputs = self.forward_and_adapt(x, self.model, self.optimizer) return outputs def forward_and_adapt(self, *args): raise NotImplementedError(\"implement forward_and_adapt by yourself!\") def configure_model(self, model): raise NotImplementedError(\"implement configure_model by yourself!\") def collect_params(self, model: nn.Module): names = [] params = [] for n, p in model.named_parameters(): if p.requires_grad: names.append(n) params.append(p) return params, names def check_model(self, model): pass def before_tta(self, *args, **kwargs): pass @staticmethod def build_ema(model): ema_model = deepcopy(model) for param in ema_model.parameters(): param.detach_() return ema_model class RoTTA(BaseAdapter): def __init__(self, cfg, model, optimizer): super(RoTTA, self).__init__(cfg, model, optimizer) self.mem = CSTU(capacity=self.cfg.ADAPTER.RoTTA.MEMORY_SIZE, num_class=cfg.CORRUPTION.NUM_CLASS, lambda_t=cfg.ADAPTER.RoTTA.LAMBDA_T, lambda_u=cfg.ADAPTER.RoTTA.LAMBDA_U) self.model_ema = self.build_ema(self.model) self.transform = get_tta_transforms(cfg) self.nu = cfg.ADAPTER.RoTTA.NU self.update_frequency = cfg.ADAPTER.RoTTA.UPDATE_FREQUENCY self.current_instance = 0 @torch.enable_grad() def forward_and_adapt(self, batch_data, model, optimizer): with torch.no_grad(): model.eval() self.model_ema.eval() ema_out = self.model_ema(batch_data) predict = torch.softmax(ema_out, dim=1) pseudo_label = torch.argmax(predict, dim=1) entropy = torch.sum(- predict * torch.log(predict + 1e-6), dim=1) for i, data in enumerate(batch_data): p_l = pseudo_label[i].item() uncertainty = entropy[i].item() current_instance = (data, p_l, uncertainty) self.mem.add_instance(current_instance) self.current_instance += 1 if self.current_instance % self.update_frequency == 0: self.update_model(model, optimizer) return ema_out def update_model(self, model, optimizer): model.train() self.model_ema.train() sup_data, ages = self.mem.get_memory() l_sup = None if len(sup_data) > 0: sup_data = torch.stack(sup_data) strong_sup_aug = self.transform(sup_data) ema_sup_out = self.model_ema(sup_data) stu_sup_out = model(strong_sup_aug) instance_weight = timeliness_reweighting(ages) l_sup = (softmax_entropy(stu_sup_out, ema_sup_out) * instance_weight).mean() l = l_sup if l is not None: optimizer.zero_grad() l.backward() optimizer.step() self.update_ema_variables(self.model_ema, self.model, self.nu) @staticmethod def update_ema_variables(ema_model, model, nu): for ema_param, param in zip(ema_model.parameters(), model.parameters()): ema_param.data[:] = (1 - nu) * ema_param[:].data[:] + nu * param[:].data[:] return ema_model def configure_model(self, model: nn.Module): model.requires_grad_(False) normlayer_names = [] for name, sub_module in model.named_modules(): if isinstance(sub_module, nn.BatchNorm1d) or isinstance(sub_module, nn.BatchNorm2d): normlayer_names.append(name) for name in normlayer_names: bn_layer = get_named_submodule(model, name) if isinstance(bn_layer, nn.BatchNorm1d): NewBN = RobustBN1d elif isinstance(bn_layer, nn.BatchNorm2d): NewBN = RobustBN2d else: raise RuntimeError() momentum_bn = NewBN(bn_layer, self.cfg.ADAPTER.RoTTA.ALPHA) momentum_bn.requires_grad_(True) set_named_submodule(model, name, momentum_bn) return model def timeliness_reweighting(ages): if isinstance(ages, list): ages = torch.tensor(ages).float().cuda() return torch.exp(-ages) / (1 + torch.exp(-ages))",
    "Experiment Result": "Experimental Settings for RoTTA (assumed PeTTA implementation): - Adapter Name: rotta - Memory Size: 64 - Memory Update Frequency: 64 - EMA Update Rate (nu/alpha_t): 0.001 - Robust Batch Normalization Momentum (ALPHA): 0.05 - Memory Timeliness Reweighting Lambda (LAMBDA_T): 1.0 - Memory Uncertainty Reweighting Lambda (LAMBDA_U): 1.0 - Optimization Steps per batch: 1 - Learning Rate: 1e-3 - Optimizer Method: Adam - Test Batch Size: 64 - Dataset: cifar10 or cifar100 - Corruption Types: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression'] - Corruption Severities: [5, 4, 3, 2, 1] - Input Image Size: (32, 32) - Input Pixel Mean: [0.485, 0.456, 0.406] - Input Pixel Std: [0.229, 0.224, 0.225] - Input Transforms (initial): ('normalize',) - TTA Transforms (strong augmentation, soft=False by default):   - Clip: (min_val=0.0, max_val=1.0)   - ColorJitterPro: brightness=[0.6, 1.4], contrast=[0.7, 1.3], saturation=[0.5, 1.5], hue=[-0.06, 0.06], gamma=[0.7, 1.3]   - Pad: padding=16   - RandomAffine: degrees=[-15, 15], translate=(1/16, 1/16), scale=(0.9, 1.1), resample=PIL.Image.BILINEAR   - GaussianBlur: kernel_size=5, sigma=[0.001, 0.5]   - CenterCrop: size=32   - RandomHorizontalFlip: p=0.5   - GaussianNoise: mean=0, std=0.005   - Clip: (min_val=0.0, max_val=1.0) Note: The provided code for RoTTA implements a memory bank (CSTU), mean-teacher model with EMA, robust batch normalization, and an anchor loss based on softmax entropy. However, it does not explicitly implement the adaptive adjustment of regularization coefficient (λt) and EMA update rate (αt) based on Mahalanobis distance of feature embeddings, as described in the paper's theoretical foundation for PeTTA. Instead, λt, λu, and the EMA rate (nu) are configured as fixed values from the configuration file."
}{
    "Title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shifts",
    "Main Contributions": "The paper introduces Test-Time Training (TTT), a novel approach to improve the generalization of predictive models under distribution shifts. TTT converts a single unlabeled test sample into a self-supervised learning problem, on which model parameters are updated before making a prediction. The method extends to online data streams and demonstrates significant performance improvements on diverse image classification benchmarks evaluating robustness to distribution shifts, including CIFAR-10-C, ImageNet-C, VID-Robust, and CIFAR-10.1. A key finding is that TTT-Online often outperforms unsupervised domain adaptation methods (UDA-SS) which have access to the entire unlabeled test set. Theoretically, the paper establishes that positive gradient correlation between the main task loss and the self-supervised task loss is a sufficient condition for TTT to be beneficial in convex models, a finding empirically supported for deep learning models.",
    "Methodology": "Test-Time Training (TTT) begins with a standard K-layer neural network with a shared feature extractor (θe) and two task-specific branches: a main task branch (θm) and a self-supervised task branch (θs), forming a Y-structure. The model is first pre-trained using multi-task learning on both the main classification task (loss lm) and an auxiliary self-supervised task (loss ls) on the original training data. For the self-supervised task, rotation prediction is used, where the model predicts one of four rotation angles (0, 90, 180, 270 degrees) applied to the input image. At test time, for each unlabeled test sample, the shared feature extractor θe is fine-tuned by minimizing the self-supervised task loss ls on that specific sample. The prediction for the main task is then made using the updated parameters. The standard TTT version re-initializes parameters for each test sample, while the online version (TTT-Online) retains the updated parameters from the previous test sample, allowing adaptation to smoothly changing distributions. Optimization is performed using Stochastic Gradient Descent, with a learning rate of 0.001 and zero weight decay and momentum during test-time training. Standard TTT takes ten gradient steps per sample, while TTT-Online takes one. Data augmentation techniques like random crop and horizontal flip are also applied to the test sample during this fine-tuning step.",
    "Experimental Setup": "The method was evaluated using ResNet architectures: ResNet-26 for CIFAR-10-based experiments and ResNet-18 for ImageNet-based experiments. Group Normalization (GN) was used instead of Batch Normalization (BN) due to the small batch size (single image) at test time, which makes BN ineffective. Experiments were conducted on three categories of distribution shifts: 1. Object recognition on corrupted images using CIFAR-10-C and ImageNet-C datasets, which feature 15 types of corruptions across five severity levels. 2. Object recognition on video frames using the VID-Robust dataset, which includes video frames from ImageNet Video detection, and a re-scaled version for CIFAR-10 models. 3. Unknown distribution shifts using CIFAR-10.1, a new test set for CIFAR-10 where shifts are subtle and unidentified. Baselines included a plain ResNet model ('Object recognition task only'), a model jointly trained on main and self-supervised tasks but fixed at test time ('Joint training'), Unsupervised Domain Adaptation by Self-Supervision (UDA-SS) as an oracle, and Adversarial Logit Pairing (ALP) for CIFAR-10 benchmarks. Performance was measured using test error (%) and accuracy (%), with online version results calculated as an average over a sliding window. The theoretical findings on gradient correlation were also empirically validated on the deep learning models across various corruptions.",
    "Limitations": "A primary limitation is the computational overhead, as Test-Time Training is significantly slower (2x batch size x number of iterations) than standard inference, performing multiple forward/backward passes per test sample. While the paper prioritizes robustness over efficiency, this is a practical constraint. The effectiveness of the method depends on the quality of the self-supervised task; it needs to be well-defined and non-trivial for the given data, as observed with the 'airplane' class where rotation prediction was ineffective due to trivial visual cues or inherent ambiguity. The theoretical analysis supporting TTT's success is limited to convex models, although empirical results suggest its applicability to non-convex deep learning models. Furthermore, the method is incompatible with Batch Normalization (BN) layers due to the single-image batch size at test time, necessitating the use of Group Normalization. The online version of TTT also assumes gradually changing distribution shifts, where sequential test samples come from smoothly evolving distributions.",
    "Future Research Directions": "Future work could focus on improving the computational efficiency of Test-Time Training, potentially by designing models amenable to faster updates during training or exploring techniques like thresholding to apply updates only on challenging samples. Developing better and more general-purpose self-supervised tasks, leveraging domain knowledge from various fields (e.g., segmentation, detection, speech recognition, NLP), is another key direction. The paper also proposes using TTT as a new evaluation benchmark for self-supervised tasks. Further theoretical work is suggested to formalize the concept of variable decision boundaries, which differs from traditional learning theory. Exploring connections with and potentially improving TTT through advancements in one-shot learning is also mentioned. More broadly, the authors encourage a paradigm shift towards learning that occurs continuously after model deployment, abandoning the self-imposed constraints of fixed decision boundaries and the strict division between training and testing.",
    "Experiment Code": null,
    "Experiment Result": null
}{
    "Title": "Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning",
    "Main Contributions": "The paper addresses the novel problem of repurposing pretrained Model-Agnostic Meta-Learning (MAML) checkpoints for new few-shot classification tasks, particularly in out-of-domain scenarios, without access to the original meta-training set. It proposes an alternative meta-testing procedure that combines MAML gradient steps with uncertainty-based stepsize adaptation (USA) and adversarial training using uncertainty-based Fast Gradient Sign Method (UFGSM). The method achieves improved accuracy and robustness to base stepsize choice on same-domain and cross-domain benchmarks compared to 'vanilla' MAML, using both SGD and Adam optimizers. It is noted as the first few-shot learning method to combine ensemble methods for stepsize computation and generating adversarial examples from the meta-testing support set for enhanced robustness.",
    "Methodology": "The proposed method starts by taking a pretrained MAML checkpoint (θ0) and creating a deep ensemble by perturbing its parameters with multiplicative Gaussian noise. During T meta-testing steps, each ensemble model undergoes gradient descent using a combined cross-entropy and adversarial training (AT) loss on the support set. Layer-wise stepsizes (αadap) are dynamically adapted using Uncertainty-based Stepsize Adaptation (USA), which assigns lower stepsizes to layers with higher parameter uncertainty (standard deviation across the ensemble). Task-specific adversarial examples are generated using Uncertainty-based FGSM (UFGSM), which applies higher perturbation to input components exhibiting higher variance over the input gradient across the ensemble, and these examples augment the support set (EnAug). Finally, the original checkpoint is updated for T steps using a loss that combines cross-entropy on the support set, AT loss on the support set, and cross-entropy on the ensemble-augmented support set.",
    "Experimental Setup": "MAML was meta-trained on the miniImageNet training split, and the proposed method was evaluated on the resulting checkpoint. Evaluation datasets included miniImageNet test split (same-domain, denoted Mini) and cross-domain datasets: CUB-200-2011 (Birds), Traffic Sign (Signs), and VGG Flower (Flowers). Experiments were conducted for 5-way 1-shot, 5-way 5-shot, and 10-way 1-shot classification tasks, using SGD and Adam optimizers. Key hyperparameters included an ensemble size of 5, an FGSM coefficient ϵ=0.05, a Gaussian perturbation scale σ=0.05, and 10 test-time gradient steps. Performance was measured using three metrics: 'All' (average accuracy over all stepsizes), 'Top-1' (accuracy of the best stepsize), and 'Top-40%' (average of the top 40% accuracies, indicating robustness to stepsize choice). Ablation studies were performed to analyze the contribution of each component (USA, UFGSM, EnAug, AT). Comparisons were also made between UFGSM and standard FGSM, SGD and Adam, and the method's performance on best vs. overfitted checkpoints, and the effect of freezing uncertain BatchNorm layers.",
    "Limitations": "Not explicitly mentioned for the proposed method itself, but deep ensembles inherently add computational overhead during meta-testing compared to a single model. The problem addressed by the paper (inaccessibility of meta-training data for MAML) is itself a limitation of standard meta-learning approaches.",
    "Future Research Directions": "Future work includes applying the proposed method to related settings such as domain adaptation and transfer learning. More generally, the empirical success of the method motivates further research into alternative ways to leverage published model checkpoints for improved generalization.",
    "Experiment Code": null,
    "Experiment Result": null
}

# Instructions
Following the instructions below, please provide an evaluation of the new method.
Since I aim to pursue research of high academic significance, I request that the assessment be conducted with rigorous standards.
- output
    - novelty_reason
        - Determine whether the new method has novelty, and output the reason.
        - The reason should be as specific as possible.
        - Carefully review the content of the studies provided in "Related Works" before outputting.
    - novelty_score
        - Score the novelty of the new method on a scale of 1 to 10, where 1 means no novelty at all and 10 means extremely high novelty.
    - significance_reason
        - Determine whether the new method is significant, and output the reason.
        - Significance includes both academic and societal importance.
    - significance_score
        - Score the significance of the new method on a scale of 1 to 10, where 1 means no significance at all and 10 means extremely high significance.
Output:
{'novelty_reason': 'Most existing TTA methods (Tent, CoTTA, EATA, RoTTA, etc.) rely on iterative SGD/Adam updates of BN affine parameters with a hand-tuned learning-rate.  Only Shrink-Tent uses a proximal view, but it employs a single, isotropic L2 regulariser and still needs a tuned step-size.  The proposed ProxTTA (1) derives a *closed-form* update by solving a per-batch proximal trust-region sub-problem, (2) uses a *diagonal Fisher pre-conditioner* so each channel gets its own automatically scaled step, (3) interprets the update as a natural-gradient trust-region step that gives the first theoretical link between step size and a provable bound on the test loss, and (4) couples this with a latency-aware skipping rule that guarantees compliance with the Realistic TTA protocol without an additional model.  None of the related works combine a per-parameter closed-form natural-gradient update with on-the-fly compute budgeting, making the method substantively different rather than a minor variation on Tent.', 'novelty_score': 7, 'significance_reason': 'Convergence speed is a bottleneck under realistic online protocols that penalise slow adaptation.  By reaching Tent-level accuracy in one pass and skipping updates when the latency budget is exceeded, ProxTTA directly tackles this practical limitation, potentially widening the deployment of TTA on real-time systems such as robotics and mobile devices.  Academically, it injects optimisation-theoretic trust-region ideas into TTA and removes hyper-parameter tuning, which simplifies future research baselines.  Impact is however restricted to the BN-affine-only adaptation regime and the gains, while meaningful (≈1–1.5 % accuracy and large speed-ups), are incremental rather than paradigm-shifting.', 'significance_score': 6}
