
Input:
You are a researcher with expertise in engineering in the field of machine learning.

# Instructions
- The content described in “Repository Content” corresponds to the GitHub repository of the method described in “Method.”
- Please extract the following two pieces of information from “Repository Content”:
    - experimental_code：Extract the implementation sections that are directly related to the method described in “Method.”
    - experimental_info：Extract and output the experimental settings related to the method described in “Method.”

# Method
The methodology frames the choice of integration points (β, a d-dimensional vector) for the TVO as a time-varying Gaussian process (GP) bandit optimization problem. A time-varying reward function is defined as the difference in TVO log evidence estimates between training windows, which is equivalent to maximizing the final log evidence. A time-varying, permutation-invariant GP model is constructed by combining spatial and temporal covariance functions. Specifically, k(x,x') = kβ(β,β') × kT(t,t'), where kT is a temporal covariance function and kβ uses a projection operator Φ to ensure ordering constraints (0 < β1 < ... < βd-1 < 1) by sorting the β vector. At each round, the algorithm selects the next integration schedule βt by maximizing an acquisition function, a linear combination of the GP posterior mean and variance (GP-UCB variant), balancing exploration and exploitation. The GP model is then updated with the observed reward.

# Repository Content
File Path: data/download_MNIST.py
Content:
__author__ = "Xinqiang Ding <xqding@umich.edu>"

import numpy as np
import urllib3
import gzip
import subprocess
import pickle

## download train labels
print("Downloading train-labels-idx1-ubyte ......")
http = urllib3.PoolManager()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
train_label = np.array([data[offset+i] for i in range(num)])

## download train image
print("Downloading train-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]
train_image = image / 255.0

## download test labels
print("Downloading t10k-labels-idx1-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
test_label = np.array([data[offset+i] for i in range(num)])

## download test image
print("Downloading t10k-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
test_image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            test_image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]

test_image = test_image / 255.0

print("Saving data into a pickle file ...")
data = {'train_image': train_image,
        'train_label': train_label,
        'test_image': test_image,
        'test_label': test_label,}

with open("mnist.pkl", 'wb') as file_handle:
    pickle.dump(data, file_handle)



File Path: data/download_binarized_mnist.py
Content:
# Adapted from
# https://github.com/tensorflow/models/tree/master/research/rebar and
# https://github.com/duvenaud/relax/blob/master/datasets.py

import logging
import numpy as np
import urllib.request
import pickle
from pathlib import Path

BINARIZED_MNIST_URL_PREFIX = 'http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist'
BINARIZED_MNIST_DIR = Path('./binarized_mnist')
BINARIZED_MNIST_DIR.mkdir(exist_ok=True, parents=True)


def download_binarized_mnist():
    """Downloads the binarized MNIST dataset and saves to .npy files.

    Args:
        dir: directory where to save dataset
        url_prefix: prefix of url where to download from
        splits: list of url suffixes; subset of train, valid, test
    """
    binarized_mnist = []
    for split in ['train', 'valid', 'test']:
        filename = f'binarized_mnist_{split}.amat'
        url = f'{BINARIZED_MNIST_URL_PREFIX}/binarized_mnist_{split}.amat'
        path = BINARIZED_MNIST_DIR / filename
        urllib.request.urlretrieve(url, path)
        logging.info(f'Downloaded {url} to {path}')

        npy_filename = f'binarized_mnist_{split}.npy'
        npy_path = BINARIZED_MNIST_DIR / npy_filename
        with open(path, 'rb') as f:
            np.save(npy_path,
                    np.array([list(map(int, line.split()))
                              for line in f.readlines()], dtype='uint8'))
            logging.info(f'Saved to {npy_path}')

        binarized_mnist.append(np.load(npy_path))

    x_train, x_valid, x_test = binarized_mnist

    data = {'x_train': x_train,
            'x_valid': x_valid,
            'x_test': x_test}

    with open("binarized_mnist.pkl", 'wb') as file_handle:
        pickle.dump(data, file_handle)


download_binarized_mnist()

File Path: data/download_fashion_MNIST.py
Content:
__author__ = "Xinqiang Ding <xqding@umich.edu>"

import numpy as np
import urllib3
import gzip
import subprocess
import pickle


## download train labels
print("Downloading train-labels-idx1-ubyte ......")
http = urllib3.PoolManager()
r = http.request('GET', 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
train_label = np.array([data[offset+i] for i in range(num)])

## download train image
print("Downloading train-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]
train_image = image / 255.0

## download test labels
print("Downloading t10k-labels-idx1-ubyte ......")
http.clear()
r = http.request('GET', 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
test_label = np.array([data[offset+i] for i in range(num)])

## download test image
print("Downloading t10k-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
test_image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            test_image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]

test_image = test_image / 255.0

print("Saving data into a pickle file ...")
data = {'train_image': train_image,
        'train_label': train_label,
        'test_image': test_image,
        'test_label': test_label,}

with open("fashion_mnist.pkl", 'wb') as file_handle:
    pickle.dump(data, file_handle)

File Path: data/download_kuzushiji_MNIST.py
Content:
__author__ = "Xinqiang Ding <xqding@umich.edu>"

import numpy as np
import urllib3
import gzip
import subprocess
import pickle


## download train labels
print("Downloading train-labels-idx1-ubyte ......")
http = urllib3.PoolManager()
r = http.request('GET', 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
train_label = np.array([data[offset+i] for i in range(num)])

## download train image
print("Downloading train-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]
train_image = image / 255.0

## download test labels
print("Downloading t10k-labels-idx1-ubyte ......")
http.clear()
r = http.request('GET', 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
test_label = np.array([data[offset+i] for i in range(num)])

## download test image
print("Downloading t10k-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
test_image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            test_image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]

test_image = test_image / 255.0

print("Saving data into a pickle file ...")
data = {'train_image': train_image,
        'train_label': train_label,
        'test_image': test_image,
        'test_label': test_label,}

with open("kuzushiji_mnist.pkl", 'wb') as file_handle:
    pickle.dump(data, file_handle)

File Path: data/download_omniglot.py
Content:
__author__ = "Xinqiang Ding <xqding@umich.edu>"
import pickle
import logging
import numpy as np
import scipy.io
import urllib.request
from pathlib import Path

OMNIGLOT_URL = 'https://github.com/yburda/iwae/raw/master/datasets/OMNIGLOT/chardata.mat'

OMNIGLOT_MNIST_DIR = Path('./omniglot')
OMNIGLOT_MNIST_DIR.mkdir(exist_ok=True, parents=True)

path = OMNIGLOT_MNIST_DIR / "chardata.mat"

print("Downloading chardata.mat ...")
urllib.request.urlretrieve(OMNIGLOT_URL, path)


def reshape_data(data):
    return data.reshape((-1, 28, 28)).reshape((-1, 28 * 28), order='F')


def make_omniglot():
    omni_raw = scipy.io.loadmat(path)

    train_image = reshape_data(omni_raw['data'].T.astype('float'))
    test_image = reshape_data(omni_raw['testdata'].T.astype('float'))

    train_label = omni_raw['targetchar'].T.astype('float')
    test_label = omni_raw['testtargetchar'].T.astype('float')

    print("Saving data into a pickle file ...")

    data = {'train_image': train_image,
            'train_label': train_label,
            'test_image': test_image,
            'test_label': test_label}

    with open("omniglot.pkl", 'wb') as file_handle:
        pickle.dump(data, file_handle)


def make_binarized_omniglot():
    n_validation = 1345

    omni_raw = scipy.io.loadmat(path)
    logging.info('Loaded {}'.format(path))

    train_data = reshape_data(omni_raw['data'].T.astype('float32'))
    test_data = reshape_data(omni_raw['testdata'].T.astype('float32'))

    # Binarize the data with a fixed seed
    np.random.seed(5)
    train_data = (np.random.rand(*train_data.shape) < train_data).astype(float)
    test_data = (np.random.rand(*test_data.shape) < test_data).astype(float)

    shuffle_seed = 123
    permutation = np.random.RandomState(
        seed=shuffle_seed).permutation(train_data.shape[0])
    train_data = train_data[permutation]

    x_train = train_data[:-n_validation]
    x_valid = train_data[-n_validation:]
    x_test = test_data

    print("Saving data into a pickle file ...")

    data = {'x_train': x_train,
            'x_valid': x_valid,
            'x_test': x_test}

    with open("binarized_omniglot.pkl", 'wb') as file_handle:
        pickle.dump(data, file_handle)


make_omniglot()
make_binarized_omniglot()

File Path: data/download_tiny_MNIST.py
Content:
__author__ = "Xinqiang Ding <xqding@umich.edu>"

import numpy as np
import urllib3
import gzip
import subprocess
import pickle

## download train labels
print("Downloading train-labels-idx1-ubyte ......")
http = urllib3.PoolManager()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
train_label = np.array([data[offset+i] for i in range(num)])

## download train image
print("Downloading train-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]
train_image = image / 255.0

## download test labels
print("Downloading t10k-labels-idx1-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
offset = 8
test_label = np.array([data[offset+i] for i in range(num)])

## download test image
print("Downloading t10k-image-idx3-ubyte ......")
http.clear()
r = http.request('GET', 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz')
data = gzip.decompress(r.data)
num = int.from_bytes(data[4:8], 'big')
nrows = int.from_bytes(data[8:12], 'big')
ncols = int.from_bytes(data[12:16], 'big')
test_image = np.zeros((num, nrows * ncols))
offset = 16
for k in range(num):
    for i in range(nrows):
        for j in range(ncols):
            test_image[k, i*ncols+j] = data[16 + k*nrows*ncols + i*ncols+j]

test_image = test_image / 255.0


# select 10% of data
idxTrain=np.random.permutation(len(train_label))
train_image=train_image[idxTrain[:6000]]
train_label=train_label[idxTrain[:6000]]

idxTest=np.random.permutation(len(test_label))
test_image=test_image[idxTest[:1000]]
test_label=test_label[idxTest[:1000]]

print("Saving data into a pickle file ...")
data = {'train_image': train_image,
        'train_label': train_label,
        'test_image': test_image,
        'test_label': test_label,}

with open("tiny_mnist.pkl", 'wb') as file_handle:
    pickle.dump(data, file_handle)



File Path: main.py
Content:
import pickle
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset='tiny_mnist'
    #dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 5000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = Path(args.artifact_dir) / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if mlh.is_schedule_update_time(epoch, args):
                args.partition = args.partition_scheduler(model, args)
                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)


        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------
    opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
    save_checkpoint(model, args.epochs, train_elbo, train_logpx, opt, args)

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: main_reproduce.py
Content:
import pickle
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 10000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = Path(args.artifact_dir) / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if mlh.is_schedule_update_time(epoch, args):
                args.partition = args.partition_scheduler(model, args)
                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)


        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------
    opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
    save_checkpoint(model, args.epochs, train_elbo, train_logpx, opt, args)

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: main_test.py
Content:
import json
import os
import pickle
import uuid
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp'
    # gp: without time-varying, without permutation
    # gptv: using time-varying bandit without permutation
    # rand: random schedule with permutation (sorting)
    
    
    burn_in = 2  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # bayes quad
    bq_log_seed_point = -4.0

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 10000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = args.artifact_dir / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if 'gp'  in args.schedule:
            if args.schedule=="gp_bandit":
                if mlh.is_schedule_update_time(epoch, args) or mlh.is_drip(epoch,args):
                    args.partition = args.partition_scheduler(model, args)
    
                    if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                        args.schedule_update_frequency=args.schedule_update_frequency+1
                        print("args.schedule_update_frequency=",args.schedule_update_frequency)
            else:
                if mlh.is_schedule_update_time(epoch, args):
                    args.partition = args.partition_scheduler(model, args)
    
                    if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                        args.schedule_update_frequency=args.schedule_update_frequency+1
                        print("args.schedule_update_frequency=",args.schedule_update_frequency)
        else:
            if mlh.is_schedule_update_time(epoch, args):

                if args.schedule != 'beta_batch_gradient':
                    args.partition = args.partition_scheduler(model, args)
                if args.schedule in ['beta_gradient_descent', 'beta_batch_gradient']:
                    model.track_beta_grad = True

        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [
                optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: main_with_ablation.py
Content:
import json
import os
import pickle
import uuid
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'  # gp_bandit_gp, gp_bandit_tvgp, gp_bandit_rand, gp_bandit_log
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # bayes quad
    bq_log_seed_point = -4.0

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 10000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = args.artifact_dir / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if args.schedule=="gp_bandit" or args.schedule=="gp_bandit_log":
            if mlh.is_schedule_update_time(epoch, args) or mlh.is_drip(epoch,args):
                args.partition = args.partition_scheduler(model, args)

                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)

        else:
            if mlh.is_schedule_update_time(epoch, args):

                if args.schedule != 'beta_batch_gradient':
                    args.partition = args.partition_scheduler(model, args)
                if args.schedule in ['beta_gradient_descent', 'beta_batch_gradient']:
                    model.track_beta_grad = True

        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [
                optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: myresult/_sources/__init___d41d8cd98f00b204e9800998ecf8427e.py
Content:

File Path: myresult/_sources/assertions_7323c050416e29b2f3c2f0decab6d22a.py
Content:
import torch
import numpy as np
from src.ml_helpers import AverageMeter, get_grads, tensor, lognormexp, exponentiate_and_normalize, seed_all
from torch.distributions.multinomial import Multinomial

DUAL_OBJECTIVES = ['wake-wake', 'wake-sleep', 'tvo-sleep', 'tvo_reparam', 'tvo_reparam_iwae']
INTEGRATION_PARTITONS = ['left','right','trapz','single']
PCFGS = ['astronomers', 'brooks', 'minienglish', 'polynomial', 'quadratic', 'sids']
DISCRETE_LOSSES = ['reinforce','tvo','tvo_smoothed', 'vimco','wake-wake','wake-sleep', 'tvo-sleep']

# Assertions
def validate_hypers(args):
    assert args.schedule in [
        'log',
        'linear',
        'bq',
        'moments',
        'rand',
        'gp_bandit',
        'gp',
        'tvgp',
        #'beta_gradient_descent',
        #'beta_batch_gradient'
        ], f"schedule cannot be {args.schedule}"

    assert args.integration in INTEGRATION_PARTITONS, f"integration cannot be {args.integration}"

    assert args.integration_tvo_evidence in INTEGRATION_PARTITONS, f"integration_tvo_evidence cannot be {args.integration_tvo_evidence}"

    assert args.loss in [
        'reinforce',
        'elbo',
        'iwae',
        'tvo',
        'tvo_smoothed',
        'tvo_reparam',
        'tvo_reparam_iwae',
        'vimco',
        'wake-wake',
        'tvo-sleep',
        'wake-sleep'], f"loss cannot be {args.loss} "

    assert args.learning_task in [
        'continuous_vae',
        'discrete_vae',
        'bnn',
        'pcfg'
        ], f" learning_task cannot be {args.learning_task}"

    if args.learning_task != 'pcfg':
        assert args.dataset in [
                'tiny_mnist',
            'fashion_mnist',
            'mnist',
            'kuzushiji_mnist',
            'omniglot',
            'binarized_mnist',
            'binarized_omniglot'], f" dataset cannot be {args.dataset} "
    else:
        assert args.dataset in PCFGS, f"dataset must be one of {PCFGS}"
        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"
        assert args.loss in ['tvo','tvo-sleep','wake-sleep', 'wake-wake'], f'{args.loss} not yet implemented for PCGS yet'

    if args.schedule != 'log':
       assert args.loss in ['elbo','tvo', 'tvo-sleep', 'tvo_reparam', 'tvo_smoothed', 'tvo_reparam_iwae'],  f"{args.loss} doesn't require a partition schedule scheme"
    if args.learning_task in ['discrete_vae']:
        assert args.dataset in ['binarized_mnist', 'binarized_omniglot'], \
            f" dataset cannot be {args.dataset} with {args.learning_task}"

        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"

    if args.learning_task == 'bnn':
        assert args.dataset in ['fashion_mnist'], f" only fashion_mnist tested so far"
        assert args.loss not in DUAL_OBJECTIVES, f"BNN only has phi, can't use alternating objectives"

    if args.loss in DUAL_OBJECTIVES:
        assert not args.save_grads, 'Grad variance not able to handle duel objective methods yet'




    # Add an assertion everytime you catch yourself making a silly hyperparameter mistake so it doesn't happen again


def validate_dataset_path(args):
    learning_task = args.learning_task
    dataset = args.dataset

    if learning_task in ['discrete_vae', 'continuous_vae']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fashion_mnist.pkl'
        elif dataset == 'mnist':
            data_path = args.data_dir + '/mnist.pkl'
        elif dataset == 'tiny_mnist':
            data_path = args.data_dir + '/tiny_mnist.pkl'
        elif dataset == 'omniglot':
            data_path = args.data_dir + '/omniglot.pkl'
        elif dataset == 'kuzushiji_mnist':
            data_path = args.data_dir + '/kuzushiji_mnist.pkl'
        elif dataset == 'binarized_mnist':
            data_path = args.data_dir + '/binarized_mnist.pkl'
        elif dataset == 'binarized_omniglot':
            data_path = args.data_dir + '/binarized_omniglot.pkl'
    elif learning_task in ['bnn']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fmnist/'
    elif learning_task in ['pcfg']:
        data_path = args.data_dir + f'/pcfgs/{dataset}_pcfg.json'
    else:
        raise ValueError("Unknown learning task")

    return data_path

File Path: myresult/_sources/assertions_afdde0274a4f5a17166ea657b4730240.py
Content:
import torch
import numpy as np
from src.ml_helpers import AverageMeter, get_grads, tensor, lognormexp, exponentiate_and_normalize, seed_all
from torch.distributions.multinomial import Multinomial

DUAL_OBJECTIVES = ['wake-wake', 'wake-sleep', 'tvo-sleep', 'tvo_reparam', 'tvo_reparam_iwae']
INTEGRATION_PARTITONS = ['left','right','trapz','single']
PCFGS = ['astronomers', 'brooks', 'minienglish', 'polynomial', 'quadratic', 'sids']
DISCRETE_LOSSES = ['reinforce','tvo','tvo_smoothed', 'vimco','wake-wake','wake-sleep', 'tvo-sleep']

# Assertions
def validate_hypers(args):
    assert args.schedule in [
        'log',
        'linear',
        'bq',
        'moments',
        'rand',
        'gp_bandit',
        'gp',
        'tvgp',
        #'beta_gradient_descent',
        #'beta_batch_gradient'
        ], f"schedule cannot be {args.schedule}"

    assert args.integration in INTEGRATION_PARTITONS, f"integration cannot be {args.integration}"

    assert args.integration_tvo_evidence in INTEGRATION_PARTITONS, f"integration_tvo_evidence cannot be {args.integration_tvo_evidence}"

    assert args.loss in [
        'reinforce',
        'elbo',
        'iwae',
        'tvo',
        'tvo_smoothed',
        'tvo_reparam',
        'tvo_reparam_iwae',
        'vimco',
        'wake-wake',
        'tvo-sleep',
        'wake-sleep'], f"loss cannot be {args.loss} "

    assert args.learning_task in [
        'continuous_vae',
        'discrete_vae',
        'bnn',
        'pcfg'
        ], f" learning_task cannot be {args.learning_task}"

    if args.learning_task != 'pcfg':
        assert args.dataset in [
                'tiny_mnist',
            'fashion_mnist',
            'mnist',
            'kuzushiji_mnist',
            'omniglot',
            'binarized_mnist',
            'binarized_omniglot'], f" dataset cannot be {args.dataset} "
    else:
        assert args.dataset in PCFGS, f"dataset must be one of {PCFGS}"
        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"
        assert args.loss in ['tvo','tvo-sleep','wake-sleep', 'wake-wake'], f'{args.loss} not yet implemented for PCGS yet'

    if args.schedule != 'log':
       assert args.loss in ['tvo', 'tvo-sleep', 'tvo_reparam', 'tvo_smoothed', 'tvo_reparam_iwae'],  f"{args.loss} doesn't require a partition schedule scheme"
    if args.learning_task in ['discrete_vae']:
        assert args.dataset in ['binarized_mnist', 'binarized_omniglot'], \
            f" dataset cannot be {args.dataset} with {args.learning_task}"

        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"

    if args.learning_task == 'bnn':
        assert args.dataset in ['fashion_mnist'], f" only fashion_mnist tested so far"
        assert args.loss not in DUAL_OBJECTIVES, f"BNN only has phi, can't use alternating objectives"

    if args.loss in DUAL_OBJECTIVES:
        assert not args.save_grads, 'Grad variance not able to handle duel objective methods yet'




    # Add an assertion everytime you catch yourself making a silly hyperparameter mistake so it doesn't happen again


def validate_dataset_path(args):
    learning_task = args.learning_task
    dataset = args.dataset

    if learning_task in ['discrete_vae', 'continuous_vae']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fashion_mnist.pkl'
        elif dataset == 'mnist':
            data_path = args.data_dir + '/mnist.pkl'
        elif dataset == 'tiny_mnist':
            data_path = args.data_dir + '/tiny_mnist.pkl'
        elif dataset == 'omniglot':
            data_path = args.data_dir + '/omniglot.pkl'
        elif dataset == 'kuzushiji_mnist':
            data_path = args.data_dir + '/kuzushiji_mnist.pkl'
        elif dataset == 'binarized_mnist':
            data_path = args.data_dir + '/binarized_mnist.pkl'
        elif dataset == 'binarized_omniglot':
            data_path = args.data_dir + '/binarized_omniglot.pkl'
    elif learning_task in ['bnn']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fmnist/'
    elif learning_task in ['pcfg']:
        data_path = args.data_dir + f'/pcfgs/{dataset}_pcfg.json'
    else:
        raise ValueError("Unknown learning task")

    return data_path

File Path: myresult/_sources/bayes_quad_3cc416ed5b964b31eebb4c044115396b.py
Content:
import numpy as np
from src import util
import logging
import torch
#from GPy.models import GPRegression
#from GPy.kern import RBF
#from emukit.model_wrappers.gpy_quadrature_wrappers import BaseGaussianProcessGPy, RBFGPy
#from emukit.quadrature.kernels import QuadratureRBF
#from emukit.quadrature.kernels import QuadratureRBFLebesgueMeasure
#from emukit.quadrature.methods import VanillaBayesianQuadrature
#from emukit.quadrature.acquisitions import IntegralVarianceReduction
#from emukit.core.optimization import GradientAcquisitionOptimizer
#from emukit.core.parameter_space import ParameterSpace
from src.BOv import BayesOpt
import matplotlib.pyplot as plt
from src import ml_helpers as mlh
from src.BOv import unique_rows
import pickle
# Figure config
# NOT TUNABLE HYPERPARAMETERS
# (putting them here so I'm not tempted to tune them)

LEGEND_SIZE = 15
FIGURE_SIZE = (12, 8)
WINDOW = 5
K_MAX = 100
MIN_REL_CHANGE = 1e-3
MIN_ERR = 1e-3
LBM_GRID = np.linspace(-9, -0.1, 50)

emu_log = logging.getLogger("emukit")
emu_log.setLevel(logging.WARNING)

emu_gp = logging.getLogger("GP")
emu_gp.setLevel(logging.WARNING)


#def calculate_bq_points(model, args):
#    # Replace this with any integrand function
#    f = get_integrand_function(model, args)
#
#    # Initial partition (0, lbm, 1)
#    X = mlh.tensor((0, 10**args.bq_log_seed_point, 1.0), args)
#
#    Y = f(X)
#    emukit_method, optimizer = init_bq(X, Y)
#    points, est, k = auto_train_bq(X, Y, f, emukit_method, optimizer, args)
#
#    return points, est, k

def extract_X_Y_from_args(SearchSpace,args,T=None):
    # obtain X and Y by truncating the data in the time-varying setting
    # if the existing data is <3*arg.K, randomly generate X
    
    if T is None:
        T=args.truncation_threshold
    lenY=len(args.Y_ori)
    X=args.X_ori[max(0,lenY-T):,1:-1] # remove the first and last  column which is 0 and 1

    ur=unique_rows(X)
    if sum(ur)<(3*args.K): # random search to get initial data
        init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        init_X=np.around(init_X, decimals=4)
        init_X=np.append(0,init_X)
        init_X=np.append(init_X,1)

        return np.sort(init_X),None

    if lenY%20==0:
        strPath="{:s}/save_X_Y_{:s}_S{:d}_K{:d}.p".format(str(args.artifact_dir), args.schedule, args.S, args.K)
        pickle.dump( [args.X_ori,args.Y_ori], open( strPath, "wb" ) )

    Y=np.reshape(args.Y_ori[max(0,lenY-T):],(-1,1))

    return X,Y

def append_Xori_Yori_from_args(args):
    # append the average logpx into Y
    # append the args.partition into X

    if args.len_terminated_epoch >0: # if we terminate the betas due to drip the epoch len is shorted
        average_y=np.mean(args.logtvopx_all[-args.len_terminated_epoch:])
    else:
        average_y=np.mean(args.logtvopx_all[-args.schedule_update_frequency:])
    args.average_y=np.append(args.average_y,average_y) # averaging the logpx over this window

    # error will happen at the first iteration when we add the first average_y into our data
    # this error is intentional, i will modify it by using a flag to indicate the first time
    if len(args.average_y)==1:
        print("ignore for the first time to save the first value of Y")
        return

    prev_y=args.average_y[-1] -args.average_y[-2]

    args.X_ori=np.vstack(( args.X_ori, np.reshape(format_input(args.partition),(1,args.K+1) )))
    args.Y_ori=np.append(args.Y_ori, prev_y)
    prev_X=np.round(args.X_ori[-1],decimals=4)
    print("X",prev_X,"Y",args.Y_ori[-1])

#def extract_X_Y_from_args_log(SearchSpace,args):
#    # obtain X and Y
#
#    T=args.truncation_threshold
#    lenY=len(args.Y_ori)
#
#    X=np.log10( args.X_ori[max(0,lenY-T):,1:-1]) # remove the first column which is 0
#
#    ur=unique_rows(X)
#    if sum(ur)< (3*args.K) or 'rand' in args.schedule: # random search to get initial data
#        init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
#        init_X=np.around(10**init_X, decimals=4)
#        init_X=np.append(0,init_X)
#        init_X=np.append(init_X,1)
#
#        return np.sort(init_X),None
#
#    if args.X_ori.shape[0]%20==0: #save for analysis purpose
#        strPath="save_X_Y_{:s}_S{:d}_K{:d}.p".format(args.schedule,args.S,args.K)
#        pickle.dump( [args.X_ori,args.Y_ori], open( strPath, "wb" ) )
#
#    Y=np.reshape(args.Y_ori[max(0,lenY-T):],(-1,1))
#
#    return X,Y


def calculate_BO_points(model,args):

    # process the input X and output Y from args
    append_Xori_Yori_from_args(args)

    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            SearchSpace[kk,1]=ll[kk+1]



    # truncate the time-varying data if neccessary
    # if dont have enough data -> randomly generate data
    if args.schedule=="gp": # non timevarying
        X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori))
    else:   # time varying     
        X,Y=extract_X_Y_from_args(SearchSpace,args)
        
    if Y is None:
        return X

    # augment the data with artificial observations all zeros and all ones
    x_all_zeros=np.reshape(np.asarray([args.bandit_beta_min]*(args.K-1)),(1,-1))
    x_all_ones=np.reshape(np.asarray([args.bandit_beta_max]*(args.K-1)),(1,-1))

    worse_score=np.min(Y)

    X=np.vstack((X,x_all_zeros))
    X=np.vstack((X,x_all_ones))

    Y=np.vstack((Y,np.asarray(worse_score)))
    Y=np.vstack((Y,np.asarray(worse_score)))


    # perform GP bandit
    if args.schedule=="gp_bandit":
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace)
    elif args.schedule=="tvgp" or args.schedule=="gp": # TV but not permutation invariant
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")    
    else:
        print("please change ",args.schedule)
        
    
    myBO.init_with_data(X,Y)

    # beta is selected from here
    new_X=myBO.select_next_point()[1]

    # sorting
    new_X=np.round(new_X,decimals=4)
    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X

    
def calculate_BO_points_vanillaGP(model,args): # this is used as a baseline with vanilla GP

    # process the input X and output Y from args
    append_Xori_Yori_from_args(args)

    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            SearchSpace[kk,1]=ll[kk+1]

    X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori)) # this is non timevarying GP, takes all data
    if Y is None:
        return X

    myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")
    myBO.init_with_data(X,Y)

    # beta is selected from here
    new_X=myBO.select_next_point()[1]
    new_X=np.round(new_X,decimals=4)

    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X
    

#def get_derivative_points(X,log_weight,args):
#    Xdrv=[]
#    derivatives=[]
#    for ii in range(X.shape[0]-1): # placing init_K-1 initial derivative observations between two points
#        delta_x=np.abs(X[ii,0]-X[ii+1,0]) # different in x
#        if delta_x<1e-2:
#            continue
#        new_point=delta_x/2+X[ii,0]
#        Xdrv=Xdrv+[new_point] # set the derivative point at the middle of two points
#
#        der = util.calc_var_given_betas(log_weight, args, all_sample_mean=True, betas = new_point)
#        derivatives=derivatives+[round(np.asscalar(format_input(der)),3)]
#    print(derivatives)
#    Xdrv=np.reshape(np.asarray(Xdrv),(-1,1)) # convert Xdrv to [M*d] where d=1
#    derivatives=np.reshape(np.asarray(derivatives),(-1,1)) # convert derivatives to [M*1]
#    return Xdrv, derivatives


#def calculate_bqd_points(model, args): #cal BQ with derivative
#    # we extract log_weight two times! The above line also extracts this. So please optimise!
#    # this log_weight is used to estimate the derivative
#    log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    args.log_weight=log_weight
#
#    # Replace this with any integrand function
#
#    X,Y,f,SearchSpace=init_bqd(model,args)
#
#    #extracting the derivative points
#    Xdrv,derivatives= get_derivative_points(X,log_weight,args)
#    #Xdrv,derivatives= get_derivative_points_middle(X,log_weight,args)
#    Y=np.reshape(np.asarray(Y),(-1,1)) # convert Y to [K*1]
#
#    myGPdrv=GaussianProcessDerivative(SearchSpace)
#    myGPdrv.fit_drv(X,Y,Xdrv,derivatives,drv_index=0)
#    myGPdrv.auto_train_bq(f,MaxK=15)
#
#    est=myGPdrv.integral()[1]
#    points=myGPdrv.X.ravel()
#
#    points=np.asarray([0,0.1,1])
#    #points=np.asarray([0.0000,     0.0001,     0.0017,     0.0210,     0.0724,     0.1434,
#           # 0.1741,     0.5114,     0.8678,     0.9030,     0.9377,     0.9911,1.0000])
#    #return points, 0, len(points)
#
#    #print("[GP with drv] estimated integral is",est) # this function is useful to return the integral
#    return np.sort(points), est, len(points)


#def init_bqd(model,args):
#    log_weight = util.get_total_log_weight(model, args, args.valid_S)
#    args.log_weight=log_weight
#
#    # Replace this with any integrand function
#    # I just want to estimate f(beta=0) for normalising purpose.
#    # This is better way to estimate and do it instead of two repeating calls.
#
#    init_K=3
#    SearchSpace=np.asarray([[0,1]]) # this is the search range of beta from 0-1
#
#    if "loss" in args.schedule:
#        f=get_integrand_function_from_loss(model,args)
#    elif "log" in args.schedule:
#        f = get_integrand_function(model, args)
#        f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
#        args.f_beta0=f_beta0
#        f=get_integrand_function_subtract_beta0_log(model,args) #redefine the function using f(beta=0)
#        SearchSpace=np.asarray([[-1,0]]) # this is the search range of beta from 0-1
#    else:
#        f = get_integrand_function(model, args)
#        f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
#        args.f_beta0=f_beta0
#        f=get_integrand_function_subtract_beta0(model,args) #redefine the function using f(beta=0)
#
#    # Initial partition (0,1)
#    X=np.linspace(SearchSpace[0,0],SearchSpace[0,1],init_K)
#    X=np.reshape(X,(-1,1))
#    Xtensor = mlh.tensor(X, args)
#
#    if "log" in args.schedule:
#        Ytensor = [f(10**Xtensor[ii]) for ii in range(init_K)]
#    else:
#        Ytensor = [f(Xtensor[ii]) for ii in range(init_K)]
#
#    Y=[np.asscalar(Ytensor[ii].data.cpu().numpy()) for ii in range(init_K)] # convert to numpy
#    Y=np.reshape(np.asarray(Y),(-1,1)) # convert Y to [K*1]
#
#    return X,Y,f,SearchSpace


def format_input(*data):
    output = []
    for d in data:
        if torch.is_tensor(d):
            d = d.cpu().numpy()
        if d.ndim == 1:
            d = np.expand_dims(d, 1)
        output.append(d)

    return output[0] if len(output) == 1 else output


def plot_variance(ivr_acquisition):
    x_plot = np.linspace(0, 1, 300)[:, None]
    ivr_plot = ivr_acquisition.evaluate(x_plot)

    plt.figure(figsize=FIGURE_SIZE)
    plt.plot(x_plot, (ivr_plot - np.min(ivr_plot)) / (np.max(ivr_plot) - np.min(ivr_plot)),
             "green", label="integral variance reduction")

    plt.legend(loc=0, prop={'size': LEGEND_SIZE})
    plt.xlabel(r"$x$")
    plt.ylabel(r"$acquisition(x)$")
    plt.grid(True)
    plt.xlim(0, 1)
    plt.ylim(0, 1.04)
    plt.show()


#def init_bq(X, Y, integral_bounds=[(0, 1)]):
#    X, Y = format_input(X, Y)
#    gpy_model = GPRegression(X=X, Y=Y, kernel=RBF(input_dim=X.shape[1],
#                                                  lengthscale=0.5,
#                                                  variance=1.0))
#
#    # Kernals and stuff
#    emukit_rbf    = RBFGPy(gpy_model.kern)
#    emukit_qrbf   = QuadratureRBFLebesgueMeasure(emukit_rbf, integral_bounds=integral_bounds)
#    emukit_model  = BaseGaussianProcessGPy(kern=emukit_qrbf, gpy_model=gpy_model)
#    emukit_method = VanillaBayesianQuadrature(base_gp=emukit_model,X=X,Y=Y)
#
#    space = ParameterSpace(emukit_method.reasonable_box_bounds.convert_to_list_of_continuous_parameters())
#    optimizer = GradientAcquisitionOptimizer(space)
#
#    #space = ParameterSpace(emukit_method.integral_parameters)
#    #optimizer = GradientAcquisitionOptimizer(space)
#    return emukit_method, optimizer


#def auto_calculate_bq_points(model, args):
#    f = get_integrand_function(model, args)
#
#    best_meter = mlh.BestMeter()
#
#    for lbm in LBM_GRID:
#        print("Running lbm = {} ...".format(round(lbm, 3)))
#        X = mlh.tensor((0, 10**lbm, 1.0), args)
#        Y = f(X)
#        emukit_method, optimizer = init_bq(X, Y)
#        points, est, k = auto_train_bq(X, Y, f, emukit_method, optimizer, args)
#        best_meter.step(est, (points, lbm, k))
#
#    best_points, best_lbm, best_k = best_meter.best_obj
#    best_est = best_meter.best
#    return best_points, best_est, best_k, best_lbm


#def auto_train_bq(X, Y, f, emukit_method, optimizer, args):
#    X, Y = format_input(X, Y)
#
#    maxed_out = True
#    mean_avg, err_avg = mlh.MovingAverageMeter('mean', ':.15f', window=WINDOW), mlh.MovingAverageMeter('err', ':.15f', window=WINDOW)
#
#    for k in range(K_MAX):
#        integral_mean, integral_variance = emukit_method.integrate()
#        err = 2 * np.sqrt(integral_variance)
#
#        mean_avg.step(integral_mean)
#        err_avg.step(err)
#
#        ivr_acquisition = IntegralVarianceReduction(emukit_method)
#
#        #plot_variance(ivr_acquisition)
#
#        x_new, _ = optimizer.optimize(ivr_acquisition)
#
#        x_new = mlh.tensor(x_new, args)
#        y_new = f(x_new)
#
#        X = np.append(X, format_input(x_new), axis=0)
#        Y = np.append(Y, format_input(y_new), axis=0)
#
#
#        emukit_method.set_data(X, Y)
#
#        # check break condition
#        if (abs(mean_avg.relative_change) < MIN_REL_CHANGE) and (abs(err_avg.val) < MIN_ERR):
#            maxed_out = False
#            break
#
#    if maxed_out:
#        print("################################################")
#        print(f"---------------- Warning --------------------- ")
#        print(f"Inner loop failed to converge after {K_MAX} iterations ###")
#        print(f"mean_avg: {mean_avg}")
#        print(f"err_avg: {err_avg}")
#        print("################################################")
#
#    return mlh.tensor(np.sort(X.flatten()), args), mean_avg.val, k


#def get_integrand_function_subtract_beta0(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X):
#        partition = mlh.tensor(X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y-args.f_beta0
#    return f

#def get_integrand_function_subtract_beta0_log(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X): # we take 10**X due to the log space
#        partition = mlh.tensor(10**X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y-args.f_beta0
#    return f

#def get_integrand_function(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X):
#        partition = mlh.tensor(X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y
#    return f

def get_cov_function(model, args):

    try: # for BDQ we already have log_weight, dont need to extract it again
        log_weight=args.log_weight
    except: # for other approaches, we need to extract it
        log_weight = util.get_total_log_weight(model, args, args.valid_S)

    def f(X):
        der = util.calc_var_given_betas(log_weight, args, all_sample_mean=True,
                                        betas = X)
        return der
    return f

File Path: myresult/_sources/data_handler_a2c33e4b154fb1936090dee8d8bc094b.py
Content:
# Adapted from
# https://github.com/tensorflow/models/tree/master/research/rebar and
# https://github.com/duvenaud/relax/blob/master/datasets.py

import pickle
import logging
import numpy as np
from pathlib import Path
import torch.utils.data
from src.ml_helpers import tensor, get_data_loader
from src.models.pcfg import GenerativeModel as PCFGGenerativeModel
from src.pcfg_util import read_pcfg
from torchvision import datasets, transforms
from torch.utils.data import Dataset#, IterableDataset
from skimage import color, io as imageio, transform


class StochasticMNIST(Dataset):
    def __init__(self, image):
        super(StochasticMNIST).__init__()
        self.image = image

    def __len__(self):
        return self.image.shape[0]

    def __getitem__(self, idx):
        return (torch.bernoulli(self.image[idx, :]), )


class PixelIntensity(Dataset):
    def __init__(self, image):
        super(PixelIntensity).__init__()
        self.image = image

    def __len__(self):
        return self.image.shape[0]

    def __getitem__(self, idx):
        return (self.image[idx, :], )


class Synthetic(Dataset):
    def __init__(self, X, y=None):
        super(Synthetic).__init__()
        self.X = X
        self.y = y

        if X.ndim == 1:
            self.X = self.X.unsqueeze(1)

        if y is not None:
            assert self.X.shape[0] == self.y.shape[0]

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        if self.y is not None:
            return (self.X[idx, :], self.y[idx])
        else:
            return (self.X[idx, :], )


def make_continuous_vae_data(args):
    # read data
    with open(args.data_path, 'rb') as file_handle:
        data = pickle.load(file_handle)

    train_image = data['train_image']
    test_image = data['test_image']

    # See page 6, footnote 2 here: https://arxiv.org/pdf/1509.00519.pdf
    train_image = StochasticMNIST(tensor(train_image, args))
    test_image = StochasticMNIST(tensor(test_image, args))

    train_data_loader = get_data_loader(train_image, args.batch_size, args)
    test_data_loader = get_data_loader(test_image, args.test_batch_size, args)
    return train_data_loader, test_data_loader


def make_discrete_vae_data(args):
    """
    Annoyingly the continuous and discrete vae literature uses different train/val/test/split.
    For continuous we use 60k train / 10k test
    in accordance with IWAE paper: https://arxiv.org/pdf/1509.00519.pdf

    For discrete we use 50k train / 10k validation / 10k test
    in accordance with VIMCO paper: https://arxiv.org/pdf/1602.06725.pdf

    We don't use the 10k validation to be consistent w/ continuous case
    """
    with open(args.data_path, 'rb') as file_handle:
        data = pickle.load(file_handle)

    train_image = PixelIntensity(tensor(data['x_train'], args))
    test_image = PixelIntensity(tensor(data['x_test'], args))

    train_data_loader = get_data_loader(train_image, args.batch_size, args)
    test_data_loader  = get_data_loader(test_image, args.test_batch_size, args)

    return train_data_loader, test_data_loader


def make_bnn_data(args):
    LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}
    train_data_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            args.data_path, train=True, download=True,
            transform=transforms.ToTensor()),
        batch_size=args.batch_size, shuffle=True, **LOADER_KWARGS)
    test_data_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            args.data_path, train=False, download=True,
            transform=transforms.ToTensor()),
        batch_size=args.test_batch_size, shuffle=False, **LOADER_KWARGS)

    return train_data_loader, test_data_loader


class PCFGDataset(Dataset):
    def __init__(self, path, N=1000):
        super(PCFGDataset).__init__()
        grammar, true_production_probs = read_pcfg(path)
        self.true_generative_model = PCFGGenerativeModel(grammar, true_production_probs)
        # data comes from true_generative_model so we have an infinite amount of it.
        # Set len = 1000 arbitrarily
        self.N = N

    def __len__(self):
        return self.N

    def __getitem__(self, idx):
        return self.true_generative_model.sample_obs()

def make_pcfg_data(args):
    # instantiate a gen model w/ true production probabilities to create data
    dataset = PCFGDataset(args.data_path, N=args.batch_size)

    loader = torch.utils.data.DataLoader(
        dataset,
        batch_size=args.batch_size,
        batch_sampler=None,
        shuffle=False,
        collate_fn=lambda x: (x,) # this is important otherwise default collate_fn messes up batching
        )

    return loader, loader


def get_data(args):
    if args.learning_task == 'continuous_vae':
        return make_continuous_vae_data(args)
    elif args.learning_task == 'discrete_vae':
        return make_discrete_vae_data(args)
    elif args.learning_task == 'bnn':
        return make_bnn_data(args)
    elif args.learning_task == 'pcfg':
        return make_pcfg_data(args)
    else:
        raise ValueError(
            "{} is an invalid learning task".format(args.learning_task))

File Path: myresult/_sources/main_18befc30cf589363888cd872916443a3.py
Content:
import pickle
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset='tiny_mnist'
    #dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 5000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = Path(args.artifact_dir) / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if mlh.is_schedule_update_time(epoch, args):
                args.partition = args.partition_scheduler(model, args)
                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)


        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------
    opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
    save_checkpoint(model, args.epochs, train_elbo, train_logpx, opt, args)

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: myresult/_sources/main_987aea850250fa78c565d7d314a80931.py
Content:
import pickle
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 5000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = Path(args.artifact_dir) / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if mlh.is_schedule_update_time(epoch, args):
                args.partition = args.partition_scheduler(model, args)
                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)


        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------
    opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
    save_checkpoint(model, args.epochs, train_elbo, train_logpx, opt, args)

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: myresult/_sources/main_f12b0f8abce8b63d627401063b89afa7.py
Content:
import json
import os
import pickle
import uuid
import warnings
from pathlib import Path
from types import SimpleNamespace

import numpy as np
import torch
from sacred import Experiment
from sacred.observers import FileStorageObserver
from tqdm import tqdm

import src.ml_helpers as mlh
from src import assertions, util
from src.assertions import DUAL_OBJECTIVES
from src.bayes_quad import format_input#, get_integrand_function
from src.data_handler import get_data
from src.models import updates
from src.models.model_handler import get_model

#from src.data import get_data_loader

warnings.filterwarnings("ignore")

ex = Experiment()

torch.set_printoptions(sci_mode=False)


@ex.config
def my_config():
    """
    This specifies all the parameters for the experiment.
    Only native python objects can appear here (lists, string, dicts, are okay,
    numpy arrays and tensors are not). Everything defined here becomes
    a hyperparameter in the args object, as well as a column in omniboard.
    More complex objects are defined and manuipulated in the init() function
    and attached to the args object.
    The ProbModelBaseClass object is stateful and contains self.args,
    so hyperparameters are accessable to the model via self.args.hyper_param
    """

    # learning task
    learning_task = 'continuous_vae'
    #learning_task = 'discrete_vae'
    artifact_dir = './artifacts'
    data_dir = './data'

    # Model
    loss = 'tvo'
    hidden_dim = 100  # Hidden dimension of middle NN layers in vae
    latent_dim = 25  # Dimension of latent variable z
    integration = 'left'
    integration_tvo_evidence = 'trapz'
    # this is used to estimate get_tvo_log_evidence only
    partition_tvo_evidence = np.linspace(-9, 0, 50)

    cuda = True
    num_stochastic_layers = 1
    num_deterministic_layers = 2
    learn_prior = False
    activation = None  # override Continuous VAE layers
    iw_resample = False  # whether to importance resample TVO proposals (WIP)

    # to terminate a chosen beta for another one if the logpx drops more than this threshold
    drip_threshold = -0.05
    # if it is terminated, this indicates how many epochs have been run from the last bandit
    len_terminated_epoch = 0

    # Hyper
    K = 5
    S = 10
    lr = 0.001
    log_beta_min = -1.602  # -1.09
    bandit_beta_min = 0.05  # -1.09
    bandit_beta_max = 0.95  # -1.09

    # Scheduling
    schedule = 'gp_bandit'
    burn_in = 20  # number of epochs to wait before scheduling begins, useful to set low for debugging
    schedule_update_frequency = 6  # if 0, initalize once and never update
    per_sample = False  # Update schedule for each sample
    per_batch = False

    # bayes quad
    bq_log_seed_point = -4.0

    # Recording
    record = False
    record_partition = None #True  # unused.  possibility to std-ize partitions for evaluation
    verbose = False
    dataset = 'mnist'
    #dataset = 'omniglot'

    phi_tag = 'encoder'
    theta_tag = 'decoder'

    # Training
    seed = 1
    epochs = 10000
    batch_size = 1000  # 1000
    valid_S = 100
    test_S = 5000
    test_batch_size = 1

    increment_update_frequency=10


    optimizer = "adam"
    checkpoint_frequency = int(epochs / 5)
    checkpoint = False
    checkpoint = checkpoint if checkpoint_frequency > 0 else False

    test_frequency = 200  # 20
    test_during_training = True
    test_during_training = test_during_training if test_frequency > 0 else False
    train_only = False
    save_grads = False

    # store all betas and logpx at all epochs
    betas_all = np.empty((0, K+1), float)
    logtvopx_all = []
    truncation_threshold = 30*K
    X_ori = np.empty((0, K+1), float)
    Y_ori = []
    average_y = []


    # beta gradient descent step size
    beta_step_size = 0.01
    max_beta_step = 0.025
    adaptive_beta_step = False

    # following args all set internaly
    init_expectation = None
    expectation_diffs = 0 # mlh.AccumulatedDiff()

    if learning_task == 'discrete_vae':
        dataset = 'binarized_mnist'
        # dataset = 'binarized_omniglot'

        # To match paper (see app. I)
        num_stochastic_layers = 3
        num_deterministic_layers = 0
        increment_update_frequency=10


    if learning_task == 'bnn':
        dataset = 'fashion_mnist'

        bnn_mini_batch_elbo = True

        batch_size = 100 # To match tutorial (see: https://www.nitarshan.com/bayes-by-backprop/)
        test_batch_size = 5

        # This can still be overwritten via the command line
        S = 10
        test_S = 10
        valid_S = 10

    if learning_task == 'pcfg':
        dataset = 'astronomers'
        ## to match rrws code
        batch_size = 2
        schedule = 'log'
        S = 20
        train_only = True # testing happens in training loop
        cuda = False
        epochs = 2000

        phi_tag = 'inference_network'
        theta_tag = 'generative_model'


def init(config, _run):
    args = SimpleNamespace(**config)
    assertions.validate_hypers(args)
    mlh.seed_all(args.seed)

    args.data_path = assertions.validate_dataset_path(args)

    if args.activation is not None:
        if 'relu' in args.activation:
            args.activation = torch.nn.ReLU()
        elif 'elu' in args.activation:
            args.activation = torch.nn.ELU()
        else:
            args.activation = torch.nn.ReLU()

    args._run = _run

    Path(args.artifact_dir).mkdir(exist_ok=True)

    args.loss_name = args.loss

    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False

    args.partition_scheduler = updates.get_partition_scheduler(args)
    args.partition = util.get_partition(args)

    args.data_path = Path(args.data_path)
    return args


@ex.capture
def log_scalar(_run=None, **kwargs):
    assert "step" in kwargs, 'Step must be included in kwargs'
    step = kwargs.pop('step')

    for k, v in kwargs.items():
        _run.log_scalar(k, float(v), step)

    loss_string = " ".join(("{}: {:.4f}".format(*i) for i in kwargs.items()))
    print(f"Epoch: {step} - {loss_string}")


@ex.capture
def save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args, _run=None, _config=None):
    path = Path(args.artifact_dir) / 'model_epoch_{:04}.pt'.format(epoch)

    print("Saving checkpoint: {}".format(path))

    if args.loss in DUAL_OBJECTIVES:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer_phi': opt[0].state_dict(),
                    'optimizer_theta': opt[1].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)
    else:
        torch.save({'epoch': epoch,
                    'model': model.state_dict(),
                    'optimizer': opt[0].state_dict(),
                    'train_elbo': train_elbo,
                    'train_logpx': train_logpx,
                    'config': dict(_config)}, path)

    _run.add_artifact(path)


def train(args):
    # read data
    train_data_loader, test_data_loader = get_data(args)

    # attach data to args
    args.train_data_loader = train_data_loader
    args.test_data_loader = test_data_loader

    # Make models
    model = get_model(train_data_loader, args)

    # Make optimizer
    if args.loss in DUAL_OBJECTIVES:
        optimizer_phi = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.phi_tag in name), lr=args.lr)
        optimizer_theta = torch.optim.Adam(
            (params for name, params in model.named_parameters() if args.theta_tag in name), lr=args.lr)

    else:
        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    #for epoch in range(args.epochs):
    for epoch in tqdm(range(args.epochs)):
        if mlh.is_schedule_update_time(epoch, args):
                args.partition = args.partition_scheduler(model, args)
                if len(args.Y_ori)%args.increment_update_frequency==0 and len(args.Y_ori)>1:
                    args.schedule_update_frequency=args.schedule_update_frequency+1
                    print("args.schedule_update_frequency=",args.schedule_update_frequency)


        if args.loss in DUAL_OBJECTIVES:
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_dual_objectives(
                train_data_loader, optimizer_phi, optimizer_theta, epoch=epoch)
        else:
            # addl recording within model.base
            train_logpx, train_elbo, train_tvo_log_evidence = model.train_epoch_single_objective(
                train_data_loader, optimizer, epoch=epoch)

        log_scalar(train_elbo=train_elbo, train_logpx=train_logpx,
                   train_tvo_log_evidence=train_tvo_log_evidence, step=epoch)

        # store the information
        args.betas_all = np.vstack((args.betas_all, np.reshape(
            format_input(args.partition), (1, args.K+1))))
        args.logtvopx_all = np.append(
            args.logtvopx_all, train_tvo_log_evidence)


        if mlh.is_gradient_time(epoch, args):
            # Save grads
            grad_variance = util.calculate_grad_variance(model, args)
            log_scalar(grad_variance=grad_variance, step=epoch)

        if mlh.is_test_time(epoch, args):
            test_logpx, test_kl = model.evaluate_model_and_inference_network(test_data_loader, epoch=epoch)
            log_scalar(test_logpx=test_logpx, test_kl=test_kl, step=epoch)

        if mlh.is_checkpoint_time(epoch, args):
            opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
            save_checkpoint(model, epoch, train_elbo, train_logpx, opt, args)


        # ------ end of training loop ---------
    opt = [optimizer_phi, optimizer_theta] if args.loss in DUAL_OBJECTIVES else [optimizer]
    save_checkpoint(model, args.epochs, train_elbo, train_logpx, opt, args)

    if args.train_only:
        test_logpx, test_kl = 0, 0

    results = {
        "test_logpx": test_logpx,
        "test_kl": test_kl,
        "train_logpx": train_logpx,
        "train_elbo": train_elbo,
        "train_tvo_px": train_tvo_log_evidence,
        "average_y": args.average_y,  # average tvo_logpx within this bandit iteration
        "X": args.X_ori,  # this is betas
        # this is utility score y=f(betas)= ave_y[-1] - ave_y[-2]
        "Y": args.Y_ori
    }

    return results, model


@ex.automain
def experiment(_config, _run):
    '''
    Amended to return
    '''

    args = init(_config, _run)
    result, model = train(args)

    if args.record:
        model.record_artifacts(_run)

    return result

File Path: myresult/_sources/ml_helpers_4b3e40e9dfa8584361785141357f6b9a.py
Content:
from __future__ import division
import sys
import os
import torch
from torch._six import inf
import numpy as np
import pandas as pd
import random
from joblib import Parallel, delayed
import joblib
from pathlib import Path
from datetime import datetime
import socket

persist_dir = Path('./.persistdir')
#print(persist_dir)


class AverageMeter(object):
    """
    Computes and stores the average, var, and sample_var
    Taken from https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm
    """

    def __init__(self, name="AverageMeter", fmt=':f'):
        self.name = name
        self.fmt = fmt
        self.reset()

    def reset(self):
        self.count = 0
        self.M2 = 0

        self.mean = 0
        self.variance = 0
        self.sample_variance = 0

    def step(self, val):
        self.count += 1
        delta = val - self.mean
        self.mean += delta / self.count
        delta2 = val - self.mean
        self.M2 += delta * delta2

        self.variance = self.M2 / self.count if self.count > 2 else 0
        self.sample_variance = self.M2 / \
            (self.count - 1) if self.count > 2 else 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({var' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.mean, var=self.variance)


class MovingAverageMeter(object):
    """Computes the  moving average of a given float."""

    def __init__(self, name, fmt=':f', window=5):
        self.name = "{} (window = {})".format(name, window)
        self.fmt = fmt
        self.N = window
        self.history = []
        self.val = None
        self.reset()

    def reset(self):
        self.val = None
        self.history = []

    def step(self, val):
        self.history.append(val)
        self.previous = self.val
        if self.val is None:
            self.val = val
        else:
            window = self.history[-self.N:]
            self.val = sum(window) / len(window)
            if len(window) == self.N:
                self.history == window
        return self.val

    @property
    def relative_change(self):
        if None not in [self.val, self.previous]:
            relative_change = (self.previous - self.val) / self.previous
            return relative_change
        else:
            return 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.val, avg=self.relative_change)


class ConvergenceMeter(object):
    """This is a modification of pytorch's ReduceLROnPlateau object
        (https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#ReduceLROnPlateau)
        which acts as a convergence meter. Everything
        is the same as ReduceLROnPlateau, except it doesn't
        require an optimizer and doesn't modify the learning rate.
        When meter.converged(loss) is called it returns a boolean that
        says if the loss has converged.

    Args:
        mode (str): One of `min`, `max`. In `min` mode, lr will
            be reduced when the quantity metered has stopped
            decreasing; in `max` mode it will be reduced when the
            quantity metered has stopped increasing. Default: 'min'.
        patience (int): Number of epochs with no improvement after
            which learning rate will be reduced. For example, if
            `patience = 2`, then we will ignore the first 2 epochs
            with no improvement, and will only decrease the LR after the
            3rd epoch if the loss still hasn't improved then.
            Default: 10.
        threshold (float): Threshold for measuring the new optimum,
            to only focus on significant changes. Default: 1e-4.
        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,
            dynamic_threshold = best * ( 1 + threshold ) in 'max'
            mode or best * ( 1 - threshold ) in `min` mode.
            In `abs` mode, dynamic_threshold = best + threshold in
            `max` mode or best - threshold in `min` mode. Default: 'rel'.
        cooldown (int): Number of epochs to wait before resuming
            normal operation after lr has been reduced. Default: 0.
        min_lr (float or list): A scalar or a list of scalars. A
            lower bound on the learning rate of all param groups
            or each group respectively. Default: 0.
        eps (float): Minimal decay applied to lr. If the difference
            between new and old lr is smaller than eps, the update is
            ignored. Default: 1e-8.

    Example:
        >>> meter = Meter('min')
        >>> for epoch in range(10):
        >>>     train(...)
        >>>     val_loss = validate(...)
        >>>     if meter.converged(val_loss):
        >>>         break
    """

    def __init__(self, mode='min', patience=10,
                 verbose=False, threshold=1e-4, threshold_mode='rel',
                 cooldown=0, eps=1e-8):

        self.has_converged = False
        self.patience = patience
        self.verbose = verbose
        self.cooldown = cooldown
        self.cooldown_counter = 0
        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode
        self.best = None
        self.num_bad_epochs = None
        self.mode_worse = None  # the worse value for the chosen mode
        self.eps = eps
        self.last_epoch = -1
        self._init_is_better(mode=mode, threshold=threshold,
                             threshold_mode=threshold_mode)
        self._reset()

    def _reset(self):
        """Resets num_bad_epochs counter and cooldown counter."""
        self.best = self.mode_worse
        self.cooldown_counter = 0
        self.num_bad_epochs = 0

    def step(self, metrics, epoch=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)
        if epoch is None:
            epoch = self.last_epoch = self.last_epoch + 1
        self.last_epoch = epoch

        if self.is_better(current, self.best):
            self.best = current
            self.num_bad_epochs = 0
        else:
            self.num_bad_epochs += 1

        if self.in_cooldown:
            self.cooldown_counter -= 1
            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown

        if self.num_bad_epochs > self.patience:
            self.has_converged = True

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'rel':
            rel_epsilon = 1. - self.threshold
            return a < best * rel_epsilon

        elif self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best - self.threshold

        elif self.mode == 'max' and self.threshold_mode == 'rel':
            rel_epsilon = self.threshold + 1.
            return a > best * rel_epsilon

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best + self.threshold

    def _init_is_better(self, mode, threshold, threshold_mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if threshold_mode not in {'rel', 'abs'}:
            raise ValueError('threshold mode ' +
                             threshold_mode + ' is unknown!')

        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode


class BestMeter(object):
    """ This is like ConvergenceMeter except it stores the
        best result in a set of results. To be used in a
        grid search

    Args:
        mode (str): One of `min`, `max`. In `min` mode, best will
            be updated when the quantity metered is lower than the current best;
            in `max` mode best will be updated when the quantity metered is higher
            than the current best. Default: 'max'.

    """

    def __init__(self, mode='max', verbose=True):

        self.has_converged = False
        self.verbose = verbose
        self.mode = mode
        self.best = None
        self.best_obj = None
        self.mode_worse = None  # the worse value for the chosen mode
        self._init_is_better(mode=mode)
        self._reset()

    def _reset(self):
        self.best = self.mode_worse

    def step(self, metrics, best_obj=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)

        if self.is_better(current, self.best):
            if self.verbose:
                print("*********New best**********")
                print("value: ", current)
                print("object: ", best_obj)
                print("***************************")
            self.best = current
            self.best_obj = best_obj
            return True

        return False

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best

    def _init_is_better(self, mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode


# Disable
def block_print():
    sys.stdout = open(os.devnull, 'w')


# Restore
def enable_print():
    sys.stdout = sys.__stdout__


def get_data_loader(dataset, batch_size, args, shuffle=True):
    """Args:
        np_array: shape [num_data, data_dim]
        batch_size: int
        device: torch.device object

    Returns: torch.utils.data.DataLoader object
    """

    if args.device == torch.device('cpu'):
        kwargs = {'num_workers': 4, 'pin_memory': True}
    else:
        kwargs = {}

    return torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)


def get_mean_of_dataset(train_data_loader, args, idx=0):
    """ Compute mean without loading entire dataset into memory """
    meter = AverageMeter()
    for i in train_data_loader:
        if isinstance(i, list):
            meter.update(i[idx])
        else:
            meter.update(i)
    data_mean = meter.mean
    if data_mean.ndim == 2:
        data_mean = data_mean.mean(0)
    return tensor(data_mean, args)


def split_train_test_by_percentage(dataset, train_percentage=0.8):
    """ split pytorch Dataset object by percentage """
    train_length = int(len(dataset) * train_percentage)
    return torch.utils.data.random_split(dataset, (train_length, len(dataset) - train_length))


def pmap(f, arr, n_jobs=-1, prefer='threads', verbose=10):
    return Parallel(n_jobs=n_jobs, prefer=prefer, verbose=verbose)(delayed(f)(i) for i in arr)


def put(value, filename):
    persist_dir.mkdir(exist_ok=True)
    filename = persist_dir / filename
    print("Saving to ", filename)
    joblib.dump(value, filename)


def get(filename):
    filename = persist_dir / filename
    assert filename.exists(), "{} doesn't exist".format(filename)
    print("Saving to ", filename)
    return joblib.load(filename)


def smooth(arr, window):
    return pd.Series(arr).rolling(window, min_periods=1).mean().values


def tensor(data, args=None, dtype=torch.float):
    device = torch.device('cpu') if args is None else args.device
    if torch.is_tensor(data):
        return data.to(dtype=dtype, device=device)
    else:
        return torch.tensor(np.array(data), device=device, dtype=dtype)


def is_test_time(epoch, args):
    if args.train_only:
        return False

    # last epoch
    if epoch == (args.epochs - 1):
        return True

    # test epoch
    if (args.test_during_training and ((epoch % args.test_frequency) == 0)):
        return True

    # Else
    return False



def detect_cuda(args):
    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False
    return args

def is_early_update(epoch,args):

    if epoch<=args.burn_in or len(args.logtvopx_all)<1 or len(args.average_y)==0 or len(args.Y_ori)==0:
        return False
    #print("logtvopx[-1]-average_y[-1]",np.round(args.logtvopx_all[-1]-args.average_y[-1],4))
    if args.logtvopx_all[-1]<0 and (args.logtvopx_all[-1]-args.average_y[-1] )<args.drip_threshold:
        args.len_terminated_epoch=epoch % args.schedule_update_frequency # used to estimate the average logpx_tvo_evidence
        print("===early update===","logtvopx[-1]-average_y[-1]", np.round(args.logtvopx_all[-1]-args.average_y[-1],4),"drip_threshold",args.drip_threshold)
        return True
    args.len_terminated_epoch=0
    return False

def is_schedule_update_time(epoch, args):
    # No scheduling
    if args.loss != 'tvo':
        return False

    if args.schedule not in ["gp_bandit", 'moments']:
        return False

    if is_early_update(epoch,args):
        return True

    # First epoch, initalize
    if epoch <=args.burn_in:
        #return True
        return False

    # Update happens at each minibatch
    if args.per_sample is True:
        return False

    # Initalize once and never update
    if args.schedule_update_frequency == 0:
        return False

    # catch checkpoint epoch
    if (epoch % args.schedule_update_frequency) == 0:
        return True

    # Else
    return False


def is_checkpoint_time(epoch, args):
    # No checkpointing
    if args.checkpoint is False:
        return False

    # skip first epoch
    if (epoch == 0):
        return False

    # catch last epoch
    if epoch == (args.epochs - 1):
        return True

    # catch checkpoint epoch
    if (epoch % args.checkpoint_frequency) == 0:
        return True

    # Else
    return False


def is_gradient_time(epoch, args):
    # No checkpointing
    if args.save_grads is False:
        return False

    # catch checkpoint epoch
    if (epoch % args.test_frequency) == 0:
        return True

    # Else
    return False


def logaddexp(a, b):
    """Returns log(exp(a) + exp(b))."""

    return torch.logsumexp(torch.cat([a.unsqueeze(0), b.unsqueeze(0)]), dim=0)


def lognormexp(values, dim=0):
    """Exponentiates, normalizes and takes log of a tensor.
    """

    log_denominator = torch.logsumexp(values, dim=dim, keepdim=True)
    # log_numerator = values
    return values - log_denominator


def make_sparse(sparse_mx, args):
    """Convert a scipy sparse matrix to a torch sparse tensor."""
    sparse_mx = sparse_mx.tocoo().astype(np.float32)

    indices = tensor(
        np.vstack((sparse_mx.row, sparse_mx.col)), args, torch.long)
    values = tensor(sparse_mx.data, args)
    shape = torch.Size(sparse_mx.shape)
    return torch.sparse.FloatTensor(indices, values, shape)


def exponentiate_and_normalize(values, dim=0):
    """Exponentiates and normalizes a tensor.

    Args:
        values: tensor [dim_1, ..., dim_N]
        dim: n

    Returns:
        result: tensor [dim_1, ..., dim_N]
            where result[i_1, ..., i_N] =
                            exp(values[i_1, ..., i_N])
            ------------------------------------------------------------
             sum_{j = 1}^{dim_n} exp(values[i_1, ..., j, ..., i_N])
    """

    return torch.exp(lognormexp(values, dim=dim))


def seed_all(seed):
    """Seed all devices deterministically off of seed and somewhat
    independently."""
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def get_grads(model):
    return torch.cat([torch.flatten(p.grad.clone()) for p in model.parameters()]).cpu()


def log_ess(log_weight):
    """Log of Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: log of effective sample size [batch_size] (or [1])
    """
    dim = 1 if log_weight.ndimension() == 2 else 0

    return 2 * torch.logsumexp(log_weight, dim=dim) - \
        torch.logsumexp(2 * log_weight, dim=dim)


def ess(log_weight):
    """Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: effective sample size [batch_size] (or [1])
    """

    return torch.exp(log_ess(log_weight))


def spread(X, N, axis=0):
    """
    Takes a 1-d vector and spreads it out over
    N rows s.t spread(X, N).sum(0) = X
    """
    return (1 / N) * duplicate(X, N, axis)

def duplicate(X, N, axis=0):
    """
    Takes a 1-d vector and duplicates it across
    N rows s.t spread(X, N).sum(axis) = N*X
    """
    order = (N, 1) if axis == 0 else (1, N)
    return X.unsqueeze(axis).repeat(*order)

def get_unique_dir(comment=None):
    current_time = datetime.now().strftime('%b%d_%H-%M-%S')
    host = socket.gethostname()
    name = f"{current_time}_{host}"
    if comment: name = f"{name}_{comment}"
    return name

File Path: myresult/_sources/ml_helpers_d4b620ae46f9e906683524066e7177ca.py
Content:
from __future__ import division
import sys
import os
import torch
from torch._six import inf
import numpy as np
import pandas as pd
import random
from joblib import Parallel, delayed
import joblib
from pathlib import Path
from datetime import datetime
import socket

persist_dir = Path('./.persistdir')
#print(persist_dir)


class AverageMeter(object):
    """
    Computes and stores the average, var, and sample_var
    Taken from https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm
    """

    def __init__(self, name="AverageMeter", fmt=':f'):
        self.name = name
        self.fmt = fmt
        self.reset()

    def reset(self):
        self.count = 0
        self.M2 = 0

        self.mean = 0
        self.variance = 0
        self.sample_variance = 0

    def step(self, val):
        self.count += 1
        delta = val - self.mean
        self.mean += delta / self.count
        delta2 = val - self.mean
        self.M2 += delta * delta2

        self.variance = self.M2 / self.count if self.count > 2 else 0
        self.sample_variance = self.M2 / \
            (self.count - 1) if self.count > 2 else 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({var' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.mean, var=self.variance)


class MovingAverageMeter(object):
    """Computes the  moving average of a given float."""

    def __init__(self, name, fmt=':f', window=5):
        self.name = "{} (window = {})".format(name, window)
        self.fmt = fmt
        self.N = window
        self.history = []
        self.val = None
        self.reset()

    def reset(self):
        self.val = None
        self.history = []

    def step(self, val):
        self.history.append(val)
        self.previous = self.val
        if self.val is None:
            self.val = val
        else:
            window = self.history[-self.N:]
            self.val = sum(window) / len(window)
            if len(window) == self.N:
                self.history == window
        return self.val

    @property
    def relative_change(self):
        if None not in [self.val, self.previous]:
            relative_change = (self.previous - self.val) / self.previous
            return relative_change
        else:
            return 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.val, avg=self.relative_change)


class ConvergenceMeter(object):
    """This is a modification of pytorch's ReduceLROnPlateau object
        (https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#ReduceLROnPlateau)
        which acts as a convergence meter. Everything
        is the same as ReduceLROnPlateau, except it doesn't
        require an optimizer and doesn't modify the learning rate.
        When meter.converged(loss) is called it returns a boolean that
        says if the loss has converged.

    Args:
        mode (str): One of `min`, `max`. In `min` mode, lr will
            be reduced when the quantity metered has stopped
            decreasing; in `max` mode it will be reduced when the
            quantity metered has stopped increasing. Default: 'min'.
        patience (int): Number of epochs with no improvement after
            which learning rate will be reduced. For example, if
            `patience = 2`, then we will ignore the first 2 epochs
            with no improvement, and will only decrease the LR after the
            3rd epoch if the loss still hasn't improved then.
            Default: 10.
        threshold (float): Threshold for measuring the new optimum,
            to only focus on significant changes. Default: 1e-4.
        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,
            dynamic_threshold = best * ( 1 + threshold ) in 'max'
            mode or best * ( 1 - threshold ) in `min` mode.
            In `abs` mode, dynamic_threshold = best + threshold in
            `max` mode or best - threshold in `min` mode. Default: 'rel'.
        cooldown (int): Number of epochs to wait before resuming
            normal operation after lr has been reduced. Default: 0.
        min_lr (float or list): A scalar or a list of scalars. A
            lower bound on the learning rate of all param groups
            or each group respectively. Default: 0.
        eps (float): Minimal decay applied to lr. If the difference
            between new and old lr is smaller than eps, the update is
            ignored. Default: 1e-8.

    Example:
        >>> meter = Meter('min')
        >>> for epoch in range(10):
        >>>     train(...)
        >>>     val_loss = validate(...)
        >>>     if meter.converged(val_loss):
        >>>         break
    """

    def __init__(self, mode='min', patience=10,
                 verbose=False, threshold=1e-4, threshold_mode='rel',
                 cooldown=0, eps=1e-8):

        self.has_converged = False
        self.patience = patience
        self.verbose = verbose
        self.cooldown = cooldown
        self.cooldown_counter = 0
        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode
        self.best = None
        self.num_bad_epochs = None
        self.mode_worse = None  # the worse value for the chosen mode
        self.eps = eps
        self.last_epoch = -1
        self._init_is_better(mode=mode, threshold=threshold,
                             threshold_mode=threshold_mode)
        self._reset()

    def _reset(self):
        """Resets num_bad_epochs counter and cooldown counter."""
        self.best = self.mode_worse
        self.cooldown_counter = 0
        self.num_bad_epochs = 0

    def step(self, metrics, epoch=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)
        if epoch is None:
            epoch = self.last_epoch = self.last_epoch + 1
        self.last_epoch = epoch

        if self.is_better(current, self.best):
            self.best = current
            self.num_bad_epochs = 0
        else:
            self.num_bad_epochs += 1

        if self.in_cooldown:
            self.cooldown_counter -= 1
            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown

        if self.num_bad_epochs > self.patience:
            self.has_converged = True

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'rel':
            rel_epsilon = 1. - self.threshold
            return a < best * rel_epsilon

        elif self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best - self.threshold

        elif self.mode == 'max' and self.threshold_mode == 'rel':
            rel_epsilon = self.threshold + 1.
            return a > best * rel_epsilon

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best + self.threshold

    def _init_is_better(self, mode, threshold, threshold_mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if threshold_mode not in {'rel', 'abs'}:
            raise ValueError('threshold mode ' +
                             threshold_mode + ' is unknown!')

        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode


class BestMeter(object):
    """ This is like ConvergenceMeter except it stores the
        best result in a set of results. To be used in a
        grid search

    Args:
        mode (str): One of `min`, `max`. In `min` mode, best will
            be updated when the quantity metered is lower than the current best;
            in `max` mode best will be updated when the quantity metered is higher
            than the current best. Default: 'max'.

    """

    def __init__(self, mode='max', verbose=True):

        self.has_converged = False
        self.verbose = verbose
        self.mode = mode
        self.best = None
        self.best_obj = None
        self.mode_worse = None  # the worse value for the chosen mode
        self._init_is_better(mode=mode)
        self._reset()

    def _reset(self):
        self.best = self.mode_worse

    def step(self, metrics, best_obj=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)

        if self.is_better(current, self.best):
            if self.verbose:
                print("*********New best**********")
                print("value: ", current)
                print("object: ", best_obj)
                print("***************************")
            self.best = current
            self.best_obj = best_obj
            return True

        return False

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best

    def _init_is_better(self, mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode


# Disable
def block_print():
    sys.stdout = open(os.devnull, 'w')


# Restore
def enable_print():
    sys.stdout = sys.__stdout__


def get_data_loader(dataset, batch_size, args, shuffle=True):
    """Args:
        np_array: shape [num_data, data_dim]
        batch_size: int
        device: torch.device object

    Returns: torch.utils.data.DataLoader object
    """

    if args.device == torch.device('cpu'):
        kwargs = {'num_workers': 4, 'pin_memory': True}
    else:
        kwargs = {}

    return torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)


def get_mean_of_dataset(train_data_loader, args, idx=0):
    """ Compute mean without loading entire dataset into memory """
    meter = AverageMeter()
    for i in train_data_loader:
        if isinstance(i, list):
            meter.update(i[idx])
        else:
            meter.update(i)
    data_mean = meter.mean
    if data_mean.ndim == 2:
        data_mean = data_mean.mean(0)
    return tensor(data_mean, args)


def split_train_test_by_percentage(dataset, train_percentage=0.8):
    """ split pytorch Dataset object by percentage """
    train_length = int(len(dataset) * train_percentage)
    return torch.utils.data.random_split(dataset, (train_length, len(dataset) - train_length))


def pmap(f, arr, n_jobs=-1, prefer='threads', verbose=10):
    return Parallel(n_jobs=n_jobs, prefer=prefer, verbose=verbose)(delayed(f)(i) for i in arr)


def put(value, filename):
    persist_dir.mkdir(exist_ok=True)
    filename = persist_dir / filename
    print("Saving to ", filename)
    joblib.dump(value, filename)


def get(filename):
    filename = persist_dir / filename
    assert filename.exists(), "{} doesn't exist".format(filename)
    print("Saving to ", filename)
    return joblib.load(filename)


def smooth(arr, window):
    return pd.Series(arr).rolling(window, min_periods=1).mean().values


def tensor(data, args=None, dtype=torch.float):
    device = torch.device('cpu') if args is None else args.device
    if torch.is_tensor(data):
        return data.to(dtype=dtype, device=device)
    else:
        return torch.tensor(np.array(data), device=device, dtype=dtype)


def is_test_time(epoch, args):
    if args.train_only:
        return False

    # last epoch
    if epoch == (args.epochs - 1):
        return True

    # test epoch
    if (args.test_during_training and ((epoch % args.test_frequency) == 0)):
        return True

    # Else
    return False



def detect_cuda(args):
    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False
    return args

def is_drip(epoch,args):

    if epoch<=args.burn_in or len(args.logtvopx_all)<1 or len(args.average_y)==0 or len(args.Y_ori)==0:
        return False
    print("logtvopx[-1]-average_y[-1]",np.round(args.logtvopx_all[-1]-args.average_y[-1],4))
    if args.logtvopx_all[-1]<0 and (args.logtvopx_all[-1]-args.average_y[-1] )<args.drip_threshold:
        args.len_terminated_epoch=epoch % args.schedule_update_frequency # used to estimate the average logpx_tvo_evidence
        print("===========drip","logtvopx[-1]-average_y[-1]", np.round(args.logtvopx_all[-1]-args.average_y[-1],4),"drip_threshold",args.drip_threshold)
        return True
    args.len_terminated_epoch=0
    return False

def is_schedule_update_time(epoch, args):
    # No scheduling
    if args.loss != 'tvo':
        return False

    if args.schedule not in ["gp_bandit", 'moments']:
        return False

    if is_drip(epoch,args):
        return True

    # First epoch, initalize
    if epoch <=args.burn_in:
        #return True
        return False

    # Update happens at each minibatch
    if args.per_sample is True:
        return False

    # Initalize once and never update
    if args.schedule_update_frequency == 0:
        return False

    # catch checkpoint epoch
    if (epoch % args.schedule_update_frequency) == 0:
        return True

    # Else
    return False


def is_checkpoint_time(epoch, args):
    # No checkpointing
    if args.checkpoint is False:
        return False

    # skip first epoch
    if (epoch == 0):
        return False

    # catch last epoch
    if epoch == (args.epochs - 1):
        return True

    # catch checkpoint epoch
    if (epoch % args.checkpoint_frequency) == 0:
        return True

    # Else
    return False


def is_gradient_time(epoch, args):
    # No checkpointing
    if args.save_grads is False:
        return False

    # catch checkpoint epoch
    if (epoch % args.test_frequency) == 0:
        return True

    # Else
    return False


def logaddexp(a, b):
    """Returns log(exp(a) + exp(b))."""

    return torch.logsumexp(torch.cat([a.unsqueeze(0), b.unsqueeze(0)]), dim=0)


def lognormexp(values, dim=0):
    """Exponentiates, normalizes and takes log of a tensor.
    """

    log_denominator = torch.logsumexp(values, dim=dim, keepdim=True)
    # log_numerator = values
    return values - log_denominator


def make_sparse(sparse_mx, args):
    """Convert a scipy sparse matrix to a torch sparse tensor."""
    sparse_mx = sparse_mx.tocoo().astype(np.float32)

    indices = tensor(
        np.vstack((sparse_mx.row, sparse_mx.col)), args, torch.long)
    values = tensor(sparse_mx.data, args)
    shape = torch.Size(sparse_mx.shape)
    return torch.sparse.FloatTensor(indices, values, shape)


def exponentiate_and_normalize(values, dim=0):
    """Exponentiates and normalizes a tensor.

    Args:
        values: tensor [dim_1, ..., dim_N]
        dim: n

    Returns:
        result: tensor [dim_1, ..., dim_N]
            where result[i_1, ..., i_N] =
                            exp(values[i_1, ..., i_N])
            ------------------------------------------------------------
             sum_{j = 1}^{dim_n} exp(values[i_1, ..., j, ..., i_N])
    """

    return torch.exp(lognormexp(values, dim=dim))


def seed_all(seed):
    """Seed all devices deterministically off of seed and somewhat
    independently."""
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def get_grads(model):
    return torch.cat([torch.flatten(p.grad.clone()) for p in model.parameters()]).cpu()


def log_ess(log_weight):
    """Log of Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: log of effective sample size [batch_size] (or [1])
    """
    dim = 1 if log_weight.ndimension() == 2 else 0

    return 2 * torch.logsumexp(log_weight, dim=dim) - \
        torch.logsumexp(2 * log_weight, dim=dim)


def ess(log_weight):
    """Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: effective sample size [batch_size] (or [1])
    """

    return torch.exp(log_ess(log_weight))


def spread(X, N, axis=0):
    """
    Takes a 1-d vector and spreads it out over
    N rows s.t spread(X, N).sum(0) = X
    """
    return (1 / N) * duplicate(X, N, axis)

def duplicate(X, N, axis=0):
    """
    Takes a 1-d vector and duplicates it across
    N rows s.t spread(X, N).sum(axis) = N*X
    """
    order = (N, 1) if axis == 0 else (1, N)
    return X.unsqueeze(axis).repeat(*order)

def get_unique_dir(comment=None):
    current_time = datetime.now().strftime('%b%d_%H-%M-%S')
    host = socket.gethostname()
    name = f"{current_time}_{host}"
    if comment: name = f"{name}_{comment}"
    return name

File Path: myresult/_sources/model_handler_88f192605e31399b2b0fb9dd269f1ddd.py
Content:
from src.models.vaes import DiscreteVAE, ContinuousVAE
from src.models.bnn import BayesianNetwork
from src.models.pcfg import PCFG
from src.pcfg_util import read_pcfg

def get_model(train_data_loader, args):
    if args.learning_task == 'continuous_vae':
        D = train_data_loader.dataset.image.shape[1]
        model = ContinuousVAE(D, args)
    elif args.learning_task == 'discrete_vae':
        D = train_data_loader.dataset.image.shape[1]
        train_obs_mean = train_data_loader.dataset.image.mean(0)
        model = DiscreteVAE(D, args, train_obs_mean)
    elif args.learning_task == 'bnn':
        w, h = train_data_loader.dataset.train_data.shape[1:]
        D = w * h
        num_batches = len(args.train_data_loader)
        model = BayesianNetwork(D, num_batches, args)
    elif args.learning_task == 'pcfg':
        grammar, true_production_probs = read_pcfg(args.data_path)
        model = PCFG(grammar, args)
        # PCFG not set up for gpu
        return model
    else:
        raise ValueError("Incorrect learning task: {} not valid".format(args.learning_task))
    if args.device.type == 'cuda':
        model.cuda()

    return model

File Path: myresult/_sources/updates_fb3cfcbb2c55aec2b03709b6be117d0a.py
Content:
import torch
from torch import optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.distributions.uniform import Uniform
from torch.distributions.beta import Beta
import copy

#import torch.nn as nn
from functools import partial
import numpy as np
from src.util import compute_tvo_loss, compute_wake_theta_loss, compute_wake_phi_loss, get_curvature_loss_and_grad
from src.util import compute_vimco_loss, exponentiate_and_normalize
from src.util import calc_exp, calc_var_given_betas, get_total_log_weight, _get_multiplier
from src import gp_bandit
from src import ml_helpers as mlh

def get_partition_scheduler(args):
    """
    Args:
        args : arguments from main.py
    Returns:
        callable beta_update function
    * callable has interface f(log_iw, args, **kwargs)
    * returns beta_id, or unchanged args.partition, by default
    Beta_update functions:
        *** MUST be manually specified here
        * given via args.partition_type and other method-specific args
        * should handle 0/1 endpoint insertion internally
        * may take args.K - 1 partitions as a result (0 is given)
    """

    schedule = args.schedule
    P = args.K - 1

    if schedule=='gp_bandit' or schedule=="gp"  or schedule=="gptv":
        return GP_bandits
    elif schedule=='rand':
        return rand_search
#    elif schedule=='gp_bandit_log':
#        return GP_bandits_log
    elif schedule in ['log', 'linear']:
        return beta_id
    elif schedule in ['moments']:
        return moments
#    elif schedule =='beta_gradient_descent':
#        return beta_gradient_descent
#    elif schedule =='beta_batch_gradient':
#        return beta_gradient_descent


def beta_id(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """

    """
    f = bayes_quad.get_integrand_function(model, args)
    f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
    args.f_beta0=f_beta0
    f=bayes_quad.get_integrand_function_subtract_beta0(model,args) #redefine the function using f(beta=0)
    Ytensor=f(args.partition)
    Y=Ytensor.data.cpu().numpy()

    try:
        oldY=np.load("Y_linear50")
    except:
        oldY=np.empty((0,1+args.K),float)
    oldY=np.vstack((oldY,np.reshape(Y,(1,-1))))
    np.save("Y_linear50",oldY)
    """
    #print(args.partition)
    return args.partition


def rand_search(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """
    SearchSpace=np.asarray([0,1.0]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))
    init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
    init_X=np.around(init_X, decimals=4)
    init_X=np.append(0,init_X)
    init_X=np.append(init_X,1)

    init_X= np.sort(init_X)
    print(init_X)

    points=mlh.tensor(init_X,args)

    return points


def safe_step(partition, steps, min_val = 10**-6, max_val = 1.0, max_step = 0.01, adaptive = False, descent = False):
    ''' implement checks on beta values and sort if necessary after gradient descent step

        max_step : clips absolute value of steps = step_size * beta_derivative
        "adaptive" is very heuristic:
            scale down step size until at most 1 update is > max_step (maybe should be >= 1 since often only 1 big update)
    '''

    max_step = torch.ones_like(steps)*max_step
    min_val = torch.ones_like(partition)*min_val
    max_val = torch.ones_like(partition)*max_val;


    if adaptive:
        n_greater_than_max = torch.where(torch.abs(steps) > max_step, torch.ones_like(steps), torch.zeros_like(steps))
        while torch.sum(n_greater_than_max).item() > 1 :
            steps = steps*.1
            n_greater_than_max = torch.where(torch.abs(steps) > max_step, torch.ones_like(steps), torch.zeros_like(steps))
    else:
        steps = torch.where(torch.abs(steps) < max_step, steps, max_step*torch.sign(steps))

    partition = partition - steps.cpu() if descent else partition + steps.cpu()
    partition = torch.where(partition>=min_val, partition, min_val)
    partition = torch.where(partition<=max_val, partition, min_val)
    partition, _ = torch.sort(partition)
    return partition


def get_beta_derivative_diffs(model, args):
    '''
    Reads stored means in self.expectation_diffs and returns beta derivatives according to "async" or epoch update derivation ( i.e. variance term * 0 )
    Let f(β) = E_β log p(x,z)/q(z|x) , f'(β) = Var_β log p(x,z)/q(z|x)

    d TVO / dβ_k = f(β_k-1) - f(β_k ) - (β_k+1 - β_k) f'(β_k)

    only calculates for indices 1 => K-1 ( 0 and 1 are fixed )
    '''

    # if isinstance(model.expectation_diffs, mlh.AccumulatedDiff):
    #      # Not currently being used
    #     beta_deriv = torch.stack([(model.expectation_diffs.current[k-1] - model.expectation_diffs.current[k]) for k in range(1,model.expectation_diffs.current.shape[0]-1)])
    #     model.expectation_diffs.reset()
    # else:


    # expectation_diffs [k]= change in f(β_{k}),  derivative = change in expectation_diffs across beta

    # if isinstance(model.expectation_diffs, int):
    #     beta_deriv = torch.zeros_like(model.args.partition[1:-1].data)
    # else:
    # beta_deriv = torch.stack([(model.expectation_diffs[k-1] - model.expectation_diffs[k]) \
    #                  for k in range(1,model.expectation_diffs.shape[0]-1)])


    tvo_exps = model.exp_meter.mean.data
    tvo_vars = model.var_meter.mean.data
    last_exps = model.exp_last.data
    last_vars = model.var_last.data
    d_beta =  _get_multiplier(args.partition, 'left').squeeze().data

    # "two step" update => minus last
    beta_deriv = torch.stack( [ (tvo_exps[k-1] - tvo_exps[k]) - (last_exps[k-1] - last_exps[k] ) + d_beta[k]*(tvo_vars[k] -last_vars[k]) \
                              for k in range(1, tvo_exps.shape[0]-1) ]  )

    return beta_deriv

def get_beta_derivative_single(model, args):
    '''
    Reads stored means in self.expectation_diffs and returns beta derivatives according to "async" or epoch update derivation ( i.e. variance term * 0 )
    Let f(β) = E_β log p(x,z)/q(z|x) , f'(β) = Var_β log p(x,z)/q(z|x)

    d TVO / dβ_k = f(β_k-1) - f(β_k ) - (β_k+1 - β_k) f'(β_k)

    only calculates for indices 1 => K-1 ( 0 and 1 are fixed )
    '''

    # if isinstance(model.expectation_diffs, mlh.AccumulatedDiff):
    #      # Not currently being used
    #     beta_deriv = torch.stack([(model.expectation_diffs.current[k-1] - model.expectation_diffs.current[k]) for k in range(1,model.expectation_diffs.current.shape[0]-1)])
    #     model.expectation_diffs.reset()
    # else:


    # expectation_diffs [k]= change in f(β_{k}),  derivative = change in expectation_diffs across beta

    # if isinstance(model.expectation_diffs, int):
    #     beta_deriv = torch.zeros_like(model.args.partition[1:-1].data)
    # else:
    # beta_deriv = torch.stack([(model.expectation_diffs[k-1] - model.expectation_diffs[k]) \
    #                  for k in range(1,model.expectation_diffs.shape[0]-1)])

    tvo_exps = model.exp_meter.mean.data
    tvo_vars = model.var_meter.mean.data
    last_exps = model.exp_last.data
    last_vars = model.var_last.data
    d_beta =  _get_multiplier(args.partition, 'left').squeeze().data

    # "two step" update => minus last
    beta_deriv = torch.stack( [ (tvo_exps[k-1] - tvo_exps[k]) + d_beta[k]*tvo_vars[k] \
                              for k in range(1, tvo_exps.shape[0]-1) ]  )
    #  - (last_exps[k-1] - last_exps[k] )
    return beta_deriv



def beta_gradient_descent(model, args, cpu = True, diffs = False):
    '''
    perform manual gradient descent on beta
    - get_beta_derivative_no_var : returns dTVO / dbeta and resets beta tracking
    - safe_step clips updates

    recalculate = True is used for beta_batch_gradient
        - init_expectation = expectation before θ gradient descent update
        - expectation_diffs = expectation after θ gradient descent update
    '''

    if args.schedule=='beta_batch_gradient':
        # used to update per_batch
        # (re-calculate expectations, variance post θ-update)
        log_weight = model.elbo()
        tvo_exps = calc_exp(log_weight, args, all_sample_mean=True)
        tvo_vars = calc_var_given_betas(log_weight, args, all_sample_mean=True)

        model.exp_meter.step(tvo_exps.data)
        model.var_meter.step(tvo_vars.data)

        #if model.exp_last is None or model.var_last is None:
        #    model.exp_last = tvo_exps.data
        #    model.var_last = tvo_vars.data


    #model.expectation_diffs = tvo_exps.data - model.init_expectation
    elif model.exp_last is None or isinstance(model.exp_meter.mean, int):
        # unchanged for first epoch after burn-in on beta_gradient_descent
        return args.partition


    # also resets expectation differences
    if diffs:
        beta_derivatives = get_beta_derivative_diffs(model, args)
    else:
        beta_derivatives = get_beta_derivative_single(model, args)

    model.reset_track_beta()


    # Gradient Descent STEP
    sliced_partition = args.partition.data[1:-1]
    sliced_partition = sliced_partition.cpu() if cpu else sliced_partition

    new_partition = safe_step(sliced_partition, args.beta_step_size * beta_derivatives, max_step = args.max_beta_step, adaptive=args.adaptive_beta_step)

    # pad 0 and 1
    new_partition = torch.cat([torch.zeros_like(new_partition[0]).unsqueeze(0), new_partition,  torch.ones_like(new_partition[0]).unsqueeze(0)])

    print(args.partition)
    print("new partition ", new_partition)
    print("beta steps ", args.beta_step_size * beta_derivatives)


    return new_partition.cuda() if cpu else new_partition


def GP_bandits(model, args):
    points = gp_bandit.calculate_BO_points(model, args)
    K=len(points)
    points=mlh.tensor(points,args)
    print("==================================")
    print("K={} points={}".format(K,points))
    print("==================================")
    #args.K = K
    return points


def moments(model, args=None, **kwargs):
    args  = model.args if args is None else args
    start = 0
    stop  = 1
    threshold = 0.05

    if not args.per_sample and not args.per_batch:
        log_iw = get_total_log_weight(model, args, args.valid_S)
    else:
        log_iw = model.elbo()

    partitions = args.K-1
    targets = np.linspace(0.0, 1.0, num=args.K+1, endpoint=True)

    left  = calc_exp(log_iw, start, all_sample_mean= not(args.per_sample))
    right = calc_exp(log_iw, stop, all_sample_mean= not(args.per_sample))
    left  = torch.mean(left, axis = 0, keepdims = True) if args.per_batch else left
    right = torch.mean(right, axis = 0, keepdims= True) if args.per_batch else right
    moment_avg = right - left

    beta_result = []
    for t in range(len(targets)):
        if targets[t] == 0.0 or targets[t] == 1.0:
            beta_result.append(targets[t] * (torch.ones_like(log_iw[:,0]) if args.per_sample else 1) ) # zero if targets[t]=0
        else:
            target = targets[t]
            moment = left + target*moment_avg #for t in targets]

            start = torch.zeros_like(log_iw[:,0]) if args.per_sample else torch.zeros_like(left)
            stop = torch.ones_like(log_iw[:,0]) if args.per_sample else torch.ones_like(left)

            beta_result.append(_moment_binary_search(\
                    moment, log_iw, start = start, stop = stop, \
                        threshold=threshold, per_sample = args.per_sample))

    if args.per_sample: #or args.per_batch:
        beta_result = torch.cat([b.unsqueeze(1) for b in beta_result], axis=1).unsqueeze(1)
        beta_result, _ = torch.sort(beta_result, -1)
    else:
        beta_result = torch.cuda.FloatTensor(beta_result)

    return beta_result

def _moment_binary_search(target, log_iw, start=0, stop= 1, threshold = 0.1, recursion = 0, per_sample = False, min_beta = 0.001): #recursion = 0,
    beta_guess = .5*(stop+start)
    eta_guess = calc_exp(log_iw, beta_guess, all_sample_mean = not per_sample).squeeze()
    target = torch.ones_like(eta_guess)*(target.squeeze())
    start_ = torch.where( eta_guess <  target,  beta_guess, start)
    stop_ = torch.where( eta_guess >  target, beta_guess , stop)

    if torch.sum(  torch.abs( eta_guess - target) > threshold ).item() == 0:
        return beta_guess
    else:
        if recursion > 500:
            return beta_guess
        else:
            return _moment_binary_search(
                target,
                log_iw,
                start= start_,
                stop= stop_,
                recursion = recursion + 1,
                per_sample = per_sample)

def beta_id(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """
    return args.partition

File Path: myresult/_sources/util_25d0f8d89783b52dd1c02ee2879584d3.py
Content:
import torch
import numpy as np
from src.ml_helpers import AverageMeter, get_grads, tensor, lognormexp, exponentiate_and_normalize, seed_all
from torch.distributions.multinomial import Multinomial
import src.ml_helpers as mlh
#from src.GPv import GaussianProcessDerivative

def range_except(end, i):
    """Outputs an increasing list from 0 to (end - 1) except i.
    Args:
        end: int
        i: int

    Returns: list of length (end - 1)
    """

    result = list(set(range(end)))
    return result[:i] + result[(i + 1):]


def get_partition(args):
    """Create a non-decreasing sequence of values between zero and one.
    See https://en.wikipedia.org/wiki/Partition_of_an_interval.

    Args:
        args.num_partitions: length of sequence minus one
        args.schedule: \'linear\' or \'log\'
        args.log_beta_min: log (base ten) of beta_min. only used if partition_type
            is log. default -10 (i.e. beta_min = 1e-10).
        args.device: torch.device object (cpu by default)

    Returns: tensor of shape [num_partitions + 1]
    """
    if args.K == 1:
        partition = tensor((0., 1), args)
    else:
        if args.schedule == 'linear':
            partition = torch.linspace(0, 1, steps=args.K + 1,
                                       device=args.device)
        elif args.schedule == 'log':
            partition = torch.zeros(args.K + 1, device=args.device,
                                    dtype=torch.float)
            partition[1:] = torch.logspace(args.log_beta_min, 0, steps=args.K, device=args.device,
                                           dtype=torch.float)
        else:
            # DEFAULT IS TO START WITH LOG
            partition = torch.zeros(args.K + 1, device=args.device,
                                    dtype=torch.float)
            partition[1:] = torch.logspace(args.log_beta_min, 0, steps=args.K, device=args.device,
                                           dtype=torch.float)
    return partition


def _get_multiplier(partition, integration):
    """ Outputs partition multipers depending on integration rule
     Args:
         partition = partition of interval [0,1]
         integration : left, right, trapz, single (i.e. 1 * partition[*, 1])

        (helper function to accomodate per_sample calculations)

     Returns: tensor with size = partition.shape
     """
    if len(partition.shape) == 1:
        multiplier = torch.zeros_like(partition)
        if integration == 'trapz':
            multiplier[0] = 0.5 * (partition[1] - partition[0])
            multiplier[1:-1] = 0.5 * (partition[2:] - partition[0:-2])
            multiplier[-1] = 0.5 * (partition[-1] - partition[-2])
        elif integration == 'left':
            multiplier[:-1] = partition[1:] - partition[:-1]
        elif integration == 'right':
            multiplier[1:] = partition[1:] - partition[:-1]

    else:
        multiplier = torch.zeros_like(partition)
        if integration == 'trapz':
            multiplier[..., 0] = 0.5 * (partition[1] - partition[0])
            multiplier[..., 1:-1] = 0.5 * (partition[2:] - partition[0:-2])
            multiplier[..., -1] = 0.5 * (partition[-1] - partition[-2])
        elif integration == 'left':
            multiplier[..., :-1] = partition[..., 1:] - partition[..., :-1]
        elif integration == 'right':
            multiplier[..., 1:] = partition[..., 1:] - partition[..., :-1]
        elif integration == 'single':
            multiplier = torch.ones_like(partition)
            if multiplier.shape[-1] == 3:
                multiplier[..., 0] = 0
                multiplier[..., -1] = 0

    return multiplier


def compute_tvo_loss(log_weight, log_p, log_q, args):
    """Args:
        log_weight: tensor of shape [batch_size, num_particles]
        log_p: tensor of shape [batch_size, num_particles]
        log_q: tensor of shape [batch_size, num_particles]
        partition: partition of [0, 1];
            tensor of shape [num_partitions + 1] where partition[0] is zero and
            partition[-1] is one;
            see https://en.wikipedia.org/wiki/Partition_of_an_interval
        num_particles: int
        integration: left, right or trapz

    Returns:
        loss: scalar that we call .backward() on and step the optimizer.
        elbo: average elbo over data

    """
    partition = args.partition
    num_particles = args.S
    integration = args.integration

    log_weight = log_weight.unsqueeze(-1)

    heated_log_weight = log_weight * partition
    heated_normalized_weight = exponentiate_and_normalize(
        heated_log_weight, dim=1)

    thermo_logp = partition * log_p.unsqueeze(-1) + \
        (1 - partition) * log_q.unsqueeze(-1)

    wf = heated_normalized_weight * log_weight
    w_detached = heated_normalized_weight.detach()
    wf_detached = wf.detach()

    if num_particles == 1:
        correction = 1
    else:
        correction = num_particles / (num_particles - 1)

    cov = correction * torch.sum(
        w_detached * (log_weight - torch.sum(wf, dim=1, keepdim=True)).detach() *
        (thermo_logp - torch.sum(thermo_logp * w_detached, dim=1, keepdim=True)),
        dim=1)

    multiplier = _get_multiplier(partition, integration)

    loss = -torch.mean(torch.sum(
        multiplier * (cov + torch.sum(
            w_detached * log_weight, dim=1)),
        dim=1))

    return loss



def compute_tvo_log_evidence(log_weight, args):

    # this is special partition for tvo_log_evidence

    partition = mlh.tensor(10**args.partition_tvo_evidence, args)
    # this is the integration used for computing tvo_log_evidence only
    # should be trapz
    integration = args.integration_tvo_evidence

    log_weight = log_weight.unsqueeze(-1)

    heated_log_weight = log_weight * partition
    heated_normalized_weight = exponentiate_and_normalize(heated_log_weight, dim=1)
    Epi_beta = torch.sum(heated_normalized_weight * log_weight, dim=1)

    multiplier = _get_multiplier(partition, integration)

    tvo_logpx = torch.sum(multiplier * Epi_beta, dim=1)

    return tvo_logpx

def compute_tvo_iwae_log_evidence(log_weight, args):
    # see notes @ BQD_TVO/notes/tvo_iwae.pdf
    partition = args.partition
    S = log_weight.shape[1]

    log_weight = log_weight.unsqueeze(-1)
    heated_log_weight = log_weight * partition

    log_evidence = torch.logsumexp(heated_log_weight, dim=1) - np.log(S)
    tvo_iwae_log_evidence = torch.sum(log_evidence * 1/partition.sum(), dim=1)

    return tvo_iwae_log_evidence


def calculate_grad_variance(model, args):
    grad_var = AverageMeter()
    batch = next(iter(args.train_data_loader))
    for _ in range(10):
        model.zero_grad()
        loss, logpx, test_elbo = model.forward(batch)
        loss.backward()
        model_grads = get_grads(model)
        grad_var.step(model_grads)

    grad_std = grad_var.variance.sqrt().mean()
    return grad_std


def compute_wake_phi_loss(log_weight, log_q):
    """Returns:
        loss: scalar that we call .backward() on and step the optimizer.
    """
    normalized_weight = exponentiate_and_normalize(log_weight, dim=1)
    return torch.mean(-torch.sum(normalized_weight.detach() * log_q, dim=1))


def compute_wake_theta_loss(log_weight):
    """Args:
    log_weight: tensor of shape [batch_size, num_particles]

    Returns:
        loss: scalar that we call .backward() on and step the optimizer.
        elbo: average elbo over data
    """

    _, num_particles = log_weight.shape
    elbo = torch.mean(torch.logsumexp(
        log_weight, dim=1) - np.log(num_particles))
    return -elbo


def compute_vimco_loss(log_weight, log_q):
    num_particles = log_q.shape[1]

    # shape [batch_size, num_particles]
    # log_weight_[b, k] = 1 / (K - 1) \sum_{\ell \neq k} \log w_{b, \ell}
    log_weight_ = (torch.sum(log_weight, dim=1, keepdim=True) - log_weight) \
        / (num_particles - 1)

    # shape [batch_size, num_particles, num_particles]
    # temp[b, k, k_] =
    #     log_weight_[b, k]     if k == k_
    #     log_weight[b, k]      otherwise
    temp = log_weight.unsqueeze(-1) + torch.diag_embed(
        log_weight_ - log_weight)

    # this is the \Upsilon_{-k} term below equation 3
    # shape [batch_size, num_particles]
    control_variate = torch.logsumexp(temp, dim=1) - np.log(num_particles)

    log_evidence = torch.logsumexp(log_weight, dim=1) - np.log(num_particles)
    elbo = torch.mean(log_evidence)
    loss = -elbo - torch.mean(torch.sum(
        (log_evidence.unsqueeze(-1) - control_variate).detach() * log_q, dim=1
    ))

    return loss


def calc_exp(log_weight, args, all_sample_mean=True, snis=None):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : True averages over batch

    TO DO : replace for cleaner integration into code (pulled directly from Rob's)
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight
    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = snis * log_weight
    exp = torch.sum(exp, dim=1)
    return torch.mean(exp, dim=0) if all_sample_mean else exp

def calc_var_given_betas(log_weight, args, all_sample_mean=True, betas = None):
    """
    Args:
        log_weight : [batch, samples, *]
        args : args object
                *** Note: only args.partition is used (this can be replaced by betas arg)
        all_sample_mean : returns mean over samples if True
        betas : β points at which to evaluate variance (shape: [K β points] or  [batch or 1, 1, K β points])
    Returns:
        Variance across importance samples at each beta (2nd derivative of log Z_β wrt β)
    """

    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight


    if betas is None:
        partition = args.partition
    else:
        partition = mlh.tensor(betas, args)

    beta_iw = log_weight * partition
    snis = exponentiate_and_normalize(
        beta_iw, dim=1)
    snis_detach = snis.detach()

    # expected log weights under π_β
    exp_pi_beta_log_weight  = torch.sum(snis_detach*log_weight, dim=1, keepdim=True)

    variance = torch.sum(snis_detach*torch.pow(log_weight - exp_pi_beta_log_weight, 2), dim =1 )

    # variance is [batch, # β].  set all_sample_mean = True to average over batch dimension
    return torch.mean(variance, dim=0) if all_sample_mean else variance

def calc_var(log_weight,  args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Variance across importance samples at each beta (2nd derivative of logZβ)
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp_ = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)

    to_return = exp2 - torch.pow(exp_, 2)

    # VM: May have to switch to_return to E[(X-EX)(X-EX)] form, had numerical issues in the past
    assert not torch.isnan(to_return).any(), "Nan in calc_var() - switch to E[(X-EX)(X-EX)] form for numerical stability"


    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


#
def calc_third(log_weight, args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Third derivative of logZβ at each beta
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)
    var = exp2 - torch.pow(exp, 2)
    exp3 = torch.sum(snis * torch.pow(log_weight, 3), dim=1)

    to_return = exp3 - torch.pow(exp, 3) - 3*exp*var
    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


def calc_fourth(log_weight, args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Fourth derivative of logZβ at each beta
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)
    exp3 = torch.sum(snis * torch.pow(log_weight, 3), dim=1)
    exp4 = torch.sum(snis * torch.pow(log_weight, 4), dim=1)

    to_return = exp4 - 6*torch.pow(exp, 4) + 12*exp2 * \
        torch.pow(exp, 2) - 3*torch.pow(exp2, 2) - 4*exp*exp3
    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


def get_curvature_loss_and_grad(beta_model, model, args):
    # Refers to writeup here: tvo_icml/notes/curvature_optimization.pdf
    log_weight = get_total_log_weight(model, args, args.valid_S).unsqueeze(-1)

    log_weight = log_weight
    partition = beta_model.weight.data.squeeze(1)

    snis = exponentiate_and_normalize(log_weight * partition, dim=1)

    # Calling them first, second, third to match notation in writeup
    first  = calc_var(log_weight, args, snis=snis, all_sample_mean=True)
    second = calc_third(log_weight, args, snis=snis, all_sample_mean=True)
    third  = calc_fourth(log_weight, args, snis=snis, all_sample_mean=True)

    unsigned_curvature = second.abs() / torch.pow(1 + torch.pow(first, 2), 3 / 2)
    log_curvature = torch.log(second.abs()) - (1.5) * torch.log(1 + torch.pow(first, 2))
    grad = (third / second) - ((3 * first * second) / (1 - torch.pow(first, 2)))

    grad.unsqueeze_(1)

    return -log_curvature, grad, unsigned_curvature


class ChainDistribution(torch.distributions.Distribution):
    def __init__(self, chain_dist, get_next_dist):
        self.chain_dist = chain_dist
        self.get_next_dist = get_next_dist

    def sample(self, sample_shape=torch.Size()):
        sample_chain = self.chain_dist.sample(sample_shape=sample_shape)
        sample_next = self.get_next_dist(sample_chain[-1]).sample(
            sample_shape=())
        return sample_chain + (sample_next,)

    def rsample(self, sample_shape=torch.Size()):
        sample_chain = self.chain_dist.rsample(sample_shape=sample_shape)
        sample_next = self.get_next_dist(sample_chain[-1]).rsample(
            sample_shape=())
        return sample_chain + (sample_next,)

    def log_prob(self, value):
        log_prob_chain = self.chain_dist.log_prob(value[:-1])
        log_prob_next = self.get_next_dist(value[-2]).log_prob(value[-1])
        return log_prob_chain + log_prob_next


class ChainDistributionFromSingle(torch.distributions.Distribution):
    def __init__(self, single_dist):
        self.single_dist = single_dist

    def sample(self, sample_shape=torch.Size()):
        return (self.single_dist.sample(sample_shape=sample_shape),)

    def rsample(self, sample_shape=torch.Size()):
        return (self.single_dist.rsample(sample_shape=sample_shape),)

    def log_prob(self, value):
        return self.single_dist.log_prob(value[0])


class ReversedChainDistribution(torch.distributions.Distribution):
    def __init__(self, chain_dist):
        self.chain_dist = chain_dist

    def sample(self, sample_shape=torch.Size()):
        return tuple(reversed(self.chain_dist.sample(
            sample_shape=sample_shape)))

    def rsample(self, sample_shape=torch.Size()):
        return tuple(reversed(self.chain_dist.rsample(
            sample_shape=sample_shape)))

    def log_prob(self, value):
        return self.chain_dist.log_prob(tuple(reversed(value)))


def get_total_log_weight(model, args, S):
    with torch.no_grad():
        log_weight = []
        for obs in args.train_data_loader:
            model.set_internals(obs, S)
            elbo = model.elbo()
            log_weight.append(elbo)

        log_weight = torch.cat(log_weight)

    return log_weight

def get_total_log_weight_joint_guide(model, args, S):
    with torch.no_grad():
        log_weight = []
        log_joint = []
        log_guide = []

        for obs in args.train_data_loader:
            model.set_internals(obs, S)
            elbo = model.elbo()
            pp = model.log_joint()
            qq = model.log_guide()
            log_weight.append(elbo)
            log_joint.append(pp)
            log_guide.append(qq)

        log_weight = torch.cat(log_weight)
        log_joint = torch.cat(log_joint)
        log_guide = torch.cat(log_guide)

    return log_weight,log_joint,log_guide

def compute_tvo_reparam_loss(log_weight, log_p, log_q, args, return_full = False, amci = False):
    num_particles = args.S


    log_weight = log_weight.unsqueeze(-1) if len(log_weight.shape)<3 else log_weight
    if args.iw_resample:
        log_weight, log_p, log_q, heated_normalized_weight, zb = iw_resampler(log_weight, log_p, log_q, args)

    snis_logw, thermo_logp, snis_detach = get_tvo_components(log_weight, log_p, log_q, args, \
                                            heated_normalized_weight= heated_normalized_weight if args.iw_resample else None)


    beta_one_minus = args.partition*(1-args.partition)
    one_minus_two_beta =  torch.ones_like(args.partition)-2*args.partition

    tvo_reparam = beta_one_minus.squeeze()*torch.sum(snis_detach* \
        (log_weight.detach() - torch.sum(snis_logw, dim=1,keepdim=True).detach()) \
            * (log_weight - torch.sum(snis_detach*log_weight, dim=1,keepdim=True)), dim=1) \
                + one_minus_two_beta.squeeze() * torch.sum(snis_detach*log_weight, dim=1)

    if return_full:
        return -tvo_reparam
    else:
        multiplier = _get_multiplier(args.partition, args.integration).squeeze()
        return -torch.mean(torch.sum(multiplier*tvo_reparam, dim=1), dim=0)

def get_tvo_components(log_weight, log_p, log_q, args, heated_normalized_weight = None):

    partition = args.partition
    num_particles = args.S
    integration = args.integration

    # feed heated_normalized_weight when doing importance resampling (due to uniform expectations at selected indices)
    if heated_normalized_weight is None:

        heated_log_weight = log_weight * partition
        heated_normalized_weight = exponentiate_and_normalize(
            heated_log_weight, dim=1)

    log_p = log_p.unsqueeze(-1) if len(log_p.shape)<3 else log_p
    log_q = log_q.unsqueeze(-1) if len(log_q.shape)<3 else log_q
    thermo_logp = partition * log_p + \
            (1 - partition) * log_q

    snis_logw = heated_normalized_weight * log_weight
    snis_detach = heated_normalized_weight.detach()

    return snis_logw, thermo_logp, snis_detach

File Path: src/BOv.py
Content:
# -*- coding: utf-8 -*-
"""
Created on Wed Apr  8 10:51:04 2020

@author: Vu Nguyen
"""

# -*- coding: utf-8 -*-
"""
Created on Tue Mar 29 11:49:58 2016

"""


import numpy as np
from scipy.optimize import minimize
from src.gaussianprocess.gptv import GPTV
from src.gaussianprocess.gptv_perm import GPTV_Perm

from src.gaussianprocess.gp import GaussianProcess
import matplotlib.pyplot as plt

import time
#from sympy.utilities.iterables import multiset_permutations
from sklearn.preprocessing import MinMaxScaler


#======================================================================================================
#======================================================================================================
#======================================================================================================
#======================================================================================================
counter = 0

def unique_rows(a):
    """
    A functions to trim repeated rows that may appear when optimizing.
    This is necessary to avoid the sklearn GP object from breaking

    :param a: array to trim repeated rows from

    :return: mask of unique rows
    """

    # Sort array and kep track of where things should go back to
    order = np.lexsort(a.T)
    reorder = np.argsort(order)

    a = a[order]
    diff = np.diff(a, axis=0)
    ui = np.ones(len(a), 'bool')
    ui[1:] = (diff != 0).any(axis=1)

    return ui[reorder]


class BayesOpt:

    def __init__(self, func, SearchSpace, GPtype="timevarying_perm",verbose=1):
        """
        Input parameters
        ----------

        SearchSpace:    SearchSpace on parameters defines the min and max for each parameter
        func:           a function to be optimized
        GPtype:         "timevarying_perm" #default value: time-varying permutation
                        "vanillaGP" #this is the vanilla GP, without timevarying permutation

        Returns
        -------
        dim:            dimension
        SearchSpace:         SearchSpace on original scale
        scaleSearchSpace:    SearchSpace on normalized scale of 0-1
        time_opt:       will record the time spent on optimization
        gp:             Gaussian Process object
        """

        self.SearchSpace=SearchSpace
        self.dim = SearchSpace.shape[0]

        # for normalizing the input X [0,1]
        scaler = MinMaxScaler()
        scaler.fit(SearchSpace.T)
        self.Xscaler=scaler

        # create a scaleSearchSpace 0-1
        self.scaleSearchSpace=np.array([np.zeros(self.dim), np.ones(self.dim)]).T

        # function to be optimised
        self.f = func

        # store X in original scale
        self.X_ori= None

        # store X in 0-1 scale
        self.X = None

        # store y=f(x)
        # (y - mean)/(max-min)
        self.Y = None

        # y original scale
        self.Y_ori = None

        self.time_opt=0

        if "timevarying_perm" in GPtype:# timevarying, permutation
            self.gp=GPTV_Perm(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)
        elif GPtype=="vanillaGP": # vanilla GP
            self.gp=GaussianProcess(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)
        else:
            # time-varying, but not permutation invariant
            self.gp=GPTV(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)



        # acquisition function
        self.acq_func = None
        self.logmarginal=0


    def init(self, n_init_points=3,seed=1):
        """
        Input parameters
        ----------
        gp_params:            Gaussian Process structure
        n_init_points:        # init points
        """

        np.random.seed(seed)

        init_X = np.random.uniform(self.SearchSpace[:, 0], self.SearchSpace[:, 1],size=(n_init_points, self.dim))

        self.X_original = np.asarray(init_X)

        # Evaluate target function at all initialization
        y_init=self.f(init_X)
        y_init=np.reshape(y_init,(n_init_points,1))

        self.Y_ori = np.asarray(y_init)

        #self.Y_original_maxGP=np.asarray(y_init)
        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_original)

        # convert it to scaleX
        temp_init_point=np.divide((init_X-self.SearchSpace[:,0]),self.max_min_gap)

        self.X = np.asarray(temp_init_point)


    def init_with_data(self, init_X,init_Y,isPermutation=False):
        """
        Input parameters
        ----------
        gp_params:            Gaussian Process structure
        x,y:        # init data observations (in original scale)
        """

        init_Y=(init_Y-np.mean(init_Y))/np.std(init_Y)

        # outlier removal
        # after standardise the data, remove outlier >3 and <-3
        # this is for robustness and only happen occasionally

        idx1=np.where( init_Y<=3)[0]
        init_Y=init_Y[idx1]
        init_X=init_X[idx1]

        idx=np.where( init_Y>=-3)[0]
        init_X=init_X[idx]
        init_Y=init_Y[idx]

        self.Y_ori = np.asarray(init_Y)
        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)

        self.X_ori=np.asarray(init_X)
        self.X = self.Xscaler.transform(init_X)



    def gp_ucb(self,xTest):
        xTest=np.reshape(xTest,(-1,self.dim))
        mean, var,_,_ = self.gp.predict(xTest)
        var.flags['WRITEABLE']=True
        #var=var.copy()
        var[var<1e-10]=0
        mean=np.atleast_2d(mean).T
        var=np.atleast_2d(var).T

        # Linear in D, log in t https://github.com/kirthevasank/add-gp-bandits/blob/master/BOLibkky/getUCBUtility.m
        #beta_t = gp.X.shape[1] * np.log(len(gp.Y))
        beta_t =np.log(len(self.gp.Y))

        #beta=300*0.1*np.log(5*len(gp.Y))# delta=0.2, gamma_t=0.1
        return mean + np.sqrt(beta_t) * np.sqrt(var)


    def select_next_point(self):
        """
        Main optimization method.

        Input parameters
        ----------
        gp_params: parameter for Gaussian Process

        Returns
        -------
        x: recommented point for evaluation
        """

        #ur = unique_rows(self.X)
        self.Y=np.reshape(self.Y,(-1,1))
        self.gp.fit(self.X, self.Y)

        # Set acquisition function
        start_opt=time.time()
        x_max = self.acq_max_scipy(ac=self.gp_ucb)

        x_max_ori=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim)))

        if self.f is None:
            return x_max,x_max_ori

        # record the optimization time
        finished_opt=time.time()
        elapse_opt=finished_opt-start_opt
        self.time_opt=np.hstack((self.time_opt,elapse_opt))

        # store X
        self.X = np.vstack((self.X, x_max.reshape((1, -1))))
        # compute X in original scale

        self.X_ori=np.vstack((self.X_ori, x_max_ori))
        # evaluate Y using original X

        #self.Y = np.append(self.Y, self.f(temp_X_new_original))
        self.Y_ori = np.append(self.Y_ori, self.f(x_max_ori))

        # update Y after change Y_original
        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)

        return x_max,x_max_ori

    def acq_max_scipy(self,ac):
        """
        A function to find the maximum of the acquisition function using
        multi-start L-BFGS-B

        Input Parameters
        ----------
        ac: The acquisition function object that return its point-wise value.
        gp: A gaussian process fitted to the relevant data.
        y_max: The current maximum known value of the target function.
        SearchSpace: The variables SearchSpace to limit the search of the acq max.

        Returns
        -------
        x_max, The arg max of the acquisition function.
        """

        # Start with the lower bound as the argmax
        x_max = self.scaleSearchSpace[:, 0]
        max_acq = None

        #myopts ={'maxiter':2000,'fatol':0.01,'xatol':0.01}

        # this is the config of L-BFGS-B
        myopts ={'maxiter':50*self.dim,'maxfun':50*self.dim}

        # multi start: the number of repeatition is 3* dimension
        # higher dimensions will have more repetitions
        for i in range(3*self.dim):
            # Find the minimum of minus the acquisition function
            x_tries = np.random.uniform(self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1],size=(10*self.dim, self.dim))

            # evaluate the acquisition function
            y_tries=ac(x_tries)

            # pick the one with the best value and start L-BFGS-B from this point
            x_init_max=x_tries[np.argmax(y_tries)]

            res = minimize(lambda x: -ac(x.reshape(1, -1)),x_init_max.reshape(1, -1),
                   bounds=self.scaleSearchSpace,method="L-BFGS-B",options=myopts)#L-BFGS-B

            val=ac(res.x)

            # Store it if better than previous minimum(maximum).
            if max_acq is None or val >= max_acq:
                if 'x' not in res:
                    x_max = res
                else:
                    x_max = res.x
                max_acq = val

        return np.clip(x_max, self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1])


    def plot_acq_1d(self):
        # plot the acquisition function in 1 dimension

        x1_scale = np.linspace(self.scaleSearchSpace[0,0], self.scaleSearchSpace[0,1], 60)
        x1_scale=np.reshape(x1_scale,(-1,1))
        acq_value = self.gp_ucb(x1_scale)

        x1_ori=self.Xscaler.inverse_transform(x1_scale)

        fig = plt.figure(figsize=(12,7))
        ax = fig.add_subplot(1, 1, 1)

        # Plot the surface.
        CS_acq=ax.plot(x1_ori,acq_value.reshape(x1_ori.shape))
        ax.scatter(self.X_ori[:,0],self.Y[:],marker='o',color='r',s=130,label='Obs')

        ax.set_ylabel('Acquisition Function',fontsize=18)
        ax.set_xlabel('Beta',fontsize=18)

File Path: src/__init__.py
Content:

File Path: src/assertions.py
Content:
import torch
import numpy as np
from src.ml_helpers import AverageMeter, get_grads, tensor, lognormexp, exponentiate_and_normalize, seed_all
from torch.distributions.multinomial import Multinomial

DUAL_OBJECTIVES = ['wake-wake', 'wake-sleep', 'tvo-sleep', 'tvo_reparam', 'tvo_reparam_iwae']
INTEGRATION_PARTITONS = ['left','right','trapz','single']
PCFGS = ['astronomers', 'brooks', 'minienglish', 'polynomial', 'quadratic', 'sids']
DISCRETE_LOSSES = ['reinforce','tvo','tvo_smoothed', 'vimco','wake-wake','wake-sleep', 'tvo-sleep']

# Assertions
def validate_hypers(args):
    assert args.schedule in [
        'log',
        'linear',
        'bq',
        'moments',
        'rand',
        'gp_bandit',
        'gp',
        'tvgp',
        #'beta_gradient_descent',
        #'beta_batch_gradient'
        ], f"schedule cannot be {args.schedule}"

    assert args.integration in INTEGRATION_PARTITONS, f"integration cannot be {args.integration}"

    assert args.integration_tvo_evidence in INTEGRATION_PARTITONS, f"integration_tvo_evidence cannot be {args.integration_tvo_evidence}"

    assert args.loss in [
        'reinforce',
        'elbo',
        'iwae',
        'tvo',
        'tvo_smoothed',
        'tvo_reparam',
        'tvo_reparam_iwae',
        'vimco',
        'wake-wake',
        'tvo-sleep',
        'wake-sleep'], f"loss cannot be {args.loss} "

    assert args.learning_task in [
        'continuous_vae',
        'discrete_vae',
        'bnn',
        'pcfg'
        ], f" learning_task cannot be {args.learning_task}"

    if args.learning_task != 'pcfg':
        assert args.dataset in [
                'tiny_mnist',
            'fashion_mnist',
            'mnist',
            'kuzushiji_mnist',
            'omniglot',
            'binarized_mnist',
            'binarized_omniglot'], f" dataset cannot be {args.dataset} "
    else:
        assert args.dataset in PCFGS, f"dataset must be one of {PCFGS}"
        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"
        assert args.loss in ['tvo','tvo-sleep','wake-sleep', 'wake-wake'], f'{args.loss} not yet implemented for PCGS yet'

    if args.schedule != 'log':
       assert args.loss in ['elbo','tvo', 'tvo-sleep', 'tvo_reparam', 'tvo_smoothed', 'tvo_reparam_iwae'],  f"{args.loss} doesn't require a partition schedule scheme"
    if args.learning_task in ['discrete_vae']:
        assert args.dataset in ['binarized_mnist', 'binarized_omniglot'], \
            f" dataset cannot be {args.dataset} with {args.learning_task}"

        assert args.loss in DISCRETE_LOSSES, f"loss can't be {args.loss} with {args.learning_task}"

    if args.learning_task == 'bnn':
        assert args.dataset in ['fashion_mnist'], f" only fashion_mnist tested so far"
        assert args.loss not in DUAL_OBJECTIVES, f"BNN only has phi, can't use alternating objectives"

    if args.loss in DUAL_OBJECTIVES:
        assert not args.save_grads, 'Grad variance not able to handle duel objective methods yet'




    # Add an assertion everytime you catch yourself making a silly hyperparameter mistake so it doesn't happen again


def validate_dataset_path(args):
    learning_task = args.learning_task
    dataset = args.dataset

    if learning_task in ['discrete_vae', 'continuous_vae']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fashion_mnist.pkl'
        elif dataset == 'mnist':
            data_path = args.data_dir + '/mnist.pkl'
        elif dataset == 'tiny_mnist':
            data_path = args.data_dir + '/tiny_mnist.pkl'
        elif dataset == 'omniglot':
            data_path = args.data_dir + '/omniglot.pkl'
        elif dataset == 'kuzushiji_mnist':
            data_path = args.data_dir + '/kuzushiji_mnist.pkl'
        elif dataset == 'binarized_mnist':
            data_path = args.data_dir + '/binarized_mnist.pkl'
        elif dataset == 'binarized_omniglot':
            data_path = args.data_dir + '/binarized_omniglot.pkl'
    elif learning_task in ['bnn']:
        if dataset == 'fashion_mnist':
            data_path = args.data_dir + '/fmnist/'
    elif learning_task in ['pcfg']:
        data_path = args.data_dir + f'/pcfgs/{dataset}_pcfg.json'
    else:
        raise ValueError("Unknown learning task")

    return data_path

File Path: src/bayes_quad.py
Content:
import numpy as np
from src import util
import logging
import torch
#from GPy.models import GPRegression
#from GPy.kern import RBF
#from emukit.model_wrappers.gpy_quadrature_wrappers import BaseGaussianProcessGPy, RBFGPy
#from emukit.quadrature.kernels import QuadratureRBF
#from emukit.quadrature.kernels import QuadratureRBFLebesgueMeasure
#from emukit.quadrature.methods import VanillaBayesianQuadrature
#from emukit.quadrature.acquisitions import IntegralVarianceReduction
#from emukit.core.optimization import GradientAcquisitionOptimizer
#from emukit.core.parameter_space import ParameterSpace
from src.BOv import BayesOpt
import matplotlib.pyplot as plt
from src import ml_helpers as mlh
from src.BOv import unique_rows
import pickle
# Figure config
# NOT TUNABLE HYPERPARAMETERS
# (putting them here so I'm not tempted to tune them)

LEGEND_SIZE = 15
FIGURE_SIZE = (12, 8)
WINDOW = 5
K_MAX = 100
MIN_REL_CHANGE = 1e-3
MIN_ERR = 1e-3
LBM_GRID = np.linspace(-9, -0.1, 50)

emu_log = logging.getLogger("emukit")
emu_log.setLevel(logging.WARNING)

emu_gp = logging.getLogger("GP")
emu_gp.setLevel(logging.WARNING)


#def calculate_bq_points(model, args):
#    # Replace this with any integrand function
#    f = get_integrand_function(model, args)
#
#    # Initial partition (0, lbm, 1)
#    X = mlh.tensor((0, 10**args.bq_log_seed_point, 1.0), args)
#
#    Y = f(X)
#    emukit_method, optimizer = init_bq(X, Y)
#    points, est, k = auto_train_bq(X, Y, f, emukit_method, optimizer, args)
#
#    return points, est, k

def extract_X_Y_from_args(SearchSpace,args,T=None):
    # obtain X and Y by truncating the data in the time-varying setting
    # if the existing data is <3*arg.K, randomly generate X
    
    if T is None:
        T=args.truncation_threshold
    lenY=len(args.Y_ori)
    X=args.X_ori[max(0,lenY-T):,1:-1] # remove the first and last  column which is 0 and 1

    ur=unique_rows(X)
    if sum(ur)<(3*args.K): # random search to get initial data
        init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        init_X=np.around(init_X, decimals=4)
        init_X=np.append(0,init_X)
        init_X=np.append(init_X,1)

        return np.sort(init_X),None

    if lenY%20==0:
        strPath="{:s}/save_X_Y_{:s}_S{:d}_K{:d}.p".format(str(args.artifact_dir), args.schedule, args.S, args.K)
        pickle.dump( [args.X_ori,args.Y_ori], open( strPath, "wb" ) )

    Y=np.reshape(args.Y_ori[max(0,lenY-T):],(-1,1))

    return X,Y

def append_Xori_Yori_from_args(args):
    # append the average logpx into Y
    # append the args.partition into X

    if args.len_terminated_epoch >0: # if we terminate the betas due to drip the epoch len is shorted
        average_y=np.mean(args.logtvopx_all[-args.len_terminated_epoch:])
    else:
        average_y=np.mean(args.logtvopx_all[-args.schedule_update_frequency:])
    args.average_y=np.append(args.average_y,average_y) # averaging the logpx over this window

    # error will happen at the first iteration when we add the first average_y into our data
    # this error is intentional, i will modify it by using a flag to indicate the first time
    if len(args.average_y)==1:
        print("ignore for the first time to save the first value of Y")
        return

    prev_y=args.average_y[-1] -args.average_y[-2]

    args.X_ori=np.vstack(( args.X_ori, np.reshape(format_input(args.partition),(1,args.K+1) )))
    args.Y_ori=np.append(args.Y_ori, prev_y)
    prev_X=np.round(args.X_ori[-1],decimals=4)
    print("X",prev_X,"Y",args.Y_ori[-1])

#def extract_X_Y_from_args_log(SearchSpace,args):
#    # obtain X and Y
#
#    T=args.truncation_threshold
#    lenY=len(args.Y_ori)
#
#    X=np.log10( args.X_ori[max(0,lenY-T):,1:-1]) # remove the first column which is 0
#
#    ur=unique_rows(X)
#    if sum(ur)< (3*args.K) or 'rand' in args.schedule: # random search to get initial data
#        init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
#        init_X=np.around(10**init_X, decimals=4)
#        init_X=np.append(0,init_X)
#        init_X=np.append(init_X,1)
#
#        return np.sort(init_X),None
#
#    if args.X_ori.shape[0]%20==0: #save for analysis purpose
#        strPath="save_X_Y_{:s}_S{:d}_K{:d}.p".format(args.schedule,args.S,args.K)
#        pickle.dump( [args.X_ori,args.Y_ori], open( strPath, "wb" ) )
#
#    Y=np.reshape(args.Y_ori[max(0,lenY-T):],(-1,1))
#
#    return X,Y


def calculate_BO_points(model,args):

    # process the input X and output Y from args
    append_Xori_Yori_from_args(args)

    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            SearchSpace[kk,1]=ll[kk+1]



    # truncate the time-varying data if neccessary
    # if dont have enough data -> randomly generate data
    if args.schedule=="gp": # non timevarying
        X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori))
    else:   # time varying     
        X,Y=extract_X_Y_from_args(SearchSpace,args)
        
    if Y is None:
        return X

    # augment the data with artificial observations all zeros and all ones
    x_all_zeros=np.reshape(np.asarray([args.bandit_beta_min]*(args.K-1)),(1,-1))
    x_all_ones=np.reshape(np.asarray([args.bandit_beta_max]*(args.K-1)),(1,-1))

    worse_score=np.min(Y)

    X=np.vstack((X,x_all_zeros))
    X=np.vstack((X,x_all_ones))

    Y=np.vstack((Y,np.asarray(worse_score)))
    Y=np.vstack((Y,np.asarray(worse_score)))


    # perform GP bandit
    if args.schedule=="gp_bandit":
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace)
    elif args.schedule=="tvgp" or args.schedule=="gp": # TV but not permutation invariant
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")    
    else:
        print("please change ",args.schedule)
        
    
    myBO.init_with_data(X,Y)

    # beta is selected from here
    new_X=myBO.select_next_point()[1]

    # sorting
    new_X=np.round(new_X,decimals=4)
    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X

    
def calculate_BO_points_vanillaGP(model,args): # this is used as a baseline with vanilla GP

    # process the input X and output Y from args
    append_Xori_Yori_from_args(args)

    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            SearchSpace[kk,1]=ll[kk+1]

    X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori)) # this is non timevarying GP, takes all data
    if Y is None:
        return X

    myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")
    myBO.init_with_data(X,Y)

    # beta is selected from here
    new_X=myBO.select_next_point()[1]
    new_X=np.round(new_X,decimals=4)

    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X
    

#def get_derivative_points(X,log_weight,args):
#    Xdrv=[]
#    derivatives=[]
#    for ii in range(X.shape[0]-1): # placing init_K-1 initial derivative observations between two points
#        delta_x=np.abs(X[ii,0]-X[ii+1,0]) # different in x
#        if delta_x<1e-2:
#            continue
#        new_point=delta_x/2+X[ii,0]
#        Xdrv=Xdrv+[new_point] # set the derivative point at the middle of two points
#
#        der = util.calc_var_given_betas(log_weight, args, all_sample_mean=True, betas = new_point)
#        derivatives=derivatives+[round(np.asscalar(format_input(der)),3)]
#    print(derivatives)
#    Xdrv=np.reshape(np.asarray(Xdrv),(-1,1)) # convert Xdrv to [M*d] where d=1
#    derivatives=np.reshape(np.asarray(derivatives),(-1,1)) # convert derivatives to [M*1]
#    return Xdrv, derivatives


#def calculate_bqd_points(model, args): #cal BQ with derivative
#    # we extract log_weight two times! The above line also extracts this. So please optimise!
#    # this log_weight is used to estimate the derivative
#    log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    args.log_weight=log_weight
#
#    # Replace this with any integrand function
#
#    X,Y,f,SearchSpace=init_bqd(model,args)
#
#    #extracting the derivative points
#    Xdrv,derivatives= get_derivative_points(X,log_weight,args)
#    #Xdrv,derivatives= get_derivative_points_middle(X,log_weight,args)
#    Y=np.reshape(np.asarray(Y),(-1,1)) # convert Y to [K*1]
#
#    myGPdrv=GaussianProcessDerivative(SearchSpace)
#    myGPdrv.fit_drv(X,Y,Xdrv,derivatives,drv_index=0)
#    myGPdrv.auto_train_bq(f,MaxK=15)
#
#    est=myGPdrv.integral()[1]
#    points=myGPdrv.X.ravel()
#
#    points=np.asarray([0,0.1,1])
#    #points=np.asarray([0.0000,     0.0001,     0.0017,     0.0210,     0.0724,     0.1434,
#           # 0.1741,     0.5114,     0.8678,     0.9030,     0.9377,     0.9911,1.0000])
#    #return points, 0, len(points)
#
#    #print("[GP with drv] estimated integral is",est) # this function is useful to return the integral
#    return np.sort(points), est, len(points)


#def init_bqd(model,args):
#    log_weight = util.get_total_log_weight(model, args, args.valid_S)
#    args.log_weight=log_weight
#
#    # Replace this with any integrand function
#    # I just want to estimate f(beta=0) for normalising purpose.
#    # This is better way to estimate and do it instead of two repeating calls.
#
#    init_K=3
#    SearchSpace=np.asarray([[0,1]]) # this is the search range of beta from 0-1
#
#    if "loss" in args.schedule:
#        f=get_integrand_function_from_loss(model,args)
#    elif "log" in args.schedule:
#        f = get_integrand_function(model, args)
#        f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
#        args.f_beta0=f_beta0
#        f=get_integrand_function_subtract_beta0_log(model,args) #redefine the function using f(beta=0)
#        SearchSpace=np.asarray([[-1,0]]) # this is the search range of beta from 0-1
#    else:
#        f = get_integrand_function(model, args)
#        f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
#        args.f_beta0=f_beta0
#        f=get_integrand_function_subtract_beta0(model,args) #redefine the function using f(beta=0)
#
#    # Initial partition (0,1)
#    X=np.linspace(SearchSpace[0,0],SearchSpace[0,1],init_K)
#    X=np.reshape(X,(-1,1))
#    Xtensor = mlh.tensor(X, args)
#
#    if "log" in args.schedule:
#        Ytensor = [f(10**Xtensor[ii]) for ii in range(init_K)]
#    else:
#        Ytensor = [f(Xtensor[ii]) for ii in range(init_K)]
#
#    Y=[np.asscalar(Ytensor[ii].data.cpu().numpy()) for ii in range(init_K)] # convert to numpy
#    Y=np.reshape(np.asarray(Y),(-1,1)) # convert Y to [K*1]
#
#    return X,Y,f,SearchSpace


def format_input(*data):
    output = []
    for d in data:
        if torch.is_tensor(d):
            d = d.cpu().numpy()
        if d.ndim == 1:
            d = np.expand_dims(d, 1)
        output.append(d)

    return output[0] if len(output) == 1 else output


def plot_variance(ivr_acquisition):
    x_plot = np.linspace(0, 1, 300)[:, None]
    ivr_plot = ivr_acquisition.evaluate(x_plot)

    plt.figure(figsize=FIGURE_SIZE)
    plt.plot(x_plot, (ivr_plot - np.min(ivr_plot)) / (np.max(ivr_plot) - np.min(ivr_plot)),
             "green", label="integral variance reduction")

    plt.legend(loc=0, prop={'size': LEGEND_SIZE})
    plt.xlabel(r"$x$")
    plt.ylabel(r"$acquisition(x)$")
    plt.grid(True)
    plt.xlim(0, 1)
    plt.ylim(0, 1.04)
    plt.show()


#def init_bq(X, Y, integral_bounds=[(0, 1)]):
#    X, Y = format_input(X, Y)
#    gpy_model = GPRegression(X=X, Y=Y, kernel=RBF(input_dim=X.shape[1],
#                                                  lengthscale=0.5,
#                                                  variance=1.0))
#
#    # Kernals and stuff
#    emukit_rbf    = RBFGPy(gpy_model.kern)
#    emukit_qrbf   = QuadratureRBFLebesgueMeasure(emukit_rbf, integral_bounds=integral_bounds)
#    emukit_model  = BaseGaussianProcessGPy(kern=emukit_qrbf, gpy_model=gpy_model)
#    emukit_method = VanillaBayesianQuadrature(base_gp=emukit_model,X=X,Y=Y)
#
#    space = ParameterSpace(emukit_method.reasonable_box_bounds.convert_to_list_of_continuous_parameters())
#    optimizer = GradientAcquisitionOptimizer(space)
#
#    #space = ParameterSpace(emukit_method.integral_parameters)
#    #optimizer = GradientAcquisitionOptimizer(space)
#    return emukit_method, optimizer


#def auto_calculate_bq_points(model, args):
#    f = get_integrand_function(model, args)
#
#    best_meter = mlh.BestMeter()
#
#    for lbm in LBM_GRID:
#        print("Running lbm = {} ...".format(round(lbm, 3)))
#        X = mlh.tensor((0, 10**lbm, 1.0), args)
#        Y = f(X)
#        emukit_method, optimizer = init_bq(X, Y)
#        points, est, k = auto_train_bq(X, Y, f, emukit_method, optimizer, args)
#        best_meter.step(est, (points, lbm, k))
#
#    best_points, best_lbm, best_k = best_meter.best_obj
#    best_est = best_meter.best
#    return best_points, best_est, best_k, best_lbm


#def auto_train_bq(X, Y, f, emukit_method, optimizer, args):
#    X, Y = format_input(X, Y)
#
#    maxed_out = True
#    mean_avg, err_avg = mlh.MovingAverageMeter('mean', ':.15f', window=WINDOW), mlh.MovingAverageMeter('err', ':.15f', window=WINDOW)
#
#    for k in range(K_MAX):
#        integral_mean, integral_variance = emukit_method.integrate()
#        err = 2 * np.sqrt(integral_variance)
#
#        mean_avg.step(integral_mean)
#        err_avg.step(err)
#
#        ivr_acquisition = IntegralVarianceReduction(emukit_method)
#
#        #plot_variance(ivr_acquisition)
#
#        x_new, _ = optimizer.optimize(ivr_acquisition)
#
#        x_new = mlh.tensor(x_new, args)
#        y_new = f(x_new)
#
#        X = np.append(X, format_input(x_new), axis=0)
#        Y = np.append(Y, format_input(y_new), axis=0)
#
#
#        emukit_method.set_data(X, Y)
#
#        # check break condition
#        if (abs(mean_avg.relative_change) < MIN_REL_CHANGE) and (abs(err_avg.val) < MIN_ERR):
#            maxed_out = False
#            break
#
#    if maxed_out:
#        print("################################################")
#        print(f"---------------- Warning --------------------- ")
#        print(f"Inner loop failed to converge after {K_MAX} iterations ###")
#        print(f"mean_avg: {mean_avg}")
#        print(f"err_avg: {err_avg}")
#        print("################################################")
#
#    return mlh.tensor(np.sort(X.flatten()), args), mean_avg.val, k


#def get_integrand_function_subtract_beta0(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X):
#        partition = mlh.tensor(X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y-args.f_beta0
#    return f

#def get_integrand_function_subtract_beta0_log(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X): # we take 10**X due to the log space
#        partition = mlh.tensor(10**X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y-args.f_beta0
#    return f

#def get_integrand_function(model, args):
#
#    try: # for BDQ we already have log_weight, dont need to extract it again
#        log_weight=args.log_weight
#    except: # for other approaches, we need to extract it
#        log_weight = util.get_total_log_weight(model, args, args.valid_S)
#
#    def f(X):
#        partition = mlh.tensor(X,args)
#        heated_log_weight = log_weight.unsqueeze(-1) * partition
#
#        heated_normalized_weight = mlh.exponentiate_and_normalize(heated_log_weight, dim=1)
#        Y = torch.sum(heated_normalized_weight * log_weight.unsqueeze(-1), dim=1).mean(0)
#
#        return Y
#    return f

def get_cov_function(model, args):

    try: # for BDQ we already have log_weight, dont need to extract it again
        log_weight=args.log_weight
    except: # for other approaches, we need to extract it
        log_weight = util.get_total_log_weight(model, args, args.valid_S)

    def f(X):
        der = util.calc_var_given_betas(log_weight, args, all_sample_mean=True,
                                        betas = X)
        return der
    return f

File Path: src/data_handler.py
Content:
# Adapted from
# https://github.com/tensorflow/models/tree/master/research/rebar and
# https://github.com/duvenaud/relax/blob/master/datasets.py

import pickle
import logging
import numpy as np
from pathlib import Path
import torch.utils.data
from src.ml_helpers import tensor, get_data_loader
from src.models.pcfg import GenerativeModel as PCFGGenerativeModel
from src.pcfg_util import read_pcfg
from torchvision import datasets, transforms
from torch.utils.data import Dataset#, IterableDataset
from skimage import color, io as imageio, transform


class StochasticMNIST(Dataset):
    def __init__(self, image):
        super(StochasticMNIST).__init__()
        self.image = image

    def __len__(self):
        return self.image.shape[0]

    def __getitem__(self, idx):
        return (torch.bernoulli(self.image[idx, :]), )


class PixelIntensity(Dataset):
    def __init__(self, image):
        super(PixelIntensity).__init__()
        self.image = image

    def __len__(self):
        return self.image.shape[0]

    def __getitem__(self, idx):
        return (self.image[idx, :], )


class Synthetic(Dataset):
    def __init__(self, X, y=None):
        super(Synthetic).__init__()
        self.X = X
        self.y = y

        if X.ndim == 1:
            self.X = self.X.unsqueeze(1)

        if y is not None:
            assert self.X.shape[0] == self.y.shape[0]

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        if self.y is not None:
            return (self.X[idx, :], self.y[idx])
        else:
            return (self.X[idx, :], )


def make_continuous_vae_data(args):
    # read data
    with open(args.data_path, 'rb') as file_handle:
        data = pickle.load(file_handle)

    train_image = data['train_image']
    test_image = data['test_image']

    # See page 6, footnote 2 here: https://arxiv.org/pdf/1509.00519.pdf
    train_image = StochasticMNIST(tensor(train_image, args))
    test_image = StochasticMNIST(tensor(test_image, args))

    train_data_loader = get_data_loader(train_image, args.batch_size, args)
    test_data_loader = get_data_loader(test_image, args.test_batch_size, args)
    return train_data_loader, test_data_loader


def make_discrete_vae_data(args):
    """
    Annoyingly the continuous and discrete vae literature uses different train/val/test/split.
    For continuous we use 60k train / 10k test
    in accordance with IWAE paper: https://arxiv.org/pdf/1509.00519.pdf

    For discrete we use 50k train / 10k validation / 10k test
    in accordance with VIMCO paper: https://arxiv.org/pdf/1602.06725.pdf

    We don't use the 10k validation to be consistent w/ continuous case
    """
    with open(args.data_path, 'rb') as file_handle:
        data = pickle.load(file_handle)

    train_image = PixelIntensity(tensor(data['x_train'], args))
    test_image = PixelIntensity(tensor(data['x_test'], args))

    train_data_loader = get_data_loader(train_image, args.batch_size, args)
    test_data_loader  = get_data_loader(test_image, args.test_batch_size, args)

    return train_data_loader, test_data_loader


def make_bnn_data(args):
    LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}
    train_data_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            args.data_path, train=True, download=True,
            transform=transforms.ToTensor()),
        batch_size=args.batch_size, shuffle=True, **LOADER_KWARGS)
    test_data_loader = torch.utils.data.DataLoader(
        datasets.FashionMNIST(
            args.data_path, train=False, download=True,
            transform=transforms.ToTensor()),
        batch_size=args.test_batch_size, shuffle=False, **LOADER_KWARGS)

    return train_data_loader, test_data_loader


class PCFGDataset(Dataset):
    def __init__(self, path, N=1000):
        super(PCFGDataset).__init__()
        grammar, true_production_probs = read_pcfg(path)
        self.true_generative_model = PCFGGenerativeModel(grammar, true_production_probs)
        # data comes from true_generative_model so we have an infinite amount of it.
        # Set len = 1000 arbitrarily
        self.N = N

    def __len__(self):
        return self.N

    def __getitem__(self, idx):
        return self.true_generative_model.sample_obs()

def make_pcfg_data(args):
    # instantiate a gen model w/ true production probabilities to create data
    dataset = PCFGDataset(args.data_path, N=args.batch_size)

    loader = torch.utils.data.DataLoader(
        dataset,
        batch_size=args.batch_size,
        batch_sampler=None,
        shuffle=False,
        collate_fn=lambda x: (x,) # this is important otherwise default collate_fn messes up batching
        )

    return loader, loader


def get_data(args):
    if args.learning_task == 'continuous_vae':
        return make_continuous_vae_data(args)
    elif args.learning_task == 'discrete_vae':
        return make_discrete_vae_data(args)
    elif args.learning_task == 'bnn':
        return make_bnn_data(args)
    elif args.learning_task == 'pcfg':
        return make_pcfg_data(args)
    else:
        raise ValueError(
            "{} is an invalid learning task".format(args.learning_task))

File Path: src/file_reader_helper.py
Content:
from __future__ import division, print_function

import datetime
import errno
import json
import os
import pickle
import random
import shutil
import socket
import sys
import time
from collections import defaultdict, deque
from datetime import datetime
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import torch
import torch.distributed as dist
from joblib import Parallel, delayed
#from sklearn import metrics
from torch._six import inf


def safe_json_load(path):
    path = Path(path)
    res = {}
    if path.stat().st_size != 0:
        with open(path) as data_file:
            res = json.load(data_file)
    return res

def get_experiments_from_fs(path):
    path = Path(path)
    assert (path / '_sources/').exists(), f"Bad path: {path}"
    exps = {}
    dfs = []

    for job in path.glob("*"):
        if job.parts[-1] in ['_resources', '_sources']:
            continue
        job_id = job.parts[-1]

        run = safe_json_load(job / 'run.json')
        config = safe_json_load(job / 'config.json')
        metrics = safe_json_load(job / 'metrics.json')

        exps[job_id] = {**config, **run}

        if metrics:
            for metric, v in metrics.items():
                df = pd.DataFrame(v)
                df.index = pd.MultiIndex.from_product([[job_id], [metric], df.index], names=['_id', 'metric', 'index'])
                dfs += [df]

    exps = pd.DataFrame(exps).T
    exps.index.name = '_id'
    if dfs:
        df = pd.concat(dfs).drop('timestamps', axis=1)
    else:
        df = None
    return exps, df

def get_experiments_from_dir(path, observer_name="file_storage_observer"):
    path = Path(path)
    assert path.exists(), f'Bad path: {path}'
    exps = {}
    dfs = {}
    for p in path.rglob(observer_name):
        _id = str(p).replace(f"/{observer_name}", "")
        exp, df = get_experiments_from_fs(p)
        exps[_id] = exp
        if df is None:
            print(f"{p} returned empty df")
        else:
            dfs[_id] = df

    if exps and dfs:
        exps = pd.concat(exps.values(), keys=exps.keys()).droplevel(1)
        dfs = pd.concat(dfs.values(), keys=dfs.keys()).droplevel(1)

        exps.index.name = '_id'
        dfs.index.names = ['_id', 'metric', 'index']
    else:
        raise ValueError(f"results empty! path:{path}")

    return exps, dfs

def post_process(exp, df, CUTOFF_EPOCH=2000):
    print(f"{exp[exp.status == 'COMPLETED'].shape[0]} jobs completed")
    print(f"{exp[exp.status == 'RUNNING'].shape[0]} jobs timed out")
    print(f"{exp[exp.status == 'FAILED'].shape[0]} jobs failed")

    # Remove jobs that failed
    exp = exp[exp.status != 'FAILED']

    df = df[df.steps <= CUTOFF_EPOCH]

    # get values at last epoch
    results_at_cutoff = df[df.steps == CUTOFF_EPOCH].reset_index().pivot(index='_id', columns='metric',values='values')

    # join
    exp = exp.join(results_at_cutoff, how='outer')
    return exp, df


def process_dictionary_column(df, column_name):
    if column_name in df.columns:
        return df.drop(column_name, 1).assign(**pd.DataFrame(df[column_name].values.tolist(), index=df.index))
    else:
        return df

def process_tuple_column(df, column_name, output_column_names):
    if column_name in df.columns:
        return df.drop(column_name, 1).assign(**pd.DataFrame(df[column_name].values.tolist(), index=df.index))
    else:
        return df

def process_list_column(df, column_name, output_column_names):
    if column_name in df.columns:
        new = pd.DataFrame(df[column_name].values.tolist(), index=df.index, columns=output_column_names)
        old = df.drop(column_name, 1)
        return old.merge(new, left_index=True, right_index=True)
    else:
        return df


def get_data(path,isdir=False):
    #if 'file_storage_observer' in path or 'my_runs' in path or 'my_run_discrete' in path or "my_run" in path \
    #or 'my_run_discrete2' in path :
    #if isdir==False:
    try:
        exps, df = get_experiments_from_fs(Path(path))
    #else:
    except:
        exps, df = get_experiments_from_dir(Path(path))
    exps = exps[exps.status =='COMPLETED']
    #exps = exps[exps.schedule =='gp_bandit']
    exps = process_dictionary_column(exps, 'result')
    return exps, df

def get_baseline(name):
    exps = pd.read_csv(f"baseline_data/{name}_exps_10k.csv", index_col=0)
    df = pd.read_csv(f"baseline_data/{name}_df_10k.csv", index_col=[0,1])
    return exps, df


File Path: src/gaussianprocess/GPv.py
Content:
# -*- coding: utf-8 -*-
"""
Created on Fri Mar 20 18:35:25 2020

@author: Lenovo
"""
import numpy as np
import matplotlib.pyplot as plt
import warnings
from sklearn.metrics.pairwise import euclidean_distances
from scipy.optimize import minimize
from sklearn.preprocessing import MinMaxScaler
import scipy
from scipy.special import erf

class GaussianProcessDerivative(object):
    def __init__ (self,SearchSpace,noise_delta=1e-8,noise_drv=1e-4,verbose=0):
        self.noise_delta=noise_delta
        self.noise_drv=noise_drv
        self.mycov=self.cov_RBF
        self.SearchSpace=SearchSpace
        scaler = MinMaxScaler()
        scaler.fit(SearchSpace.T)
        self.Xscaler=scaler
        self.verbose=verbose
        self.dim=SearchSpace.shape[0]
        
        self.hyper={}
        self.hyper['var']=1 # standardise the data
        self.hyper['lengthscale']=0.1 #to be optimised
        
        #self.minY=0 # this is the value of f(beta=0)

        return None

    #def set_min_Y(self,minY):
        #self.minY=minY
        
    def fit(self,X,Y):
        """
        Fit a Gaussian Process model
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        """       
        #Y=Y-self.minY
        self.X_ori=X # this is the output in original scale
        self.X= self.Xscaler.transform(X) #this is the normalised data [0-1] in each column
        self.Y_ori=Y # this is the output in original scale
        self.Y=(Y-np.mean(Y))/np.std(Y) # this is the standardised output N(0,1)
        
        self.hyper['lengthscale']=self.optimise()         # optimise GP hyperparameters
        self.KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta     
        if np.isnan(self.KK_x_x).any(): #NaN
            print("nan in KK_x_x !")
      
        self.L=scipy.linalg.cholesky(self.KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)
        
    def fit_drv(self,X,Y,Xdrv,Ydrv,drv_index=0):
        """
        Fit a Gaussian Process model using derivative
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        Xdrv: input 2d array of derivative obs [M*d]
        Ydrv: output 2d array of derivative obs [M*1]
        drv_index: the derivative is applicalbe at drv_index (in this case drv_index=0)
        """    
        #Y=Y-self.minY

        self.drv_index=drv_index
        self.Xdrv_ori=np.reshape(Xdrv,(-1,X.shape[1]))
        self.Xdrv=self.Xscaler.transform(Xdrv) #normalised the derivative input [0-1]
        self.X_ori=X
        self.X= self.Xscaler.transform(X) # normalised the input [0-1]
        self.Y_ori=Y
        self.Ydrv_ori=np.copy(Ydrv )
        self.Ydrv=Ydrv/np.std(Y) # standardize derivative given the data
        #print("Ydrv_ori",Ydrv)
        #print("Ydrv",self.Ydrv)
        #self.Ydrv=np.copy(Ydrv )
        #print("stdY",np.std(Y))
        self.Y=(Y-np.mean(Y))/np.std(Y)
        
        if self.verbose:
            print("Y",self.Y)
        self.Y_combined=np.vstack((self.Y,self.Ydrv))
        self.hyper['lengthscale']=self.optimise_drv()         # optimise GP hyperparameters

        KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta     
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")
            
        KK_x_v=self.cov_RBF_drv(self.Xdrv,self.X,self.hyper,drv_index).T

        flag=True
        #self.noise_drv=1
        while(flag==True and self.noise_drv<10):
            try:
                KK_v_v=self.cov_RBF_drv_drv_itself(self.Xdrv, self.hyper,drv_index)\
                            +np.eye(self.Xdrv.shape[0])*self.noise_drv
                top_matrix=np.hstack((KK_x_x,KK_x_v))
                bottom_matrix=np.hstack((KK_x_v.T, KK_v_v))
                self.KK_combined_drv=np.vstack((top_matrix,bottom_matrix))
        
                self.Ldrv=scipy.linalg.cholesky(self.KK_combined_drv,lower=True)
                flag=False
            except:
                self.noise_drv=self.noise_drv*2 #double the noise in the covariance is not invertable
                
        if self.verbose:
            print(self.noise_drv)
                
        temp=np.linalg.solve(self.Ldrv,self.Y_combined)
        self.alphadrv=np.linalg.solve(self.Ldrv.T,temp)
        
        self.L=scipy.linalg.cholesky(KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)
        

    def cov_RBF(self,x1, x2,hyper):        
        """
        Radial Basic function kernel (or SE kernel)
        """
        
        variance=hyper['var']
        lengthscale=hyper['lengthscale']

        if x1.shape[1]!=x2.shape[1]:
            x1=np.reshape(x1,(-1,x2.shape[1]))
        Euc_dist=euclidean_distances(x1,x2)

        return variance*np.exp(-np.square(Euc_dist)/lengthscale)
    
    def cov_RBF_drv(self,x1, x2,hyper, drv_index=0): # the first argument is drv       
        """
        x1: xdrv
        x2: x
        Radial Basic function kernel (or SE kernel)
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']
            
        if x1.shape[1]!=x2.shape[1]:
            x1=np.reshape(x1,(-1,x2.shape[1]))
            
        Euc_dist=euclidean_distances(x1,x2)
        k_x_xdrv=variance*np.exp(-np.square(Euc_dist)/lengthscale)
        
        temp1=np.atleast_2d(x1[:,drv_index]).T
        temp2=np.atleast_2d(x2[:,drv_index]).T
        temp=np.squeeze(temp1[:,None] - temp2)
        dist_x_xdrv_d=-temp*1.0/lengthscale
        dist_x_xdrv_d=np.reshape(dist_x_xdrv_d,(x1.shape[0],x2.shape[0]))
        return k_x_xdrv*dist_x_xdrv_d
    
    def cov_RBF_drv_drv_itself(self,xx,hyper, drv_index=0):        
        """
        second derivative of xx to itself at drv_index
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']
            
        temp1=np.atleast_2d(xx[:,drv_index]).T
        temp2=np.atleast_2d(xx[:,drv_index]).T
        
        Euc_dist_xdrv_xdrv=euclidean_distances(temp1,temp2)
        K_xdrv_xdrv=variance*np.exp(-np.square(Euc_dist_xdrv_xdrv)/lengthscale)
        
        temp=np.squeeze(temp1[:,None] - temp2)
        
        #dist_xdrv_xdrv_d=(temp*temp.T)/lengthscale
        dist_xdrv_xdrv_d=np.multiply(temp,temp)/lengthscale


        #return np.multiply(K_xdrv_xdrv,(np.eye(xx.shape[0])-dist_xdrv_xdrv_d))/lengthscale
        return np.multiply(K_xdrv_xdrv,(1-dist_xdrv_xdrv_d))/lengthscale

    def cov_RBF_drv_drv(self,xx1,xx2,hyper, drv_index=0):        
        """
        second derivative of xx1 vs xx2 at drv_index
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']
        
        temp1=np.atleast_2d(xx1[:,drv_index]).T
        temp2=np.atleast_2d(xx2[:,drv_index]).T
        
        Euc_dist_xdrv_xdrv=euclidean_distances(temp1,temp2)
        K_xdrv_xdrv=variance*np.exp(-np.square(Euc_dist_xdrv_xdrv)/lengthscale)
        
        temp12=np.squeeze(temp1[:,None] - temp2)
        #temp21=np.squeeze(temp2[:,None] - temp1)

        dist_xdrv_xdrv_d=np.multiply(temp12,temp12)/lengthscale
        #dist_xdrv_xdrv_d=(temp12*temp21.T)/lengthscale

        return np.multiply(K_xdrv_xdrv,(1-dist_xdrv_xdrv_d))/lengthscale
    
    def cov_RBF_integral(self,xx1,xx2,hyper,integral_idx=0):
        """
        estimate the \int k(x1,x2) dx1 at dimension integral_idx
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']

        temp1=np.atleast_2d(xx1[:,integral_idx]).T
        temp2=np.atleast_2d(xx2[:,integral_idx]).T
        
        Euc_dist_xint_x=euclidean_distances(temp1,temp2)
        #K_xint_x=variance*np.exp(-np.square(Euc_dist_xint_x)/lengthscale)
        
        return 0.5*np.sqrt(3.14*lengthscale)*variance*erf(Euc_dist_xint_x/np.sqrt(lengthscale))
    
    def cov_RBF_integral_integral(self,xx1,xx2,hyper,integral_idx=0):
        """
        estimate the \int \int k(x1,x2) dx1 dx2 at dimension integral_idx
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']

        temp1=np.atleast_2d(xx1[:,integral_idx]).T
        temp2=np.atleast_2d(xx2[:,integral_idx]).T
        
        Euc_dist_xint_xint=euclidean_distances(temp1,temp2)
        #K_xint_x=variance*np.exp(-np.square(Euc_dist_xint_x)/lengthscale)
        
        return 0.5*np.sqrt(3.14)*lengthscale*variance*erf(Euc_dist_xint_xint/np.sqrt(lengthscale))
    
    
    def cov_lin_RBF(self,x1, x2,hyper):
        return self.cov_linear(x1, x2)+self.cov_RBF(x1, x2,hyper)

    def log_llk(self,X,y,lengthscale,noise_delta=1e-5):
        
        hyper={}
        hyper['var']=1
        hyper['lengthscale']=lengthscale

        KK_x_x=self.mycov(X,X,hyper)+np.eye(len(X))*noise_delta     
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")   

        try:
            L=scipy.linalg.cholesky(KK_x_x,lower=True)
            alpha=np.linalg.solve(KK_x_x,y)

        except: # singular
            #print("singular",hyper['lengthscale'],noise_delta)
            return -np.inf
        try:
            #print("okay",hyper['lengthscale'],noise_delta)

            first_term=-0.5*np.dot(self.Y.T,alpha)
            W_logdet=np.sum(np.log(np.diag(L)))
            second_term=-W_logdet

        except: # singular
            return -np.inf

        logmarginal=first_term+second_term-0.5*len(y)*np.log(2*3.14)
        return np.asscalar(logmarginal)
    
    def log_llk_drv(self,X,y,lengthscale,noise_delta=1e-5,noise_drv=1):

        hyper={}
        hyper['var']=1
        hyper['lengthscale']=lengthscale
        
        KK_x_x=self.mycov(X,X,hyper)+np.eye(len(X))*noise_delta     
        KK_x_v=self.cov_RBF_drv(self.Xdrv,X,hyper,self.drv_index).T
 
        try:
            KK_v_v=self.cov_RBF_drv_drv_itself(self.Xdrv, hyper,self.drv_index)
            +np.eye(self.Xdrv.shape[0])*noise_drv
            top_matrix=np.hstack((KK_x_x,KK_x_v))
            bottom_matrix=np.hstack((KK_x_v.T, KK_v_v))
            KK_combined_drv=np.vstack((top_matrix,bottom_matrix))
    
            Ldrv=scipy.linalg.cholesky(KK_combined_drv,lower=True)
            alpha=np.linalg.solve(KK_combined_drv,self.Y_combined)

        except: # singular
            #print("singular",hyper['lengthscale'],noise_delta,noise_drv)
            return -np.inf
        try:
            #print("okay",hyper['lengthscale'],noise_delta,noise_drv)
            first_term=-0.5*np.dot(self.Y_combined.T,alpha)
            W_logdet=np.sum(np.log(np.diag(Ldrv)))
            second_term=-W_logdet

        except: # singular
            return -np.inf

        logmarginal=first_term+second_term-0.5*len(y)*np.log(2*3.14)
        #print(np.asscalar(logmarginal))

        return np.asscalar(logmarginal)
    
    def select_next_point_byentropy(self):
        """
        Select next point to evaluate by entropy reduction
        x_t
        """
        
        def acq_var(Xtest):
            if len(Xtest.shape)==1: # 1d
                Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
            #Xtest=self.Xscaler.transform(Xtest)
            KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
            KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)
    
            v=np.linalg.solve(self.L,KK_xTest_x.T)
            var=KK_xTest_xTest-np.dot(v.T,v)
    
            std=np.reshape(np.diag(var),(-1,1))
            return std
        
        def acq_var_drv(Xtest):
            if len(Xtest.shape)==1: # 1d
                Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
                
            #Xtest=self.Xscaler.transform(Xtest)
            KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
            KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)
            KK_xTest_xdrv=self.cov_RBF_drv(self.Xdrv,Xtest,self.hyper,self.drv_index).T
            KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))
            
            v=np.linalg.solve(self.Ldrv,KK_xTest_x_xdrv.T)
            var=KK_xTest_xTest-np.dot(v.T,v)
            std=np.reshape(np.diag(var),(-1,1))

            return std

            
        opts ={'maxiter':500,'maxfun':500,'disp': False}
        SearchSpaceScale=np.asarray([[0,1]])
        
        init_points = np.random.uniform(SearchSpaceScale[:,0], SearchSpaceScale[:,1],size=(5, 1))
        init_output=acq_var(init_points)
            
        x0=init_points[np.argmax(init_output)]
        res = minimize(lambda xx: -acq_var_drv(xx),x0,
                       bounds=SearchSpaceScale,method="L-BFGS-B",options=opts)
        
        max_var=acq_var_drv(res.x)
        return res.x,max_var
    
    def auto_train_bq(self,myfunction,MaxK=7):
        flagNonStop=True
        all_new_points= np.empty((0,self.dim), float)
        while(flagNonStop and len(self.Y_ori)<MaxK): # querying more points
            
            new_point,max_var=self.select_next_point_byentropy()
            if self.verbose:
                print("max_var",max_var)
            all_new_points=np.vstack((all_new_points,new_point))
            if max_var<1e-4: # this is a threshold to stop querying more points
                flagNonStop=False
                continue
                
            new_point=np.reshape(new_point,(1,1))
            new_point_ori=self.Xscaler.inverse_transform(new_point)
            output=myfunction(np.atleast_2d(new_point_ori))
            self.X_ori=np.vstack((self.X_ori,new_point_ori))
            output=output.data.cpu().numpy()
            self.Y_ori=np.vstack((self.Y_ori,output))
            
            self.fit_drv(self.X_ori,self.Y_ori,self.Xdrv_ori,self.Ydrv_ori,drv_index=0)

        return self.X_ori
    
    def optimise(self):
        """
        Optimise the GP kernel hyperparameters
        Returns
        x_t
        """
        
        opts ={'maxiter':200,'maxfun':200,'disp': False}

        #x0=[0.01,0.02]
        bounds=np.asarray([[1e-2,1]])
        
        init_theta = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(20, 1))
        logllk=[0]*init_theta.shape[0]
        for ii,val in enumerate(init_theta):           
            logllk[ii]=self.log_llk(self.X,self.Y,lengthscale=val,noise_delta=self.noise_delta)
            
        x0=init_theta[np.argmax(logllk)]

        res = minimize(lambda x: -self.log_llk(self.X,self.Y,lengthscale=x,noise_delta=self.noise_delta),x0,
                                   bounds=bounds,method="L-BFGS-B",options=opts)#L-BFGS-B
        
        if self.verbose:
            print(res.x)
            
        self.hyper['lengthscale']=res.x
        return res.x
    
    def optimise_drv(self):
        """
        Optimise the GP kernel hyperparameters
        Returns
        x_t
        """
        
        opts ={'maxiter':200,'maxfun':200,'disp': False}

        #bounds=np.asarray([[1,1],[0.0001,1]])
        bounds=np.asarray([[0.3,1.5]])
        
        init_theta = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(20,1))
        logllk=[0]*init_theta.shape[0]
        for ii,val in enumerate(init_theta):      
            
            logllk[ii]=self.log_llk_drv(self.X,self.Y,val,
                  noise_delta=self.noise_delta,noise_drv=self.noise_drv)
            
        x0=init_theta[np.argmax(logllk)]

        res = minimize(lambda x: -self.log_llk_drv(self.X,self.Y,x,noise_delta=self.noise_delta,
                   noise_drv=self.noise_drv),x0,bounds=bounds,method="L-BFGS-B",options=opts)#L-BFGS-B
        
        if self.verbose:
            print("estimated hyperparameters:",res.x)
        return res.x
    
    def predict_gradient(self,Xtest):
        """
        Predicting the gradient value at Xtest
        """
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.cov_RBF_drv_drv_itself(Xtest,self.hyper,drv_index=0)+np.eye(Xtest.shape[0])*self.noise_drv
        KK_xTest_x=self.cov_RBF_drv(Xtest,self.X,self.hyper)

        mean_grad=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_grad_ori= mean_grad*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std_grad=np.reshape(np.diag(var),(-1,1))
        
        std_grad_ori=std_grad*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean_grad,std_grad,mean_grad_ori,std_grad_ori
    
    def predict_gradient_with_drv(self,Xtest):
        """
        Predicting the gradient value at Xtest
        """
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.cov_RBF_drv_drv_itself(Xtest,self.hyper,drv_index=0)+np.eye(Xtest.shape[0])*self.noise_drv
        #KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta

        KK_xTest_x=self.cov_RBF_drv(Xtest,self.X,self.hyper)
        
        KK_xTest_xdrv=self.cov_RBF_drv_drv(Xtest,self.Xdrv,self.hyper)
        #KK_xTest_xdrv=self.mycov(Xtest,self.Xdrv,self.hyper)

        KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))

        mean_grad=np.dot(KK_xTest_x_xdrv,self.alphadrv)
        v=np.linalg.solve(self.Ldrv,KK_xTest_x_xdrv.T)
        var=KK_xTest_xTest-np.dot(v.T,v)


        mean_grad_ori=    mean_grad*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std_grad=np.reshape(np.diag(var),(-1,1))
        
        std_grad_ori=std_grad*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean_grad,std_grad,mean_grad_ori,std_grad_ori
        
    def predict_integral(self,Xtest):
        """
        Given the original function X,y
        Given some points of the integral function Xint, yint
        predict the integral function at Xtest

        This is equivalent to given the derivative Xdrv, ydrv
        Given some points of the original func X, y
        predict the original function at Xtest
        """
        integral_idx=0
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.cov_RBF_integral_integral(Xtest,Xtest,self.hyper,integral_idx=0) \
                                +np.eye(Xtest.shape[0])*self.noise_drv*0
        #KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta

        # integral->integral or original->original
        KK_xTest_x=self.cov_RBF_integral_integral(Xtest,self.X,self.hyper,integral_idx)
        
        # integral -> original or original -> dev
        KK_xTest_xdrv=self.cov_RBF_integral(Xtest,self.Xdrv,self.hyper,integral_idx)
        #KK_xTest_xdrv=self.mycov(Xtest,self.Xdrv,self.hyper)

        KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))
        
        KK_x_x=self.cov_RBF_integral_integral(self.X,self.X,self.hyper)+np.eye(len(self.X))*self.noise_delta*1 
        KK_x_v=self.cov_RBF_integral(self.Xdrv,self.X,self.hyper,integral_idx).T

        KK_v_v=self.mycov(self.Xdrv, self.Xdrv, self.hyper)\
                    +np.eye(self.Xdrv.shape[0])*self.noise_drv*0
        top_matrix=np.hstack((KK_x_x,KK_x_v))
        bottom_matrix=np.hstack((KK_x_v.T, KK_v_v))
        self.KK_combined_drv=np.vstack((top_matrix,bottom_matrix))

        self.Ldrv=scipy.linalg.cholesky(self.KK_combined_drv,lower=True)
                

        # [y, ydrv]
        #mean_grad=np.dot(KK_xTest_x_xdrv,self.alphadrv)
        v=np.linalg.solve(self.Ldrv,KK_xTest_x_xdrv.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_grad_ori=    mean_grad*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std_grad=np.reshape(np.diag(var),(-1,1))
        
        std_grad_ori=std_grad*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean_grad,std_grad,mean_grad_ori,std_grad_ori
    
    
    def predict(self,Xtest):
        """
        ----------
        Xtest: the testing points  [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """    
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)

        mean=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))
        
        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean,std,mean_ori,std_ori
    
    def predict_with_drv(self,Xtest):
        """
        ----------
        Xtest: the testing points [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """    
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)
        
        # compute KK_xTest_xdrv
        KK_xTest_xdrv=self.cov_RBF_drv(self.Xdrv,Xtest,self.hyper,self.drv_index).T
        
        KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))
        
        # using Cholesky update
        mean=np.dot(KK_xTest_x_xdrv,self.alphadrv)
        v=np.linalg.solve(self.Ldrv,KK_xTest_x_xdrv.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))
        
        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean,std,mean_ori,std_ori
    
    def find_key_point(self):
        # finding a single point giving the value = the integral value
        #integral_val=self.integral()[1]
        integral_val=self.integral_by_GPmean()[1]
        #desired_score=2*integral_val-np.max(self.Y_ori)
        desired_score=integral_val
        if self.verbose:
            print("integral_val",integral_val)
        
        def acq_mean(Xtest):
            if len(Xtest.shape)==1: # 1d
                Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
                
            KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)
            KK_xTest_xdrv=self.cov_RBF_drv(self.Xdrv,Xtest,self.hyper,self.drv_index).T
            KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))
            mean=np.dot(KK_xTest_x_xdrv,self.alphadrv)
            mean_ori=mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
            return np.abs(desired_score-mean_ori)

        opts ={'maxiter':100,'maxfun':100,'disp': False}
        SearchSpaceScale=np.asarray([[0,1]])
        
        init_points = np.random.uniform(SearchSpaceScale[:,0], SearchSpaceScale[:,1],size=(5, 1))
        init_output=acq_mean(init_points)
            
        x0=init_points[np.argmin(init_output)]
        res = minimize(lambda xx: acq_mean(xx),x0,
                       bounds=SearchSpaceScale,method="L-BFGS-B",options=opts)
        
        gap_at_keypoint=acq_mean(res.x)
        return res.x,gap_at_keypoint
    
    def integral_by_GPmean(self):
        
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        
        # using Cholesky update
        pred_mean,pred_var,pred_mean_ori,pred_var_ori=self.predict_with_drv(Xtest)
        return np.mean(pred_mean),np.mean(pred_mean_ori)        
        
    def integral(self):
        # compute the integral using closed-form
        
        ubs=self.SearchSpace[:,1]
        lbs=self.SearchSpace[:,0]
        sqrt_ls=np.sqrt(self.hyper['lengthscale'])
        term1 = np.sqrt(3.14)*self.hyper['var']*sqrt_ls/(2*(ubs-lbs))
        term2= erf((self.X_ori-lbs)/sqrt_ls)-erf((self.X_ori-ubs)/sqrt_ls)
        closed_form_integral=np.dot(term1*term2.T,self.alpha)
        closed_form_integral_ori=closed_form_integral*np.std(self.Y_ori)+np.mean(self.Y_ori)
        return np.asscalar(closed_form_integral),np.asscalar(closed_form_integral_ori)
    
    def plot_1d_drv(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        Y_ori_at_drv=myfunction(self.Xdrv)
        pred_mean_drv,pred_std_drv,pred_mean_ori_drv,pred_std_ori_drv=self.predict_with_drv(Xtest)

        fig = plt.figure(figsize=(8,5))
        ax = fig.add_subplot(1,1,1)
        CS_acq=ax.plot(Xtest,pred_mean_ori_drv.reshape(Xtest.shape),':k',linewidth=3,label='GP mean drv')
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_mean_ori_drv - 1.9600 * pred_std_ori_drv, 
                                   (pred_mean_ori_drv + 1.9600 * pred_std_ori_drv)[::-1]])
        ax.scatter(self.X_ori,self.Y_ori,marker='s',s=100,color='g',label='True Obs')  
        ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        y_org=myfunction(Xtest)
        
        CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        def line_from_gradient(gradient):        # helper function to plot the gradient vector
            myin=np.linspace(0,0.08,30)
            return gradient*myin

        for ii in range(len(self.Ydrv_ori)):
            mylbs=self.Xdrv[ii]-0.05
            myubs=self.Xdrv[ii]+0.03
            myin=np.linspace(mylbs,myubs,30)
            myout=line_from_gradient(self.Ydrv_ori[ii])
        
            if ii==0:
                plt.plot(myin, myout+Y_ori_at_drv[ii]+0.5, '-b', label='Gradient')
            else:
                plt.plot(myin, myout+Y_ori_at_drv[ii]+0.5, '-b')
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("Integrand",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("MNIST TVO VAE",fontsize=20)  
        strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig(strPath)
        
    def plot_1d(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_mean_drv,pred_std_drv,pred_mean_ori_drv,pred_std_ori_drv=self.predict(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_mean_ori_drv.reshape(Xtest.shape),':k',linewidth=3,label='GP mean')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_mean_ori_drv - 1.9600 * pred_std_ori_drv, (pred_mean_ori_drv + 1.9600 * pred_std_ori_drv)[::-1]])
        ax.scatter(self.X_ori,self.Y_ori,marker='s',s=100,color='g',label='True Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        y_org=myfunction(Xtest)
        
        CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("f(x)",fontsize=16)

        #ax.set_ylabel("Integrand",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Original Function f",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig("plot/original_func.pdf")
        
    def plot_integral_1d(self,myfunction):
        # given gradient func, and a few points in original function
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_int,pred_std_of_int,pred_int_ori,pred_std_of_int_ori=self.predict_integral(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_int.reshape(Xtest.shape),':k',linewidth=3,label='Integral of Derivative')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_int - 1.9600 * pred_std_of_int, (pred_int + 1.9600 * pred_std_of_int)[::-1]])
        ax.scatter(self.X,self.Y,marker='s',s=100,color='g',label='Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        #ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        #y_org=myfunction(Xtest)
        
        #CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("$f(x)$",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Integral Function $\int f'$ Given f'",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        #fig.savefig("plot/der.pdf")
        
    def plot_gradient_1d_drv(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_grad,pred_std_of_grad,pred_grad_ori,pred_std_of_grad_ori=self.predict_gradient_with_drv(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_grad.reshape(Xtest.shape),':k',linewidth=3,label='Derivative of GPmean')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_grad - 1.9600 * pred_std_of_grad, (pred_grad + 1.9600 * pred_std_of_grad)[::-1]])
        ax.scatter(self.Xdrv,self.Ydrv,marker='s',s=100,color='g',label='Derivative Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        #ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        #y_org=myfunction(Xtest)
        
        #CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("$\delta f(x)$",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Derivative Function f'",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig("plot/der.pdf")
        
    def plot_gradient_1d(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_grad,pred_std_of_grad,pred_grad_ori,pred_std_of_grad_ori=self.predict_gradient(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_grad.reshape(Xtest.shape),':k',linewidth=3,label='Derivative of GPmean')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_grad - 1.9600 * pred_std_of_grad, (pred_grad + 1.9600 * pred_std_of_grad)[::-1]])
        ax.scatter(self.Xdrv,self.Ydrv,marker='s',s=100,color='g',label='Derivative Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        #ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        #y_org=myfunction(Xtest)
        
        #CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("$\delta f(x)$",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Derivative Function f'",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig("plot/der.pdf")
File Path: src/gaussianprocess/__init__.py
Content:

File Path: src/gaussianprocess/gp.py
Content:
# -*- coding: utf-8 -*-
"""
Created on Fri Mar 20 18:35:25 2020

@author: Lenovo
"""
import numpy as np
import matplotlib.pyplot as plt
import warnings
from sklearn.metrics.pairwise import euclidean_distances
from scipy.optimize import minimize
from sklearn.preprocessing import MinMaxScaler
import scipy
from scipy.special import erf

class GaussianProcess(object):
    def __init__ (self,SearchSpace,noise_delta=1e-8,noise_drv=1e-4,verbose=0):
        self.noise_delta=noise_delta
        self.noise_drv=noise_drv
        self.mycov=self.cov_RBF
        self.SearchSpace=SearchSpace
        scaler = MinMaxScaler()
        scaler.fit(SearchSpace.T)
        self.Xscaler=scaler
        self.verbose=verbose
        self.dim=SearchSpace.shape[0]
        
        self.hyper={}
        self.hyper['var']=1 # standardise the data
        self.hyper['lengthscale']=0.1 #to be optimised
        
        #self.minY=0 # this is the value of f(beta=0)

        return None

        
    def fit(self,X,Y):
        """
        Fit a Gaussian Process model
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        """       
        #Y=Y-self.minY
        self.X_ori=X # this is the output in original scale
        self.X= self.Xscaler.transform(X) #this is the normalised data [0-1] in each column
        self.Y_ori=Y # this is the output in original scale
        self.Y=(Y-np.mean(Y))/np.std(Y) # this is the standardised output N(0,1)
        
        if len(self.Y)%5==0:
            self.hyper['lengthscale']=self.optimise()         # optimise GP hyperparameters
        self.KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta     
        if np.isnan(self.KK_x_x).any(): #NaN
            print("nan in KK_x_x !")
      
        self.L=scipy.linalg.cholesky(self.KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)
        
    def fit_drv(self,X,Y,Xdrv,Ydrv,drv_index=0):
        """
        Fit a Gaussian Process model using derivative
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        Xdrv: input 2d array of derivative obs [M*d]
        Ydrv: output 2d array of derivative obs [M*1]
        drv_index: the derivative is applicalbe at drv_index (in this case drv_index=0)
        """    
        #Y=Y-self.minY

        self.drv_index=drv_index
        self.Xdrv_ori=np.reshape(Xdrv,(-1,X.shape[1]))
        self.Xdrv=self.Xscaler.transform(Xdrv) #normalised the derivative input [0-1]
        self.X_ori=X
        self.X= self.Xscaler.transform(X) # normalised the input [0-1]
        self.Y_ori=Y
        self.Ydrv_ori=np.copy(Ydrv )
        self.Ydrv=Ydrv/np.std(Y) # standardize derivative given the data
        #print("Ydrv_ori",Ydrv)
        #print("Ydrv",self.Ydrv)
        #self.Ydrv=np.copy(Ydrv )
        #print("stdY",np.std(Y))
        self.Y=(Y-np.mean(Y))/np.std(Y)
        
        if self.verbose:
            print("Y",self.Y)
        self.Y_combined=np.vstack((self.Y,self.Ydrv))
        self.hyper['lengthscale']=self.optimise_drv()         # optimise GP hyperparameters

        KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta     
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")
            
        KK_x_v=self.cov_RBF_drv(self.Xdrv,self.X,self.hyper,drv_index).T

        flag=True
        #self.noise_drv=1
        while(flag==True and self.noise_drv<10):
            try:
                KK_v_v=self.cov_RBF_drv_drv_itself(self.Xdrv, self.hyper,drv_index)\
                            +np.eye(self.Xdrv.shape[0])*self.noise_drv
                top_matrix=np.hstack((KK_x_x,KK_x_v))
                bottom_matrix=np.hstack((KK_x_v.T, KK_v_v))
                self.KK_combined_drv=np.vstack((top_matrix,bottom_matrix))
        
                self.Ldrv=scipy.linalg.cholesky(self.KK_combined_drv,lower=True)
                flag=False
            except:
                self.noise_drv=self.noise_drv*2 #double the noise in the covariance is not invertable
                
        if self.verbose:
            print(self.noise_drv)
                
        temp=np.linalg.solve(self.Ldrv,self.Y_combined)
        self.alphadrv=np.linalg.solve(self.Ldrv.T,temp)
        
        self.L=scipy.linalg.cholesky(KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)
        

    def cov_RBF(self,x1, x2,hyper):        
        """
        Radial Basic function kernel (or SE kernel)
        """
        
        variance=hyper['var']
        lengthscale=hyper['lengthscale']

        if x1.shape[1]!=x2.shape[1]:
            x1=np.reshape(x1,(-1,x2.shape[1]))
        Euc_dist=euclidean_distances(x1,x2)

        return variance*np.exp(-np.square(Euc_dist)/lengthscale)
  
    def cov_lin_RBF(self,x1, x2,hyper):
        return self.cov_linear(x1, x2)+self.cov_RBF(x1, x2,hyper)

    def log_llk(self,X,y,lengthscale,noise_delta=1e-5):
        
        hyper={}
        hyper['var']=1
        hyper['lengthscale']=lengthscale

        KK_x_x=self.mycov(X,X,hyper)+np.eye(len(X))*noise_delta     
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")   

        try:
            L=scipy.linalg.cholesky(KK_x_x,lower=True)
            alpha=np.linalg.solve(KK_x_x,y)

        except: # singular
            #print("singular",hyper['lengthscale'],noise_delta)
            return -np.inf
        try:
            #print("okay",hyper['lengthscale'],noise_delta)

            first_term=-0.5*np.dot(self.Y.T,alpha)
            W_logdet=np.sum(np.log(np.diag(L)))
            second_term=-W_logdet

        except: # singular
            return -np.inf

        logmarginal=first_term+second_term-0.5*len(y)*np.log(2*3.14)
        return np.asscalar(logmarginal)
    
    
    def optimise(self):
        """
        Optimise the GP kernel hyperparameters
        Returns
        x_t
        """
        
        opts ={'maxiter':200,'maxfun':200,'disp': False}

        #x0=[0.01,0.02]
        bounds=np.asarray([[1e-2,1]])
        
        init_theta = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(20, 1))
        logllk=[0]*init_theta.shape[0]
        for ii,val in enumerate(init_theta):           
            logllk[ii]=self.log_llk(self.X,self.Y,lengthscale=val,noise_delta=self.noise_delta)
            
        x0=init_theta[np.argmax(logllk)]

        res = minimize(lambda x: -self.log_llk(self.X,self.Y,lengthscale=x,noise_delta=self.noise_delta),x0,
                                   bounds=bounds,method="L-BFGS-B",options=opts)#L-BFGS-B
        
        if self.verbose:
            print(res.x)
            
        self.hyper['lengthscale']=res.x
        return res.x
    
  
    
    def predict_gradient(self,Xtest):
        """
        Predicting the gradient value at Xtest
        """
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.cov_RBF_drv_drv_itself(Xtest,self.hyper,drv_index=0)+np.eye(Xtest.shape[0])*self.noise_drv
        KK_xTest_x=self.cov_RBF_drv(Xtest,self.X,self.hyper)

        mean_grad=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_grad_ori= mean_grad*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std_grad=np.reshape(np.diag(var),(-1,1))
        
        std_grad_ori=std_grad*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean_grad,std_grad,mean_grad_ori,std_grad_ori
    
   
    
    def predict(self,Xtest):
        """
        ----------
        Xtest: the testing points  [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """    
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)

        mean=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))
        
        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean,std,mean_ori,std_ori
    
    def predict_with_drv(self,Xtest):
        """
        ----------
        Xtest: the testing points [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """    
        Xtest=self.Xscaler.transform(Xtest)
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)
        
        # compute KK_xTest_xdrv
        KK_xTest_xdrv=self.cov_RBF_drv(self.Xdrv,Xtest,self.hyper,self.drv_index).T
        
        KK_xTest_x_xdrv=np.hstack((KK_xTest_x,KK_xTest_xdrv))
        
        # using Cholesky update
        mean=np.dot(KK_xTest_x_xdrv,self.alphadrv)
        v=np.linalg.solve(self.Ldrv,KK_xTest_x_xdrv.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))
        
        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean,std,mean_ori,std_ori
    

 
    def plot_1d_drv(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        Y_ori_at_drv=myfunction(self.Xdrv)
        pred_mean_drv,pred_std_drv,pred_mean_ori_drv,pred_std_ori_drv=self.predict_with_drv(Xtest)

        fig = plt.figure(figsize=(8,5))
        ax = fig.add_subplot(1,1,1)
        CS_acq=ax.plot(Xtest,pred_mean_ori_drv.reshape(Xtest.shape),':k',linewidth=3,label='GP mean drv')
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_mean_ori_drv - 1.9600 * pred_std_ori_drv, 
                                   (pred_mean_ori_drv + 1.9600 * pred_std_ori_drv)[::-1]])
        ax.scatter(self.X_ori,self.Y_ori,marker='s',s=100,color='g',label='True Obs')  
        ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        y_org=myfunction(Xtest)
        
        CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        def line_from_gradient(gradient):        # helper function to plot the gradient vector
            myin=np.linspace(0,0.08,30)
            return gradient*myin

        for ii in range(len(self.Ydrv_ori)):
            mylbs=self.Xdrv[ii]-0.05
            myubs=self.Xdrv[ii]+0.03
            myin=np.linspace(mylbs,myubs,30)
            myout=line_from_gradient(self.Ydrv_ori[ii])
        
            if ii==0:
                plt.plot(myin, myout+Y_ori_at_drv[ii]+0.5, '-b', label='Gradient')
            else:
                plt.plot(myin, myout+Y_ori_at_drv[ii]+0.5, '-b')
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("Integrand",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("MNIST TVO VAE",fontsize=20)  
        strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig(strPath)
        
    def plot_1d(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_mean_drv,pred_std_drv,pred_mean_ori_drv,pred_std_ori_drv=self.predict(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_mean_ori_drv.reshape(Xtest.shape),':k',linewidth=3,label='GP mean')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_mean_ori_drv - 1.9600 * pred_std_ori_drv, (pred_mean_ori_drv + 1.9600 * pred_std_ori_drv)[::-1]])
        ax.scatter(self.X_ori,self.Y_ori,marker='s',s=100,color='g',label='True Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        y_org=myfunction(Xtest)
        
        CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("f(x)",fontsize=16)

        #ax.set_ylabel("Integrand",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Original Function f",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig("plot/original_func.pdf")
  

    def plot_gradient_1d(self,myfunction):
        # plot 1d function using derivative observations
        Xtest = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 100)
        Xtest=np.atleast_2d(Xtest).T
        pred_grad,pred_std_of_grad,pred_grad_ori,pred_std_of_grad_ori=self.predict_gradient(Xtest)

        fig = plt.figure(figsize=(8,5))
        
        ax = fig.add_subplot(1,1,1)
        
        #my_cmap = plt.get_cmap('Blues')
        CS_acq=ax.plot(Xtest,pred_grad.reshape(Xtest.shape),':k',linewidth=3,label='Derivative of GPmean')
        
        temp_xaxis=np.concatenate([Xtest, Xtest[::-1]])
        temp_yaxis=np.concatenate([pred_grad - 1.9600 * pred_std_of_grad, (pred_grad + 1.9600 * pred_std_of_grad)[::-1]])
        ax.scatter(self.Xdrv,self.Ydrv,marker='s',s=100,color='g',label='Derivative Obs')  
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        #ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')

        #y_org=myfunction(Xtest)
        
        #CS_acq=ax.plot(Xtest,y_org.reshape(Xtest.shape),'r',label="True Function")
        
        ax.legend(prop={'size': 14})
        
        ax.set_ylabel("$\delta f(x)$",fontsize=16)
        ax.set_xlabel("Beta",fontsize=16)
        
        ax.set_title("Derivative Function f'",fontsize=20)  
        #strPath="plot/MNIST_TVO_VAE_BQD_{:d}_points.pdf".format(len(self.Y))
        fig.savefig("plot/der.pdf")
File Path: src/gaussianprocess/gptv.py
Content:
# -*- coding: utf-8 -*-
"""
Created on April 2020

@author: Vu Nguyen
"""
import numpy as np
#import matplotlib.pyplot as plt
#import warnings
from sklearn.metrics.pairwise import euclidean_distances
from scipy.optimize import minimize
from sklearn.preprocessing import MinMaxScaler
import scipy
#from scipy.special import erf
from sklearn.metrics import pairwise_distances
import matplotlib.pyplot as plt

from src.gaussianprocess.gp import GaussianProcess

class GPTV(object):#GP TV, but no permutation invariant
    def __init__ (self,SearchSpace,noise_delta=1e-6,noise_drv=1e-4,verbose=0):
        self.noise_delta=noise_delta
        self.noise_drv=noise_drv
        self.mycov=self.cov_RBF_time
        self.SearchSpace=SearchSpace
        scaler = MinMaxScaler()
        scaler.fit(SearchSpace.T)
        self.Xscaler=scaler
        self.verbose=verbose
        self.dim=SearchSpace.shape[0]

        self.hyper={}
        self.hyper['var']=1 # standardise the data
        self.hyper['lengthscale']=0.1 #to be optimised
        self.hyper['epsilon']=0.1 #to be optimised

        return None

    def fit(self,X,Y):
        """
        Fit a Gaussian Process model
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        """
        self.X_ori=X # this is the output in original scale
        #self.X= self.Xscaler.transform(X) #this is the normalised data [0-1] in each column
        self.X=X
        self.Y_ori=Y # this is the output in original scale
        self.Y=(Y-np.mean(Y))/np.std(Y) # this is the standardised output N(0,1)

        if len(self.Y)%5==0:
            self.hyper['epsilon'],self.hyper['lengthscale'],self.noise_delta=self.optimise()         # optimise GP hyperparameters
        self.KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta
        if np.isnan(self.KK_x_x).any(): #NaN
            print("nan in KK_x_x !")

        self.L=scipy.linalg.cholesky(self.KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)

#    def cov_RBF(self,x1, x2,hyper):
#        """
#        Radial Basic function kernel (or SE kernel)
#        """
#        return  super(GaussianProcess, self).cov_RBF(x1, x2,hyper)


    def cov_RBF_time(self,x1,x2,hyper):
        """
        Radial Basic function kernel (or SE kernel)
        product with time-varying function
        SE(x1,x2) x (1-epsilon)^0.5*|t1-t2|
        see https://arxiv.org/pdf/1601.06650.pdf
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']
        eps=hyper['epsilon']

        if x1.shape[1]!=x2.shape[1]: # check the dimension
            x1=np.reshape(x1,(-1,x2.shape[1]))


        Euc_dist=euclidean_distances(x1,x2)
        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)

        if x1.shape[0]==1: # K(xnew, X)
            #time_vector1=np.asarray([x2.shape[0]+1]) # we consider predicting at T+1 timestep
            time_vector1=np.asarray([1])
        else: # K(X,X) # the timesteps for X is from 0,1,2....N
            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)
            time_vector1=time_vector1/(x1.shape[0]+1) #normalise 0-1
            time_vector1=time_vector1[:-1]

        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))

        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)
        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))
        time_vector2=time_vector2/(x1.shape[0]+1) #normalise 0-1
        time_vector2=time_vector2[:-1]

        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')

        timekernel=(1-eps)**(0.5*dists)
        output=RBF*timekernel

        return output


    def log_llk(self,X,y,hyper_values):

        #print(hyper_values)
        hyper={}
        hyper['var']=1
        hyper['lengthscale']=hyper_values[1]
        hyper['epsilon']=hyper_values[0]
        noise_delta=hyper_values[2]

        KK_x_x=self.mycov(X,X,hyper)+np.eye(len(X))*noise_delta
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")

        try:
            L=scipy.linalg.cholesky(KK_x_x,lower=True)
            alpha=np.linalg.solve(KK_x_x,y)

        except: # singular
            return -np.inf
        try:
            first_term=-0.5*np.dot(self.Y.T,alpha)
            W_logdet=np.sum(np.log(np.diag(L)))
            second_term=-W_logdet

        except: # singular
            return -np.inf

        logmarginal=first_term+second_term-0.5*len(y)*np.log(2*3.14)

        #print(hyper_values,logmarginal)
        return np.asscalar(logmarginal)

    def optimise(self):
        """
        Optimise the GP kernel hyperparameters
        Returns
        x_t
        """
        opts ={'maxiter':200,'maxfun':200,'disp': False}

        # epsilon, ls, var, noise var
        bounds=np.asarray([[0,0.9],[5e-1,5],[1e-4,5e-1]])
        #bounds=np.asarray([[0,0.0],[1e-2,1],[1e-7,1e-5]])


        init_theta = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(200, 3))
        logllk=[0]*init_theta.shape[0]
        for ii,val in enumerate(init_theta):
            logllk[ii]=self.log_llk(self.X,self.Y,hyper_values=val) #noise_delta=self.noise_delta

        x0=init_theta[np.argmax(logllk)]

        res = minimize(lambda x: -self.log_llk(self.X,self.Y,hyper_values=x),x0,
                                   bounds=bounds,method="L-BFGS-B",options=opts)#L-BFGS-B

        if self.verbose:
            print("estimated [epsilon lengthscale noisevar]",res.x)

        return res.x

    def predict(self,Xtest,isOriScale=False):
        """
        ----------
        Xtest: the testing points  [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """

        if isOriScale:
            Xtest=self.Xscaler.transform(Xtest)

        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))

        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))

        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)

        mean=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))

        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)

        return mean,std,mean_ori,std_ori


    def estimate_Lipschitz(self):
        xtest=np.random.uniform(self.SearchSpace[:,0],self.SearchSpace[:,1],(5000,self.dim))

        mean,std,mean_ori,std_ori = self.predict(xtest,isOriScale=True)

        return np.max(mean)

    # supporting functions for visualisation
    def plot_1d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)

        mean,std,mean_ori,std_ori = self.predict(x1_ori)

        fig = plt.figure(figsize=(12,7))
        ax = fig.add_subplot(1, 1, 1)

        # Plot the surface.
        CS_acq=ax.plot(x1_ori,mean_ori.reshape(x1_ori.shape))
        ax.scatter(self.X_ori[:,0],self.Y_ori[:],marker='o',color='r',s=130,label='Obs')


        ax.set_ylabel('Utility f(beta)',fontsize=18)
        ax.set_xlabel('Beta',fontsize=18)

    def plot_2d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 60)
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]

        mean,std,mean_ori,std_ori = self.predict(X_ori)

        fig = plt.figure(figsize=(12,7))
        ax = fig.add_subplot(1, 1, 1)

        # Plot the surface.
        CS_acq=ax.contourf(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape),origin='lower')
        CS2_acq = plt.contour(CS_acq, levels=CS_acq.levels[::2],colors='r',origin='lower')
        ax.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=130,label='Obs')

        try:
            ax.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=130,label='Der')
        except:
            print()

        ax.set_xlabel(r'$\beta_1$',fontsize=18)
        ax.set_ylabel(r'$\beta_2$',fontsize=18)
        fig.colorbar(CS_acq, ax=ax, shrink=0.9)

    def plot_1d_mean_var(self):
        X_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)

        mean,std,mean_ori,std_ori = self.predict(X_ori)

        fig = plt.figure(figsize=(13,6))
        ax_mean = fig.add_subplot(1, 2, 1)
        ax_var = fig.add_subplot(1, 2, 2)

        # Plot the surface.
        CS_acq=ax_mean.plot(X_ori,mean_ori.reshape(X_ori.shape))
        ax_mean.scatter(self.X_ori[:,0],self.Y_ori[:],marker='o',color='r',s=100,label='Obs')


        ax_mean.set_xlabel('Epoch',fontsize=18)
        ax_mean.set_ylabel('Beta',fontsize=18)
        ax_mean.set_title(r"GP Predictive Mean $\mu()$",fontsize=20)


        # Plot the surface.
        CS_var=ax_var.plot(X_ori,std.reshape(X_ori.shape))
        ax_var.scatter(self.X_ori[:,0],self.Y_ori,marker='o',color='r',s=100,label='Obs')


        temp_xaxis=np.concatenate([X_ori, X_ori[::-1]])
        temp_yaxis=np.concatenate([mean_ori - 1.9600 * std, (mean_ori + 1.9600 * std)[::-1]])
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')
        ax_var.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')



        ax_var.set_xlabel('Epoch',fontsize=18)
        ax_var.set_ylabel('Beta',fontsize=18)
        ax_var.set_title(r"GP Predictive Var $\sigma()$",fontsize=20)


    def plot_2d_mean_var(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 50)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 50)
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]

        #x1 = np.linspace(0, 1, 60)
        #x2 = np.linspace(0, 1, 60)
        #x1g,x2g=np.meshgrid(x1,x2)
        #X=np.c_[x1g.flatten(), x2g.flatten()]

        mean,std,mean_ori,std_ori = self.predict(X_ori)

        fig = plt.figure(figsize=(13,4.5))
        ax_mean = fig.add_subplot(1, 2, 1)
        ax_var = fig.add_subplot(1, 2, 2)

        # Plot the surface.
        CS_acq=ax_mean.contourf(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape),origin='lower')
        #CS2_acq = ax_mean.contour(CS_acq, levels=CS_acq.levels[::2],colors='r',origin='lower')
        ax_mean.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=100,label='Obs')

        try:
            ax_mean.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=100,label='Der')
        except:
            print()

        ax_mean.set_xlabel(r'$\beta_1$',fontsize=18)
        ax_mean.set_ylabel(r'$\beta_2$',fontsize=18)
        ax_mean.set_title(r"GP $\mu( \beta)$",fontsize=20)
        ax_mean.set_xlim(0,1)
        ax_mean.set_ylim(0,1)
        fig.colorbar(CS_acq, ax=ax_mean)



        # Plot the surface.
        CS_var=ax_var.contourf(x1g_ori,x2g_ori,std.reshape(x1g_ori.shape),origin='lower')
        #CS2_var = ax_var.contour(CS_var, levels=CS_var.levels[::2],colors='r',origin='lower')
        ax_var.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=100,label='Obs')

        try:
            ax_var.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=130,label='Der')
        except:
            print()

        ax_var.set_xlabel(r'$\beta_1$',fontsize=18)
        ax_var.set_ylabel(r'$\beta_2$',fontsize=18)
        ax_var.set_title(r"GP $\sigma( \beta)$",fontsize=20)
        ax_var.set_xlim(0,1)
        ax_var.set_ylim(0,1)
        fig.colorbar(CS_var, ax=ax_var)

        fig.savefig("GP2d_not_per_invariant.pdf",bbox_inches="tight")


    def plot_3d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 60)
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]

        #x1 = np.linspace(0, 1, 60)
        #x2 = np.linspace(0, 1, 60)
        #x1g,x2g=np.meshgrid(x1,x2)
        #X=np.c_[x1g.flatten(), x2g.flatten()]

        mean,std,mean_ori,std_ori = self.predict(X_ori)

        fig = plt.figure(figsize=(12,7))
        ax = plt.axes(projection="3d")

        # Plot the surface.
        #ax.scatter(self.X_ori[:,0],self.X_ori[:,1],self.Y_ori,marker='o',color='r',s=130,label='Data')
        ax.plot_wireframe(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape), color='green')

        ax.set_xlabel('Epoch',fontsize=18)
        ax.set_ylabel('Beta',fontsize=18)
        ax.set_zlabel('f(x)',fontsize=18)

File Path: src/gaussianprocess/gptv_perm.py
Content:
# -*- coding: utf-8 -*-
"""
Created on April 2020

@author: Vu Nguyen
"""
import numpy as np
#import matplotlib.pyplot as plt
#import warnings
from sklearn.metrics.pairwise import euclidean_distances
from scipy.optimize import minimize
from sklearn.preprocessing import MinMaxScaler
import scipy
#from scipy.special import erf
from sklearn.metrics import pairwise_distances
import matplotlib.pyplot as plt
from src.gaussianprocess.gptv import GPTV


class GPTV_Perm(GPTV): #Gaussian process time-varying permutation
    def __init__ (self,SearchSpace,noise_delta=1e-6,noise_drv=1e-4,verbose=0):
        self.noise_delta=noise_delta
        self.noise_drv=noise_drv
        self.mycov=self.cov_RBF_time_set
        self.SearchSpace=SearchSpace
        scaler = MinMaxScaler()
        scaler.fit(SearchSpace.T)
        self.Xscaler=scaler
        self.verbose=verbose
        self.dim=SearchSpace.shape[0]
        
        self.hyper={}
        self.hyper['var']=1 # standardise the data
        self.hyper['lengthscale']=0.1 #to be optimised
        self.hyper['epsilon']=0.1 #to be optimised

        return None
        
    def fit(self,X,Y):
        """
        Fit a Gaussian Process model
        X: input 2d array [N*d]
        Y: output 2d array [N*1]
        """       
        self.X_ori=X # this is the output in original scale
        #self.X= self.Xscaler.transform(X) #this is the normalised data [0-1] in each column
        self.X=X
        self.Y_ori=Y # this is the output in original scale
        self.Y=(Y-np.mean(Y))/np.std(Y) # this is the standardised output N(0,1)
        
        if len(self.Y)%5==0:
            self.hyper['epsilon'],self.hyper['lengthscale'],self.noise_delta=self.optimise()         # optimise GP hyperparameters
        self.KK_x_x=self.mycov(self.X,self.X,self.hyper)+np.eye(len(X))*self.noise_delta     
        if np.isnan(self.KK_x_x).any(): #NaN
            print("nan in KK_x_x !")
      
        self.L=scipy.linalg.cholesky(self.KK_x_x,lower=True)
        temp=np.linalg.solve(self.L,self.Y)
        self.alpha=np.linalg.solve(self.L.T,temp)

        
    def cov_RBF(self,x1, x2,hyper):        
        """
        Radial Basic function kernel (or SE kernel)
        """
        return super(GPTV, self).cov_RBF(x1, x2,hyper)
    
    def cov_RBF_time(self,x1,x2,hyper):        
        """
        Radial Basic function kernel (or SE kernel)
        product with time-varying function
        SE(x1,x2) x (1-epsilon)^0.5*|t1-t2|
        see https://arxiv.org/pdf/1601.06650.pdf
        """
        return super(GPTV, self).cov_RBF_time(x1, x2,hyper)

    
    def cov_RBF_time_set(self,x1,x2,hyper):        
        """
        Radial Basic function kernel (or SE kernel)
        product with time-varying function
        SE(x1,x2) x (1-epsilon)^0.5*|t1-t2|
        see https://arxiv.org/pdf/1601.06650.pdf
        """
        variance=hyper['var']
        lengthscale=hyper['lengthscale']
        eps=hyper['epsilon']

        if x1.shape[1]!=x2.shape[1]: # check the dimension
            x1=np.reshape(x1,(-1,x2.shape[1]))
            
        x1=np.sort(x1,axis=1) # sorting
        x2=np.sort(x2,axis=1) # sorting
        Euc_dist=euclidean_distances(x1,x2)
        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)
        
        if x1.shape[0]==1: # K(xnew, X)
            #time_vector1=np.asarray([x2.shape[0]+1]) # we consider predicting at T+1 timestep
            time_vector1=np.asarray([1])
        else: # K(X,X) # the timesteps for X is from 0,1,2....N
            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)
            time_vector1=time_vector1/(x1.shape[0]+1) #normalise 0-1
            time_vector1=time_vector1[:-1]
            
        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))

        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)
        time_vector2=time_vector2/(x1.shape[0]+1) #normalise 0-1
        time_vector2=time_vector2[:-1]
        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))

        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')
 
        timekernel=(1-eps)**(0.5*dists)
        output=RBF*timekernel
        
        return output
    
    
    def log_llk(self,X,y,hyper_values):
        
        #print(hyper_values)
        #print(hyper_values)
        hyper={}
        hyper['var']=1
        hyper['lengthscale']=hyper_values[1]
        hyper['epsilon']=hyper_values[0]
        noise_delta=hyper_values[2]

        KK_x_x=self.mycov(X,X,hyper)+np.eye(len(X))*noise_delta     
        if np.isnan(KK_x_x).any(): #NaN
            print("nan in KK_x_x !")   

        try:
            L=scipy.linalg.cholesky(KK_x_x,lower=True)
            alpha=np.linalg.solve(KK_x_x,y)

        except: # singular
            return -np.inf
        try:
            first_term=-0.5*np.dot(self.Y.T,alpha)
            W_logdet=np.sum(np.log(np.diag(L)))
            second_term=-W_logdet

        except: # singular
            return -np.inf

        logmarginal=first_term+second_term-0.5*len(y)*np.log(2*3.14)
        
        #print(hyper_values,logmarginal)
        return np.asscalar(logmarginal)
    
    def optimise(self):
        """
        Optimise the GP kernel hyperparameters
        Returns
        x_t
        """
        opts ={'maxiter':200,'maxfun':200,'disp': False}

        # epsilon, ls, var, noise var
        bounds=np.asarray([[0,0.9],[5e-1,5],[1e-4,5e-1]])
        #bounds=np.asarray([[0,0.0],[1e-2,1],[1e-7,1e-5]])

        
        init_theta = np.random.uniform(bounds[:, 0], bounds[:, 1],size=(200, 3))
        logllk=[0]*init_theta.shape[0]
        for ii,val in enumerate(init_theta):           
            logllk[ii]=self.log_llk(self.X,self.Y,hyper_values=val) #noise_delta=self.noise_delta
            
        x0=init_theta[np.argmax(logllk)]

        res = minimize(lambda x: -self.log_llk(self.X,self.Y,hyper_values=x),x0,
                                   bounds=bounds,method="L-BFGS-B",options=opts)#L-BFGS-B
        
        if self.verbose:
            print("estimated [epsilon lengthscale noisevar]",res.x)
            
        return res.x  

   
    def predict(self,Xtest,isOriScale=False):
        """
        ----------
        Xtest: the testing points  [N*d]

        Returns
        -------
        pred mean, pred var, pred mean original scale, pred var original scale
        """    
        
        if isOriScale:
            Xtest=self.Xscaler.transform(Xtest)
            
        if len(Xtest.shape)==1: # 1d
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
            
        if Xtest.shape[1] != self.X.shape[1]: # different dimension
            Xtest=np.reshape(Xtest,(-1,self.X.shape[1]))
       
        KK_xTest_xTest=self.mycov(Xtest,Xtest,self.hyper)+np.eye(Xtest.shape[0])*self.noise_delta
        KK_xTest_x=self.mycov(Xtest,self.X,self.hyper)

        mean=np.dot(KK_xTest_x,self.alpha)
        v=np.linalg.solve(self.L,KK_xTest_x.T)
        var=KK_xTest_xTest-np.dot(v.T,v)

        mean_ori=    mean*np.std(self.Y_ori)+np.mean(self.Y_ori)
        std=np.reshape(np.diag(var),(-1,1))
        
        std_ori=std*np.std(self.Y_ori)#+np.mean(self.Y_ori)
        
        return mean,std,mean_ori,std_ori
  
    def estimate_Lipschitz(self):
        xtest=np.random.uniform(self.SearchSpace[:,0],self.SearchSpace[:,1],(5000,self.dim))
      
        mean,std,mean_ori,std_ori = self.predict(xtest,isOriScale=True)
        
        return np.max(mean)
        
    def plot_1d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        
        mean,std,mean_ori,std_ori = self.predict(x1_ori)
        
        fig = plt.figure(figsize=(12,7))
        ax = fig.add_subplot(1, 1, 1)
        
        # Plot the surface.
        CS_acq=ax.plot(x1_ori,mean_ori.reshape(x1_ori.shape))
        ax.scatter(self.X_ori[:,0],self.Y_ori[:],marker='o',color='r',s=130,label='Obs')
      
        temp_xaxis=np.concatenate([x1_ori, x1_ori[::-1]])
        temp_yaxis=np.concatenate([mean_ori - 1.9600 * std, (mean_ori + 1.9600 * std)[::-1]])
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')


        ax.set_ylabel('Utility f(beta)',fontsize=18)
        ax.set_xlabel('Beta',fontsize=18)
        
    def plot_2d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 60)  
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]
        
        mean,std,mean_ori,std_ori = self.predict(X_ori)
        
        fig = plt.figure(figsize=(12,7))
        ax = fig.add_subplot(1, 1, 1)
        
        # Plot the surface.
        CS_acq=ax.contourf(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape),origin='lower')
        CS2_acq = plt.contour(CS_acq, levels=CS_acq.levels[::2],colors='r',origin='lower')
        ax.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=130,label='Obs')
        
        try:
            ax.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=130,label='Der')
        except:
            print()
        
        ax.set_xlabel('Epoch',fontsize=18)
        ax.set_ylabel('Beta',fontsize=18)
        fig.colorbar(CS_acq, ax=ax, shrink=0.9)
        
    def plot_1d_mean_var(self):
        X_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        
        mean,std,mean_ori,std_ori = self.predict(X_ori)
        
        fig = plt.figure(figsize=(14,4))
        ax_mean = fig.add_subplot(1, 2, 1)
        ax_var = fig.add_subplot(1, 2, 2)

        # Plot the surface.
        CS_acq=ax_mean.plot(X_ori,mean_ori.reshape(X_ori.shape))
        ax_mean.scatter(self.X_ori[:,0],self.Y_ori[:],marker='o',color='r',s=100,label='Obs')
       
        
        ax_mean.set_xlabel('Log of Beta',fontsize=18)
        ax_mean.set_ylabel('f(beta)',fontsize=18)
        ax_mean.set_title("GP Mean",fontsize=20)
        
        
        # Plot the surface.
        CS_var=ax_var.plot(X_ori,mean_ori.reshape(X_ori.shape))
        ax_var.scatter(self.X_ori[:,0],self.Y_ori,marker='o',color='r',s=100,label='Obs')
        
        
        temp_xaxis=np.concatenate([X_ori, X_ori[::-1]])
        temp_yaxis=np.concatenate([mean_ori - 1.9600 * std, (mean_ori + 1.9600 * std)[::-1]])
        #ax.scatter(self.Xdrv,Y_ori_at_drv,marker='*',s=200,color='m',label='Derivative Obs')  
        ax_var.fill(temp_xaxis, temp_yaxis,alpha=.3, fc='g', ec='None', label='95% CI')



        ax_var.set_xlabel('Log of Beta',fontsize=18)
        ax_var.set_ylabel('f(beta)',fontsize=18)
        ax_var.set_title("GP Var",fontsize=20)
        fig.savefig("1d_mean_var.pdf")
        
        
    def plot_2d_mean_var(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 60)  
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]
     
        
        mean,std,mean_ori,std_ori = self.predict(X_ori)
        
        fig = plt.figure(figsize=(13,6))
        ax_mean = fig.add_subplot(1, 2, 1)
        ax_var = fig.add_subplot(1, 2, 2)

        # Plot the surface.
        CS_acq=ax_mean.contourf(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape),origin='lower')
        CS2_acq = ax_mean.contour(CS_acq, levels=CS_acq.levels[::2],colors='r',origin='lower')
        ax_mean.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=100,label='Obs')
        
        try:
            ax_mean.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=100,label='Der')
        except:
            print()
        
        ax_mean.set_xlabel('Epoch',fontsize=18)
        ax_mean.set_ylabel('Beta',fontsize=18)
        ax_mean.set_title("GP Mean",fontsize=20)
        fig.colorbar(CS_acq, ax=ax_mean, shrink=0.9)
        
        
        
        # Plot the surface.
        CS_var=ax_var.contourf(x1g_ori,x2g_ori,std.reshape(x1g_ori.shape),origin='lower')
        CS2_var = ax_var.contour(CS_var, levels=CS_var.levels[::2],colors='r',origin='lower')
        ax_var.scatter(self.X_ori[:,0],self.X_ori[:,1],marker='o',color='r',s=100,label='Obs')
        
        try:
            ax_var.scatter(self.Xdrv_ori[:,0],self.Xdrv_ori[:,1],marker='s',color='y',s=130,label='Der')
        except:
            print()
        
        ax_var.set_xlabel('Epoch',fontsize=18)
        ax_var.set_ylabel('Beta',fontsize=18)
        ax_var.set_title("GP Var",fontsize=20)
        fig.colorbar(CS_var, ax=ax_var, shrink=0.9)
        
    
    def plot_3d(self):
        x1_ori = np.linspace(self.SearchSpace[0,0], self.SearchSpace[0,1], 60)
        x2_ori = np.linspace(self.SearchSpace[1,0], self.SearchSpace[1,1], 60) 
        x1g_ori,x2g_ori=np.meshgrid(x1_ori,x2_ori)
        X_ori=np.c_[x1g_ori.flatten(), x2g_ori.flatten()]
        
        mean,std,mean_ori,std_ori = self.predict(X_ori)
        
        fig = plt.figure(figsize=(12,7))
        ax = plt.axes(projection="3d")
        
        # Plot the surface.
        #ax.scatter(self.X_ori[:,0],self.X_ori[:,1],self.Y_ori,marker='o',color='r',s=130,label='Data')
        ax.plot_wireframe(x1g_ori,x2g_ori,mean_ori.reshape(x1g_ori.shape), color='green')

        ax.set_xlabel('Epoch',fontsize=18)
        ax.set_ylabel('Beta',fontsize=18)
        ax.set_zlabel('f(x)',fontsize=18)
File Path: src/gp_bandit.py
Content:
import numpy as np
from src import util
import logging
import torch



#from src.cyDPP.decompose_kernel import decompose_kernel
#from src.cyDPP.sample_dpp import sample_dpp

from src.BOv import BayesOpt
#import matplotlib.pyplot as plt
#from src import ml_helpers as mlh
from src.BOv import unique_rows
import pickle
# Figure config
# NOT TUNABLE HYPERPARAMETERS
# (putting them here so I'm not tempted to tune them)

LEGEND_SIZE = 15
FIGURE_SIZE = (12, 8)
WINDOW = 5
K_MAX = 100
MIN_REL_CHANGE = 1e-3
MIN_ERR = 1e-3
LBM_GRID = np.linspace(-9, -0.1, 50)

emu_log = logging.getLogger("emukit")
emu_log.setLevel(logging.WARNING)

emu_gp = logging.getLogger("GP")
emu_gp.setLevel(logging.WARNING)


def extract_X_Y_from_args(SearchSpace,args,T=None):
    # obtain X and Y
    if T is None:
        T=args.truncation_threshold
    lenY=len(args.Y_ori)
    X=args.X_ori[max(0,lenY-T):,1:-1] # remove the first and last  column which is 0 and 1

    ur=unique_rows(X)
    if sum(ur)<(3*args.K) or 'rand' in args.schedule: # random search to get initial data
        init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        init_X=np.around(init_X, decimals=4)
        init_X=np.append(0,init_X)
        init_X=np.append(init_X,1)

        return np.sort(init_X),None

#    if lenY%20==0:
#        strPath="{:s}/save_X_Y_{:s}_S{:d}_K{:d}.p".format(str(args.artifact_dir), args.schedule, args.S, args.K)
#        pickle.dump( [args.X_ori,args.Y_ori], open( strPath, "wb" ) )

    Y=np.reshape(args.Y_ori[max(0,lenY-T):],(-1,1))

    return X,Y

def append_Xori_Yori_from_args(args):
    # append the average logpx into Y
    # append the args.partition into X


    if args.len_terminated_epoch >0: # if we terminate the betas due to drip the epoch len is shorted
        average_y=np.mean(args.logtvopx_all[-args.len_terminated_epoch:])
    else:
        average_y=np.mean(args.logtvopx_all[-args.schedule_update_frequency:])
    args.average_y=np.append(args.average_y,average_y) # averaging the logpx over this window

    # error will happen at the first iteration when we add the first average_y into our data
    # this error is intentional, i will modify it by using a flag to indicate the first time
    if len(args.average_y)==1:
        print("ignore for the first time to save the first value of Y")
        return

    prev_y=args.average_y[-1] -args.average_y[-2]

    args.X_ori=np.vstack(( args.X_ori, np.reshape(format_input(args.partition),(1,args.K+1) )))
    args.Y_ori=np.append(args.Y_ori, prev_y)
    prev_X=np.round(args.X_ori[-1],decimals=4)
    #print("X",prev_X,"Y",args.Y_ori[-1])



def calculate_BO_points(model,args):
    append_Xori_Yori_from_args(args)

    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            #SearchSpace[kk,0]=ll[kk]
            SearchSpace[kk,1]=ll[kk+1]

    if args.schedule=="gp": # non timevarying
        X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori))
    else:   # time varying
        X,Y=extract_X_Y_from_args(SearchSpace,args)


    if Y is None:
        return X

    # augment the data with artificial observations all zeros and all ones
    x_all_zeros=np.reshape(np.asarray([args.bandit_beta_min]*(args.K-1)),(1,-1))
    x_all_ones=np.reshape(np.asarray([args.bandit_beta_max]*(args.K-1)),(1,-1))

    worse_score=np.min(Y)

    X=np.vstack((X,x_all_zeros))
    X=np.vstack((X,x_all_ones))

    Y=np.vstack((Y,np.asarray(worse_score)))
    Y=np.vstack((Y,np.asarray(worse_score)))

    if args.schedule=="gp_bandit":
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace)
    elif args.schedule=="gptv" or args.schedule=="gp": # TV but not permutation invariant
        myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")
    else:
        print("the schedule is not implemented ",args.schedule)


    myBO.init_with_data(X,Y)

    new_X=myBO.select_next_point()[1]

    new_X=np.round(new_X,decimals=4)

    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    #print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X


def calculate_BO_points_vanillaGP(model,args):

    append_Xori_Yori_from_args(args)


    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))

    if args.K==2:
        SearchSpace[0,1]=0.7
    else:
        ll=np.linspace(0,args.bandit_beta_max,args.K) # to discourage selecting 1
        for kk in range(args.K-1):
            #SearchSpace[kk,0]=ll[kk]
            SearchSpace[kk,1]=ll[kk+1]

    X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori)) # this is non timevarying GP, takes all data
    if Y is None:
        return X

    myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype="vanillaGP")
    myBO.init_with_data(X,Y)

    new_X=myBO.select_next_point()[1]
    new_X=np.round(new_X,decimals=4)

    new_X = np.append(np.append(0,np.sort(new_X)), 1)
    print(new_X)

    temp_new_X=np.unique(new_X)

    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or \
        np.array_equal(temp_new_X, [0, 1]) :#0.01 is due to the search bound
        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
        return np.append(np.append(0,np.sort(rand_X)), 1)
    else:
        return new_X


def format_input(*data):
    output = []
    for d in data:
        if torch.is_tensor(d):
            d = d.cpu().numpy()
        if d.ndim == 1:
            d = np.expand_dims(d, 1)
        output.append(d)

    return output[0] if len(output) == 1 else output


File Path: src/ml_helpers.py
Content:
from __future__ import division
import sys
import os
import torch
from torch._six import inf
import numpy as np
import pandas as pd
import random
from joblib import Parallel, delayed
import joblib
from pathlib import Path
from datetime import datetime
import socket

persist_dir = Path('./.persistdir')
#print(persist_dir)


class AverageMeter(object):
    """
    Computes and stores the average, var, and sample_var
    Taken from https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm
    """

    def __init__(self, name="AverageMeter", fmt=':f'):
        self.name = name
        self.fmt = fmt
        self.reset()

    def reset(self):
        self.count = 0
        self.M2 = 0

        self.mean = 0
        self.variance = 0
        self.sample_variance = 0

    def step(self, val):
        self.count += 1
        delta = val - self.mean
        self.mean += delta / self.count
        delta2 = val - self.mean
        self.M2 += delta * delta2

        self.variance = self.M2 / self.count if self.count > 2 else 0
        self.sample_variance = self.M2 / \
            (self.count - 1) if self.count > 2 else 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({var' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.mean, var=self.variance)


class MovingAverageMeter(object):
    """Computes the  moving average of a given float."""

    def __init__(self, name, fmt=':f', window=5):
        self.name = "{} (window = {})".format(name, window)
        self.fmt = fmt
        self.N = window
        self.history = []
        self.val = None
        self.reset()

    def reset(self):
        self.val = None
        self.history = []

    def step(self, val):
        self.history.append(val)
        self.previous = self.val
        if self.val is None:
            self.val = val
        else:
            window = self.history[-self.N:]
            self.val = sum(window) / len(window)
            if len(window) == self.N:
                self.history == window
        return self.val

    @property
    def relative_change(self):
        if None not in [self.val, self.previous]:
            relative_change = (self.previous - self.val) / self.previous
            return relative_change
        else:
            return 0

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(name=self.name, val=self.val, avg=self.relative_change)


class ConvergenceMeter(object):
    """This is a modification of pytorch's ReduceLROnPlateau object
        (https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#ReduceLROnPlateau)
        which acts as a convergence meter. Everything
        is the same as ReduceLROnPlateau, except it doesn't
        require an optimizer and doesn't modify the learning rate.
        When meter.converged(loss) is called it returns a boolean that
        says if the loss has converged.

    Args:
        mode (str): One of `min`, `max`. In `min` mode, lr will
            be reduced when the quantity metered has stopped
            decreasing; in `max` mode it will be reduced when the
            quantity metered has stopped increasing. Default: 'min'.
        patience (int): Number of epochs with no improvement after
            which learning rate will be reduced. For example, if
            `patience = 2`, then we will ignore the first 2 epochs
            with no improvement, and will only decrease the LR after the
            3rd epoch if the loss still hasn't improved then.
            Default: 10.
        threshold (float): Threshold for measuring the new optimum,
            to only focus on significant changes. Default: 1e-4.
        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,
            dynamic_threshold = best * ( 1 + threshold ) in 'max'
            mode or best * ( 1 - threshold ) in `min` mode.
            In `abs` mode, dynamic_threshold = best + threshold in
            `max` mode or best - threshold in `min` mode. Default: 'rel'.
        cooldown (int): Number of epochs to wait before resuming
            normal operation after lr has been reduced. Default: 0.
        min_lr (float or list): A scalar or a list of scalars. A
            lower bound on the learning rate of all param groups
            or each group respectively. Default: 0.
        eps (float): Minimal decay applied to lr. If the difference
            between new and old lr is smaller than eps, the update is
            ignored. Default: 1e-8.

    Example:
        >>> meter = Meter('min')
        >>> for epoch in range(10):
        >>>     train(...)
        >>>     val_loss = validate(...)
        >>>     if meter.converged(val_loss):
        >>>         break
    """

    def __init__(self, mode='min', patience=10,
                 verbose=False, threshold=1e-4, threshold_mode='rel',
                 cooldown=0, eps=1e-8):

        self.has_converged = False
        self.patience = patience
        self.verbose = verbose
        self.cooldown = cooldown
        self.cooldown_counter = 0
        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode
        self.best = None
        self.num_bad_epochs = None
        self.mode_worse = None  # the worse value for the chosen mode
        self.eps = eps
        self.last_epoch = -1
        self._init_is_better(mode=mode, threshold=threshold,
                             threshold_mode=threshold_mode)
        self._reset()

    def _reset(self):
        """Resets num_bad_epochs counter and cooldown counter."""
        self.best = self.mode_worse
        self.cooldown_counter = 0
        self.num_bad_epochs = 0

    def step(self, metrics, epoch=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)
        if epoch is None:
            epoch = self.last_epoch = self.last_epoch + 1
        self.last_epoch = epoch

        if self.is_better(current, self.best):
            self.best = current
            self.num_bad_epochs = 0
        else:
            self.num_bad_epochs += 1

        if self.in_cooldown:
            self.cooldown_counter -= 1
            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown

        if self.num_bad_epochs > self.patience:
            self.has_converged = True

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'rel':
            rel_epsilon = 1. - self.threshold
            return a < best * rel_epsilon

        elif self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best - self.threshold

        elif self.mode == 'max' and self.threshold_mode == 'rel':
            rel_epsilon = self.threshold + 1.
            return a > best * rel_epsilon

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best + self.threshold

    def _init_is_better(self, mode, threshold, threshold_mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if threshold_mode not in {'rel', 'abs'}:
            raise ValueError('threshold mode ' +
                             threshold_mode + ' is unknown!')

        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode
        self.threshold = threshold
        self.threshold_mode = threshold_mode


class BestMeter(object):
    """ This is like ConvergenceMeter except it stores the
        best result in a set of results. To be used in a
        grid search

    Args:
        mode (str): One of `min`, `max`. In `min` mode, best will
            be updated when the quantity metered is lower than the current best;
            in `max` mode best will be updated when the quantity metered is higher
            than the current best. Default: 'max'.

    """

    def __init__(self, mode='max', verbose=True):

        self.has_converged = False
        self.verbose = verbose
        self.mode = mode
        self.best = None
        self.best_obj = None
        self.mode_worse = None  # the worse value for the chosen mode
        self._init_is_better(mode=mode)
        self._reset()

    def _reset(self):
        self.best = self.mode_worse

    def step(self, metrics, best_obj=None):
        # convert `metrics` to float, in case it's a zero-dim Tensor
        current = float(metrics)

        if self.is_better(current, self.best):
            if self.verbose:
                print("*********New best**********")
                print("value: ", current)
                print("object: ", best_obj)
                print("***************************")
            self.best = current
            self.best_obj = best_obj
            return True

        return False

    @property
    def in_cooldown(self):
        return self.cooldown_counter > 0

    def is_better(self, a, best):
        if self.mode == 'min' and self.threshold_mode == 'abs':
            return a < best

        else:  # mode == 'max' and epsilon_mode == 'abs':
            return a > best

    def _init_is_better(self, mode):
        if mode not in {'min', 'max'}:
            raise ValueError('mode ' + mode + ' is unknown!')
        if mode == 'min':
            self.mode_worse = inf
        else:  # mode == 'max':
            self.mode_worse = -inf

        self.mode = mode


# Disable
def block_print():
    sys.stdout = open(os.devnull, 'w')


# Restore
def enable_print():
    sys.stdout = sys.__stdout__


def get_data_loader(dataset, batch_size, args, shuffle=True):
    """Args:
        np_array: shape [num_data, data_dim]
        batch_size: int
        device: torch.device object

    Returns: torch.utils.data.DataLoader object
    """

    if args.device == torch.device('cpu'):
        kwargs = {'num_workers': 4, 'pin_memory': True}
    else:
        kwargs = {}

    return torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, **kwargs)


def get_mean_of_dataset(train_data_loader, args, idx=0):
    """ Compute mean without loading entire dataset into memory """
    meter = AverageMeter()
    for i in train_data_loader:
        if isinstance(i, list):
            meter.update(i[idx])
        else:
            meter.update(i)
    data_mean = meter.mean
    if data_mean.ndim == 2:
        data_mean = data_mean.mean(0)
    return tensor(data_mean, args)


def split_train_test_by_percentage(dataset, train_percentage=0.8):
    """ split pytorch Dataset object by percentage """
    train_length = int(len(dataset) * train_percentage)
    return torch.utils.data.random_split(dataset, (train_length, len(dataset) - train_length))


def pmap(f, arr, n_jobs=-1, prefer='threads', verbose=10):
    return Parallel(n_jobs=n_jobs, prefer=prefer, verbose=verbose)(delayed(f)(i) for i in arr)


def put(value, filename):
    persist_dir.mkdir(exist_ok=True)
    filename = persist_dir / filename
    print("Saving to ", filename)
    joblib.dump(value, filename)


def get(filename):
    filename = persist_dir / filename
    assert filename.exists(), "{} doesn't exist".format(filename)
    print("Saving to ", filename)
    return joblib.load(filename)


def smooth(arr, window):
    return pd.Series(arr).rolling(window, min_periods=1).mean().values


def tensor(data, args=None, dtype=torch.float):
    device = torch.device('cpu') if args is None else args.device
    if torch.is_tensor(data):
        return data.to(dtype=dtype, device=device)
    else:
        return torch.tensor(np.array(data), device=device, dtype=dtype)


def is_test_time(epoch, args):
    if args.train_only:
        return False

    # last epoch
    if epoch == (args.epochs - 1):
        return True

    # test epoch
    if (args.test_during_training and ((epoch % args.test_frequency) == 0)):
        return True

    # Else
    return False



def detect_cuda(args):
    if args.cuda and torch.cuda.is_available():
        args.device = torch.device('cuda')
        args.cuda = True
    else:
        args.device = torch.device('cpu')
        args.cuda = False
    return args

def is_early_update(epoch,args):

    if epoch<=args.burn_in or len(args.logtvopx_all)<1 or len(args.average_y)==0 or len(args.Y_ori)==0:
        return False
    #print("logtvopx[-1]-average_y[-1]",np.round(args.logtvopx_all[-1]-args.average_y[-1],4))
    if args.logtvopx_all[-1]<0 and (args.logtvopx_all[-1]-args.average_y[-1] )<args.drip_threshold:
        args.len_terminated_epoch=epoch % args.schedule_update_frequency # used to estimate the average logpx_tvo_evidence
        print("===early update===","logtvopx[-1]-average_y[-1]", np.round(args.logtvopx_all[-1]-args.average_y[-1],4),"drip_threshold",args.drip_threshold)
        return True
    args.len_terminated_epoch=0
    return False

def is_schedule_update_time(epoch, args):
    # No scheduling
    if args.loss != 'tvo':
        return False

    if args.schedule not in ["gp_bandit", 'moments']:
        return False

    if is_early_update(epoch,args):
        return True

    # First epoch, initalize
    if epoch <=args.burn_in:
        #return True
        return False

    # Update happens at each minibatch
    if args.per_sample is True:
        return False

    # Initalize once and never update
    if args.schedule_update_frequency == 0:
        return False

    # catch checkpoint epoch
    if (epoch % args.schedule_update_frequency) == 0:
        return True

    # Else
    return False


def is_checkpoint_time(epoch, args):
    # No checkpointing
    if args.checkpoint is False:
        return False

    # skip first epoch
    if (epoch == 0):
        return False

    # catch last epoch
    if epoch == (args.epochs - 1):
        return True

    # catch checkpoint epoch
    if (epoch % args.checkpoint_frequency) == 0:
        return True

    # Else
    return False


def is_gradient_time(epoch, args):
    # No checkpointing
    if args.save_grads is False:
        return False

    # catch checkpoint epoch
    if (epoch % args.test_frequency) == 0:
        return True

    # Else
    return False


def logaddexp(a, b):
    """Returns log(exp(a) + exp(b))."""

    return torch.logsumexp(torch.cat([a.unsqueeze(0), b.unsqueeze(0)]), dim=0)


def lognormexp(values, dim=0):
    """Exponentiates, normalizes and takes log of a tensor.
    """

    log_denominator = torch.logsumexp(values, dim=dim, keepdim=True)
    # log_numerator = values
    return values - log_denominator


def make_sparse(sparse_mx, args):
    """Convert a scipy sparse matrix to a torch sparse tensor."""
    sparse_mx = sparse_mx.tocoo().astype(np.float32)

    indices = tensor(
        np.vstack((sparse_mx.row, sparse_mx.col)), args, torch.long)
    values = tensor(sparse_mx.data, args)
    shape = torch.Size(sparse_mx.shape)
    return torch.sparse.FloatTensor(indices, values, shape)


def exponentiate_and_normalize(values, dim=0):
    """Exponentiates and normalizes a tensor.

    Args:
        values: tensor [dim_1, ..., dim_N]
        dim: n

    Returns:
        result: tensor [dim_1, ..., dim_N]
            where result[i_1, ..., i_N] =
                            exp(values[i_1, ..., i_N])
            ------------------------------------------------------------
             sum_{j = 1}^{dim_n} exp(values[i_1, ..., j, ..., i_N])
    """

    return torch.exp(lognormexp(values, dim=dim))


def seed_all(seed):
    """Seed all devices deterministically off of seed and somewhat
    independently."""
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def get_grads(model):
    return torch.cat([torch.flatten(p.grad.clone()) for p in model.parameters()]).cpu()


def log_ess(log_weight):
    """Log of Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: log of effective sample size [batch_size] (or [1])
    """
    dim = 1 if log_weight.ndimension() == 2 else 0

    return 2 * torch.logsumexp(log_weight, dim=dim) - \
        torch.logsumexp(2 * log_weight, dim=dim)


def ess(log_weight):
    """Effective sample size.
    Args:
        log_weight: Unnormalized log weights
            torch.Tensor [batch_size, S] (or [S])
    Returns: effective sample size [batch_size] (or [1])
    """

    return torch.exp(log_ess(log_weight))


def spread(X, N, axis=0):
    """
    Takes a 1-d vector and spreads it out over
    N rows s.t spread(X, N).sum(0) = X
    """
    return (1 / N) * duplicate(X, N, axis)

def duplicate(X, N, axis=0):
    """
    Takes a 1-d vector and duplicates it across
    N rows s.t spread(X, N).sum(axis) = N*X
    """
    order = (N, 1) if axis == 0 else (1, N)
    return X.unsqueeze(axis).repeat(*order)

def get_unique_dir(comment=None):
    current_time = datetime.now().strftime('%b%d_%H-%M-%S')
    host = socket.gethostname()
    name = f"{current_time}_{host}"
    if comment: name = f"{name}_{comment}"
    return name

File Path: src/models/__init__.py
Content:

File Path: src/models/base.py
Content:
from torch import nn
from src import ml_helpers as mlh
from collections import defaultdict
import numpy as np
import torch
from tqdm import tqdm

from src.util import (calc_exp, calc_var_given_betas, compute_tvo_loss, compute_wake_theta_loss, compute_wake_phi_loss, \
        compute_vimco_loss, compute_tvo_log_evidence, compute_tvo_iwae_log_evidence,  compute_tvo_reparam_loss)
from src import util



class ProbModelBaseClass(nn.Module):
    def __init__(self, D, args):
        """Base class for probabilistic model.
            - Uses internal state to avoid having to pass data around
            - self.set_internals(), self.log_guide(), self.log_prior(), self.sample_latent(),
              must be overwritten by subclass

        Args:
            D (int): [Size of observation dimension]
            S (int, optional): [Number of samples to be used in MC approx]. Defaults to 25.
        """
        super().__init__()

        # Dimensions
        self.D = D
        self.args = args

        self.hist = defaultdict(list)
        self.record_results = defaultdict(mlh.AverageMeter)

        
        #self.init_expectation = None 
        self.exp_last = None
        self.var_last = None
        self.exp_meter = mlh.AverageMeter()
        self.var_meter = mlh.AverageMeter()

        self.track_beta_grad = False

        if self.args.loss in ['elbo', 'iwae', 'tvo_reparam', 'tvo_reparam_iwae']:
            print("Reparam turned: ON")
            self.reparam = True
        else:
            print("Reparam turned: OFF")
            self.reparam = False

        # Internal state
        self.x = None  # Observations
        self.y = None  # Labels
        self.z = None  # Latent samples

    def __iter__(self):
        for attr, value in self.__dict__.items():
            yield attr, value

    # For debugging
    def show_state(self):
        for a in self:
            print(a)

    def elbo(self):
        """
        Returns: [N, S]
        """
        self.check_internals()
        return self.log_joint() - self.log_guide()

    def set_internals(self, data, S):
        """
        Implemented by subclass

        This sets the internal state variables so all the functions work

        Raises:
            NotImplementedError: [description]
        """
        raise NotImplementedError

    def check_internals(self):
        """Verify internal state variables have been set.
         - False means not used,
         - None means error
        """
        assert self.x is not None, "self.x not set"
        assert self.y is not None, "self.y not set"
        assert self.z is not None, "self.z not set"

    def log_joint(self):
        """
        log p(x, z)
        Implemented by subclass

        Returns: [N, S]
        Raises:
            NotImplementedError: [description]
        """
        self.check_internals()
        prior = self.log_prior()
        likelihood = self.log_likelihood()
        # if prior.ndim == 1:
        if len(prior.shape) == 1:
            N = self.x.shape[0]
            prior = (1 / N) * prior.unsqueeze(0).repeat(N, 1)
            return likelihood + (1 / self.args.batch_size) * prior
        else:
            return prior + likelihood

    def log_prior(self):
        """
        log p(z) or log p(θ), depending on
        if the prior is over latent parameters
        p(z) or global parameters p(θ)

        Implemented by subclass

        Returns: [N, S] or [S]
            p(z) -> [N, S]
            p(θ) -> [S]
        Raises:
            NotImplementedError: [description]
        """
        raise NotImplementedError

    def log_likelihood(self):
        """
        log p(x|z)
        Implemented by subclass

        Returns: [N, S]
        Raises:
            NotImplementedError: [description]
        """
        raise NotImplementedError

    def log_guide(self):
        """
        log q(z|x) or log q(z)
        Implemented by subclass

        Returns: [N, S]
        Raises:
            NotImplementedError: [description]
        """
        raise NotImplementedError

    def sample_latent(self, S):
        """
        Implemented by subclass

        Note: S is in the *first* index for sample_latent,
        This is done to match pytorch's broadcasting semantics
        * can be anything. i.e. [S, N, D0, D1, ...]

        Returns: [S, *]
        Raises:
            NotImplementedError: [description]
        """
        raise NotImplementedError

    # ============================
    # ---------- Helpers ----------
    # ============================

    def get_test_metrics(self, data, S):
        """
        Computes logpx, test_elbo, tvo_log_evidence
        with a single forward pass. About 1.5x faster
        on my machine
        """
        with torch.no_grad():
            self.set_internals(data, S)
            log_weight = self.elbo()
            logpx = self.get_test_log_evidence(data, S, log_weight=log_weight)
            test_elbo = self.get_test_elbo(data, S, log_weight=log_weight)
            tvo_log_evidence = self.get_tvo_log_evidence(data, S, log_weight=log_weight)
        return logpx, test_elbo, tvo_log_evidence

    def get_test_log_evidence(self, data, S, log_weight=None):
        with torch.no_grad():
            if log_weight is None:
                self.set_internals(data, S)
                log_weight = self.elbo()
            log_evidence = torch.logsumexp(log_weight, dim=1) - np.log(S)
            iwae_log_evidence = torch.mean(log_evidence)

        return iwae_log_evidence

    def get_tvo_log_evidence(self, data, S, log_weight=None):
        with torch.no_grad():
            if log_weight is None:
                self.set_internals(data, S)
                log_weight = self.elbo()
            tvo_log_evidence = compute_tvo_log_evidence(log_weight, self.args)
        return torch.mean(tvo_log_evidence)

    def get_tvo_iwae_log_evidence(self, data, S, log_weight=None):
        with torch.no_grad():
            if log_weight is None:
                self.set_internals(data, S)
                log_weight = self.elbo()
            tvo_iwae_log_evidence = compute_tvo_iwae_log_evidence(log_weight, self.args)
        return torch.mean(tvo_iwae_log_evidence)

    def get_test_elbo(self, data, S, log_weight=None):
        with torch.no_grad():
            if log_weight is None:
                self.set_internals(data, S)
                log_weight = self.elbo()
            elbo = torch.mean(log_weight)
        return elbo

    def get_log_p_and_kl(self, data, S, log_weight=None):
        with torch.no_grad():
            if log_weight is None:
                self.set_internals(data, S)
                log_weight = self.elbo()
        log_p = torch.logsumexp(log_weight, dim=1) - np.log(S)
        elbo = torch.mean(log_weight, dim=1)
        kl = log_p - elbo

        return log_p, kl

    def record_artifacts(self, _run):
        """ -- Record artifacts --
            args: sacred _run object
        """
        import pandas as pd

        for k in self.hist.keys():
            df = pd.DataFrame(self.hist[k])
            df.columns = [f"beta_{i}" for i in df.columns]

            # To prevent collisions if jobs are run in parallel
            path = self.args.unique_directory / f'{k}.csv'

            df.to_csv(path)

            # Fed run as argument to train... could also capture?
            _run.add_artifact(path, name=k)

    def save_record(self):
        for k, meter in self.record_results.items():
            self.hist[k].append(meter.mean.detach().cpu().numpy())
            meter.reset()

        betas = self.args.partition.cpu().numpy()

        if len(betas.shape) == 3 and betas.shape[0] > 1:
            betas = np.squeeze(np.mean(betas, axis=0))

        self.hist['beta'].append(betas)

        if self.args.verbose:
            print('betas : ', np.mean(betas, axis=0)
                  if len(betas.shape) > 1 else betas)
            print('tvo exp : ', self.hist['tvo_exp'][-1])
            #print('tvo curvature : ', self.hist['curvature'][-1])

    def train_epoch_single_objective(self, data_loader, optimizer, epoch=None):
        train_logpx = 0
        train_elbo = 0
        train_tvo_log_evidence = 0
        data_loader = tqdm(data_loader) if self.args.verbose else data_loader

        for idx, data in enumerate(data_loader):
            optimizer.zero_grad()
            loss, logpx, elbo, tvo_log_evidence = self.forward(data)

            loss.backward()
            optimizer.step()

            if self.args.record:
                self.record_stats(loss=loss.item(), epoch=epoch, batch_idx=idx)

            if self.args.schedule == 'beta_batch_gradient' and self.track_beta_grad:
                self.args.partition = self.args.partition_scheduler(self, self.args)


            train_logpx += logpx.item()
            train_elbo += elbo.item()
            train_tvo_log_evidence+=tvo_log_evidence.item()

        train_logpx = train_logpx / len(data_loader)
        train_elbo = train_elbo / len(data_loader)
        train_tvo_log_evidence = train_tvo_log_evidence/len(data_loader)


        if self.args.record:
            self.save_record()


        return train_logpx, train_elbo, train_tvo_log_evidence

    def train_epoch_dual_objectives(self, data_loader, optimizer_phi, optimizer_theta, epoch=None):
        train_logpx = 0
        train_elbo = 0
        train_tvo_log_evidence = 0
        data_loader = tqdm(data_loader) if self.args.verbose else data_loader

        for idx, data in enumerate(data_loader):
            optimizer_phi.zero_grad()
            optimizer_theta.zero_grad()

            if self.args.loss == 'tvo_reparam': # p (generative model) optimized using TVO
                wake_theta_loss = self.get_tvo_loss(data)
            elif self.args.loss  == 'tvo_reparam_iwae': # p optimized using IWAE bound
                wake_theta_loss = self.get_iwae_loss(data)
            else:
                wake_theta_loss = self.get_wake_theta_loss(data)
            wake_theta_loss.backward()
            optimizer_theta.step()

            optimizer_phi.zero_grad()
            optimizer_theta.zero_grad()

            if self.args.loss == 'wake-sleep':
                sleep_phi_loss = self.get_sleep_phi_loss(data)
                sleep_phi_loss.backward()
            elif self.args.loss == 'wake-wake':
                wake_phi_loss = self.get_wake_phi_loss(data)
                wake_phi_loss.backward()
            elif self.args.loss in ['tvo_reparam', 'tvo_reparam_iwae']:
                sleep_phi_loss = self.get_tvo_reparam_loss(data)
                sleep_phi_loss.backward()
            else:
                raise ValueError(
                    "{} is an invalid loss".format(self.args.loss))

            optimizer_phi.step()

            logpx = self.get_test_log_evidence(data, self.args.valid_S)
            elbo = self.get_test_elbo(data, self.args.valid_S)
            tvo_log_evidence=self.get_tvo_log_evidence(data,self.args.valid_S)

            if self.args.record:
                self.record_stats(epoch=epoch, batch_idx=idx)

            train_logpx += logpx.item()
            train_elbo += elbo.item()
            train_tvo_log_evidence+=tvo_log_evidence.item()

        train_logpx = train_logpx / len(data_loader)
        train_elbo = train_elbo / len(data_loader)
        train_tvo_log_evidence=train_tvo_log_evidence/len(data_loader)

        if self.args.record:
            self.save_record()

        return train_logpx, train_elbo, train_tvo_log_evidence

    def evaluate_model_and_inference_network(self, data_loader, epoch=None):
        log_p_total = 0
        kl_total = 0
        num_data = 0
        with torch.no_grad():
            data_loader = tqdm(data_loader) if self.args.verbose else data_loader
            for data in iter(data_loader):
                log_p, kl = self.get_log_p_and_kl(data, self.args.test_S)
                log_p_total += torch.sum(log_p).item()
                kl_total += torch.sum(kl).item()
                num_data += data[0].shape[0]
        return log_p_total / num_data, kl_total / num_data

    def evaluate_model(self, data_loader):
        log_px = 0
        with torch.no_grad():
            for idx, data in enumerate(data_loader):
                log_px += self.get_test_log_evidence(data, self.args.test_S)
        return log_px / len(data_loader)

    def record_stats(self, loss=None, record_partition=False, epoch=None, batch_idx=None):
        '''
            Records (across β) : expectation / variance / 3rd / 4th derivatives
                curvature, IWAE β estimator
                intermediate TVO integrals (WIP)
            Also used in BNN to record classification metrics
        '''

        '''Possibility of different, standardized partition for evaluation?
            - may run with record_partition specified or overall arg'''

        # Always use validation sample size
        S = self.args.valid_S

        with torch.no_grad():
            if self.args.record_partition is not None:
                partition = self.args.record_partition
            elif record_partition:
                partition = torch.linspace(0, 1.0, 101, device='cuda')
            else:
                partition = self.args.partition

            log_iw = self.elbo().unsqueeze(-1) if len(self.elbo().shape) < 3 else self.elbo()

            heated_log_weight = log_iw * partition

            snis = util.exponentiate_and_normalize(heated_log_weight, dim=1)

            # Leaving open possibility of addl calculations on batch dim (mean = False)
            tvo_expectations = util.calc_exp(
                log_iw, partition, snis=snis, all_sample_mean=True)
            tvo_vars = util.calc_var(
                log_iw, partition, snis=snis, all_sample_mean=True)
            tvo_thirds = util.calc_third(
                log_iw, partition, snis=snis, all_sample_mean=True)
            tvo_fourths = util.calc_fourth(
                log_iw, partition, snis=snis, all_sample_mean=True)

            curvature = tvo_thirds/(torch.pow(1+torch.pow(tvo_vars, 2), 1.5))
            iwae_beta = torch.mean(torch.logsumexp(
                heated_log_weight, dim=1) - np.log(S), axis=0)

            # Using average meter
            # torch.mean(tvo_expectations, dim=0)
            self.record_results['tvo_exp'].step(tvo_expectations.cpu())
            self.record_results['tvo_var'].step(tvo_vars.cpu())
            self.record_results['tvo_third'].step(tvo_thirds.cpu())
            self.record_results['tvo_fourth'].step(tvo_fourths.cpu())

            # per sample curvature by beta (gets recorded as mean over batches)
            self.record_results['curvature'].step(curvature.cpu())
            # [K] length vector of MC estimators of log Z_β
            self.record_results['iwae_beta'].step(iwae_beta.cpu())

    # ============================
    # ---------- Losses ----------
    # ============================

    def forward(self, data):
        assert isinstance(data, (tuple, list)), "Data must be a tuple (X,y) or (X, )"
        if self.args.loss == 'reinforce':
            loss = self.get_reinforce_loss(data)
        elif self.args.loss == 'elbo':
            loss = self.get_elbo_loss(data)
        elif self.args.loss == 'iwae':
            loss = self.get_iwae_loss(data)
        elif self.args.loss == 'thermo' or self.args.loss == 'tvo':
            loss = self.get_tvo_loss(data)
        elif self.args.loss == 'tvo_smoothed':
            loss = self.get_tvo_smoothed_loss(data)
        elif self.args.loss == 'vimco':
            loss = self.get_vimco_loss(data)
        else:
            raise ValueError("{} is an invalid loss".format(self.args.loss))

        logpx, test_elbo, tvo_log_evidence = self.get_test_metrics(data, self.args.valid_S)

        return loss, logpx, test_elbo, tvo_log_evidence


    def get_iwae_loss(self, data):
        assert self.reparam is True, 'Reparam must be on for iwae loss'
        self.set_internals(data, self.args.S)

        log_weight = self.elbo()
        stable_log_weight = log_weight - \
            torch.max(log_weight, 1)[0].unsqueeze(1)
        weight = torch.exp(stable_log_weight)
        normalized_weight = weight / torch.sum(weight, 1).unsqueeze(1)

        loss = - \
            torch.mean(torch.sum(normalized_weight.detach() * log_weight, 1), 0)
        return loss

    def get_elbo_loss(self, data):
        assert self.reparam is True, 'Reparam must be on for elbo loss'
        self.set_internals(data, self.args.S)
        log_weight = self.elbo()
        train_elbo = torch.mean(log_weight)

        loss = -train_elbo
        return loss

    def get_reinforce_loss(self, data):
        assert self.reparam is False, 'Reparam must be off for reinforce loss'
        self.set_internals(data, self.args.S)

        log_weight = self.elbo()
        log_q = self.log_guide()

        reinforce = log_weight.detach() * log_q + log_weight

        loss = -torch.mean(reinforce)
        return loss

    def reset_track_beta(self):
        self.exp_last = None
        self.var_last = None
        self.exp_meter.reset()
        self.var_meter.reset()


    def track_beta_grads(self, log_weight):       
        if self.exp_last is None or self.var_last is None:            
            if self.args.schedule == 'beta_gradient_descent':
                #  initial calculation over entire dataset for stability
                log_weight = util.get_total_log_weight(self, self.args, self.args.S).data
            # else: 'beta_batch_gradient' should be over batch only
            tvo_exps = calc_exp(log_weight, self.args, all_sample_mean=True)
            tvo_vars = calc_var_given_betas(log_weight, self.args, all_sample_mean=True)

            self.exp_last = tvo_exps
            self.var_last = tvo_vars
            
        else:
            tvo_exps = calc_exp(log_weight, self.args, all_sample_mean=True)
            tvo_vars = calc_var_given_betas(log_weight, self.args, all_sample_mean=True)
        # beta gradient includes a telescoping sum, reduces to (Ε_βκ(t=T) - Ε_βκ(t=0)) = expectation_diffs
        
        self.exp_meter.step(tvo_exps.data)
        self.var_meter.step(tvo_vars.data)

        #self.expectation_diffs.step(tvo_exps.data)

    def get_tvo_loss(self, data):
        assert self.reparam is False or self.args.loss == 'tvo_reparam', 'Reparam must be off for tvo loss'
        self.set_internals(data, self.args.S)

        if self.args.per_sample:
            self.args.partition = self.args.partition_scheduler(
                self, self.args)

        log_weight = self.elbo()
        log_joint = self.log_joint()
        log_guide = self.log_guide()
        loss = compute_tvo_loss(log_weight, log_joint, log_guide, self.args)

        if self.args.schedule in ['beta_gradient_descent', 'beta_batch_gradient'] and self.track_beta_grad:
            self.track_beta_grads(log_weight)

        return loss

    def get_tvo_smoothed_loss(self, data):
        assert self.reparam is False or self.args.loss == 'tvo_reparam', 'Reparam must be off for tvo loss'
        self.set_internals(data, self.args.S)

        if self.args.per_sample:
            self.args.partition = self.args.partition_scheduler(
                self, self.args)

        log_weight = self.elbo()
        log_joint = self.log_joint()
        log_guide = self.log_guide()
        loss = compute_tvo_smoothed_loss(log_weight, log_joint, log_guide, self.args)

        if self.track_beta_grad:
            self.track_beta_grads(log_weight)

        return loss

    def get_tvo_reparam_loss(self, data, old_extra_beta = True):
        assert self.reparam is True, 'Reparam must be ON for TVO Reparam'
        self.set_internals(data, self.args.S)

        self.args.old_extra_beta = old_extra_beta

        if self.args.per_sample:
            self.args.partition = self.args.partition_scheduler(self, self.args)

        log_weight = self.elbo()
        log_joint = self.log_joint()
        log_guide = self.log_guide()


        loss = compute_tvo_reparam_loss(log_weight, log_joint, log_guide, self.args)


        if self.track_beta_grad:
            self.track_beta_grads(log_weight)

        return loss



    def get_wake_theta_loss(self, data):
        """Scalar that we call .backward() on and step the optimizer.

        Args:
            generative_model: models.GenerativeModel object
            inference_network: models.InferenceNetwork object
            obs: tensor of shape [batch_size]
            num_particles: int

        Returns:
            loss: scalar that we call .backward() on and step the optimizer.
            elbo: average elbo over data
        """
        assert self.reparam is False, 'Reparam must be off for wake_theta_loss'
        self.set_internals(data, self.args.S)

        log_weight = self.elbo()
        return compute_wake_theta_loss(log_weight)

    def get_wake_phi_loss(self, data):
        """
        Args:
            generative_model: models.GenerativeModel object
            inference_network: models.InferenceNetwork object
            obs: tensor of shape [batch_size]
            num_particles: int

        Returns:
            loss: scalar that we call .backward() on and step the optimizer.
        """
        assert self.reparam is False, 'Reparam must be off for wake_phi_loss'
        self.set_internals(data, self.args.S)

        log_weight = self.elbo()
        log_q = self.log_guide()
        return compute_wake_phi_loss(log_weight, log_q)

    def get_sleep_phi_loss(self, data):
        """Returns:
        loss: scalar that we call .backward() on and step the optimizer.
        """
        assert self.reparam is False, 'Reparam must be off for sleep_loss'
        self.set_internals(data, self.args.S)
        log_q = self.log_guide()
        return -torch.mean(log_q)

    def get_vimco_loss(self, data):
        """Almost twice faster version of VIMCO loss (measured for batch_size = 24,
        num_particles = 1000). Inspired by Adam Kosiorek's implementation.

        Args:
            generative_model: models.GenerativeModel object
            inference_network: models.InferenceNetwork object
            obs: tensor of shape [batch_size]
            num_particles: int

        Returns:

            loss: scalar that we call .backward() on and step the optimizer.
            elbo: average elbo over data
        """
        assert self.reparam is False, 'Reparam must be off for vimco_loss'
        self.set_internals(data, self.args.S)

        # assert self.reparam is True, 'Reparam must be on for wake_phi_loss'
        log_weight = self.elbo()
        log_q = self.log_guide()
        return compute_vimco_loss(log_weight, log_q)

    def get_concrete_loss(self, data):
        raise NotImplementedError

    def get_relax_loss(self, data):
        raise NotImplementedError

File Path: src/models/bnn.py
Content:
# credit: https://www.nitarshan.com/bayes-by-backprop/
import math
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from tqdm import tqdm, trange
import pandas as pd
from src.ml_helpers import duplicate, spread, get_unique_dir
from src.models.base import ProbModelBaseClass
from torch.utils.tensorboard import SummaryWriter
from pathlib import Path

PI = 0.5
SIGMA_1 = torch.FloatTensor([math.exp(-0)])
SIGMA_2 = torch.FloatTensor([math.exp(-6)])

# SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])
# SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])

class Gaussian(object):
    def __init__(self, mu, rho, device):
        super().__init__()
        self.mu = mu
        self.rho = rho
        self.normal = torch.distributions.Normal(0,1)
        self.size = self.rho.size()
        self.device = device
        self.sum_dim = [1,2] if len(self.size) == 2 else [1]

    @property
    def sigma(self):
        return torch.log1p(torch.exp(self.rho))

    def sample(self, S=1):
        epsilon = self.normal.sample([S, *self.size]).to(self.device)
        return self.mu + self.sigma * epsilon

    def log_prob(self, input):
        return (-math.log(math.sqrt(2 * math.pi))
                - torch.log(self.sigma)
                - ((input - self.mu) ** 2) / (2 * self.sigma ** 2)).sum(self.sum_dim)


class ScaleMixtureGaussian(object):
    def __init__(self, pi, sigma1, sigma2):
        super().__init__()
        self.pi = pi
        self.sigma1 = sigma1
        self.sigma2 = sigma2
        self.gaussian1 = torch.distributions.Normal(0,sigma1)
        self.gaussian2 = torch.distributions.Normal(0,sigma2)

    # replace w/ logsumexp
    def log_prob(self, input):
        prob1 = torch.exp(self.gaussian1.log_prob(input))
        prob2 = torch.exp(self.gaussian2.log_prob(input))
        sum_dim = [1,2] if input.ndim == 3 else [1]
        return (torch.log(self.pi * prob1 + (1-self.pi) * prob2)).sum(sum_dim)


class BayesianLinear(nn.Module):
    def __init__(self, in_features, out_features, args):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        # Weight parameters
        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-0.2, 0.2))
        self.weight_rho = nn.Parameter(torch.Tensor(out_features, in_features).uniform_(-5,-4))
        self.weight = Gaussian(self.weight_mu, self.weight_rho, args.device)
        # Bias parameters
        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))
        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))
        self.bias = Gaussian(self.bias_mu, self.bias_rho, args.device)
        # Prior distributions
        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)
        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)
        self.log_prior = 0
        self.log_guide = 0

    def forward(self, input, sample=False, S=1):
        if self.training or sample:
            weight = self.weight.sample(S=S)
            bias = self.bias.sample(S=S)
        else:
            weight = self.weight.mu.unsqueeze(0)
            bias = self.bias.mu.unsqueeze(0)

        self.log_prior = self.weight_prior.log_prob(weight) + self.bias_prior.log_prob(bias)
        self.log_guide = self.weight.log_prob(weight) + self.bias.log_prob(bias)

        # vectorized
        return torch.matmul(input, weight.permute(0,2,1)) + bias.unsqueeze(1)


class BayesianNetwork(ProbModelBaseClass):
    def __init__(self, D, num_batches, args, num_classes=10):
        super(BayesianNetwork, self).__init__(D, args)
        self.NUM_BATCHES = num_batches # M in eq. 8 https://arxiv.org/pdf/1505.05424.pdf
        self.NUM_CLASSES = num_classes # M in eq. 8 https://arxiv.org/pdf/1505.05424.pdf

        self.l1 = BayesianLinear(D, 400, args)
        self.l2 = BayesianLinear(400, 400, args)
        self.l3 = BayesianLinear(400, 10, args)
        self.tensorboard_dir = Path(args.artifact_dir) / get_unique_dir()
        self.writer = SummaryWriter(self.tensorboard_dir)


    def set_internals(self, data, S):
        assert isinstance(data, (tuple, list)), "Data must be a tuple (X,y)"
        assert len(data) == 2, "Data must be a tuple (X,y)"
        self.x = data[0].to(self.args.device)
        self.y = data[1].to(self.args.device)
        self.z = self.sample_latent(S, sample=True)
        self.check_internals()

    def check_internals(self):
        """Verify internal state variables have been set.
         - False means not used,
         - None means error
        """
        assert self.x is not None, "self.x not set"
        assert self.y is not None, "self.y not set"
        assert self.z is not None, "self.z not set"

    def sample_latent(self, S, sample=True):
        # sample=False used for eval
        x = self.x.view(-1, self.D)
        x = F.relu(self.l1(x, sample=sample, S=S))
        x = F.relu(self.l2(x, sample=sample, S=S))
        return F.log_softmax(self.l3(x, sample=sample, S=S), dim=2)

    def log_prior(self):
        N = self.x.shape[0]
        log_prior = self.l1.log_prior + self.l2.log_prior + self.l3.log_prior
        return spread(log_prior, N) # to obey [NxS] output requirement

    def log_guide(self):
        N = self.x.shape[0]
        log_guide = self.l1.log_guide + self.l2.log_guide + self.l2.log_guide
        return spread(log_guide, N) # to obey [NxS] output requirement

    def log_likelihood(self):
        S = self.z.shape[0]
        # permute to obey [NxS] output requirement
        negative_log_likelihood = F.nll_loss(self.z.permute(1,2,0), duplicate(self.y, S, axis=1),  reduction='none')
        return -negative_log_likelihood

    def elbo(self):
        # this is the mini-batch weighted loss discussed in eq. 8 of the BBB paper.
        # Same trick works for tvo terms
        return (self.log_likelihood() + (self.log_prior() - self.log_guide())/self.NUM_BATCHES)

    # def elbo(self):
    #     # this is the mini-batch weighted loss discussed in eq. 8 of the BBB paper.
    #     # We multiply by N so torch.mean(elbo) in base.py is a sum to match eq. 8
    #     # Same trick works for tvo terms
    #     N = self.x.shape[0]
    #     return N*(self.log_likelihood() + (self.log_prior() - self.log_guide())/self.NUM_BATCHES)


    def get_prediction(self):
        self.check_internals()
        outputs = torch.zeros(self.args.test_S+1, self.args.test_batch_size, self.NUM_CLASSES).to(self.args.device)
        outputs[:self.args.test_S] = self.z
        outputs[self.args.test_S] = self.sample_latent(S=1, sample=False)
        output = outputs.mean(0)
        preds = preds = outputs.max(2, keepdim=True)[1]
        pred = output.max(1, keepdim=True)[1] # index of max log-probability

        sample_prediction = preds.eq(self.y.view_as(pred)).sum(dim=1).squeeze().cpu().numpy()
        ensemble_prediction = pred.eq(self.y.view_as(pred)).sum().item()

        return sample_prediction, ensemble_prediction

    def record_stats(self, loss=None, record_partition=False, epoch=None, batch_idx=None):
        if batch_idx == 0:
            self.write_weight_histograms(epoch)

        elbo = self.elbo().mean()
        log_prior = self.log_prior().mean()
        log_guide = self.log_guide().mean()
        negative_log_likelihood  = -self.log_likelihood().mean()

        global_step = epoch*self.NUM_BATCHES+batch_idx

        self.writer.add_scalar('logs/loss', loss, global_step)
        self.writer.add_scalar('logs/elbo', loss, global_step)
        self.writer.add_scalar('logs/complexity_cost', log_guide-log_prior, global_step)
        self.writer.add_scalar('logs/log_prior', log_prior, global_step)
        self.writer.add_scalar('logs/log_guide', log_guide, global_step)
        self.writer.add_scalar('logs/negative_log_likelihood', negative_log_likelihood, global_step)


    def write_weight_histograms(self, epoch):
        self.writer.add_histogram('histogram/w1_mu', self.l1.weight_mu, epoch)
        self.writer.add_histogram('histogram/w1_rho', self.l1.weight_rho, epoch)
        self.writer.add_histogram('histogram/w2_mu', self.l2.weight_mu, epoch)
        self.writer.add_histogram('histogram/w2_rho', self.l2.weight_rho, epoch)
        self.writer.add_histogram('histogram/w3_mu', self.l3.weight_mu, epoch)
        self.writer.add_histogram('histogram/w3_rho', self.l3.weight_rho, epoch)
        self.writer.add_histogram('histogram/b1_mu', self.l1.bias_mu, epoch)
        self.writer.add_histogram('histogram/b1_rho', self.l1.bias_rho, epoch)
        self.writer.add_histogram('histogram/b2_mu', self.l2.bias_mu, epoch)
        self.writer.add_histogram('histogram/b2_rho', self.l2.bias_rho, epoch)
        self.writer.add_histogram('histogram/b3_mu', self.l3.bias_mu, epoch)
        self.writer.add_histogram('histogram/b3_rho', self.l3.bias_rho, epoch)


    def evaluate_model_and_inference_network(self, data_loader, epoch=None):
        """
        overwrite evaluate_model_and_inference_network to add classification
        evaluation as well. this avoids having to add bnn-specific conditionals in main.py
        """
        self.eval()
        correct = 0
        corrects = np.zeros(self.args.test_S+1, dtype=int)
        TEST_SIZE = len(data_loader.dataset)

        log_p_total = 0
        kl_total = 0
        num_data = 0

        with torch.no_grad():
            data_loader = tqdm(data_loader) if self.args.verbose else data_loader
            for data in iter(data_loader):
                log_p, kl = self.get_log_p_and_kl(data, self.args.test_S)
                sample_prediction, ensemble_prediction = self.get_prediction()

                corrects += sample_prediction
                correct += ensemble_prediction

                log_p_total += torch.sum(log_p).item()
                kl_total += torch.sum(kl).item()

        df = pd.DataFrame(np.append(corrects, correct)) / TEST_SIZE

        df.index = [f"sample_{i}" for i in range(self.args.test_S)] + ["posterior"] + ["ensemble"]
        # df.to_csv(self.tensorboard_dir / f"classification_accuracy_epoch_{epoch}.csv")

        for name, row in df.iterrows():
            self.writer.add_scalar(f'accuracy/{name}', float(row), epoch)
            self.args._run.log_scalar(name, float(row), epoch)

        print(df)

        return log_p_total / TEST_SIZE, kl_total / TEST_SIZE


    def save_record(self):
        # here just to overwrite base class's save_record
        pass

File Path: src/models/mlp.py
Content:
import torch
import torch.nn as nn


class MLP(nn.Module):
    def __init__(self, dims, non_linearity):
        """
        Args:
            dims: list of ints
            non_linearity: differentiable function

        Returns: nn.Module which represents an MLP with architecture

            x -> Linear(dims[0], dims[1]) -> non_linearity ->
            ...
            Linear(dims[-3], dims[-2]) -> non_linearity ->
            Linear(dims[-2], dims[-1]) -> y"""

        super(MLP, self).__init__()
        self.dims = dims
        self.non_linearity = non_linearity
        self.linear_modules = nn.ModuleList()
        for in_dim, out_dim in zip(dims[:-1], dims[1:]):
            self.linear_modules.append(nn.Linear(in_dim, out_dim))

    def forward(self, x):
        temp = x
        for linear_module in self.linear_modules[:-1]:
            temp = self.non_linearity(linear_module(temp))
        return self.linear_modules[-1](temp)


class MLPTwoProng(nn.Module):
    def __init__(self, dims, non_linearity):
        """
        Args:
            dims: list of ints
            non_linearity: differentiable function

        Returns: nn.Module which represents an MLP with architecture

            x -> Linear(dims[0], dims[1]) -> non_linearity ->
            ...
            Linear(dims[-3], dims[-2]) ->
            non_linearity -> Linear(dims[-2], dims[-1]) -> mu
                          -> Linear(dims[-2], dims[-1]) -> exp -> std

        """

        super(MLPTwoProng, self).__init__()
        self.dims = dims
        self.non_linearity = non_linearity
        self.linear_modules = nn.ModuleList()
        for in_dim, out_dim in zip(dims[:-1], dims[1:]):
            self.linear_modules.append(nn.Linear(in_dim, out_dim))
        self.logsigma = nn.Linear(in_dim, out_dim)

    def forward(self, x):
        temp = x
        for linear_module in self.linear_modules[:-1]:
            temp = self.non_linearity(linear_module(temp))
        mu = self.linear_modules[-1](temp)
        sig = torch.exp(self.logsigma(temp))
        return mu, sig


class ControlVariate(nn.Module):
    def __init__(self, num_mixtures, device=torch.device('cpu')):
        super(ControlVariate, self).__init__()
        self.num_mixtures = num_mixtures
        self.mlp = nn.Sequential(
            nn.Linear(num_mixtures, 16),
            nn.Tanh(),
            nn.Linear(16, 16),
            nn.Tanh(),
            nn.Linear(16, 1)
        )
        self.device = device

    def forward(self, aux, mean=True):
        """Args:
            aux: tensor of shape [batch_size, S, num_mixtures]
            obs: tensor of shape [batch_size]

        Returns: tensor of shape [batch_size]
        """
        batch_size, S, num_mixtures = aux.shape
        input = aux.view(-1, num_mixtures)
        output = self.mlp(input).squeeze(-1).view(batch_size, S)
        if mean:
            return torch.mean(output, dim=1)
        else:
            return output


def init_mlp(in_dim, out_dim, hidden_dim, num_layers, non_linearity):
    """Initializes a MultilayerPerceptron.

    Args:
        in_dim: int
        out_dim: int
        hidden_dim: int
        num_layers: int
        non_linearity: differentiable function

    Returns: a MultilayerPerceptron with the architecture

        x -> Linear(in_dim, hidden_dim) -> non_linearity ->
        ...
        Linear(hidden_dim, hidden_dim) -> non_linearity ->
        Linear(hidden_dim, out_dim) -> y

        where num_layers = 0 corresponds to

        x -> Linear(in_dim, out_dim) -> y"""
    dims = [in_dim] + [hidden_dim for _ in range(num_layers)] + [out_dim]
    return MLP(dims, nn.Tanh())


def init_two_prong_mlp(in_dim, out_dim, hidden_dim, num_layers, non_linearity=nn.Tanh()):
    """Initializes a MultilayerPerceptronNormal.

    Args:
        in_dim: int
        out_dim: int
        hidden_dim: int
        num_layers: int
        non_linearity: differentiable function

    Returns: a MultilayerPerceptron with the architecture

        x -> Linear(in_dim, hidden_dim) -> non_linearity ->
        ...
        Linear(hidden_dim, hidden_dim) -> non_linearity ->
        Linear(hidden_dim, out_dim) -> y

        where num_layers = 0 corresponds to

        x -> Linear(in_dim, out_dim) -> mu
          -> Linear(in_dim, out_dim) -> exp -> std
        """
    dims = [in_dim] + [hidden_dim for _ in range(num_layers)] + [out_dim]
    return MLPTwoProng(dims, non_linearity)

File Path: src/models/model_handler.py
Content:
from src.models.vaes import DiscreteVAE, ContinuousVAE
from src.models.bnn import BayesianNetwork
from src.models.pcfg import PCFG
from src.pcfg_util import read_pcfg

def get_model(train_data_loader, args):
    if args.learning_task == 'continuous_vae':
        D = train_data_loader.dataset.image.shape[1]
        model = ContinuousVAE(D, args)
    elif args.learning_task == 'discrete_vae':
        D = train_data_loader.dataset.image.shape[1]
        train_obs_mean = train_data_loader.dataset.image.mean(0)
        model = DiscreteVAE(D, args, train_obs_mean)
    elif args.learning_task == 'bnn':
        w, h = train_data_loader.dataset.train_data.shape[1:]
        D = w * h
        num_batches = len(args.train_data_loader)
        model = BayesianNetwork(D, num_batches, args)
    elif args.learning_task == 'pcfg':
        grammar, true_production_probs = read_pcfg(args.data_path)
        model = PCFG(grammar, args)
        # PCFG not set up for gpu
        return model
    else:
        raise ValueError("Incorrect learning task: {} not valid".format(args.learning_task))
    if args.device.type == 'cuda':
        model.cuda()

    return model

File Path: src/models/pcfg.py
Content:
import torch
import torch.nn as nn
import src.pcfg_util as util
from torch.distributions import *
from src.models.base import ProbModelBaseClass
import numpy as np


class GenerativeModel(nn.Module):
    def __init__(self, grammar, production_probs_init=None, max_depth=30):
        super(GenerativeModel, self).__init__()
        self.grammar = grammar
        if self.grammar['name'] == 'polynomial':
            self.xs = torch.linspace(-10, 10, 100)
        if production_probs_init is None:
            self.production_logits = nn.ParameterDict({
                k: nn.Parameter(torch.randn((len(v),)))
                for k, v in grammar['productions'].items()})
        else:
            self.production_logits = nn.ParameterDict({
                k: nn.Parameter(torch.log(v))
                for k, v in production_probs_init.items()})
        self.max_depth = max_depth

    def sample_tree(self, symbol=None, depth=0):
        """Sample tree from prior.

        Args: start symbol
        Returns: list of lists or string
        """

        if symbol is None:
            symbol = self.grammar['start_symbol']

        if symbol in self.grammar['terminals']:
            return symbol
        elif depth > self.max_depth:
            return symbol
        else:
            dist = Categorical(logits=self.production_logits[symbol])
            production_index = dist.sample().detach()
            production = self.grammar['productions'][symbol][production_index]
            return [symbol] + \
                [self.sample_tree(s, depth=depth + 1) for s in production]

    def sample_tree_and_obs(self):
        """Samples a (tree, obs) tuple from prior."""

        tree = self.sample_tree()
        if self.grammar['name'] == 'astronomers':
            sentence = util.get_leaves(tree)
            obs = sentence
        elif self.grammar['name'] == 'polynomial':
            ys = util.eval_polynomial(tree, self.xs)
            obs = ys
        return tree, obs

    def sample_obs(self):
        """Samples obs from prior."""

        return self.sample_tree_and_obs()[1]

    def get_tree_log_prob(self, tree):
        """Log probability of tree.

        Args:
            tree: list of lists or string

        Returns: scalar tensor
        """

        if isinstance(tree, list):
            non_terminal = tree[0]
            subtrees = tree[1:]
            production = [util.get_root(subtree) for subtree in subtrees]
            production_index = util.get_production_index(
                non_terminal, production, self.grammar['productions'])
            dist = Categorical(logits=self.production_logits[non_terminal])
            log_prob = dist.log_prob(torch.tensor(production_index))
            subtree_log_probs = [self.get_tree_log_prob(subtree)
                                 for subtree in subtrees]
            return log_prob + sum(subtree_log_probs)
        else:
            return torch.zeros(())

    def get_sentence_log_likelihood(self, sentence, tree):
        """Minus ABC distance instead of log p(sentence | tree). ABC distance
        is the Levenshtein distance.

        Args:
            sentence: list of strings
            tree: list of lists or string

        Returns: scalar tensor"""

        sentence_from_tree = util.get_leaves(tree)
        levenshtein_distance = torch.tensor(
            util.get_levenshtein_distance(sentence_from_tree, sentence,
                                          self.grammar['terminals']),
            dtype=torch.float)
        # if levenshtein_distance.item() == 0:
        #     return levenshtein_distance
        # else:
        #     return torch.tensor(float('-inf'))
        # return -(torch.exp(levenshtein_distance) - 1)
        # return -levenshtein_distance
        return -levenshtein_distance**2

    def get_polynomial_log_likelihood(self, ys, tree):
        """Minus ABC distance instead of log p(ys | tree, xs) where xs is
            torch.linspace(-10, 10, 100). ABC distance is log(1 + mse).

        Args:
            ys: torch.tensor of shape [100]
            tree: list of lists or string

        Returns: -log(1 + mse(ys, eval(tree))); scalar tensor
        """

        return -torch.log(
            1 + util.mse(ys, util.eval_polynomial(tree, self.xs)))

    def get_log_prob(self, tree, obs, sum_prior_and_likelihood=True):
        """Joint log probability p(obs, tree).

        Args:
            tree: list of lists or string
            obs: sentence (list of strings) or ys (torch.tensor of shape [100])

        Returns: scalar tensor
        """

        if self.grammar['name'] == 'astronomers':
            sentence = obs
            if sum_prior_and_likelihood:
                return self.get_tree_log_prob(tree) + \
                    self.get_sentence_log_likelihood(sentence, tree)
            else:
                return self.get_tree_log_prob(tree), self.get_sentence_log_likelihood(sentence, tree)

            # The following is the non-ABC version for which p(sentence | tree)
            # is 1 if tree's leaves match the sentence and 0 otherwise
            #
            # if util.get_leaves(tree) == sentence:
            #     return self.get_tree_log_prob(tree)
            # else:
            #     return torch.tensor(float('-inf'))
        elif self.grammar['name'] == 'polynomial':
            ys = obs
            if sum_prior_and_likelihood:
                return self.get_tree_log_prob(tree) + \
                    self.get_polynomial_log_likelihood(ys, tree)
            else:
                return self.get_tree_log_prob(tree), self.get_polynomial_log_likelihood(ys, tree)


class InferenceNetwork(nn.Module):
    def __init__(self, grammar, obs_embedding_dim=100,
                 inference_hidden_dim=100, max_depth=30):
        super(InferenceNetwork, self).__init__()
        self.grammar = grammar
        self.obs_embedding_dim = obs_embedding_dim
        self.inference_hidden_dim = inference_hidden_dim
        self.max_depth = max_depth
        self.sample_address_embedding_dim = len(grammar['non_terminals'])
        self.word_embedding_dim = len(self.grammar['terminals'])

        if grammar['name'] == 'astronomers':
            self.sentence_embedder_gru = nn.GRU(
                input_size=self.word_embedding_dim,
                hidden_size=self.obs_embedding_dim,
                num_layers=1)
        elif grammar['name'] == 'polynomial':
            self.xs = torch.linspace(-10, 10, 100)
            self.gray_embedder_cnn = nn.Sequential(
                nn.Conv2d(1, 20, 3),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(20, 20, 3),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(20, 20, 3),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(20, 10, 3),
                nn.ReLU())
            self.gray_embedder_mlp = nn.Sequential(
                nn.Linear(640, 320),
                nn.ReLU(),
                nn.Linear(320, 160),
                nn.ReLU(),
                nn.Linear(160, obs_embedding_dim))
        self.sample_embedding_dim = max(
            [len(v) for _, v in self.grammar['productions'].items()])
        self.inference_gru = nn.GRUCell(
            input_size=self.obs_embedding_dim + self.sample_embedding_dim
            + self.sample_address_embedding_dim,
            hidden_size=self.inference_hidden_dim)
        self.proposal_layers = nn.ModuleDict({
            k: nn.Sequential(nn.Linear(inference_hidden_dim, 50),
                             nn.ReLU(),
                             nn.Linear(50, 25),
                             nn.ReLU(),
                             nn.Linear(25, len(v)))
            for k, v in grammar['productions'].items()})

    def get_sentence_embedding(self, sentence):
        """Args:
            sentence: list of strings

        Returns: tensor of shape [obs_embedding_dim]
        """

        output, _ = self.sentence_embedder_gru(util.sentence_to_one_hots(
            sentence, self.grammar['terminals']).unsqueeze(1))
        return output[-1][0]

    def get_ys_embedding(self, ys):
        """Args:
            ys: tensor of shape [100]

        Returns: tensor of shape [obs_embedding_dim]
        """

        gray = util.xsys2gray(self.xs, ys)
        input_to_mlp = self.gray_embedder_cnn(
            gray.view(1, 1, 100, 100)).view(-1).squeeze(0)
        return self.gray_embedder_mlp(input_to_mlp).squeeze(0)

    def get_obs_embedding(self, obs):
        """Args:
            obs: sentence (list of strings) or ys (torch.tensor of shape [100])

        Returns: tensor of shape [obs_embedding_dim]
        """

        if self.grammar['name'] == 'astronomers':
            sentence = obs
            return self.get_sentence_embedding(sentence)
        elif self.grammar['name'] == 'polynomial':
            ys = obs
            return self.get_ys_embedding(ys)

    def get_logits_from_inference_gru_output(self, inference_gru_output,
                                             non_terminal):
        """Args:
            inference_gru_output: tensor of shape [inference_hidden_dim]
            non_terminal: string

        Returns: logits for Categorical distribution
        """

        input_ = inference_gru_output.unsqueeze(0)
        return self.proposal_layers[non_terminal](input_).squeeze(0)

    def get_sample_embedding(self, production_index):
        """Args: int

        Returns: one hot vector of shape [sample_embedding_dim]
        """
        return util.one_hot(torch.tensor([production_index]),
                            self.sample_embedding_dim)[0]

    def get_inference_gru_output(self, obs_embedding,
                                 previous_sample_embedding,
                                 sample_address_embedding, inference_hidden):
        """Args:
            obs_embedding: tensor [obs_embedding_dim]
            previous_sample_embedding: tensor [sample_embedding_dim]
            sample_address_embedding: tensor [sample_embedding_address_dim]
            inference_hidden: tensor [inference_hidden_dim]

        Returns: tensor [inference_hidden_dim]
        """

        return self.inference_gru(
            torch.cat([obs_embedding,
                       previous_sample_embedding,
                       sample_address_embedding]).unsqueeze(0),
            inference_hidden.unsqueeze(0)).squeeze(0)

    def get_tree_log_prob(self, tree, obs_embedding=None,
                          previous_sample_embedding=None,
                          inference_hidden=None, obs=None):
        """Log probability of tree given obs.

        Args:
            tree: list or string
            obs_embedding: tensor [obs_embedding_dim]
            previous_sample_embedding: tensor [sample_embedding_dim]
            inference_hidden: tensor [inference_hidden_dim]
            obs: sentence (list of strings) or ys (torch.tensor of shape [100])

        Returns: log_prob (scalar tensor)"""

        if obs_embedding is None:
            obs_embedding = self.get_obs_embedding(obs)

        if previous_sample_embedding is None:
            previous_sample_embedding = torch.zeros(
                (self.sample_embedding_dim,))

        if inference_hidden is None:
            inference_hidden = torch.zeros((self.inference_hidden_dim,))

        if isinstance(tree, list):
            non_terminal = tree[0]
            sample_address_embedding = util.get_sample_address_embedding(
                non_terminal, self.grammar['non_terminals'])
            inference_gru_output = self.get_inference_gru_output(
                obs_embedding, previous_sample_embedding,
                sample_address_embedding, inference_hidden)

            subtrees = tree[1:]
            production = [util.get_root(subtree) for subtree in subtrees]
            production_index = util.get_production_index(
                non_terminal, production, self.grammar['productions'])
            sample_embedding = self.get_sample_embedding(production_index)
            logits = self.get_logits_from_inference_gru_output(
                inference_gru_output, non_terminal)
            dist = Categorical(logits=logits)
            log_prob = dist.log_prob(torch.tensor(production_index))
            subtree_log_probs = [
                self.get_tree_log_prob(subtree, obs_embedding,
                                       sample_embedding, inference_gru_output)
                for subtree in subtrees]
            return log_prob + sum(subtree_log_probs)
        else:
            return torch.zeros(())

    def sample_tree(self, symbol=None, obs_embedding=None,
                    previous_sample_embedding=None, inference_hidden=None,
                    obs=None, depth=0):
        """Samples a tree given a obs and a start symbol (can be terminal
            or non-terminal).

        Args:
            symbol: string
            obs_embedding: tensor [obs_embedding_dim]
            previous_sample_embedding: tensor [sample_embedding_dim]
            inference_hidden: tensor [inference_hidden_dim]
            obs: sentence (list of strings) or ys (torch.tensor of shape [100])

        Returns: tree
        """

        if symbol is None:
            symbol = self.grammar['start_symbol']

        if obs_embedding is None:
            obs_embedding = self.get_obs_embedding(obs)

        if previous_sample_embedding is None:
            previous_sample_embedding = torch.zeros(
                (self.sample_embedding_dim,))

        if inference_hidden is None:
            inference_hidden = torch.zeros((self.inference_hidden_dim,))

        if symbol in self.grammar['terminals']:
            return symbol
        elif depth > self.max_depth:
            return symbol
        else:
            sample_address_embedding = util.get_sample_address_embedding(
                symbol, self.grammar['non_terminals'])
            inference_gru_output = self.get_inference_gru_output(
                obs_embedding, previous_sample_embedding,
                sample_address_embedding, inference_hidden)
            logits = self.get_logits_from_inference_gru_output(
                inference_gru_output, symbol)
            dist = Categorical(logits=logits)
            production_index = dist.sample().detach()
            sample_embedding = self.get_sample_embedding(production_index)
            production = self.grammar['productions'][symbol][production_index]

            return [symbol] + [
                self.sample_tree(s, obs_embedding, sample_embedding,
                                 inference_gru_output, depth=depth + 1)
                for s in production]

    def sample_tree_relax(self, symbol=None, obs_embedding=None,
                          previous_sample_embedding=None,
                          inference_hidden=None, obs=None, depth=0):
        """Samples a tree given a obs and a start symbol (can be terminal
            or non-terminal).

        Args:
            symbol: string
            obs_embedding: tensor [obs_embedding_dim]
            previous_sample_embedding: tensor [sample_embedding_dim]
            inference_hidden: tensor [inference_hidden_dim]
            obs: sentence (list of strings) or ys (torch.tensor of shape [100])

        Returns:
            tree: e.g.
                ['S', ['NP', 'astronomers'],
                      ['VP', ['V' 'saw'],
                             ['NP' 'stars']]]
                or 'stars'
            tree_aux: e.g.
                [[0.5], [[.9, 1., .2, .1, -.1, .1], None],
                        [[-0.3 0.8], [[0.3], None]
                                     [[.9, -.1, .2, .1, 1., .1], None]]]
                or None
            tree_aux_tilde: similar to tree_aux
        """

        if symbol is None:
            symbol = self.grammar['start_symbol']

        if obs_embedding is None:
            obs_embedding = self.get_obs_embedding(obs)

        if previous_sample_embedding is None:
            previous_sample_embedding = torch.zeros(
                (self.sample_embedding_dim,))

        if inference_hidden is None:
            inference_hidden = torch.zeros((self.inference_hidden_dim,))

        if symbol in self.grammar['terminals']:
            return symbol, None, None
        elif depth > self.max_depth:
            return symbol, None, None
        else:
            sample_address_embedding = util.get_sample_address_embedding(
                symbol, self.grammar['non_terminals'])
            inference_gru_output = self.get_inference_gru_output(
                obs_embedding, previous_sample_embedding,
                sample_address_embedding, inference_hidden)
            logits = self.get_logits_from_inference_gru_output(
                inference_gru_output, symbol)
            oh_production_index, production_index_aux, \
                production_index_aux_tilde = util.sample_relax(logits=logits)
            production_index = torch.argmax(oh_production_index)
            sample_embedding = self.get_sample_embedding(production_index)
            production = self.grammar['productions'][symbol][production_index]

            tree = [symbol]
            tree_aux = [production_index_aux]
            tree_aux_tilde = [production_index_aux_tilde]
            for s in production:
                subtree, subtree_aux, subtree_aux_tilde = \
                    self.sample_tree_relax(
                        s, obs_embedding, sample_embedding,
                        inference_gru_output, depth=depth + 1)
                tree.append(subtree)
                tree_aux.append(subtree_aux)
                tree_aux_tilde.append(subtree_aux_tilde)
            return tree, tree_aux, tree_aux_tilde


class ControlVariate(nn.Module):
    def __init__(self, grammar, obs_embedding_dim=100,
                 tree_obs_embedding_dim=100):
        super(ControlVariate, self).__init__()
        self.grammar = grammar
        self.obs_embedding_dim = obs_embedding_dim
        self.word_embedding_dim = len(self.grammar['terminals'])
        self.tree_obs_embedding_dim = tree_obs_embedding_dim
        self.obs_embedder_gru = nn.GRU(
            input_size=self.word_embedding_dim,
            hidden_size=self.obs_embedding_dim,
            num_layers=1)
        self.sample_address_embedding_dim = len(grammar['non_terminals'])
        self.sample_embedding_dim = max(
            [len(v) for _, v in grammar['productions'].items()])
        self.tree_obs_embedder_gru = nn.GRUCell(
            input_size=self.obs_embedding_dim + self.sample_embedding_dim +
            self.sample_address_embedding_dim,
            hidden_size=tree_obs_embedding_dim)
        self.tree_obs_mlp = nn.Sequential(
            nn.Linear(tree_obs_embedding_dim, 50),
            nn.ReLU(),
            nn.Linear(50, 25),
            nn.ReLU(),
            nn.Linear(25, 1))

    def get_obs_embedding(self, obs):
        """Args:
            obs: list of strings

        Returns: tensor of shape [obs_embedding_dim]
        """

        output, _ = self.obs_embedder_gru(util.sentence_to_one_hots(
            obs, self.grammar['terminals']).unsqueeze(1))
        return output[-1][0]

    def get_tree_obs_gru_output(self, obs_embedding, sample_embedding,
                                sample_address_embedding, tree_obs_hidden):
        """Args:
            obs_embedding: tensor [obs_embedding_dim]
            sample_embedding: tensor [sample_embedding_dim]
            sample_address_embedding: tensor [sample_embedding_address_dim]
            tree_obs_hidden: tensor [tree_obs_embedding_dim]

        Returns: tensor of shape [tree_obs_embedding_dim]
        """
        return self.tree_obs_embedder_gru(
            torch.cat([obs_embedding,
                       sample_embedding,
                       sample_address_embedding]).unsqueeze(0),
            tree_obs_hidden.unsqueeze(0)).squeeze(0)

    def get_tree_obs_embedding(self, tree, tree_aux, obs_embedding):
        """Args:
            tree: e.g.
                ['S', ['NP', 'astronomers'],
                      ['VP', ['V' 'saw'],
                             ['NP' 'stars']]]
                or 'stars'
            tree_aux: e.g.
                [[0.5], [[.9, 1., .2, .1, -.1, .1], None],
                        [[-0.3 0.8], [[0.3], None]
                                     [[.9, -.1, .2, .1, 1., .1], None]]]
                or None
            obs_embedding: tensor of shape [obs_embedding_dim]

        Returns: tensor of shape [tree_obs_embedding_dim]
        """

        if isinstance(tree, list):
            non_terminal = tree[0]
            sample_address_embedding = util.get_sample_address_embedding(
                non_terminal, self.grammar['non_terminals'])
            sample_embedding = util.pad_zeros(tree_aux[0],
                                              self.sample_embedding_dim)
            subtrees = tree[1:]
            subtrees_aux = tree_aux[1:]
            tree_obs_hidden = 0
            for subtree, subtree_aux in zip(subtrees, subtrees_aux):
                tree_obs_hidden += self.get_tree_obs_embedding(
                    subtree, subtree_aux, obs_embedding)
            return self.get_tree_obs_gru_output(
                obs_embedding, sample_embedding, sample_address_embedding,
                tree_obs_hidden)
        else:
            return torch.zeros((self.tree_obs_embedding_dim,))

    def control_variate_single(self, tree, tree_aux, obs_embedding):
        """Args:
            tree: e.g.
                ['S', ['NP', 'astronomers'],
                      ['VP', ['V' 'saw'],
                             ['NP' 'stars']]]
                or 'stars'
            tree_aux: e.g.
                [[0.5], [[.9, 1., .2, .1, -.1, .1], None],
                        [[-0.3 0.8], [[0.3], None]
                                     [[.9, -.1, .2, .1, 1., .1], None]]]
                or None
            obs_embedding: tensor of shape [obs_embedding_dim]

        Returns: scalar tensor
        """
        return self.tree_obs_mlp(self.get_tree_obs_embedding(
            tree, tree_aux, obs_embedding).unsqueeze(0)).squeeze(0)

    def forward(self, trees, trees_aux, obs_embeddings):
        """Args:
            trees_aux: list of lists of shape [num_obs, num_particles] where
                each element is either a tree_aux or tree_aux_tilde
            obs_embeddings: list of tensors of length num_obs where each tensor
                is of shape [obs_embedding_dim]

        Returns: tensor of shape [num_obs]
        """

        num_obs = len(obs_embeddings)
        num_particles = len(trees_aux[0])
        c = torch.zeros(num_obs, num_particles)
        for obs_idx in range(num_obs):
            for particle_idx in range(num_particles):
                c[obs_idx, particle_idx] = self.control_variate_single(
                    trees[obs_idx][particle_idx],
                    trees_aux[obs_idx][particle_idx], obs_embeddings[obs_idx])
        return torch.logsumexp(c, dim=1) - np.log(num_particles)



class PCFG(ProbModelBaseClass):
    def __init__(self, grammar, args, **kwargs):
        D = None # trees have no fixed dimension
        super(PCFG, self).__init__(D, args)
        self.generative_model = GenerativeModel(grammar, **kwargs)
        self.inference_network = InferenceNetwork(grammar, **kwargs)

        self._log_q = None
        self._log_prior = None
        self._log_likelihood = None


    def set_internals(self, data, S):
        self.x = data[0]
        self.y = False # unsupervised
        self.z = False # we compute log_prior, log_likelihood, log_guide directly below

        log_q = torch.zeros(len(self.x), S)
        log_prior = torch.zeros(len(self.x), S)
        log_likelihood = torch.zeros(len(self.x), S)

        # this is painful, batching difficult b/c of different length trees.
        # therefore iterate once and save log_prior, log_guide, log_likelihood
        # manually
        for obs_idx, obs in enumerate(self.x):
            for particle_idx in range(S):
                tree = self.inference_network.sample_tree(obs=obs)
                log_q_ = self.inference_network.get_tree_log_prob(tree, obs=obs)
                log_prior_, log_likelihood_ = self.generative_model.get_log_prob(tree, obs, sum_prior_and_likelihood=False)
                log_q[obs_idx, particle_idx] = log_q_
                log_prior[obs_idx, particle_idx] = log_prior_
                log_likelihood[obs_idx, particle_idx] = log_likelihood_

        self._log_q  = log_q
        self._log_prior  = log_prior
        self._log_likelihood  = log_likelihood

        self.check_internals()

    def check_internals(self):
        super().check_internals()
        assert self._log_q is not None, "self._log_q not set"
        assert self._log_prior is not None, "self._log_prior not set"
        assert self._log_likelihood is not None, "self._log_likelihood not set"

    def sample_latent(self, S, sample=True):
        raise ValueError("Sample latent not used in PCFG")

    def log_prior(self):
        return self._log_prior

    def log_guide(self):
        return self._log_q

    def log_likelihood(self):
        return self._log_likelihood

    # These functions are overwritten to avoid repeated calls to set_internal which is expensive
    def train_epoch_single_objective(self, data_loader, optimizer, epoch=None):
        train_logpx = 0
        train_elbo = 0
        train_tvo_log_evidence = 0

        for idx, data in enumerate(data_loader):
            optimizer.zero_grad()
            loss, logpx, elbo, tvo_log_evidence = self.forward(data)
            loss.backward()
            optimizer.step()

            train_logpx += logpx.item()
            train_elbo += elbo.item()
            train_tvo_log_evidence+=tvo_log_evidence.item()

        train_logpx = train_logpx / len(data_loader)
        train_elbo = train_elbo / len(data_loader)
        train_tvo_log_evidence = train_tvo_log_evidence/len(data_loader)

        self.evaluate_pq(data_loader, epoch)

        return train_logpx, train_elbo, train_tvo_log_evidence


    def train_epoch_dual_objectives(self, data_loader, optimizer_phi, optimizer_theta, epoch=None):
        train_logpx = 0
        train_elbo = 0
        train_tvo_log_evidence = 0
        for idx, data in enumerate(data_loader):
            optimizer_phi.zero_grad()
            optimizer_theta.zero_grad()
            if self.args.loss == 'tvo-sleep':
                wake_theta_loss = self.get_tvo_loss(data)
            else:
                wake_theta_loss = self.get_wake_theta_loss(data)
            wake_theta_loss.backward()
            optimizer_theta.step()

            optimizer_phi.zero_grad()
            optimizer_theta.zero_grad()

            if self.args.loss in ['wake-sleep', 'tvo-sleep']:
                sleep_phi_loss = self.get_sleep_phi_loss()
                sleep_phi_loss.backward()
            elif self.args.loss in ['wake-wake']:
                wake_phi_loss = self.get_wake_phi_loss(data)
                wake_phi_loss.backward()
            else:
                raise ValueError(
                    "{} is an invalid loss".format(self.args.loss))

            optimizer_phi.step()

            with torch.no_grad():
                log_weight = self.elbo()
                logpx = self.get_test_log_evidence(data, self.args.S, log_weight=log_weight)
                elbo = self.get_test_elbo(data, self.args.S, log_weight=log_weight)
                tvo_log_evidence = self.get_tvo_log_evidence(data, self.args.S, log_weight=log_weight)

            train_logpx += logpx.item()
            train_elbo += elbo.item()
            train_tvo_log_evidence+=tvo_log_evidence.item()

        train_logpx = train_logpx / len(data_loader)
        train_elbo = train_elbo / len(data_loader)
        train_tvo_log_evidence=train_tvo_log_evidence/len(data_loader)

        self.evaluate_pq(data_loader, epoch)

        return train_logpx, train_elbo, train_tvo_log_evidence

    def forward(self, data):
        assert isinstance(data, (tuple, list)), "Data must be a tuple (X,y) or (X, )"

        if self.args.loss == 'reinforce':
            loss = self.get_reinforce_loss(data)
        elif self.args.loss == 'thermo' or self.args.loss == 'tvo':
            loss = self.get_tvo_loss(data)
        else:
            raise ValueError("{} is an invalid loss".format(self.args.loss))

        # This functions is overwritten to avoid repeated calls to set_internal which is expensive
        with torch.no_grad():
            log_weight = self.elbo()
            logpx = self.get_test_log_evidence(data, self.args.S, log_weight=log_weight)
            elbo = self.get_test_elbo(data, self.args.S, log_weight=log_weight)
            tvo_log_evidence = self.get_tvo_log_evidence(data, self.args.S, log_weight=log_weight)

        return loss, logpx, elbo, tvo_log_evidence

    def evaluate_pq(self, data_loader, epoch):
        true_generative_model = data_loader.dataset.true_generative_model

        metrics = {
            "p_error":util.get_p_error(true_generative_model, self.generative_model),
            "q_error_to_true":util.get_q_error(true_generative_model, self.inference_network),
            "q_error_to_model":util.get_q_error(self.generative_model, self.inference_network)
            }

        for k, v in metrics.items():
            self.args._run.log_scalar(k, float(v), epoch)

        loss_string = " ".join(("{}: {:.4f}".format(*i) for i in metrics.items()))
        print(f"Epoch: {epoch} - {loss_string}")

    def get_sleep_phi_loss(self):
        """Returns:
            loss: scalar that we call .backward() on and step the optimizer.
        """
        log_q_sum = 0
        for _ in range(self.args.S):
            tree, obs = self.generative_model.sample_tree_and_obs()
            log_q = self.inference_network.get_tree_log_prob(tree, obs=obs)
            log_q_sum = log_q_sum + log_q
        return -log_q_sum / self.args.S

File Path: src/models/updates.py
Content:
import torch
from torch import optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.distributions.uniform import Uniform
from torch.distributions.beta import Beta
import copy

#import torch.nn as nn
from functools import partial
import numpy as np
from src.util import compute_tvo_loss, compute_wake_theta_loss, compute_wake_phi_loss, get_curvature_loss_and_grad
from src.util import compute_vimco_loss, exponentiate_and_normalize
from src.util import calc_exp, calc_var_given_betas, get_total_log_weight, _get_multiplier
from src import gp_bandit
from src import ml_helpers as mlh

def get_partition_scheduler(args):
    """
    Args:
        args : arguments from main.py
    Returns:
        callable beta_update function
    * callable has interface f(log_iw, args, **kwargs)
    * returns beta_id, or unchanged args.partition, by default
    Beta_update functions:
        *** MUST be manually specified here
        * given via args.partition_type and other method-specific args
        * should handle 0/1 endpoint insertion internally
        * may take args.K - 1 partitions as a result (0 is given)
    """

    schedule = args.schedule
    P = args.K - 1

    if schedule=='gp_bandit' or schedule=="gp"  or schedule=="gptv":
        return GP_bandits
    elif schedule=='rand':
        return rand_search
#    elif schedule=='gp_bandit_log':
#        return GP_bandits_log
    elif schedule in ['log', 'linear']:
        return beta_id
    elif schedule in ['moments']:
        return moments
#    elif schedule =='beta_gradient_descent':
#        return beta_gradient_descent
#    elif schedule =='beta_batch_gradient':
#        return beta_gradient_descent


def beta_id(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """

    """
    f = bayes_quad.get_integrand_function(model, args)
    f_beta0=f(mlh.tensor(0,args)) # compute f(beta=0)
    args.f_beta0=f_beta0
    f=bayes_quad.get_integrand_function_subtract_beta0(model,args) #redefine the function using f(beta=0)
    Ytensor=f(args.partition)
    Y=Ytensor.data.cpu().numpy()

    try:
        oldY=np.load("Y_linear50")
    except:
        oldY=np.empty((0,1+args.K),float)
    oldY=np.vstack((oldY,np.reshape(Y,(1,-1))))
    np.save("Y_linear50",oldY)
    """
    #print(args.partition)
    return args.partition


def rand_search(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """
    SearchSpace=np.asarray([0,1.0]*(args.K-1)).astype(float) # this is the search range of beta from 0-1
    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))
    init_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))
    init_X=np.around(init_X, decimals=4)
    init_X=np.append(0,init_X)
    init_X=np.append(init_X,1)

    init_X= np.sort(init_X)
    print(init_X)

    points=mlh.tensor(init_X,args)

    return points


def safe_step(partition, steps, min_val = 10**-6, max_val = 1.0, max_step = 0.01, adaptive = False, descent = False):
    ''' implement checks on beta values and sort if necessary after gradient descent step

        max_step : clips absolute value of steps = step_size * beta_derivative
        "adaptive" is very heuristic:
            scale down step size until at most 1 update is > max_step (maybe should be >= 1 since often only 1 big update)
    '''

    max_step = torch.ones_like(steps)*max_step
    min_val = torch.ones_like(partition)*min_val
    max_val = torch.ones_like(partition)*max_val;


    if adaptive:
        n_greater_than_max = torch.where(torch.abs(steps) > max_step, torch.ones_like(steps), torch.zeros_like(steps))
        while torch.sum(n_greater_than_max).item() > 1 :
            steps = steps*.1
            n_greater_than_max = torch.where(torch.abs(steps) > max_step, torch.ones_like(steps), torch.zeros_like(steps))
    else:
        steps = torch.where(torch.abs(steps) < max_step, steps, max_step*torch.sign(steps))

    partition = partition - steps.cpu() if descent else partition + steps.cpu()
    partition = torch.where(partition>=min_val, partition, min_val)
    partition = torch.where(partition<=max_val, partition, min_val)
    partition, _ = torch.sort(partition)
    return partition


def get_beta_derivative_diffs(model, args):
    '''
    Reads stored means in self.expectation_diffs and returns beta derivatives according to "async" or epoch update derivation ( i.e. variance term * 0 )
    Let f(β) = E_β log p(x,z)/q(z|x) , f'(β) = Var_β log p(x,z)/q(z|x)

    d TVO / dβ_k = f(β_k-1) - f(β_k ) - (β_k+1 - β_k) f'(β_k)

    only calculates for indices 1 => K-1 ( 0 and 1 are fixed )
    '''

    # if isinstance(model.expectation_diffs, mlh.AccumulatedDiff):
    #      # Not currently being used
    #     beta_deriv = torch.stack([(model.expectation_diffs.current[k-1] - model.expectation_diffs.current[k]) for k in range(1,model.expectation_diffs.current.shape[0]-1)])
    #     model.expectation_diffs.reset()
    # else:


    # expectation_diffs [k]= change in f(β_{k}),  derivative = change in expectation_diffs across beta

    # if isinstance(model.expectation_diffs, int):
    #     beta_deriv = torch.zeros_like(model.args.partition[1:-1].data)
    # else:
    # beta_deriv = torch.stack([(model.expectation_diffs[k-1] - model.expectation_diffs[k]) \
    #                  for k in range(1,model.expectation_diffs.shape[0]-1)])


    tvo_exps = model.exp_meter.mean.data
    tvo_vars = model.var_meter.mean.data
    last_exps = model.exp_last.data
    last_vars = model.var_last.data
    d_beta =  _get_multiplier(args.partition, 'left').squeeze().data

    # "two step" update => minus last
    beta_deriv = torch.stack( [ (tvo_exps[k-1] - tvo_exps[k]) - (last_exps[k-1] - last_exps[k] ) + d_beta[k]*(tvo_vars[k] -last_vars[k]) \
                              for k in range(1, tvo_exps.shape[0]-1) ]  )

    return beta_deriv

def get_beta_derivative_single(model, args):
    '''
    Reads stored means in self.expectation_diffs and returns beta derivatives according to "async" or epoch update derivation ( i.e. variance term * 0 )
    Let f(β) = E_β log p(x,z)/q(z|x) , f'(β) = Var_β log p(x,z)/q(z|x)

    d TVO / dβ_k = f(β_k-1) - f(β_k ) - (β_k+1 - β_k) f'(β_k)

    only calculates for indices 1 => K-1 ( 0 and 1 are fixed )
    '''

    # if isinstance(model.expectation_diffs, mlh.AccumulatedDiff):
    #      # Not currently being used
    #     beta_deriv = torch.stack([(model.expectation_diffs.current[k-1] - model.expectation_diffs.current[k]) for k in range(1,model.expectation_diffs.current.shape[0]-1)])
    #     model.expectation_diffs.reset()
    # else:


    # expectation_diffs [k]= change in f(β_{k}),  derivative = change in expectation_diffs across beta

    # if isinstance(model.expectation_diffs, int):
    #     beta_deriv = torch.zeros_like(model.args.partition[1:-1].data)
    # else:
    # beta_deriv = torch.stack([(model.expectation_diffs[k-1] - model.expectation_diffs[k]) \
    #                  for k in range(1,model.expectation_diffs.shape[0]-1)])

    tvo_exps = model.exp_meter.mean.data
    tvo_vars = model.var_meter.mean.data
    last_exps = model.exp_last.data
    last_vars = model.var_last.data
    d_beta =  _get_multiplier(args.partition, 'left').squeeze().data

    # "two step" update => minus last
    beta_deriv = torch.stack( [ (tvo_exps[k-1] - tvo_exps[k]) + d_beta[k]*tvo_vars[k] \
                              for k in range(1, tvo_exps.shape[0]-1) ]  )
    #  - (last_exps[k-1] - last_exps[k] )
    return beta_deriv



def beta_gradient_descent(model, args, cpu = True, diffs = False):
    '''
    perform manual gradient descent on beta
    - get_beta_derivative_no_var : returns dTVO / dbeta and resets beta tracking
    - safe_step clips updates

    recalculate = True is used for beta_batch_gradient
        - init_expectation = expectation before θ gradient descent update
        - expectation_diffs = expectation after θ gradient descent update
    '''

    if args.schedule=='beta_batch_gradient':
        # used to update per_batch
        # (re-calculate expectations, variance post θ-update)
        log_weight = model.elbo()
        tvo_exps = calc_exp(log_weight, args, all_sample_mean=True)
        tvo_vars = calc_var_given_betas(log_weight, args, all_sample_mean=True)

        model.exp_meter.step(tvo_exps.data)
        model.var_meter.step(tvo_vars.data)

        #if model.exp_last is None or model.var_last is None:
        #    model.exp_last = tvo_exps.data
        #    model.var_last = tvo_vars.data


    #model.expectation_diffs = tvo_exps.data - model.init_expectation
    elif model.exp_last is None or isinstance(model.exp_meter.mean, int):
        # unchanged for first epoch after burn-in on beta_gradient_descent
        return args.partition


    # also resets expectation differences
    if diffs:
        beta_derivatives = get_beta_derivative_diffs(model, args)
    else:
        beta_derivatives = get_beta_derivative_single(model, args)

    model.reset_track_beta()


    # Gradient Descent STEP
    sliced_partition = args.partition.data[1:-1]
    sliced_partition = sliced_partition.cpu() if cpu else sliced_partition

    new_partition = safe_step(sliced_partition, args.beta_step_size * beta_derivatives, max_step = args.max_beta_step, adaptive=args.adaptive_beta_step)

    # pad 0 and 1
    new_partition = torch.cat([torch.zeros_like(new_partition[0]).unsqueeze(0), new_partition,  torch.ones_like(new_partition[0]).unsqueeze(0)])

    print(args.partition)
    print("new partition ", new_partition)
    print("beta steps ", args.beta_step_size * beta_derivatives)


    return new_partition.cuda() if cpu else new_partition


def GP_bandits(model, args):
    points = gp_bandit.calculate_BO_points(model, args)
    K=len(points)
    points=mlh.tensor(points,args)
    print("==================================")
    print("K={} points={}".format(K,points))
    print("==================================")
    #args.K = K
    return points


def moments(model, args=None, **kwargs):
    args  = model.args if args is None else args
    start = 0
    stop  = 1
    threshold = 0.05

    if not args.per_sample and not args.per_batch:
        log_iw = get_total_log_weight(model, args, args.valid_S)
    else:
        log_iw = model.elbo()

    partitions = args.K-1
    targets = np.linspace(0.0, 1.0, num=args.K+1, endpoint=True)

    left  = calc_exp(log_iw, start, all_sample_mean= not(args.per_sample))
    right = calc_exp(log_iw, stop, all_sample_mean= not(args.per_sample))
    left  = torch.mean(left, axis = 0, keepdims = True) if args.per_batch else left
    right = torch.mean(right, axis = 0, keepdims= True) if args.per_batch else right
    moment_avg = right - left

    beta_result = []
    for t in range(len(targets)):
        if targets[t] == 0.0 or targets[t] == 1.0:
            beta_result.append(targets[t] * (torch.ones_like(log_iw[:,0]) if args.per_sample else 1) ) # zero if targets[t]=0
        else:
            target = targets[t]
            moment = left + target*moment_avg #for t in targets]

            start = torch.zeros_like(log_iw[:,0]) if args.per_sample else torch.zeros_like(left)
            stop = torch.ones_like(log_iw[:,0]) if args.per_sample else torch.ones_like(left)

            beta_result.append(_moment_binary_search(\
                    moment, log_iw, start = start, stop = stop, \
                        threshold=threshold, per_sample = args.per_sample))

    if args.per_sample: #or args.per_batch:
        beta_result = torch.cat([b.unsqueeze(1) for b in beta_result], axis=1).unsqueeze(1)
        beta_result, _ = torch.sort(beta_result, -1)
    else:
        beta_result = torch.cuda.FloatTensor(beta_result)

    return beta_result

def _moment_binary_search(target, log_iw, start=0, stop= 1, threshold = 0.1, recursion = 0, per_sample = False, min_beta = 0.001): #recursion = 0,
    beta_guess = .5*(stop+start)
    eta_guess = calc_exp(log_iw, beta_guess, all_sample_mean = not per_sample).squeeze()
    target = torch.ones_like(eta_guess)*(target.squeeze())
    start_ = torch.where( eta_guess <  target,  beta_guess, start)
    stop_ = torch.where( eta_guess >  target, beta_guess , stop)

    if torch.sum(  torch.abs( eta_guess - target) > threshold ).item() == 0:
        return beta_guess
    else:
        if recursion > 500:
            return beta_guess
        else:
            return _moment_binary_search(
                target,
                log_iw,
                start= start_,
                stop= stop_,
                recursion = recursion + 1,
                per_sample = per_sample)

def beta_id(model, args = None, **kwargs):
    """
    dummy beta update for static / unspecified partition_types
    """
    return args.partition

File Path: src/models/vaes.py
Content:
from src.models.base import ProbModelBaseClass
from src.models.mlp import init_mlp, init_two_prong_mlp
import torch
from torch.distributions import Independent
import torch.nn as nn
from src import util


class VAEBaseClass(ProbModelBaseClass):
    def __init__(self, D, args):
        super(VAEBaseClass, self).__init__(D, args)

        self.num_stochastic_layers = args.num_stochastic_layers
        self.latent_dim = args.latent_dim
        self.hidden_dim = args.hidden_dim
        self.num_deterministic_layers = args.num_deterministic_layers

        if isinstance(self.latent_dim, int):
            self.latent_dims = [self.latent_dim for _ in range(
                self.num_stochastic_layers)]

        elif isinstance(self.latent_dim, list):
            assert len(self.latent_dim) == self.num_stochastic_layers
            self.latent_dims = self.latent_dim

        # Gen model
        self.decoders = None
        self.decoder_to_obs = None

        # Inf network
        self.encoder_to_obs = None
        self.encoders = None

        self.layer_0_params = None

        # internal distribution object set by
        # self.set_internals
        self.inf_network = None

    # ======== Model methods ========

    def get_decoder_latent_layer_param(self, layer_idx, previous_latent_layer=None):
        # pylint: disable=not-callable,unsubscriptable-object
        """Returns params of distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx > 0)

        Returns:
            mu for Normal latent of shape [N, latent_dim]
            sig for Normal latent of shape [N, latent_dim]

            if layer_idx is 0, shape [latent_dim],
            otherwise [N, latent_dim]"""

        if layer_idx == 0:
            return self.layer_0_params
        else:
            return self.decoders[str(layer_idx)](previous_latent_layer)

    def get_decoder_latent_layer(self, layer_idx, previous_latent_layer=None):
        # pylint: disable=not-callable,unsubscriptable-object,no-value-for-parameter
        """Returns distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx > 0)

        Returns: Normal distribution with event_shape [latent_dim]
            if layer_idx is 0, batch_shape is [],
            otherwise [N]"""

        mu, sig = self.get_decoder_latent_layer_param(
            layer_idx, previous_latent_layer)
        return Independent(torch.distributions.Normal(mu, sig), reinterpreted_batch_ndims=1)

    def get_decoder_latent_dist(self):
        """Returns: distribution for all latent layers:

            dist.sample(sample_shape=[sample_shape]) returns
            (latent_0, ..., latent_N) where each latent_n
            is of shape [sample_shape, latent_dim] and latent_0
            corresponds to the latent furthest away from obs

            if latent_n is of shape [batch_shape, latent_dim]
            dist.log_prob(latent_0, ..., latent_N) returns
            sum_n log_prob(latent_n) which is of shape [batch_shape]"""

        latent_dist = util.ChainDistributionFromSingle(
            self.get_decoder_latent_layer(layer_idx=0))
        for layer_idx in range(1, self.num_stochastic_layers):
            # be careful about closures
            # https://stackoverflow.com/questions/2295290/what-do-lambda-function-closures-capture/2295372
            latent_dist = util.ChainDistribution(
                latent_dist,
                lambda previous_latent_layer, layer_idx=layer_idx: self.get_decoder_latent_layer(
                    layer_idx=layer_idx, previous_latent_layer=previous_latent_layer))
        return latent_dist

    def get_obs_param(self, latent):
        # pylint: disable=not-callable,unsubscriptable-object
        """
        Args:
            latent: tuple (latent_0, ..., latent_N) where each
                latent_n is a tensor of shape [N, latent_dim]
                with values in {0, 1}

        Returns: logits of Bernoulli likelihood of shape
            [N, batch_size]
        """
        latent_layer = latent[-1]
        return self.decoder_to_obs(latent_layer)

    def get_obs_dist(self, latent):
        """Args:
            latent: tuple (latent_0, ..., latent_N) where each
                latent_n is a tensor of shape [N, latent_dim]
                with values in {0, 1}

        Returns: Bernoulli distribution of batch_shape [N] and
            event_shape [batch_size]
        """
        return Independent(torch.distributions.Bernoulli(logits=self.get_obs_param(latent)), reinterpreted_batch_ndims=1)

    def sample_model_latent_and_obs(self, num_samples=1):
        """Args:
            num_samples: int

        Returns:
            latent: tuple (latent_0, ..., latent_N) where each
                latent_n is a tensor of shape [N, latent_dim]
                with values in {0, 1}
            obs: tensor of shape [num_samples, batch_size]
        """
        decoder_latent_dist = self.get_decoder_latent_dist()

        if self.reparam:
            latent = decoder_latent_dist.rsample((num_samples, ))
        else:
            latent = decoder_latent_dist.sample((num_samples, ))

        obs_dist = self.get_obs_dist(latent)
        obs = obs_dist.sample()

        return latent, obs

    def sample_model_obs(self, num_samples=1):
        """Args:
            num_samples: int

        Returns:
            obs: tensor of shape [num_samples, batch_size]
        """
        return self.sample_model_latent_and_obs(num_samples)[1]

    # ======== Inf Network functions ========

    def get_encoder_latent_layer_param(self, layer_idx, previous_latent_layer=None, obs=None):
        # pylint: disable=not-callable,unsubscriptable-object
        """Returns params of distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx < num_stochastic_layers - 1)
            obs: tensor of shape [N, batch_size] of values in {0, 1}
                (only applicable if layer_idx = num_stochastic_layers - 1)

        Returns:
            mu for Normal latent of shape [N, latent_dim]
            sig for Normal latent of shape [N, latent_dim]
            """
        if layer_idx == self.num_stochastic_layers - 1:
            return self.encoder_to_obs(obs)
        else:
            return self.encoders[str(layer_idx)](previous_latent_layer)

    def get_encoder_latent_layer(self, layer_idx, previous_latent_layer=None):
        # pylint: disable=no-value-for-parameter
        """Returns distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx < num_stochastic_layers - 1)
            obs: tensor of shape [N, batch_size] of values in {0, 1}
                (only applicable if layer_idx = num_stochastic_layers - 1)

        Returns: Normal distribution with event_shape [latent_dim]
            and batch_shape is [N]"""

        mu, sig = self.get_encoder_latent_layer_param(layer_idx, previous_latent_layer, obs=self.x)
        return Independent(torch.distributions.Normal(mu, sig), reinterpreted_batch_ndims=1)

    def get_inf_network(self):
        latent_dist = util.ChainDistributionFromSingle(
            self.get_encoder_latent_layer(layer_idx=self.num_stochastic_layers - 1))
        for layer_idx in reversed(range(self.num_stochastic_layers - 1)):
            # be careful about closures
            # https://stackoverflow.com/questions/2295290/what-do-lambda-function-closures-capture/2295372
            latent_dist = util.ChainDistribution(
                latent_dist,
                lambda previous_latent_layer, layer_idx=layer_idx: self.get_encoder_latent_layer(
                    layer_idx=layer_idx, previous_latent_layer=previous_latent_layer))
        return util.ReversedChainDistribution(latent_dist)

    def set_internals(self, data, S=10):
        self.y = False  # VAEs are unsupervised
        self.x = data[0]
        self.inf_network = self.get_inf_network()
        self.z = self.sample_latent(S)
        self.check_internals()

    def log_prior(self):
        """
        Returns: tensor of shape [N, S]
        """
        return self.get_decoder_latent_dist().log_prob(self.z).transpose(0, 1)

    def log_likelihood(self):
        """
        Returns: tensor of shape [N, S]
        """
        return self.get_obs_dist(self.z).log_prob(self.x).transpose(0, 1)

    def log_guide(self):
        """Log q(latent | obs).

        Args:

        Returns: tensor of shape [N, S]
        """
        assert self.inf_network is not None, 'log_guide() called before self.inf_network is set!'
        assert self.z is not None, 'log_guide() called before self.z is set!'
        return self.inf_network.log_prob(self.z).transpose(0, 1)

    def sample_latent(self, S):
        """Samples from q(latent | obs)

        Args:
            S: int

        Returns:
            latent: tuple of tensors of shape [S, N, latent_dim].
            len(tuple) == num_stochastic_layers
        """
        assert self.inf_network is not None, 'sample_latent() called before self.inf_network is set!'
        if self.reparam:
            return self.inf_network.rsample((S, ))
        else:
            return self.inf_network.sample((S, ))


class ContinuousVAE(VAEBaseClass):
    def __init__(self, D, args):
        super().__init__(D, args)
        if self.args.learn_prior:
            print("Learning prior")
            self.decoder_latent_param_mu = nn.Parameter(torch.zeros(
                self.latent_dims[0], device=self.args.device, dtype=torch.float))
            self.decoder_latent_param_sig = nn.Parameter(torch.ones(
                self.latent_dims[0], device=self.args.device, dtype=torch.float))
        else:
            self.decoder_latent_param_mu = torch.zeros(
                self.latent_dims[0], device=self.args.device, dtype=torch.float)
            self.decoder_latent_param_sig = torch.ones(
                self.latent_dims[0], device=self.args.device, dtype=torch.float)

        self.layer_0_params = (self.decoder_latent_param_mu,
                               self.decoder_latent_param_sig)

        self.decoders = nn.ModuleDict()
        for i in range(1, self.num_stochastic_layers):
            self.decoders[str(i)] = init_two_prong_mlp(in_dim=self.latent_dims[i - 1],
                                                       out_dim=self.latent_dims[i],
                                                       hidden_dim=self.hidden_dim,
                                                       num_layers=self.num_deterministic_layers,
                                                       non_linearity=nn.Tanh() if self.args.activation is None else self.args.activation)

        # This is the mlp from discrete.py that doesn't produce a sigma
        self.decoder_to_obs = init_mlp(in_dim=self.latent_dims[-1],
                                       out_dim=self.D,
                                       hidden_dim=self.hidden_dim,
                                       num_layers=self.num_deterministic_layers,
                                       non_linearity=nn.Tanh() if self.args.activation is None else self.args.activation)

        self.encoder_to_obs = init_two_prong_mlp(in_dim=self.D,
                                                 out_dim=self.latent_dims[-1],
                                                 hidden_dim=self.hidden_dim,
                                                 num_layers=self.num_deterministic_layers,
                                                 non_linearity=nn.Tanh() if self.args.activation is None else self.args.activation)

        self.encoders = nn.ModuleDict()
        for i in reversed(range(self.num_stochastic_layers - 1)):
            self.encoders[str(i)] = init_two_prong_mlp(in_dim=self.latent_dims[i + 1],
                                                       out_dim=self.latent_dims[i],
                                                       hidden_dim=self.hidden_dim,
                                                       num_layers=self.num_deterministic_layers,
                                                       non_linearity=nn.Tanh() if self.args.activation is None else self.args.activation)


class DiscreteVAE(VAEBaseClass):
    def __init__(self, D, args, train_obs_mean):
        super().__init__(D, args)

        if train_obs_mean is None:
            self.train_obs_mean = torch.ones(
                self.D, device=self.args.device, dtype=torch.float) / 2
        else:
            self.train_obs_mean = train_obs_mean

        # ---------------
        # --- Decoder ---
        # ---------------

        self.decoders = nn.ModuleDict()

        self.decoder_latent_param_logits = nn.Parameter(torch.zeros(
            self.latent_dims[0], device=self.args.device, dtype=torch.float))

        for i in range(1, self.num_stochastic_layers):
            self.decoders[str(i)] = init_mlp(in_dim=self.latent_dims[i - 1],
                                             out_dim=self.latent_dims[i],
                                             hidden_dim=self.latent_dims[i - 1],
                                             num_layers=self.num_deterministic_layers,
                                             non_linearity=nn.Tanh())

        self.decoder_to_obs = init_mlp(in_dim=self.latent_dims[-1],
                                       out_dim=self.D,
                                       hidden_dim=self.latent_dims[-1],
                                       num_layers=self.num_deterministic_layers,
                                       non_linearity=nn.Tanh())

        # https://github.com/duvenaud/relax/blob/master/binary_vae_multilayer_per_layer.py#L273
        # https://github.com/tensorflow/models/blob/master/research/rebar/rebar.py#L49
        # self.train_obs_bias = -torch.log(1 / torch.clamp(self.train_obs_mean, 0.001, 0.999) - 1)

        self.decoder_to_obs.linear_modules[-1].bias.data = -torch.log(
            1 / torch.clamp(self.train_obs_mean, 1e-4, 1 - 1e-4) - 1)

        # ---------------
        # --- Encoder ---
        # ---------------

        self.encoder_to_obs = init_mlp(in_dim=self.D,
                                       out_dim=self.latent_dims[-1],
                                       hidden_dim=self.latent_dims[-1],
                                       num_layers=self.num_deterministic_layers,
                                       non_linearity=nn.Tanh())

        self.encoders = nn.ModuleDict()

        for i in reversed(range(self.num_stochastic_layers - 1)):
            self.encoders[str(i)] = init_mlp(in_dim=self.latent_dims[i + 1],
                                             out_dim=self.latent_dims[i],
                                             hidden_dim=self.latent_dims[i + 1],
                                             num_layers=self.num_deterministic_layers,
                                             non_linearity=nn.Tanh())

    def get_decoder_latent_layer_param(self, layer_idx, previous_latent_layer=None):
        """Returns params of distribution for single latent layer.
        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [batch_size, latent_dim]
                (only applicable if layer_idx > 0)
        Returns: logits for Bernoulli latent
            if layer_idx is 0, shape [latent_dim],
            otherwise [batch_size, latent_dim]"""
        if layer_idx == 0:
            return self.decoder_latent_param_logits
        else:
            return self.decoders[str(layer_idx)](previous_latent_layer * 2 - 1)

    def get_decoder_latent_layer(self, layer_idx, previous_latent_layer=None):
        # pylint: disable=not-callable,unsubscriptable-object,no-value-for-parameter
        """Returns distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx > 0)

        Returns: Normal distribution with event_shape [latent_dim]
            if layer_idx is 0, batch_shape is [],
            otherwise [N]"""

        logits = self.get_decoder_latent_layer_param(
            layer_idx, previous_latent_layer)
        return Independent(torch.distributions.Bernoulli(logits=logits), reinterpreted_batch_ndims=1)

    def get_encoder_latent_layer_param(self, layer_idx, previous_latent_layer=None, obs=None):
        # pylint: disable=not-callable,unsubscriptable-object
        """Returns params of distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx < num_stochastic_layers - 1)
            obs: tensor of shape [N, batch_size] of values in {0, 1}
                (only applicable if layer_idx = num_stochastic_layers - 1)

        Returns:
            logits for Bernoulli latent of shape [N, latent_dim]
            """
        if layer_idx == self.num_stochastic_layers - 1:
            return self.encoder_to_obs((obs - self.train_obs_mean + 1) / 2)
        else:
            return self.encoders[str(layer_idx)](previous_latent_layer * 2 - 1)

    def get_encoder_latent_layer(self, layer_idx, previous_latent_layer=None):
        # pylint: disable=no-value-for-parameter
        """Returns distribution for single latent layer.

        Args:
            layer_idx: 0 means the layer furthest away from obs
            previous_latent_layer: tensor of shape [N, latent_dim]
                (only applicable if layer_idx < num_stochastic_layers - 1)
            obs: tensor of shape [N, batch_size] of values in {0, 1}
                (only applicable if layer_idx = num_stochastic_layers - 1)

        Returns: Normal distribution with event_shape [latent_dim]
            and batch_shape is [N]"""

        logits = self.get_encoder_latent_layer_param(
            layer_idx, previous_latent_layer, obs=self.x)
        return Independent(torch.distributions.Bernoulli(logits=logits), reinterpreted_batch_ndims=1)

    def get_obs_param(self, latent):
        """Args:
            latent: tuple (latent_0, ..., latent_N) where each
                latent_n is a tensor of shape [N, latent_dim]
                with values in {0, 1}

        Returns: logits of Bernoulli likelihood of shape
            [N, batch_size]
        """
        latent_layer = latent[-1]

        # https://github.com/tensorflow/models/blob/master/research/rebar/rebar.py#L265
        # https://github.com/duvenaud/relax/blob/master/binary_vae_multilayer_per_layer.py#L159-L160
        return self.decoder_to_obs(latent_layer * 2 - 1)

File Path: src/pcfg_util.py
Content:
import torch
import itertools
import json
import os
import string
import Levenshtein
import pickle
import uuid
import datetime
import numpy as np
import nltk
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import seaborn as sns


def lognormexp(values, dim=0):
    """Exponentiates, normalizes and takes log of a tensor.

    Args:
        values: tensor [dim_1, ..., dim_N]
        dim: n

    Returns:
        result: tensor [dim_1, ..., dim_N]
            where result[i_1, ..., i_N] =
                                 exp(values[i_1, ..., i_N])
            log( ------------------------------------------------------------ )
                    sum_{j = 1}^{dim_n} exp(values[i_1, ..., j, ..., i_N])
    """

    log_denominator = torch.logsumexp(values, dim=dim, keepdim=True)
    # log_numerator = values
    return values - log_denominator


def exponentiate_and_normalize(values, dim=0):
    """Exponentiates and normalizes a tensor.

    Args:
        values: tensor [dim_1, ..., dim_N]
        dim: n

    Returns:
        result: tensor [dim_1, ..., dim_N]
            where result[i_1, ..., i_N] =
                            exp(values[i_1, ..., i_N])
            ------------------------------------------------------------
             sum_{j = 1}^{dim_n} exp(values[i_1, ..., j, ..., i_N])
    """

    return torch.exp(lognormexp(values, dim=dim))


def production_probs_to_tensor(production_probs):
    """Convert production_probs in list to tensor.

    Args:
        production_probs: dict whose keys are non-terminals and values are
            probabilities of productions represented as list of shape
            [num_productions]

    Returns: same as production_probs but values are tensors instead of
    lists.
    """
    return {k: torch.tensor(v, dtype=torch.float)
            for k, v in production_probs.items()}


def one_hot(indices, num_bins):
    """Returns one hot vector given indices.

    Args:
        indices: tensors
        num_bins: number of bins

    Returns: matrix where ith row corresponds to a one
        hot version of indices[i].
    """
    return torch.zeros(len(indices), num_bins).scatter_(
        1, indices.long().unsqueeze(-1), 1)


def get_sample_address_embedding(non_terminal, non_terminals):
    """Returns an embedding of the sample address of a production.

    Args:
        non_terminal: string
        non_terminals: set of non_terminal symbols

    Returns: one-hot vector
    """
    num_bins = len(non_terminals)
    i = sorted(non_terminals).index(non_terminal)
    return one_hot(torch.tensor([i]), num_bins)[0]


def get_root(tree):
    """Returns root of a tree.

    Args: list of lists or string
    Returns: string
    """
    if isinstance(tree, list):
        return tree[0]
    else:
        return tree


def get_production_index(non_terminal, production, productions):
    """Args:
        non_terminal: string
        production: list of strings
        productions: dict where key is a non-terminal and value is a list of
            productions

    Returns: int
    """
    return productions[non_terminal].index(production)


def word_to_one_hot(word, terminals):
    """Convert word to its one-hot representation.

    Args:
        word: string
        terminals: set of terminal strings

    Returns: one hot tensor of shape [len(terminals)] or zeros if word is not
        in terminals
    """
    num_bins = len(terminals)
    try:
        i = sorted(terminals).index(word)
        return one_hot(torch.tensor([i]), num_bins)[0]
    except ValueError:
        return torch.zeros((num_bins,))


def sentence_to_one_hots(sentence, terminals):
    """Convert sentence to one-hots.

    Args:
        sentence: list of strings
        terminals: set of terminal strings

    Returns: matrix where ith row corresponds to a one-hot of ith word, shape
        [num_words, len(terminals)]
    """
    return torch.cat([word_to_one_hot(word, terminals).unsqueeze(0)
                      for word in sentence])


def get_leaves(tree):
    """Return leaves of a tree.

    Args: list of lists or string
    Returns: list of strings
    """
    if isinstance(tree, list):
        return list(itertools.chain.from_iterable(
            [get_leaves(subtree) for subtree in tree[1:]]))
    else:
        return [tree]


def read_pcfg(pcfg_path):
    with open(pcfg_path) as json_data:
        data = json.load(json_data)

    grammar = {
        'terminals': set(data['terminals']),
        'non_terminals': set(data['non_terminals']),
        'productions': data['productions'],
        'start_symbol': data['start_symbol'],
        'name': data['name']
    }
    true_production_probs = production_probs_to_tensor(
        data['production_probs'])

    return grammar, true_production_probs


def save_models(generative_model, inference_network, pcfg_path,
                model_folder='.'):
    generative_model_path = os.path.join(model_folder, 'gen.pt')
    inference_network_path = os.path.join(model_folder, 'inf.pt')
    pcfg_path_path = os.path.join(model_folder, 'pcfg_path.txt')

    if not os.path.exists(model_folder):
        os.makedirs(model_folder)

    torch.save(generative_model.state_dict(), generative_model_path)
    print_with_time('Saved to {}'.format(generative_model_path))
    torch.save(inference_network.state_dict(), inference_network_path)
    print_with_time('Saved to {}'.format(inference_network_path))
    with open(pcfg_path_path, 'w') as f:
        f.write(pcfg_path)
    print_with_time('Saved to {}'.format(pcfg_path_path))


def word_to_index(word, terminals):
    """Convert word to int.

    Args:
        word: string
        terminals: set of terminal strings

    Returns: int; -1 if word is not in terminals
    """

    try:
        return sorted(terminals).index(word)
    except ValueError:
        return -1


def sentence_to_indices(sentence, terminals):
    """Convert sentence to list of indices.

    Args:
        sentence: list of strings
        terminals: set of terminal strings

    Returns: list of indices of length len(sentence); index is -1 if word is
        not in terminals
    """
    return [word_to_index(word, terminals) for word in sentence]


def _indices_to_string(indices):
    return ''.join([string.printable[index] for index in indices])


def _sentence_to_string(sentence, terminals):
    return _indices_to_string(sentence_to_indices(sentence, terminals))


def get_levenshtein_distance(sentence_1, sentence_2, terminals):
    """Levenshtein distance between two sentences.

    Args:
        sentence_1: list of strings
        sentence_2: list of strings
        terminals: vocabulary; list of valid strings

    Returns: int"""
    return Levenshtein.distance(_sentence_to_string(sentence_1, terminals),
                                _sentence_to_string(sentence_2, terminals))



def range_except(end, i):
    """Outputs an increasing list from 0 to (end - 1) except i.
    Args:
        end: int
        i: int

    Returns: list of length (end - 1)
    """

    result = list(set(range(end)))
    return result[:i] + result[(i + 1):]


def normalize(x, dim=0):
    return x / torch.sum(x, dim=0, keepdim=True)


def get_production_probs(generative_model):
    return {
        non_terminal: normalize(torch.exp(
            generative_model.production_logits[non_terminal])).detach()
        for non_terminal in generative_model.grammar['non_terminals']}


def get_kl(probs_1, probs_2):
    """KL between two probability tensors.

    Args:
        probs_1: probability tensor of shape [num_probs]
        probs_2: probability tensor of shape [num_probs]

    Returns: KL(p1 || p2), scalar tensor
    """
    return torch.sum(probs_1 * (torch.log(probs_1) - torch.log(probs_2)))

def get_sleep_loss(generative_model, inference_network, num_samples=1):
    """Returns:
        loss: scalar that we call .backward() on and step the optimizer.
    """
    log_q_sum = 0
    for _ in range(num_samples):
        tree, obs = generative_model.sample_tree_and_obs()
        log_q = inference_network.get_tree_log_prob(tree, obs=obs)
        log_q_sum = log_q_sum + log_q
    return -log_q_sum / num_samples

def get_q_error(generative_model, inference_network, num_samples=100):
    """Expected KL(posterior || q) + const as a measure of q's quality.

    Returns: detached scalar E_p(x)[KL(p(z | x) || q(z | x))] + H(z | x) where
        the second term is constant wrt the inference network.
    """

    return get_sleep_loss(generative_model, inference_network,
                                 num_samples).detach()


def get_p_error(true_generative_model, generative_model):
    """Average KL between true and learned productions probs."""

    true_generative_model_probs = get_production_probs(true_generative_model)
    generative_model_probs = get_production_probs(generative_model)
    non_terminals = true_generative_model.grammar['non_terminals']
    result = 0
    for non_terminal in non_terminals:
        kl = get_kl(true_generative_model_probs[non_terminal],
                    generative_model_probs[non_terminal])
        result += kl
    return result / len(non_terminals)


# https://stackoverflow.com/questions/4529815/saving-an-object-data-persistence
def save_object(obj, filename):
    dir = os.path.dirname(filename)
    if not os.path.exists(dir):
        os.makedirs(dir)

    with open(filename, 'wb') as output:
        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)
    print_with_time('Saved to {}'.format(filename))


def load_object(filename):
    with open(filename, 'rb') as input_:
        obj = pickle.load(input_)
    return obj


def get_stats_filename(model_folder='.'):
    return os.path.join(model_folder, 'stats.pkl')


def get_variance_analysis_filename():
    return './variance_analysis/data.pkl'


def get_uuid():
    return str(uuid.uuid4())[:8]


def get_yyyymmdd():
    return str(datetime.date.today()).replace('-', '')


def get_hhmmss():
    return datetime.datetime.now().strftime('%H:%M:%S')


def get_model_folder(rootdir='./models/'):
    return os.path.join(rootdir, get_yyyymmdd() + '_' + get_uuid())


def get_args_filename(model_folder='.'):
    return os.path.join(model_folder, 'args.pkl')


def args_match(model_folder, **kwargs):
    """Do training args match kwargs?"""

    args_filename = get_args_filename(model_folder)
    if os.path.exists(args_filename):
        args = load_object(args_filename)
        for k, v in kwargs.items():
            if args.__dict__[k] != v:
                return False
        return True
    else:
        return False


def list_subdirs(rootdir):
    for file in os.listdir(rootdir):
        path = os.path.join(rootdir, file)
        if os.path.isdir(path):
            yield(path)


def list_model_folders_args_match(rootdir='./models/', **kwargs):
    """Return a list of model folders whose training args
    match kwargs.
    """

    result = []
    for model_folder in list_subdirs(rootdir):
        # print(model_folder)
        if model_folder == './models/__pycache__' or model_folder == './models/jobs_out_err' or model_folder == './models/models' or model_folder == './models/pcfgs' or model_folder == './models/variance_analysis':
            continue
        month = int(model_folder[13:15])
        day = int(model_folder[15:17])
        if day < 8 and month == 3 and args_match(model_folder, **kwargs):
            result.append(model_folder)
    return result


def print_with_time(str):
    print(get_yyyymmdd() + ' ' + get_hhmmss() + ' ' + str)


def set_seed(seed):
    torch.manual_seed(seed)
    np.random.seed(seed)


def tree_to_string(tree):
    return str(tree).replace('\'', '')\
                    .replace(',', '')\
                    .replace('[', '(')\
                    .replace(']', ')')


def tree_to_nltk_tree(tree):
    return nltk.Tree.fromstring(tree_to_string(tree))


def logaddexp(a, b):
    """Returns log(exp(a) + exp(b))."""

    torch.logsumexp(torch.cat([a.unsqueeze(0), b.unsqueeze(0)]), dim=0)


def get_posterior(generative_model, inference_network, obs, num_particles=100):
    """Returns a sequence of (tree, log_weight) tuples sorted by
    weight in a descending order. tree is a string representation
    of a tree.
    """

    trees = [inference_network.sample_tree(obs=obs)
             for _ in range(num_particles)]
    log_weights = [(generative_model.get_log_prob(tree, obs) -
                    inference_network.get_tree_log_prob(
                        tree, obs=obs)).detach()
                   for tree in trees]
    tree_log_weight_dict = dict()
    for tree, log_weight in zip(trees, log_weights):
        string_tree = tree_to_string(tree)
        if string_tree in tree_log_weight_dict:
            tree_log_weight_dict[string_tree] = torch.logsumexp(
                torch.cat([tree_log_weight_dict[string_tree].unsqueeze(0),
                           log_weight.unsqueeze(0)]), dim=0)
        else:
            tree_log_weight_dict[string_tree] = log_weight
    return sorted(list(tree_log_weight_dict.items()),
                  key=lambda x: x[1], reverse=True)


def get_inference_network_distribution(inference_network, obs,
                                       num_samples=1000):
    """Returns a sequence of (tree, log_weight) tuples sorted by weight in a
    descending order. tree is a string representation.
    """
    trees = [inference_network.sample_tree(obs=obs)
             for _ in range(num_samples)]
    log_weights = [-torch.log(torch.tensor(num_samples, dtype=torch.float))
                   for _ in trees]

    # refactor (this is just copying the code snippet from get_posterior)
    tree_log_weight_dict = dict()
    for tree, log_weight in zip(trees, log_weights):
        string_tree = tree_to_string(tree)
        if string_tree in tree_log_weight_dict:
            tree_log_weight_dict[string_tree] = torch.logsumexp(
                torch.cat([tree_log_weight_dict[string_tree].unsqueeze(0),
                           log_weight.unsqueeze(0)]), dim=0)
        else:
            tree_log_weight_dict[string_tree] = log_weight
    return sorted(list(tree_log_weight_dict.items()),
                  key=lambda x: x[1], reverse=True)


def empty_list_of_size(*sizes):
    if len(sizes) == 1:
        return [None for _ in range(sizes[0])]
    else:
        return [empty_list_of_size(*sizes[1:]) for _ in range(sizes[0])]


def eval_quadratic(tree, x):
    if isinstance(tree, list):
        root = tree[0]
        subtrees = tree[1:]
        if root == 'Q' or root == 'L':
            if len(subtrees) == 3:
                a, op, b = subtrees
                if op == '+':
                    return eval_quadratic(a, x) + eval_quadratic(b, x)
                elif op == '-':
                    return eval_quadratic(a, x) - eval_quadratic(b, x)
                elif op == '*':
                    return eval_quadratic(a, x) * eval_quadratic(b, x)
                else:
                    raise ArithmeticError
            elif len(subtrees) == 1:
                return eval_quadratic(subtrees[0], x)
        elif root == 'N':
            return eval_quadratic(subtrees[0], x)
    else:
        root = tree
        if root == 'x':
            return x
        elif root == 'x**2':
            return x**2
        elif int(root) in range(1, 21):
            return torch.full_like(x, int(root), dtype=torch.float)


def eval_polynomial(tree, x):
    if isinstance(tree, list):
        root = tree[0]
        subtrees = tree[1:]
        if root == 'E':
            a, op, b = subtrees
            if op == '+':
                return eval_polynomial(a, x) + eval_polynomial(b, x)
            elif op == '-':
                return eval_polynomial(a, x) - eval_polynomial(b, x)
            elif op == '*':
                return eval_polynomial(a, x) * eval_polynomial(b, x)
            else:
                raise ArithmeticError
        elif root == 'E1' or root == 'N':
            return eval_polynomial(subtrees[0], x)
    else:
        root = tree
        if root == 'x':
            return x
        elif int(root) in range(1, 4):
            return torch.full_like(x, int(root), dtype=torch.float)


def mse(ys1, ys2):
    return torch.mean((ys1 - ys2)**2)


def fig2rgba(fig):
    """Convert a Matplotlib figure to a 4D numpy array with RGBA channels and
        return it. From
        http://www.icare.univ-lille1.fr/tutorials/convert_a_matplotlib_figure

    Args:
        fig: a matplotlib figure

    Returns: a numpy 3D array of RGBA values of shape [w, h, 4]
    """

    fig.canvas.draw()
    w, h = fig.canvas.get_width_height()
    rgba = np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8)
    rgba.shape = (w, h, 4)
    rgba = np.roll(rgba, 3, axis=2)
    plt.close(fig)

    return rgba


def rgba2gray(rgba):
    # from https://stackoverflow.com/a/12201744/1357509
    return np.dot(rgba[..., :3], [0.299, 0.587, 0.114])


# This function needs to be optimized
def xsys2gray(xs, ys):
    """Args:
        xs: tensor of shape [100]
        ys: tensor of shape [100]

    Returns: grayscale image repr. by tensor of shape
        [100, 100] where 1 is white and 0 is black"""

    fig, ax = plt.subplots(1, 1, figsize=(1, 1), dpi=100)
    ax.plot(xs.numpy(), ys.numpy(), color='black')
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_ylim(-100, 100)
    ax.set_xlim(-10, 10)
    sns.despine(ax=ax, left=True, bottom=True)
    fig.tight_layout(pad=0)

    return torch.tensor(rgba2gray(fig2rgba(fig)) / 255.0,
                        dtype=torch.float)


def get_most_recent_model_folder_args_match(**kwargs):
    model_folders = list_model_folders_args_match(**kwargs)
    if len(model_folders) > 0:
        return model_folders[np.argmax(
            [os.stat(x).st_mtime for x in model_folders])]


def sample_relax(logits, epsilon=1e-6):
    """This implements Appendix C in the REBAR paper.

    Args:
        logits: tensor of shape [num_categories]

    Returns:
        latent, latent_aux, latent_aux_tilde: tensors of shape [num_categories]
    """
    num_categories = len(logits)
    probs = exponentiate_and_normalize(logits)

    # latent_aux
    u = torch.distributions.Uniform(0 + epsilon, 1 - epsilon).sample(
        sample_shape=(num_categories,))
    latent_aux = torch.log(probs) - torch.log(-torch.log(u))

    # latent
    latent = torch.zeros(num_categories)
    latent[torch.argmax(latent_aux)] = 1
    latent_byte = latent.byte()

    # latent_aux_tilde
    v = torch.distributions.Uniform(0 + epsilon, 1 - epsilon).sample(
        sample_shape=(num_categories,))
    latent_aux_tilde = torch.zeros(num_categories)
    latent_aux_tilde[latent_byte] = -torch.log(-torch.log(v[latent_byte]))
    latent_aux_tilde[1 - latent_byte] = -torch.log(
        -torch.log(v[1 - latent_byte]) / probs[1 - latent_byte] -
        torch.log(v[latent_byte]))
    return latent, latent_aux, latent_aux_tilde


def pad_zeros(x, new_length):
    """Args:

        x: tensor of shape [length]
        new_length: int which is >= length

    Returns:
        y: tensor of shape [new_length] where y[i] = x[i]
            for i = {0, ..., length - 1} and y[i] = 0 otherwise
    """

    y = torch.zeros((new_length,), dtype=x.dtype, device=x.device,
                    layout=x.layout)
    y[:len(x)] = x
    return y


def detach_tree_aux(tree_aux):
    """Args:
        tree_aux: e.g.
            [[0.5], [[.9, 1., .2, .1, -.1, .1], None],
                    [[-0.3 0.8], [[0.3], None]
                                 [[.9, -.1, .2, .1, 1., .1], None]]]
            or None

    Returns: tree_aux detached
    """

    tree_aux_detached = []
    if isinstance(tree_aux, list):
        return [tree_aux[0].detach()] + [detach_tree_aux(subtree_aux)
                                         for subtree_aux in tree_aux[1:]]
    else:
        return tree_aux


class OnlineMeanStd():
    def __init__(self):
        self.count = 0
        self.means = None
        self.M2s = None

    def update(self, new_variables):
        if self.count == 0:
            self.count = 1
            self.means = []
            self.M2s = []
            for new_var in new_variables:
                self.means.append(new_var.data)
                self.M2s.append(new_var.data.new(new_var.size()).fill_(0))
        else:
            self.count = self.count + 1
            for new_var_idx, new_var in enumerate(new_variables):
                delta = new_var.data - self.means[new_var_idx]
                self.means[new_var_idx] = self.means[new_var_idx] + delta / \
                    self.count
                delta_2 = new_var.data - self.means[new_var_idx]
                self.M2s[new_var_idx] = self.M2s[new_var_idx] + delta * delta_2

    def means_stds(self):
        if self.count < 2:
            raise ArithmeticError('Need more than 1 value. Have {}'.format(
                self.count))
        else:
            stds = []
            for i in range(len(self.means)):
                stds.append(torch.sqrt(self.M2s[i] / self.count))
            return self.means, stds

    def avg_of_means_stds(self):
        means, stds = self.means_stds()
        num_parameters = np.sum([len(p) for p in means])
        return (np.sum([torch.sum(p) for p in means]) / num_parameters,
                np.sum([torch.sum(p) for p in stds]) / num_parameters)

File Path: src/psis.py
Content:
"""Pareto smoothed importance sampling (PSIS)

This module implements Pareto smoothed importance sampling (PSIS) and PSIS
leave-one-out (LOO) cross-validation for Python (Numpy).

Included functions
------------------
psisloo
    Pareto smoothed importance sampling leave-one-out log predictive densities.

psislw
    Pareto smoothed importance sampling.

gpdfitnew
    Estimate the paramaters for the Generalized Pareto Distribution (GPD).

gpinv
    Inverse Generalised Pareto distribution function.

sumlogs
    Sum of vector where numbers are represented by their logarithms.

References
----------
Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Practical
Bayesian model evaluation using leave-one-out cross-validation
and WAIC. Statistics and Computing, 27(5):1413–1432.
doi:10.1007/s11222-016-9696-4. https://arxiv.org/abs/1507.04544

Aki Vehtari, Andrew Gelman and Jonah Gabry (2017). Pareto
smoothed importance sampling. https://arxiv.org/abs/arXiv:1507.02646v5

"""

from __future__ import division # For Python 2 compatibility
import numpy as np

# 3-Clause BSD License
"""
Copyright 2017 Aki Vehtari, Tuomas Sivula

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
this list of conditions and the following disclaimer in the documentation and/or
other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its contributors
may be used to endorse or promote products derived from this software without
specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. """


def psisloo(log_lik, **kwargs):
    r"""PSIS leave-one-out log predictive densities.

    Computes the log predictive densities given posterior samples of the log
    likelihood terms :math:`p(y_i|\theta^s)` in input parameter `log_lik`.
    Returns a sum of the leave-one-out log predictive densities `loo`,
    individual leave-one-out log predictive density terms `loos` and an estimate
    of Pareto tail indeces `ks`. The estimates are unreliable if tail index
    ``k > 0.7`` (see more in the references listed in the module docstring).

    Additional keyword arguments are passed to the :meth:`psislw()` function
    (see the corresponding documentation).

    Parameters
    ----------
    log_lik : ndarray
        Array of size n x m containing n posterior samples of the log likelihood
        terms :math:`p(y_i|\theta^s)`.

    Returns
    -------
    loo : scalar
        sum of the leave-one-out log predictive densities

    loos : ndarray
        individual leave-one-out log predictive density terms

    ks : ndarray
        estimated Pareto tail indeces

    """
    # ensure overwrite flag in passed arguments
    kwargs['overwrite_lw'] = True
    # log raw weights from log_lik
    lw = -log_lik
    # compute Pareto smoothed log weights given raw log weights
    lw, ks = psislw(lw, **kwargs)
    # compute
    lw += log_lik
    loos = sumlogs(lw, axis=0)
    loo = loos.sum()
    return loo, loos, ks


def psislw(lw, Reff=1.0, overwrite_lw=False):
    """Pareto smoothed importance sampling (PSIS).

    Parameters
    ----------
    lw : ndarray
        Array of size n x m containing m sets of n log weights. It is also
        possible to provide one dimensional array of length n.

    Reff : scalar, optional
        relative MCMC efficiency ``N_eff / N``

    overwrite_lw : bool, optional
        If True, the input array `lw` is smoothed in-place, assuming the array
        is F-contiguous. By default, a new array is allocated.

    Returns
    -------
    lw_out : ndarray
        smoothed log weights
    kss : ndarray
        Pareto tail indices

    """
    if lw.ndim == 2:
        n, m = lw.shape
    elif lw.ndim == 1:
        n = len(lw)
        m = 1
    else:
        raise ValueError("Argument `lw` must be 1 or 2 dimensional.")
    if n <= 1:
        raise ValueError("More than one log-weight needed.")

    if overwrite_lw and lw.flags.f_contiguous:
        # in-place operation
        lw_out = lw
    else:
        # allocate new array for output
        lw_out = np.copy(lw, order='F')

    # allocate output array for kss
    kss = np.empty(m)

    # precalculate constants
    cutoff_ind = - int(np.ceil(min(0.2 * n, 3 * np.sqrt(n / Reff)))) - 1
    cutoffmin = np.log(np.finfo(float).tiny)
    logn = np.log(n)
    k_min = 1/3

    # loop over sets of log weights
    for i, x in enumerate(lw_out.T if lw_out.ndim == 2 else lw_out[None, :]):
        # improve numerical accuracy
        x -= np.max(x)
        # sort the array
        x_sort_ind = np.argsort(x)
        # divide log weights into body and right tail
        xcutoff = max(
            x[x_sort_ind[cutoff_ind]],
            cutoffmin
        )
        expxcutoff = np.exp(xcutoff)
        tailinds, = np.where(x > xcutoff)
        x2 = x[tailinds]
        n2 = len(x2)
        if n2 <= 4:
            # not enough tail samples for gpdfitnew
            k = np.inf
        else:
            # order of tail samples
            x2si = np.argsort(x2)
            # fit generalized Pareto distribution to the right tail samples
            np.exp(x2, out=x2)
            x2 -= expxcutoff
            k, sigma = gpdfitnew(x2, sort=x2si)
        if k >= k_min and not np.isinf(k):
            # no smoothing if short tail or GPD fit failed
            # compute ordered statistic for the fit
            sti = np.arange(0.5, n2)
            sti /= n2
            qq = gpinv(sti, k, sigma)
            qq += expxcutoff
            np.log(qq, out=qq)
            # place the smoothed tail into the output array
            x[tailinds[x2si]] = qq
            # truncate smoothed values to the largest raw weight 0
            x[x > 0] = 0
        # renormalize weights
        x -= sumlogs(x)
        # store tail index k
        kss[i] = k

    # If the provided input array is one dimensional, return kss as scalar.
    if lw_out.ndim == 1:
        kss = kss[0]

    return lw_out, kss


def gpdfitnew(x, sort=True, sort_in_place=False, return_quadrature=False):
    """Estimate the paramaters for the Generalized Pareto Distribution (GPD)

    Returns empirical Bayes estimate for the parameters of the two-parameter
    generalized Parato distribution given the data.

    Parameters
    ----------
    x : ndarray
        One dimensional data array

    sort : bool or ndarray, optional
        If known in advance, one can provide an array of indices that would
        sort the input array `x`. If the input array is already sorted, provide
        False. If True (default behaviour), the array is sorted internally.

    sort_in_place : bool, optional
        If `sort` is True and `sort_in_place` is True, the array is sorted
        in-place (False by default).

    return_quadrature : bool, optional
        If True, quadrature points and weight `ks` and `w` of the marginal posterior distribution of k are also calculated and returned. False by
        default.

    Returns
    -------
    k, sigma : float
        estimated parameter values

    ks, w : ndarray
        Quadrature points and weights of the marginal posterior distribution
        of `k`. Returned only if `return_quadrature` is True.

    Notes
    -----
    This function returns a negative of Zhang and Stephens's k, because it is
    more common parameterisation.

    """
    if x.ndim != 1 or len(x) <= 1:
        raise ValueError("Invalid input array.")

    # check if x should be sorted
    if sort is True:
        if sort_in_place:
            x.sort()
            xsorted = True
        else:
            sort = np.argsort(x)
            xsorted = False
    elif sort is False:
        xsorted = True
    else:
        xsorted = False

    n = len(x)
    PRIOR = 3
    m = 30 + int(np.sqrt(n))

    bs = np.arange(1, m + 1, dtype=float)
    bs -= 0.5
    np.divide(m, bs, out=bs)
    np.sqrt(bs, out=bs)
    np.subtract(1, bs, out=bs)
    if xsorted:
        bs /= PRIOR * x[int(n/4 + 0.5) - 1]
        bs += 1 / x[-1]
    else:
        bs /= PRIOR * x[sort[int(n/4 + 0.5) - 1]]
        bs += 1 / x[sort[-1]]

    ks = np.negative(bs)
    temp = ks[:,None] * x
    np.log1p(temp, out=temp)
    np.mean(temp, axis=1, out=ks)

    L = bs / ks
    np.negative(L, out=L)
    np.log(L, out=L)
    L -= ks
    L -= 1
    L *= n

    temp = L - L[:,None]
    np.exp(temp, out=temp)
    w = np.sum(temp, axis=1)
    np.divide(1, w, out=w)

    # remove negligible weights
    dii = w >= 10 * np.finfo(float).eps
    if not np.all(dii):
        w = w[dii]
        bs = bs[dii]
    # normalise w
    w /= w.sum()

    # posterior mean for b
    b = np.sum(bs * w)
    # Estimate for k, note that we return a negative of Zhang and
    # Stephens's k, because it is more common parameterisation.
    temp = (-b) * x
    np.log1p(temp, out=temp)
    k = np.mean(temp)
    if return_quadrature:
        np.negative(x, out=temp)
        temp = bs[:, None] * temp
        np.log1p(temp, out=temp)
        ks = np.mean(temp, axis=1)
    # estimate for sigma
    sigma = -k / b * n / (n - 0)
    # weakly informative prior for k
    a = 10
    k = k * n / (n+a) + a * 0.5 / (n+a)
    if return_quadrature:
        ks *= n / (n+a)
        ks += a * 0.5 / (n+a)

    if return_quadrature:
        return k, sigma, ks, w
    else:
        return k, sigma


def gpinv(p, k, sigma):
    """Inverse Generalised Pareto distribution function."""
    x = np.empty(p.shape)
    x.fill(np.nan)
    if sigma <= 0:
        return x
    ok = (p > 0) & (p < 1)
    if np.all(ok):
        if np.abs(k) < np.finfo(float).eps:
            np.negative(p, out=x)
            np.log1p(x, out=x)
            np.negative(x, out=x)
        else:
            np.negative(p, out=x)
            np.log1p(x, out=x)
            x *= -k
            np.expm1(x, out=x)
            x /= k
        x *= sigma
    else:
        if np.abs(k) < np.finfo(float).eps:
            # x[ok] = - np.log1p(-p[ok])
            temp = p[ok]
            np.negative(temp, out=temp)
            np.log1p(temp, out=temp)
            np.negative(temp, out=temp)
            x[ok] = temp
        else:
            # x[ok] = np.expm1(-k * np.log1p(-p[ok])) / k
            temp = p[ok]
            np.negative(temp, out=temp)
            np.log1p(temp, out=temp)
            temp *= -k
            np.expm1(temp, out=temp)
            temp /= k
            x[ok] = temp
        x *= sigma
        x[p == 0] = 0
        if k >= 0:
            x[p == 1] = np.inf
        else:
            x[p == 1] = -sigma / k
    return x


def sumlogs(x, axis=None, out=None):
    """Sum of vector where numbers are represented by their logarithms.

    Calculates ``np.log(np.sum(np.exp(x), axis=axis))`` in such a fashion that
    it works even when elements have large magnitude.

    """
    maxx = x.max(axis=axis, keepdims=True)
    xnorm = x - maxx
    np.exp(xnorm, out=xnorm)
    out = np.sum(xnorm, axis=axis, out=out)
    if isinstance(out, np.ndarray):
        np.log(out, out=out)
    else:
        out = np.log(out)
    out += np.squeeze(maxx)
    return out

File Path: src/util.py
Content:
import torch
import numpy as np
from src.ml_helpers import AverageMeter, get_grads, tensor, lognormexp, exponentiate_and_normalize, seed_all
from torch.distributions.multinomial import Multinomial
import src.ml_helpers as mlh
#from src.GPv import GaussianProcessDerivative

def range_except(end, i):
    """Outputs an increasing list from 0 to (end - 1) except i.
    Args:
        end: int
        i: int

    Returns: list of length (end - 1)
    """

    result = list(set(range(end)))
    return result[:i] + result[(i + 1):]


def get_partition(args):
    """Create a non-decreasing sequence of values between zero and one.
    See https://en.wikipedia.org/wiki/Partition_of_an_interval.

    Args:
        args.num_partitions: length of sequence minus one
        args.schedule: \'linear\' or \'log\'
        args.log_beta_min: log (base ten) of beta_min. only used if partition_type
            is log. default -10 (i.e. beta_min = 1e-10).
        args.device: torch.device object (cpu by default)

    Returns: tensor of shape [num_partitions + 1]
    """
    if args.K == 1:
        partition = tensor((0., 1), args)
    else:
        if args.schedule == 'linear':
            partition = torch.linspace(0, 1, steps=args.K + 1,
                                       device=args.device)
        elif args.schedule == 'log':
            partition = torch.zeros(args.K + 1, device=args.device,
                                    dtype=torch.float)
            partition[1:] = torch.logspace(args.log_beta_min, 0, steps=args.K, device=args.device,
                                           dtype=torch.float)
        else:
            # DEFAULT IS TO START WITH LOG
            partition = torch.zeros(args.K + 1, device=args.device,
                                    dtype=torch.float)
            partition[1:] = torch.logspace(args.log_beta_min, 0, steps=args.K, device=args.device,
                                           dtype=torch.float)
    return partition


def _get_multiplier(partition, integration):
    """ Outputs partition multipers depending on integration rule
     Args:
         partition = partition of interval [0,1]
         integration : left, right, trapz, single (i.e. 1 * partition[*, 1])

        (helper function to accomodate per_sample calculations)

     Returns: tensor with size = partition.shape
     """
    if len(partition.shape) == 1:
        multiplier = torch.zeros_like(partition)
        if integration == 'trapz':
            multiplier[0] = 0.5 * (partition[1] - partition[0])
            multiplier[1:-1] = 0.5 * (partition[2:] - partition[0:-2])
            multiplier[-1] = 0.5 * (partition[-1] - partition[-2])
        elif integration == 'left':
            multiplier[:-1] = partition[1:] - partition[:-1]
        elif integration == 'right':
            multiplier[1:] = partition[1:] - partition[:-1]

    else:
        multiplier = torch.zeros_like(partition)
        if integration == 'trapz':
            multiplier[..., 0] = 0.5 * (partition[1] - partition[0])
            multiplier[..., 1:-1] = 0.5 * (partition[2:] - partition[0:-2])
            multiplier[..., -1] = 0.5 * (partition[-1] - partition[-2])
        elif integration == 'left':
            multiplier[..., :-1] = partition[..., 1:] - partition[..., :-1]
        elif integration == 'right':
            multiplier[..., 1:] = partition[..., 1:] - partition[..., :-1]
        elif integration == 'single':
            multiplier = torch.ones_like(partition)
            if multiplier.shape[-1] == 3:
                multiplier[..., 0] = 0
                multiplier[..., -1] = 0

    return multiplier


def compute_tvo_loss(log_weight, log_p, log_q, args):
    """Args:
        log_weight: tensor of shape [batch_size, num_particles]
        log_p: tensor of shape [batch_size, num_particles]
        log_q: tensor of shape [batch_size, num_particles]
        partition: partition of [0, 1];
            tensor of shape [num_partitions + 1] where partition[0] is zero and
            partition[-1] is one;
            see https://en.wikipedia.org/wiki/Partition_of_an_interval
        num_particles: int
        integration: left, right or trapz

    Returns:
        loss: scalar that we call .backward() on and step the optimizer.
        elbo: average elbo over data

    """
    partition = args.partition
    num_particles = args.S
    integration = args.integration

    log_weight = log_weight.unsqueeze(-1)

    heated_log_weight = log_weight * partition
    heated_normalized_weight = exponentiate_and_normalize(
        heated_log_weight, dim=1)

    thermo_logp = partition * log_p.unsqueeze(-1) + \
        (1 - partition) * log_q.unsqueeze(-1)

    wf = heated_normalized_weight * log_weight
    w_detached = heated_normalized_weight.detach()
    wf_detached = wf.detach()

    if num_particles == 1:
        correction = 1
    else:
        correction = num_particles / (num_particles - 1)

    cov = correction * torch.sum(
        w_detached * (log_weight - torch.sum(wf, dim=1, keepdim=True)).detach() *
        (thermo_logp - torch.sum(thermo_logp * w_detached, dim=1, keepdim=True)),
        dim=1)

    multiplier = _get_multiplier(partition, integration)

    loss = -torch.mean(torch.sum(
        multiplier * (cov + torch.sum(
            w_detached * log_weight, dim=1)),
        dim=1))

    return loss



def compute_tvo_log_evidence(log_weight, args):

    # this is special partition for tvo_log_evidence

    partition = mlh.tensor(10**args.partition_tvo_evidence, args)
    # this is the integration used for computing tvo_log_evidence only
    # should be trapz
    integration = args.integration_tvo_evidence

    log_weight = log_weight.unsqueeze(-1)

    heated_log_weight = log_weight * partition
    heated_normalized_weight = exponentiate_and_normalize(heated_log_weight, dim=1)
    Epi_beta = torch.sum(heated_normalized_weight * log_weight, dim=1)

    multiplier = _get_multiplier(partition, integration)

    tvo_logpx = torch.sum(multiplier * Epi_beta, dim=1)

    return tvo_logpx

def compute_tvo_iwae_log_evidence(log_weight, args):
    # see notes @ BQD_TVO/notes/tvo_iwae.pdf
    partition = args.partition
    S = log_weight.shape[1]

    log_weight = log_weight.unsqueeze(-1)
    heated_log_weight = log_weight * partition

    log_evidence = torch.logsumexp(heated_log_weight, dim=1) - np.log(S)
    tvo_iwae_log_evidence = torch.sum(log_evidence * 1/partition.sum(), dim=1)

    return tvo_iwae_log_evidence


def calculate_grad_variance(model, args):
    grad_var = AverageMeter()
    batch = next(iter(args.train_data_loader))
    for _ in range(10):
        model.zero_grad()
        loss, logpx, test_elbo = model.forward(batch)
        loss.backward()
        model_grads = get_grads(model)
        grad_var.step(model_grads)

    grad_std = grad_var.variance.sqrt().mean()
    return grad_std


def compute_wake_phi_loss(log_weight, log_q):
    """Returns:
        loss: scalar that we call .backward() on and step the optimizer.
    """
    normalized_weight = exponentiate_and_normalize(log_weight, dim=1)
    return torch.mean(-torch.sum(normalized_weight.detach() * log_q, dim=1))


def compute_wake_theta_loss(log_weight):
    """Args:
    log_weight: tensor of shape [batch_size, num_particles]

    Returns:
        loss: scalar that we call .backward() on and step the optimizer.
        elbo: average elbo over data
    """

    _, num_particles = log_weight.shape
    elbo = torch.mean(torch.logsumexp(
        log_weight, dim=1) - np.log(num_particles))
    return -elbo


def compute_vimco_loss(log_weight, log_q):
    num_particles = log_q.shape[1]

    # shape [batch_size, num_particles]
    # log_weight_[b, k] = 1 / (K - 1) \sum_{\ell \neq k} \log w_{b, \ell}
    log_weight_ = (torch.sum(log_weight, dim=1, keepdim=True) - log_weight) \
        / (num_particles - 1)

    # shape [batch_size, num_particles, num_particles]
    # temp[b, k, k_] =
    #     log_weight_[b, k]     if k == k_
    #     log_weight[b, k]      otherwise
    temp = log_weight.unsqueeze(-1) + torch.diag_embed(
        log_weight_ - log_weight)

    # this is the \Upsilon_{-k} term below equation 3
    # shape [batch_size, num_particles]
    control_variate = torch.logsumexp(temp, dim=1) - np.log(num_particles)

    log_evidence = torch.logsumexp(log_weight, dim=1) - np.log(num_particles)
    elbo = torch.mean(log_evidence)
    loss = -elbo - torch.mean(torch.sum(
        (log_evidence.unsqueeze(-1) - control_variate).detach() * log_q, dim=1
    ))

    return loss


def calc_exp(log_weight, args, all_sample_mean=True, snis=None):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : True averages over batch

    TO DO : replace for cleaner integration into code (pulled directly from Rob's)
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight
    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = snis * log_weight
    exp = torch.sum(exp, dim=1)
    return torch.mean(exp, dim=0) if all_sample_mean else exp

def calc_var_given_betas(log_weight, args, all_sample_mean=True, betas = None):
    """
    Args:
        log_weight : [batch, samples, *]
        args : args object
                *** Note: only args.partition is used (this can be replaced by betas arg)
        all_sample_mean : returns mean over samples if True
        betas : β points at which to evaluate variance (shape: [K β points] or  [batch or 1, 1, K β points])
    Returns:
        Variance across importance samples at each beta (2nd derivative of log Z_β wrt β)
    """

    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight


    if betas is None:
        partition = args.partition
    else:
        partition = mlh.tensor(betas, args)

    beta_iw = log_weight * partition
    snis = exponentiate_and_normalize(
        beta_iw, dim=1)
    snis_detach = snis.detach()

    # expected log weights under π_β
    exp_pi_beta_log_weight  = torch.sum(snis_detach*log_weight, dim=1, keepdim=True)

    variance = torch.sum(snis_detach*torch.pow(log_weight - exp_pi_beta_log_weight, 2), dim =1 )

    # variance is [batch, # β].  set all_sample_mean = True to average over batch dimension
    return torch.mean(variance, dim=0) if all_sample_mean else variance

def calc_var(log_weight,  args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Variance across importance samples at each beta (2nd derivative of logZβ)
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp_ = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)

    to_return = exp2 - torch.pow(exp_, 2)

    # VM: May have to switch to_return to E[(X-EX)(X-EX)] form, had numerical issues in the past
    assert not torch.isnan(to_return).any(), "Nan in calc_var() - switch to E[(X-EX)(X-EX)] form for numerical stability"


    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


#
def calc_third(log_weight, args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Third derivative of logZβ at each beta
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)
    var = exp2 - torch.pow(exp, 2)
    exp3 = torch.sum(snis * torch.pow(log_weight, 3), dim=1)

    to_return = exp3 - torch.pow(exp, 3) - 3*exp*var
    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


def calc_fourth(log_weight, args, snis=None, all_sample_mean=True):
    """
    Args:
        log_weight : [batch, samples, *]
        args : either args object or partition [batch, 1, K partitions]
        all_sample_mean : returns mean over samples if True
        snis : optionally feed weights to avoid recomputation
    Returns:
        Fourth derivative of logZβ at each beta
    """
    log_weight = log_weight.unsqueeze(-1) if len(
        log_weight.shape) < 3 else log_weight

    if snis is None:
        try:  # args.partition or partition tensor directly
            partition = args.partition
        except:
            partition = args
        beta_iw = log_weight * partition
        snis = exponentiate_and_normalize(
            beta_iw, dim=1)
    else:
        pass

    exp = torch.sum(snis * log_weight, dim=1)
    exp2 = torch.sum(snis * torch.pow(log_weight, 2), dim=1)
    exp3 = torch.sum(snis * torch.pow(log_weight, 3), dim=1)
    exp4 = torch.sum(snis * torch.pow(log_weight, 4), dim=1)

    to_return = exp4 - 6*torch.pow(exp, 4) + 12*exp2 * \
        torch.pow(exp, 2) - 3*torch.pow(exp2, 2) - 4*exp*exp3
    return torch.mean(to_return, dim=0) if all_sample_mean else to_return


def get_curvature_loss_and_grad(beta_model, model, args):
    # Refers to writeup here: tvo_icml/notes/curvature_optimization.pdf
    log_weight = get_total_log_weight(model, args, args.valid_S).unsqueeze(-1)

    log_weight = log_weight
    partition = beta_model.weight.data.squeeze(1)

    snis = exponentiate_and_normalize(log_weight * partition, dim=1)

    # Calling them first, second, third to match notation in writeup
    first  = calc_var(log_weight, args, snis=snis, all_sample_mean=True)
    second = calc_third(log_weight, args, snis=snis, all_sample_mean=True)
    third  = calc_fourth(log_weight, args, snis=snis, all_sample_mean=True)

    unsigned_curvature = second.abs() / torch.pow(1 + torch.pow(first, 2), 3 / 2)
    log_curvature = torch.log(second.abs()) - (1.5) * torch.log(1 + torch.pow(first, 2))
    grad = (third / second) - ((3 * first * second) / (1 - torch.pow(first, 2)))

    grad.unsqueeze_(1)

    return -log_curvature, grad, unsigned_curvature


class ChainDistribution(torch.distributions.Distribution):
    def __init__(self, chain_dist, get_next_dist):
        self.chain_dist = chain_dist
        self.get_next_dist = get_next_dist

    def sample(self, sample_shape=torch.Size()):
        sample_chain = self.chain_dist.sample(sample_shape=sample_shape)
        sample_next = self.get_next_dist(sample_chain[-1]).sample(
            sample_shape=())
        return sample_chain + (sample_next,)

    def rsample(self, sample_shape=torch.Size()):
        sample_chain = self.chain_dist.rsample(sample_shape=sample_shape)
        sample_next = self.get_next_dist(sample_chain[-1]).rsample(
            sample_shape=())
        return sample_chain + (sample_next,)

    def log_prob(self, value):
        log_prob_chain = self.chain_dist.log_prob(value[:-1])
        log_prob_next = self.get_next_dist(value[-2]).log_prob(value[-1])
        return log_prob_chain + log_prob_next


class ChainDistributionFromSingle(torch.distributions.Distribution):
    def __init__(self, single_dist):
        self.single_dist = single_dist

    def sample(self, sample_shape=torch.Size()):
        return (self.single_dist.sample(sample_shape=sample_shape),)

    def rsample(self, sample_shape=torch.Size()):
        return (self.single_dist.rsample(sample_shape=sample_shape),)

    def log_prob(self, value):
        return self.single_dist.log_prob(value[0])


class ReversedChainDistribution(torch.distributions.Distribution):
    def __init__(self, chain_dist):
        self.chain_dist = chain_dist

    def sample(self, sample_shape=torch.Size()):
        return tuple(reversed(self.chain_dist.sample(
            sample_shape=sample_shape)))

    def rsample(self, sample_shape=torch.Size()):
        return tuple(reversed(self.chain_dist.rsample(
            sample_shape=sample_shape)))

    def log_prob(self, value):
        return self.chain_dist.log_prob(tuple(reversed(value)))


def get_total_log_weight(model, args, S):
    with torch.no_grad():
        log_weight = []
        for obs in args.train_data_loader:
            model.set_internals(obs, S)
            elbo = model.elbo()
            log_weight.append(elbo)

        log_weight = torch.cat(log_weight)

    return log_weight

def get_total_log_weight_joint_guide(model, args, S):
    with torch.no_grad():
        log_weight = []
        log_joint = []
        log_guide = []

        for obs in args.train_data_loader:
            model.set_internals(obs, S)
            elbo = model.elbo()
            pp = model.log_joint()
            qq = model.log_guide()
            log_weight.append(elbo)
            log_joint.append(pp)
            log_guide.append(qq)

        log_weight = torch.cat(log_weight)
        log_joint = torch.cat(log_joint)
        log_guide = torch.cat(log_guide)

    return log_weight,log_joint,log_guide

def compute_tvo_reparam_loss(log_weight, log_p, log_q, args, return_full = False, amci = False):
    num_particles = args.S


    log_weight = log_weight.unsqueeze(-1) if len(log_weight.shape)<3 else log_weight
    if args.iw_resample:
        log_weight, log_p, log_q, heated_normalized_weight, zb = iw_resampler(log_weight, log_p, log_q, args)

    snis_logw, thermo_logp, snis_detach = get_tvo_components(log_weight, log_p, log_q, args, \
                                            heated_normalized_weight= heated_normalized_weight if args.iw_resample else None)


    beta_one_minus = args.partition*(1-args.partition)
    one_minus_two_beta =  torch.ones_like(args.partition)-2*args.partition

    tvo_reparam = beta_one_minus.squeeze()*torch.sum(snis_detach* \
        (log_weight.detach() - torch.sum(snis_logw, dim=1,keepdim=True).detach()) \
            * (log_weight - torch.sum(snis_detach*log_weight, dim=1,keepdim=True)), dim=1) \
                + one_minus_two_beta.squeeze() * torch.sum(snis_detach*log_weight, dim=1)

    if return_full:
        return -tvo_reparam
    else:
        multiplier = _get_multiplier(args.partition, args.integration).squeeze()
        return -torch.mean(torch.sum(multiplier*tvo_reparam, dim=1), dim=0)

def get_tvo_components(log_weight, log_p, log_q, args, heated_normalized_weight = None):

    partition = args.partition
    num_particles = args.S
    integration = args.integration

    # feed heated_normalized_weight when doing importance resampling (due to uniform expectations at selected indices)
    if heated_normalized_weight is None:

        heated_log_weight = log_weight * partition
        heated_normalized_weight = exponentiate_and_normalize(
            heated_log_weight, dim=1)

    log_p = log_p.unsqueeze(-1) if len(log_p.shape)<3 else log_p
    log_q = log_q.unsqueeze(-1) if len(log_q.shape)<3 else log_q
    thermo_logp = partition * log_p + \
            (1 - partition) * log_q

    snis_logw = heated_normalized_weight * log_weight
    snis_detach = heated_normalized_weight.detach()

    return snis_logw, thermo_logp, snis_detach

Output:
{
    "experimental_code": "File Path: src/BOv.py---class BayesOpt:    def __init__(self, func, SearchSpace, GPtype=\"timevarying_perm\",verbose=1):        self.SearchSpace=SearchSpace        self.dim = SearchSpace.shape[0]        scaler = MinMaxScaler()        scaler.fit(SearchSpace.T)        self.Xscaler=scaler        self.scaleSearchSpace=np.array([np.zeros(self.dim), np.ones(self.dim)]).T        self.f = func        self.X_ori= None        self.X = None        self.Y = None        self.Y_ori = None        self.time_opt=0        if \"timevarying_perm\" in GPtype:            self.gp=GPTV_Perm(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        elif GPtype==\"vanillaGP\":            self.gp=GaussianProcess(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        else:            self.gp=GPTV(self.scaleSearchSpace,noise_delta=1e-3,verbose=1)        self.acq_func = None        self.logmarginal=0    def init_with_data(self, init_X,init_Y,isPermutation=False):        init_Y=(init_Y-np.mean(init_Y))/np.std(init_Y)        idx1=np.where( init_Y<=3)[0]        init_Y=init_Y[idx1]        init_X=init_X[idx1]        idx=np.where( init_Y>=-3)[0]        init_X=init_X[idx]        init_Y=init_Y[idx]        self.Y_ori = np.asarray(init_Y)        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)        self.X_ori=np.asarray(init_X)        self.X = self.Xscaler.transform(init_X)    def gp_ucb(self,xTest):        xTest=np.reshape(xTest,(-1,self.dim))        mean, var,_,_ = self.gp.predict(xTest)        var.flags['WRITEABLE']=True        var[var<1e-10]=0        mean=np.atleast_2d(mean).T        var=np.atleast_2d(var).T        beta_t =np.log(len(self.gp.Y))        return mean + np.sqrt(beta_t) * np.sqrt(var)    def select_next_point(self):        self.Y=np.reshape(self.Y,(-1,1))        self.gp.fit(self.X, self.Y)        start_opt=time.time()        x_max = self.acq_max_scipy(ac=self.gp_ucb)        x_max_ori=self.Xscaler.inverse_transform(np.reshape(x_max,(-1,self.dim)))        if self.f is None:            return x_max,x_max_ori        finished_opt=time.time()        elapse_opt=finished_opt-start_opt        self.time_opt=np.hstack((self.time_opt,elapse_opt))        self.X = np.vstack((self.X, x_max.reshape((1, -1))))        self.X_ori=np.vstack((self.X_ori, x_max_ori))        self.Y_ori = np.append(self.Y_ori, self.f(x_max_ori))        self.Y=(self.Y_ori-np.mean(self.Y_ori))/np.std(self.Y_ori)        return x_max,x_max_ori    def acq_max_scipy(self,ac):        x_max = self.scaleSearchSpace[:, 0]        max_acq = None        myopts ={'maxiter':50*self.dim,'maxfun':50*self.dim}        for i in range(3*self.dim):            x_tries = np.random.uniform(self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1],size=(10*self.dim, self.dim))            y_tries=ac(x_tries)            x_init_max=x_tries[np.argmax(y_tries)]            res = minimize(lambda x: -ac(x.reshape(1, -1)),x_init_max.reshape(1, -1),                   bounds=self.scaleSearchSpace,method=\"L-BFGS-B\",options=myopts)            val=ac(res.x)            if max_acq is None or val >= max_acq:                if 'x' not in res:                    x_max = res                else:                    x_max = res.x                max_acq = val        return np.clip(x_max, self.scaleSearchSpace[:, 0], self.scaleSearchSpace[:, 1])\nFile Path: src/gaussianprocess/gptv.py---class GPTV(object):    def cov_RBF_time(self,x1,x2,hyper):        variance=hyper['var']        lengthscale=hyper['lengthscale']        eps=hyper['epsilon']        if x1.shape[1]!=x2.shape[1]:            x1=np.reshape(x1,(-1,x2.shape[1]))        Euc_dist=euclidean_distances(x1,x2)        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)        if x1.shape[0]==1:            time_vector1=np.asarray([1])        else:            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)            time_vector1=time_vector1/(x1.shape[0]+1)            time_vector1=time_vector1[:-1]        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)        time_vector2=time_vector2/(x1.shape[0]+1)        time_vector2=time_vector2[:-1]        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')        timekernel=(1-eps)**(0.5*dists)        output=RBF*timekernel        return output\nFile Path: src/gaussianprocess/gptv_perm.py---class GPTV_Perm(GPTV):    def cov_RBF_time_set(self,x1,x2,hyper):        variance=hyper['var']        lengthscale=hyper['lengthscale']        eps=hyper['epsilon']        if x1.shape[1]!=x2.shape[1]:            x1=np.reshape(x1,(-1,x2.shape[1]))        x1=np.sort(x1,axis=1)        x2=np.sort(x2,axis=1)        Euc_dist=euclidean_distances(x1,x2)        RBF=variance*np.exp(-np.square(Euc_dist)/lengthscale)        if x1.shape[0]==1:            time_vector1=np.asarray([1])        else:            time_vector1=np.linspace(0,x1.shape[0],x1.shape[0]+1)            time_vector1=time_vector1/(x1.shape[0]+1)            time_vector1=time_vector1[:-1]        time_vector1=np.reshape(time_vector1,(x1.shape[0],1))        time_vector2=np.linspace(0,x2.shape[0],x2.shape[0]+1)        time_vector2=time_vector2/(x1.shape[0]+1)        time_vector2=time_vector2[:-1]        time_vector2=np.reshape(time_vector2,(x2.shape[0],1))        dists = pairwise_distances(time_vector1,time_vector2, 'cityblock')        timekernel=(1-eps)**(0.5*dists)        output=RBF*timekernel        return output\nFile Path: src/gp_bandit.py---def append_Xori_Yori_from_args(args):    if args.len_terminated_epoch >0:        average_y=np.mean(args.logtvopx_all[-args.len_terminated_epoch:])    else:        average_y=np.mean(args.logtvopx_all[-args.schedule_update_frequency:])    args.average_y=np.append(args.average_y,average_y)    if len(args.average_y)==1:        print(\"ignore for the first time to save the first value of Y\")        return    prev_y=args.average_y[-1] -args.average_y[-2]    args.X_ori=np.vstack(( args.X_ori, np.reshape(format_input(args.partition),(1,args.K+1) )))    args.Y_ori=np.append(args.Y_ori, prev_y)    prev_X=np.round(args.X_ori[-1],decimals=4)\ndef calculate_BO_points(model,args):    append_Xori_Yori_from_args(args)    SearchSpace=np.asarray([args.bandit_beta_min,args.bandit_beta_max]*(args.K-1)).astype(float)    SearchSpace=np.reshape(SearchSpace,(args.K-1,2))    if args.K==2:        SearchSpace[0,1]=0.7    else:        ll=np.linspace(0,args.bandit_beta_max,args.K)        for kk in range(args.K-1):            SearchSpace[kk,1]=ll[kk+1]    if args.schedule==\"gp\":        X,Y=extract_X_Y_from_args(SearchSpace,args,T=len(args.Y_ori))    else:        X,Y=extract_X_Y_from_args(SearchSpace,args)    if Y is None:        return X    x_all_zeros=np.reshape(np.asarray([args.bandit_beta_min]*(args.K-1)),(1,-1))    x_all_ones=np.reshape(np.asarray([args.bandit_beta_max]*(args.K-1)),(1,-1))    worse_score=np.min(Y)    X=np.vstack((X,x_all_zeros))    X=np.vstack((X,x_all_ones))    Y=np.vstack((Y,np.asarray(worse_score)))    Y=np.vstack((Y,np.asarray(worse_score)))    if args.schedule==\"gp_bandit\":        myBO=BayesOpt(func=None,SearchSpace=SearchSpace)    elif args.schedule==\"gptv\" or args.schedule==\"gp\":        myBO=BayesOpt(func=None,SearchSpace=SearchSpace,GPtype=\"vanillaGP\")    else:        print(\"the schedule is not implemented \",args.schedule)    myBO.init_with_data(X,Y)    new_X=myBO.select_next_point()[1]    new_X=np.round(new_X,decimals=4)    new_X = np.append(np.append(0,np.sort(new_X)), 1)    temp_new_X=np.unique(new_X)    if np.array_equal(temp_new_X, [0, args.bandit_beta_min, 1]) or         np.array_equal(temp_new_X, [0, 1]) :        rand_X = np.random.uniform(SearchSpace[:, 0], SearchSpace[:, 1],size=(1,args.K-1))        return np.append(np.append(0,np.sort(rand_X)), 1)    else:        return new_X\nFile Path: src/models/updates.py---def GP_bandits(model, args):    points = gp_bandit.calculate_BO_points(model, args)    K=len(points)    points=mlh.tensor(points,args)    print(\"==================================\")    print(\"K={} points={}\".format(K,points))    print(\"==================================\")    return points",
    "experimental_info": "The experiments use the Thermodynamic Variational Objective (TVO) loss. The choice of integration points (beta, a d-dimensional vector) for TVO is framed as a time-varying Gaussian Process (GP) bandit optimization problem. The GP model used is time-varying and permutation-invariant. The reward function for the bandit is defined as the difference in TVO log evidence estimates between training windows, maximizing the final log evidence. An acquisition function (GP-UCB variant) balances exploration and exploitation. Ordering constraints (0 < beta1 < ... < betad-1 < 1) are maintained by sorting the beta vector. Hyperparameters for the GP bandit scheduling include:\n- `schedule`: 'gp_bandit'\n- `K`: 5 (number of internal integration points, so d=K+1 total points including 0 and 1)\n- `S`: 10 (number of samples for MC estimates)\n- `burn_in`: 20 epochs before scheduling begins\n- `schedule_update_frequency`: 6 epochs (how often the schedule is updated)\n- `bandit_beta_min`: 0.05 (lower bound for beta search space)\n- `bandit_beta_max`: 0.95 (upper bound for beta search space)\n- `truncation_threshold`: 30*K (for truncating historical data in time-varying settings)\n- `increment_update_frequency`: 10 (frequency for increasing schedule_update_frequency if conditions are met)\n- `drip_threshold`: -0.05 (threshold to terminate a chosen beta early if logpx drops significantly)\n\nThe datasets used can be variants of MNIST, such as 'tiny_mnist' or 'mnist'."
}
