@misc{airas2025,
  author    = {Toma Tanaka and Takumi Matsuzawa and Yuki Yoshino and Ilya Horiguchi and Shiro Takagi and Ryutaro Yamauchi and Wataru Kumagai},
  title     = {{AIRAS}},
  year      = {2025},
  publisher = {GitHub},
  url       = {https://github.com/airas-org/airas}
}

% ===========================================
% REQUIRED CITATIONS
% These papers must be cited in the manuscript
% ===========================================

@article{aitchison-2018-bayesian,
 abstract = {We formulate the problem of neural network optimization as Bayesian
filtering, where the observations are the backpropagated gradients. While
neural network optimization has previously been studied using natural gradient
methods which are closely related to Bayesian inference, they were unable to
recover standard optimizers such as Adam and RMSprop with a root-mean-square
gradient normalizer, instead getting a mean-square normalizer. To recover the
root-mean-square normalizer, we find it necessary to account for the temporal
dynamics of all the other parameters as they are geing optimized. The resulting
optimizer, AdaBayes, adaptively transitions between SGD-like and Adam-like
behaviour, automatically recovers AdamW, a state of the art variant of Adam
with decoupled weight decay, and has generalisation performance competitive
with SGD.},
 arxiv_url = {https://arxiv.org/pdf/1807.07540v5.pdf},
 author = {Laurence Aitchison},
 title = { Bayesian filtering unifies adaptive and non-adaptive neural network optimization methods },
 year = {2018}
}

@article{alfarra-2023-evaluation,
 abstract = {This paper proposes a novel online evaluation protocol for Test Time
Adaptation (TTA) methods, which penalizes slower methods by providing them with
fewer samples for adaptation. TTA methods leverage unlabeled data at test time
to adapt to distribution shifts. Although many effective methods have been
proposed, their impressive performance usually comes at the cost of
significantly increased computation budgets. Current evaluation protocols
overlook the effect of this extra computation cost, affecting their real-world
applicability. To address this issue, we propose a more realistic evaluation
protocol for TTA methods, where data is received in an online fashion from a
constant-speed data stream, thereby accounting for the method's adaptation
speed. We apply our proposed protocol to benchmark several TTA methods on
multiple datasets and scenarios. Extensive experiments show that, when
accounting for inference speed, simple and fast approaches can outperform more
sophisticated but slower methods. For example, SHOT from 2020, outperforms the
state-of-the-art method SAR from 2023 in this setting. Our results reveal the
importance of developing practical TTA methods that are both accurate and
efficient.},
 arxiv_url = {https://arxiv.org/pdf/2304.04795v2.pdf},
 author = {Motasem Alfarra and Hani Itani and Alejandro Pardo and Shyma Alhuwaider and Merey Ramazanova and Juan C. Pérez and Zhipeng Cai and Matthias Müller and Bernard Ghanem},
 title = {Evaluation of Test-Time Adaptation Under Computational Time Constraints},
 year = {2023}
}

@article{anagnostidis-2023-navigating,
 abstract = {In recent years, the state-of-the-art in deep learning has been dominated by
very large models that have been pre-trained on vast amounts of data. The
paradigm is very simple: investing more computational resources (optimally)
leads to better performance, and even predictably so; neural scaling laws have
been derived that accurately forecast the performance of a network for a
desired level of compute. This leads to the notion of a `compute-optimal'
model, i.e. a model that allocates a given level of compute during training
optimally to maximize performance. In this work, we extend the concept of
optimality by allowing for an `adaptive' model, i.e. a model that can change
its shape during training. By doing so, we can design adaptive models that
optimally traverse between the underlying scaling laws and outpace their
`static' counterparts, leading to a significant reduction in the required
compute to reach a given target performance. We show that our approach
generalizes across modalities and different shape parameters.},
 arxiv_url = {https://arxiv.org/pdf/2311.03233v3.pdf},
 author = {Sotiris Anagnostidis and Gregor Bachmann and Imanol Schlag and Thomas Hofmann},
 title = {Navigating Scaling Laws: Compute Optimality in Adaptive Model Training},
 year = {2023}
}

@article{author-year-adatune,
 title = {AdaTune: Adaptive Tensor Program Compilation Made Efficient}
}

@article{author-year-anyda,
 title = {AnyDA: Anytime Domain Adaptation}
}

@article{author-year-extrapolative,
 title = {Extrapolative Continuous-time Bayesian Neural Network for Fast Training-free Test-time Adaptation}
}

@article{author-year-learning,
 title = {Learning to Adapt to Evolving Domains}
}

@article{author-year-leveraging,
 title = {Leveraging Proxy of Training Data for Test-Time Adaptation}
}

@article{author-year-post,
 title = {Post-hoc estimators for learning to defer to an expert}
}

@article{author-year-stationary,
 title = {Stationary Latent Weight Inference for Unreliable Observations from Online Test-Time Adaptation}
}

@article{author-year-test,
 title = {Test Time Adaptation With Regularized Loss for Weakly Supervised Salient Object Detection}
}

@article{author-year-ttt,
 title = {TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?}
}

@article{chen-2023-improved,
 abstract = {The main challenge in domain generalization (DG) is to handle the
distribution shift problem that lies between the training and test data. Recent
studies suggest that test-time training (TTT), which adapts the learned model
with test data, might be a promising solution to the problem. Generally, a TTT
strategy hinges its performance on two main factors: selecting an appropriate
auxiliary TTT task for updating and identifying reliable parameters to update
during the test phase. Both previous arts and our experiments indicate that TTT
may not improve but be detrimental to the learned model if those two factors
are not properly considered. This work addresses those two factors by proposing
an Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically
defining an auxiliary objective, we propose a learnable consistency loss for
the TTT task, which contains learnable parameters that can be adjusted toward
better alignment between our TTT task and the main prediction task. Second, we
introduce additional adaptive parameters for the trained model, and we suggest
only updating the adaptive parameters during the test phase. Through extensive
experiments, we show that the proposed two strategies are beneficial for the
learned model (see Figure 1), and ITTA could achieve superior performance to
the current state-of-the-art methods on several DG benchmarks. Code is
available at https://github.com/liangchen527/ITTA.},
 arxiv_url = {https://arxiv.org/pdf/2304.04494v2.pdf},
 author = {Liang Chen and Yong Zhang and Yibing Song and Ying Shan and Lingqiao Liu},
 github_url = {https://github.com/liangchen527/ITTA},
 title = {Improved Test-Time Adaptation for Domain Generalization},
 year = {2023}
}

@article{chriefabdellatif-2019-convergence,
 abstract = {Variational inference is becoming more and more popular for approximating
intractable posterior distributions in Bayesian statistics and machine
learning. Meanwhile, a few recent works have provided theoretical justification
and new insights on deep neural networks for estimating smooth functions in
usual settings such as nonparametric regression. In this paper, we show that
variational inference for sparse deep learning retains the same generalization
properties than exact Bayesian inference. In particular, we highlight the
connection between estimation and approximation theories via the classical
bias-variance trade-off and show that it leads to near-minimax rates of
convergence for H\"older smooth functions. Additionally, we show that the model
selection framework over the neural network architecture via ELBO maximization
does not overfit and adaptively achieves the optimal rate of convergence.},
 arxiv_url = {https://arxiv.org/pdf/1908.04847v2.pdf},
 author = {Badr-Eddine Chérief-Abdellatif},
 title = {Convergence Rates of Variational Inference in Sparse Deep Learning},
 year = {2019}
}

@article{goyal-2022-test,
 abstract = {Test-time adaptation (TTA) refers to adapting neural networks to distribution
shifts, with access to only the unlabeled test samples from the new domain at
test-time. Prior TTA methods optimize over unsupervised objectives such as the
entropy of model predictions in TENT [Wang et al., 2021], but it is unclear
what exactly makes a good TTA loss. In this paper, we start by presenting a
surprising phenomenon: if we attempt to meta-learn the best possible TTA loss
over a wide class of functions, then we recover a function that is remarkably
similar to (a temperature-scaled version of) the softmax-entropy employed by
TENT. This only holds, however, if the classifier we are adapting is trained
via cross-entropy; if trained via squared loss, a different best TTA loss
emerges. To explain this phenomenon, we analyze TTA through the lens of the
training losses's convex conjugate. We show that under natural conditions, this
(unsupervised) conjugate function can be viewed as a good local approximation
to the original supervised loss and indeed, it recovers the best losses found
by meta-learning. This leads to a generic recipe that can be used to find a
good TTA loss for any given supervised training loss function of a general
class. Empirically, our approach consistently dominates other baselines over a
wide range of benchmarks. Our approach is particularly of interest when applied
to classifiers trained with novel loss functions, e.g., the recently-proposed
PolyLoss, where it differs substantially from (and outperforms) an
entropy-based loss. Further, we show that our approach can also be interpreted
as a kind of self-training using a very specific soft label, which we refer to
as the conjugate pseudolabel. Overall, our method provides a broad framework
for better understanding and improving test-time adaptation. Code is available
at https://github.com/locuslab/tta_conjugate.},
 arxiv_url = {https://arxiv.org/pdf/2207.09640v2.pdf},
 author = {Sachin Goyal and Mingjie Sun and Aditi Raghunathan and Zico Kolter},
 title = {Test Time Adaptation via Conjugate Pseudo-labels},
 year = {2022}
}

@article{gui-2024-active,
 abstract = {Test-time adaptation (TTA) addresses distribution shifts for streaming test
data in unsupervised settings. Currently, most TTA methods can only deal with
minor shifts and rely heavily on heuristic and empirical studies.
  To advance TTA under domain shifts, we propose the novel problem setting of
active test-time adaptation (ATTA) that integrates active learning within the
fully TTA setting.
  We provide a learning theory analysis, demonstrating that incorporating
limited labeled test instances enhances overall performances across test
domains with a theoretical guarantee. We also present a sample entropy
balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We
introduce a simple yet effective ATTA algorithm, known as SimATTA, using
real-time sample selection techniques. Extensive experimental results confirm
consistency with our theoretical analyses and show that the proposed ATTA
method yields substantial performance improvements over TTA methods while
maintaining efficiency and shares similar effectiveness to the more demanding
active domain adaptation (ADA) methods. Our code is available at
https://github.com/divelab/ATTA},
 arxiv_url = {https://arxiv.org/pdf/2404.05094v1.pdf},
 author = {Shurui Gui and Xiner Li and Shuiwang Ji},
 github_url = {https://github.com/divelab/ATTA},
 title = {Active Test-Time Adaptation: Theoretical Analyses and An Algorithm},
 year = {2024}
}

@article{hoang-2023-persistent,
 abstract = {Current test-time adaptation (TTA) approaches aim to adapt a machine learning
model to environments that change continuously. Yet, it is unclear whether TTA
methods can maintain their adaptability over prolonged periods. To answer this
question, we introduce a diagnostic setting - recurring TTA where environments
not only change but also recur over time, creating an extensive data stream.
This setting allows us to examine the error accumulation of TTA models, in the
most basic scenario, when they are regularly exposed to previous testing
environments. Furthermore, we simulate a TTA process on a simple yet
representative $\epsilon$-perturbed Gaussian Mixture Model Classifier, deriving
theoretical insights into the dataset- and algorithm-dependent factors
contributing to gradual performance degradation. Our investigation leads us to
propose persistent TTA (PeTTA), which senses when the model is diverging
towards collapse and adjusts the adaptation strategy, striking a balance
between the dual objectives of adaptation and model collapse prevention. The
supreme stability of PeTTA over existing approaches, in the face of lifelong
TTA scenarios, has been demonstrated over comprehensive experiments on various
benchmarks. Our project page is available at https://hthieu166.github.io/petta.},
 arxiv_url = {https://arxiv.org/pdf/2311.18193v4.pdf},
 author = {Trung-Hieu Hoang and Duc Minh Vo and Minh N. Do},
 github_url = {https://github.com/BIT-DA/RoTTA},
 title = {Persistent Test-time Adaptation in Recurring Testing Scenarios},
 year = {2023}
}

@article{kwon-2021-repurposing,
 abstract = {Model-agnostic meta-learning (MAML) is a popular method for few-shot learning
but assumes that we have access to the meta-training set. In practice, training
on the meta-training set may not always be an option due to data privacy
concerns, intellectual property issues, or merely lack of computing resources.
In this paper, we consider the novel problem of repurposing pretrained MAML
checkpoints to solve new few-shot classification tasks. Because of the
potential distribution mismatch, the original MAML steps may no longer be
optimal. Therefore we propose an alternative meta-testing procedure and combine
MAML gradient steps with adversarial training and uncertainty-based stepsize
adaptation. Our method outperforms "vanilla" MAML on same-domain and
cross-domains benchmarks using both SGD and Adam optimizers and shows improved
robustness to the choice of base stepsize.},
 arxiv_url = {https://arxiv.org/pdf/2103.09027v1.pdf},
 author = {Namyeong Kwon and Hwidong Na and Gabriel Huang and Simon Lacoste-Julien},
 title = {Repurposing Pretrained Models for Robust Out-of-domain Few-Shot Learning},
 year = {2021}
}

@article{lim-2023-ttn,
 abstract = {This paper proposes a novel batch normalization strategy for test-time
adaptation. Recent test-time adaptation methods heavily rely on the modified
batch normalization, i.e., transductive batch normalization (TBN), which
calculates the mean and the variance from the current test batch rather than
using the running mean and variance obtained from the source data, i.e.,
conventional batch normalization (CBN). Adopting TBN that employs test batch
statistics mitigates the performance degradation caused by the domain shift.
However, re-estimating normalization statistics using test data depends on
impractical assumptions that a test batch should be large enough and be drawn
from i.i.d. stream, and we observed that the previous methods with TBN show
critical performance drop without the assumptions. In this paper, we identify
that CBN and TBN are in a trade-off relationship and present a new test-time
normalization (TTN) method that interpolates the statistics by adjusting the
importance between CBN and TBN according to the domain-shift sensitivity of
each BN layer. Our proposed TTN improves model robustness to shifted domains
across a wide range of batch sizes and in various realistic evaluation
scenarios. TTN is widely applicable to other test-time adaptation methods that
rely on updating model parameters via backpropagation. We demonstrate that
adopting TTN further improves their performance and achieves state-of-the-art
performance in various standard benchmarks.},
 arxiv_url = {https://arxiv.org/pdf/2302.05155v2.pdf},
 author = {Hyesu Lim and Byeonggeun Kim and Jaegul Choo and Sungha Choi},
 title = {TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation},
 year = {2023}
}

@article{nguyen-2020-gaussian,
 abstract = {Achieving the full promise of the Thermodynamic Variational Objective (TVO),
a recently proposed variational lower bound on the log evidence involving a
one-dimensional Riemann integral approximation, requires choosing a "schedule"
of sorted discretization points. This paper introduces a bespoke Gaussian
process bandit optimization method for automatically choosing these points. Our
approach not only automates their one-time selection, but also dynamically
adapts their positions over the course of optimization, leading to improved
model learning and inference. We provide theoretical guarantees that our bandit
optimization converges to the regret-minimizing choice of integration points.
Empirical validation of our algorithm is provided in terms of improved learning
and inference in Variational Autoencoders and Sigmoid Belief Networks.},
 arxiv_url = {https://arxiv.org/pdf/2010.15750v3.pdf},
 author = {Vu Nguyen and Vaden Masrani and Rob Brekelmans and Michael A. Osborne and Frank Wood},
 github_url = {https://github.com/ntienvu/tvo_gp_bandit},
 title = {Gaussian Process Bandit Optimization of the Thermodynamic Variational Objective},
 year = {2020}
}

@article{niu-2023-towards,
 abstract = {Test-time adaptation (TTA) has shown to be effective at tackling distribution
shifts between training and testing data by adapting a given model on test
samples. However, the online model updating of TTA may be unstable and this is
often a key obstacle preventing existing TTA methods from being deployed in the
real world. Specifically, TTA may fail to improve or even harm the model
performance when test data have: 1) mixed distribution shifts, 2) small batch
sizes, and 3) online imbalanced label distribution shifts, which are quite
common in practice. In this paper, we investigate the unstable reasons and find
that the batch norm layer is a crucial factor hindering TTA stability.
Conversely, TTA can perform more stably with batch-agnostic norm layers, \ie,
group or layer norm. However, we observe that TTA with group and layer norms
does not always succeed and still suffers many failure cases. By digging into
the failure cases, we find that certain noisy test samples with large gradients
may disturb the model adaption and result in collapsed trivial solutions, \ie,
assigning the same class label for all samples. To address the above collapse
issue, we propose a sharpness-aware and reliable entropy minimization method,
called SAR, for further stabilizing TTA from two aspects: 1) remove partial
noisy samples with large gradients, 2) encourage model weights to go to a flat
minimum so that the model is robust to the remaining noisy samples. Promising
results demonstrate that SAR performs more stably over prior methods and is
computationally efficient under the above wild test scenarios.},
 arxiv_url = {https://arxiv.org/pdf/2302.12400v1.pdf},
 author = {Shuaicheng Niu and Jiaxiang Wu and Yifan Zhang and Zhiquan Wen and Yaofo Chen and Peilin Zhao and Mingkui Tan},
 title = {Towards Stable Test-time Adaptation in Dynamic Wild World},
 year = {2023}
}

@article{park-2024-test,
 abstract = {It is common to observe performance degradation when transferring models
trained on some (source) datasets to target testing data due to a domain gap
between them. Existing methods for bridging this gap, such as domain adaptation
(DA), may require the source data on which the model was trained (often not
available), while others, i.e., source-free DA, require many passes through the
testing data. We propose an online test-time adaptation method for depth
completion, the task of inferring a dense depth map from a single image and
associated sparse depth map, that closes the performance gap in a single pass.
We first present a study on how the domain shift in each data modality affects
model performance. Based on our observations that the sparse depth modality
exhibits a much smaller covariate shift than the image, we design an embedding
module trained in the source domain that preserves a mapping from features
encoding only sparse depth to those encoding image and sparse depth. During
test time, sparse depth features are projected using this map as a proxy for
source domain features and are used as guidance to train a set of auxiliary
parameters (i.e., adaptation layer) to align image and sparse depth features
from the target test domain to that of the source domain. We evaluate our
method on indoor and outdoor scenarios and show that it improves over baselines
by an average of 21.1%.},
 arxiv_url = {https://arxiv.org/pdf/2402.03312v4.pdf},
 author = {Hyoungseob Park and Anjali Gupta and Alex Wong},
 title = {Test-Time Adaptation for Depth Completion},
 year = {2024}
}

@article{song-2023-ecotta,
 abstract = {This paper presents a simple yet effective approach that improves continual
test-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be
conducted on edge devices with limited memory, so reducing memory is crucial
but has been overlooked in previous TTA studies. In addition, long-term
adaptation often leads to catastrophic forgetting and error accumulation, which
hinders applying TTA in real-world deployments. Our approach consists of two
components to address these issues. First, we present lightweight meta networks
that can adapt the frozen original networks to the target domain. This novel
architecture minimizes memory consumption by decreasing the size of
intermediate activations required for backpropagation. Second, our novel
self-distilled regularization controls the output of the meta networks not to
deviate significantly from the output of the frozen original networks, thereby
preserving well-trained knowledge from the source domain. Without additional
memory, this regularization prevents error accumulation and catastrophic
forgetting, resulting in stable performance even in long-term test-time
adaptation. We demonstrate that our simple yet effective strategy outperforms
other state-of-the-art methods on various benchmarks for image classification
and semantic segmentation tasks. Notably, our proposed method with ResNet-50
and WideResNet-40 takes 86% and 80% less memory than the recent
state-of-the-art method, CoTTA.},
 arxiv_url = {https://arxiv.org/pdf/2303.01904v4.pdf},
 author = {Junha Song and Jungsoo Lee and In So Kweon and Sungha Choi},
 github_url = {https://github.com/qinenergy/cotta},
 title = {EcoTTA: Memory-Efficient Continual Test-Time Adaptation via Self-Distilled Regularization},
 year = {2023}
}

@article{sun-2019-test,
 abstract = {In this paper, we propose Test-Time Training, a general approach for
improving the performance of predictive models when training and test data come
from different distributions. We turn a single unlabeled test sample into a
self-supervised learning problem, on which we update the model parameters
before making a prediction. This also extends naturally to data in an online
stream. Our simple approach leads to improvements on diverse image
classification benchmarks aimed at evaluating robustness to distribution
shifts.},
 arxiv_url = {https://arxiv.org/pdf/1909.13231v3.pdf},
 author = {Yu Sun and Xiaolong Wang and Zhuang Liu and John Miller and Alexei A. Efros and Moritz Hardt},
 title = {Test-Time Training with Self-Supervision for Generalization under Distribution Shifts},
 year = {2019}
}

@article{taskesen-2021-sequential,
 abstract = {Least squares estimators, when trained on a few target domain samples, may
predict poorly. Supervised domain adaptation aims to improve the predictive
accuracy by exploiting additional labeled training samples from a source
distribution that is close to the target distribution. Given available data, we
investigate novel strategies to synthesize a family of least squares estimator
experts that are robust with regard to moment conditions. When these moment
conditions are specified using Kullback-Leibler or Wasserstein-type
divergences, we can find the robust estimators efficiently using convex
optimization. We use the Bernstein online aggregation algorithm on the proposed
family of robust experts to generate predictions for the sequential stream of
target test samples. Numerical experiments on real data show that the robust
strategies may outperform non-robust interpolations of the empirical least
squares estimators.},
 arxiv_url = {https://arxiv.org/pdf/2106.00322v1.pdf},
 author = {Bahar Taskesen and Man-Chung Yue and Jose Blanchet and Daniel Kuhn and Viet Anh Nguyen},
 title = {Sequential Domain Adaptation by Synthesizing Distributionally Robust Experts},
 year = {2021}
}

@article{wang-2020-tent,
 abstract = {A model must adapt itself to generalize to new and different data during
testing. In this setting of fully test-time adaptation the model has only the
test data and its own parameters. We propose to adapt by test entropy
minimization (tent): we optimize the model for confidence as measured by the
entropy of its predictions. Our method estimates normalization statistics and
optimizes channel-wise affine transformations to update online on each batch.
Tent reduces generalization error for image classification on corrupted
ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on
ImageNet-C. Tent handles source-free domain adaptation on digit recognition
from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to
Cityscapes, and on the VisDA-C benchmark. These results are achieved in one
epoch of test-time optimization without altering training.},
 arxiv_url = {https://arxiv.org/pdf/2006.10726v3.pdf},
 author = {Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell},
 github_url = {https://github.com/DequanWang/tent},
 title = {Tent: Fully Test-Time Adaptation by Entropy Minimization},
 year = {2020}
}

@article{yoo-2023-what,
 abstract = {It is a well-known fact that the performance of deep learning models
deteriorates when they encounter a distribution shift at test time. Test-time
adaptation (TTA) algorithms have been proposed to adapt the model online while
inferring test data. However, existing research predominantly focuses on
classification tasks through the optimization of batch normalization layers or
classification heads, but this approach limits its applicability to various
model architectures like Transformers and makes it challenging to apply to
other tasks, such as object detection. In this paper, we propose a novel online
adaption approach for object detection in continually changing test domains,
considering which part of the model to update, how to update it, and when to
perform the update. By introducing architecture-agnostic and lightweight
adaptor modules and only updating these while leaving the pre-trained backbone
unchanged, we can rapidly adapt to new test domains in an efficient way and
prevent catastrophic forgetting. Furthermore, we present a practical and
straightforward class-wise feature aligning method for object detection to
resolve domain shifts. Additionally, we enhance efficiency by determining when
the model is sufficiently adapted or when additional adaptation is needed due
to changes in the test distribution. Our approach surpasses baselines on widely
used benchmarks, achieving improvements of up to 4.9\%p and 7.9\%p in mAP for
COCO $\rightarrow$ COCO-corrupted and SHIFT, respectively, while maintaining
about 20 FPS or higher.},
 arxiv_url = {https://arxiv.org/pdf/2312.08875v1.pdf},
 author = {Jayeon Yoo and Dongkwan Lee and Inseop Chung and Donghyun Kim and Nojun Kwak},
 title = {What How and When Should Object Detectors Update in Continually Changing Test Domains?},
 year = {2023}
}

@article{yuan-2023-robust,
 abstract = {Test-time adaptation (TTA) intends to adapt the pretrained model to test
distributions with only unlabeled test data streams. Most of the previous TTA
methods have achieved great success on simple test data streams such as
independently sampled data from single or multiple distributions. However,
these attempts may fail in dynamic scenarios of real-world applications like
autonomous driving, where the environments gradually change and the test data
is sampled correlatively over time. In this work, we explore such practical
test data streams to deploy the model on the fly, namely practical test-time
adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA)
method against the complex data stream in PTTA. More specifically, we present a
robust batch normalization scheme to estimate the normalization statistics.
Meanwhile, a memory bank is utilized to sample category-balanced data with
consideration of timeliness and uncertainty. Further, to stabilize the training
procedure, we develop a time-aware reweighting strategy with a teacher-student
model. Extensive experiments prove that RoTTA enables continual testtime
adaptation on the correlatively sampled data streams. Our method is easy to
implement, making it a good choice for rapid deployment. The code is publicly
available at https://github.com/BIT-DA/RoTTA},
 arxiv_url = {https://arxiv.org/pdf/2303.13899v1.pdf},
 author = {Longhui Yuan and Binhui Xie and Shuang Li},
 github_url = {https://github.com/BIT-DA/RoTTA},
 title = {Robust Test-Time Adaptation in Dynamic Scenarios},
 year = {2023}
}

@article{zhao-2023-delta,
 abstract = {Fully test-time adaptation aims at adapting a pre-trained model to the test
stream during real-time inference, which is urgently required when the test
distribution differs from the training distribution. Several efforts have been
devoted to improving adaptation performance. However, we find that two
unfavorable defects are concealed in the prevalent adaptation methodologies
like test-time batch normalization (BN) and self-learning. First, we reveal
that the normalization statistics in test-time BN are completely affected by
the currently received test samples, resulting in inaccurate estimates. Second,
we show that during test-time adaptation, the parameter update is biased
towards some dominant classes. In addition to the extensively studied test
stream with independent and class-balanced samples, we further observe that the
defects can be exacerbated in more complicated test environments, such as
(time) dependent or class-imbalanced data. We observe that previous approaches
work well in certain scenarios while show performance degradation in others due
to their faults. In this paper, we provide a plug-in solution called DELTA for
Degradation-freE fuLly Test-time Adaptation, which consists of two components:
(i) Test-time Batch Renormalization (TBR), introduced to improve the estimated
normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to
address the class bias within optimization. We investigate various test-time
adaptation methods on three commonly used datasets with four scenarios, and a
newly introduced real-world dataset. DELTA can help them deal with all
scenarios simultaneously, leading to SOTA performance.},
 arxiv_url = {https://arxiv.org/pdf/2301.13018v1.pdf},
 author = {Bowen Zhao and Chen Chen and Shu-Tao Xia},
 title = {DELTA: DEGRADATION-FREE FULLY TEST-TIME ADAPTATION},
 year = {2023}
}

@article{zrnic-2024-active,
 abstract = {Inspired by the concept of active learning, we propose active
inference$\unicode{x2013}$a methodology for statistical inference with
machine-learning-assisted data collection. Assuming a budget on the number of
labels that can be collected, the methodology uses a machine learning model to
identify which data points would be most beneficial to label, thus effectively
utilizing the budget. It operates on a simple yet powerful intuition:
prioritize the collection of labels for data points where the model exhibits
uncertainty, and rely on the model's predictions where it is confident. Active
inference constructs provably valid confidence intervals and hypothesis tests
while leveraging any black-box machine learning model and handling any data
distribution. The key point is that it achieves the same level of accuracy with
far fewer samples than existing baselines relying on non-adaptively-collected
data. This means that for the same number of collected samples, active
inference enables smaller confidence intervals and more powerful p-values. We
evaluate active inference on datasets from public opinion research, census
analysis, and proteomics.},
 arxiv_url = {https://arxiv.org/pdf/2403.03208v2.pdf},
 author = {Tijana Zrnic and Emmanuel J. Candès},
 github_url = {https://github.com/tijana-zrnic/active-inference},
 title = {Active Statistical Inference},
 year = {2024}
}

% ===========================================
% REFERENCE CANDIDATES
% Additional reference papers for context
% ===========================================

@article{recht-2018-cifar,
 abstract = {Machine learning is currently dominated by largely experimental work focused
on improvements in a few key tasks. However, the impressive accuracy numbers of
the best performing models are questionable because the same test sets have
been used to select these models for multiple years now. To understand the
danger of overfitting, we measure the accuracy of CIFAR-10 classifiers by
creating a new test set of truly unseen images. Although we ensure that the new
test set is as close to the original data distribution as possible, we find a
large drop in accuracy (4% to 10%) for a broad range of deep learning models.
Yet more recent models with higher original accuracy show a smaller drop and
better overall performance, indicating that this drop is likely not due to
overfitting based on adaptivity. Instead, we view our results as evidence that
current accuracy numbers are brittle and susceptible to even minute natural
variations in the data distribution.},
 arxiv_url = {https://arxiv.org/pdf/1806.00451v1.pdf},
 author = {Benjamin Recht and Rebecca Roelofs and Ludwig Schmidt and Vaishaal Shankar},
 title = {Do CIFAR-10 classifiers generalize to CIFAR-10?},
 year = {2018}
}